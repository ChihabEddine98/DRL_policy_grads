{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Preamble\n",
        "This is a full working google collab notebook for the DRL homework 2 (Policy Gradients)\n",
        "\n",
        "Group:\n",
        "Abdelkader Benamara | Mohamed Ali Benrekia | Aymen Djelid"
      ],
      "metadata": {
        "id": "06R69b8l_UDr"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gwo9bpaVgxXF"
      },
      "source": [
        "##Setup\n",
        "\n",
        "You will need to make a copy of this notebook in your Google Drive before you can edit the homework files. You can do so with **File &rarr; Save a copy in Drive**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6CAdiyTKi4Se",
        "outputId": "55d744f3-05f4-433a-b807-d137364a3e77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "#@title mount your Google Drive\n",
        "#@markdown Your work will be stored in a folder called `cs285_f2021` by default to prevent Colab instance timeouts from deleting your edits.\n",
        "\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "BKE5nA1Fgwwy"
      },
      "outputs": [],
      "source": [
        "#@title set up mount symlink\n",
        "\n",
        "DRIVE_PATH = '/content/gdrive/My\\ Drive/cs285_f2021'\n",
        "DRIVE_PYTHON_PATH = DRIVE_PATH.replace('\\\\', '')\n",
        "if not os.path.exists(DRIVE_PYTHON_PATH):\n",
        "  %mkdir $DRIVE_PATH\n",
        "\n",
        "## the space in `My Drive` causes some issues,\n",
        "## make a symlink to avoid this\n",
        "SYM_PATH = '/content/cs285_f2021'\n",
        "if not os.path.exists(SYM_PATH):\n",
        "  !ln -s $DRIVE_PATH $SYM_PATH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FGK4kbpg3iP",
        "outputId": "94e38a8b-5697-41f9-8055-2524ae2af542"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rGet:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "\u001b[33m\r0% [Connecting to archive.ubuntu.com (91.189.88.142)] [1 InRelease 14.2 kB/88.7\u001b[0m\r                                                                               \rGet:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Ign:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:5 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Ign:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [696 B]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:9 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n",
            "Hit:11 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Hit:13 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Get:14 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,557 kB]\n",
            "Get:15 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,466 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu bionic-security/multiverse amd64 Packages [21.1 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [781 kB]\n",
            "Get:19 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,825 kB]\n",
            "Get:21 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [917 kB]\n",
            "Get:22 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [935 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [29.1 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,244 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,995 kB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [815 kB]\n",
            "Get:27 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [42.8 kB]\n",
            "Fetched 14.9 MB in 3s (4,302 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "62 packages can be upgraded. Run 'apt list --upgradable' to see them.\n"
          ]
        }
      ],
      "source": [
        "#@title apt install requirements\n",
        "\n",
        "#@markdown Run each section with Shift+Enter\n",
        "\n",
        "#@markdown Double-click on section headers to show code.\n",
        "\n",
        "!apt update \n",
        "!apt install -y --no-install-recommends \\\n",
        "        build-essential \\\n",
        "        curl \\\n",
        "        git \\\n",
        "        gnupg2 \\\n",
        "        make \\\n",
        "        cmake \\\n",
        "        ffmpeg \\\n",
        "        swig \\\n",
        "        libz-dev \\\n",
        "        unzip \\\n",
        "        zlib1g-dev \\\n",
        "        libglfw3 \\\n",
        "        libglfw3-dev \\\n",
        "        libxrandr2 \\\n",
        "        libxinerama-dev \\\n",
        "        libxi6 \\\n",
        "        libxcursor-dev \\\n",
        "        libgl1-mesa-dev \\\n",
        "        libgl1-mesa-glx \\\n",
        "        libglew-dev \\\n",
        "        libosmesa6-dev \\\n",
        "        lsb-release \\\n",
        "        ack-grep \\\n",
        "        patchelf \\\n",
        "        wget \\\n",
        "        xpra \\\n",
        "        xserver-xorg-dev \\\n",
        "        xvfb \\\n",
        "        python-opengl \\\n",
        "        ffmpeg > /dev/null 2>&1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YNGuuABeg99q",
        "outputId": "8eb1c293-e844-4c90-943c-38e105bc3826"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/My Drive/cs285_f2021/mujoco\n"
          ]
        }
      ],
      "source": [
        "#@title download mujoco\n",
        "\n",
        "MJC_PATH = '{}/mujoco'.format(SYM_PATH)\n",
        "if not os.path.exists(MJC_PATH):\n",
        "  %mkdir $MJC_PATH\n",
        "%cd $MJC_PATH\n",
        "if not os.path.exists(os.path.join(MJC_PATH, 'mujoco200')):\n",
        "  !wget -q https://www.roboti.us/download/mujoco200_linux.zip\n",
        "  !unzip -q mujoco200_linux.zip\n",
        "  %mv mujoco200_linux mujoco200\n",
        "  %rm mujoco200_linux.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "y0MiuTJ4hT5z"
      },
      "outputs": [],
      "source": [
        "#@title update mujoco paths\n",
        "\n",
        "import os\n",
        "\n",
        "os.environ['LD_LIBRARY_PATH'] += ':{}/mujoco200/bin'.format(MJC_PATH)\n",
        "os.environ['MUJOCO_PY_MUJOCO_PATH'] = '{}/mujoco200'.format(MJC_PATH)\n",
        "os.environ['MUJOCO_PY_MJKEY_PATH'] = '{}/mjkey.txt'.format(MJC_PATH)\n",
        "\n",
        "## installation on colab does not find *.so files\n",
        "## in LD_LIBRARY_PATH, copy over manually instead\n",
        "!cp $MJC_PATH/mujoco200/bin/*.so /usr/lib/x86_64-linux-gnu/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GQvbeuV1hi5I",
        "outputId": "e900a9d9-1b2d-4c17-9621-782017cbca53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/My Drive/cs285_f2021\n",
            "fatal: destination path 'DRL_policy_grads' already exists and is not an empty directory.\n",
            "/content/gdrive/My Drive/cs285_f2021/DRL_policy_grads\n",
            "Collecting gym==0.17.2\n",
            "  Downloading gym-0.17.2.tar.gz (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 27.9 MB/s \n",
            "\u001b[?25hCollecting tensorboard==2.3.0\n",
            "  Downloading tensorboard-2.3.0-py3-none-any.whl (6.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.8 MB 39.7 MB/s \n",
            "\u001b[?25hCollecting tensorboardX==1.8\n",
            "  Downloading tensorboardX-1.8-py2.py3-none-any.whl (216 kB)\n",
            "\u001b[K     |████████████████████████████████| 216 kB 44.4 MB/s \n",
            "\u001b[?25hCollecting matplotlib==2.2.2\n",
            "  Downloading matplotlib-2.2.2-cp37-cp37m-manylinux1_x86_64.whl (12.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.6 MB 40.2 MB/s \n",
            "\u001b[?25hCollecting ipython==6.4.0\n",
            "  Downloading ipython-6.4.0-py3-none-any.whl (750 kB)\n",
            "\u001b[K     |████████████████████████████████| 750 kB 48.8 MB/s \n",
            "\u001b[?25hCollecting moviepy==1.0.0\n",
            "  Downloading moviepy-1.0.0.tar.gz (398 kB)\n",
            "\u001b[K     |████████████████████████████████| 398 kB 47.9 MB/s \n",
            "\u001b[?25hCollecting pyvirtualdisplay==1.3.2\n",
            "  Downloading PyVirtualDisplay-1.3.2-py2.py3-none-any.whl (14 kB)\n",
            "Collecting torch==1.6.0\n",
            "  Downloading torch-1.6.0-cp37-cp37m-manylinux1_x86_64.whl (748.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 748.8 MB 16 kB/s \n",
            "\u001b[?25hCollecting opencv-python==4.4.0.42\n",
            "\u001b[33m  WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))': /packages/fa/e3/7ed67a8f3116113a364671fb4142c446dd804c63f3d9df5c11168a1e4dbb/opencv_python-4.4.0.42-cp37-cp37m-manylinux2014_x86_64.whl\u001b[0m\n",
            "  Downloading opencv_python-4.4.0.42-cp37-cp37m-manylinux2014_x86_64.whl (49.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 49.4 MB 277 kB/s \n",
            "\u001b[?25hCollecting ipdb==0.13.3\n",
            "  Downloading ipdb-0.13.3.tar.gz (14 kB)\n",
            "Collecting box2d-py\n",
            "  Downloading box2d_py-2.3.8-cp37-cp37m-manylinux1_x86_64.whl (448 kB)\n",
            "\u001b[K     |████████████████████████████████| 448 kB 51.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym==0.17.2->-r requirements_colab.txt (line 1)) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from gym==0.17.2->-r requirements_colab.txt (line 1)) (1.19.5)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym==0.17.2->-r requirements_colab.txt (line 1)) (1.5.0)\n",
            "Requirement already satisfied: cloudpickle<1.4.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym==0.17.2->-r requirements_colab.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.3.0->-r requirements_colab.txt (line 2)) (0.37.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.3.0->-r requirements_colab.txt (line 2)) (1.0.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.3.0->-r requirements_colab.txt (line 2)) (57.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.3.0->-r requirements_colab.txt (line 2)) (3.3.6)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.3.0->-r requirements_colab.txt (line 2)) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.3.0->-r requirements_colab.txt (line 2)) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.3.0->-r requirements_colab.txt (line 2)) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.3.0->-r requirements_colab.txt (line 2)) (1.8.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.3.0->-r requirements_colab.txt (line 2)) (1.15.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.3.0->-r requirements_colab.txt (line 2)) (1.35.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.3.0->-r requirements_colab.txt (line 2)) (1.43.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.3.0->-r requirements_colab.txt (line 2)) (3.17.3)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from matplotlib==2.2.2->-r requirements_colab.txt (line 4)) (2018.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib==2.2.2->-r requirements_colab.txt (line 4)) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==2.2.2->-r requirements_colab.txt (line 4)) (3.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==2.2.2->-r requirements_colab.txt (line 4)) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==2.2.2->-r requirements_colab.txt (line 4)) (1.3.2)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython==6.4.0->-r requirements_colab.txt (line 5)) (4.8.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython==6.4.0->-r requirements_colab.txt (line 5)) (5.1.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython==6.4.0->-r requirements_colab.txt (line 5)) (0.7.5)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython==6.4.0->-r requirements_colab.txt (line 5)) (0.8.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.15 in /usr/local/lib/python3.7/dist-packages (from ipython==6.4.0->-r requirements_colab.txt (line 5)) (1.0.18)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython==6.4.0->-r requirements_colab.txt (line 5)) (2.6.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython==6.4.0->-r requirements_colab.txt (line 5)) (0.2.0)\n",
            "Requirement already satisfied: jedi>=0.10 in /usr/local/lib/python3.7/dist-packages (from ipython==6.4.0->-r requirements_colab.txt (line 5)) (0.18.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython==6.4.0->-r requirements_colab.txt (line 5)) (4.4.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.7/dist-packages (from moviepy==1.0.0->-r requirements_colab.txt (line 6)) (4.62.3)\n",
            "Collecting proglog<=1.0.0\n",
            "  Downloading proglog-0.1.9.tar.gz (10 kB)\n",
            "Collecting imageio<3.0,>=2.5\n",
            "  Downloading imageio-2.15.0-py3-none-any.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 35.3 MB/s \n",
            "\u001b[?25hCollecting imageio_ffmpeg>=0.2.0\n",
            "  Downloading imageio_ffmpeg-0.4.5-py3-none-manylinux2010_x86_64.whl (26.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 26.9 MB 56.4 MB/s \n",
            "\u001b[?25hCollecting EasyProcess\n",
            "  Downloading EasyProcess-1.1-py3-none-any.whl (8.7 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0->-r requirements_colab.txt (line 8)) (0.16.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard==2.3.0->-r requirements_colab.txt (line 2)) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard==2.3.0->-r requirements_colab.txt (line 2)) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard==2.3.0->-r requirements_colab.txt (line 2)) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard==2.3.0->-r requirements_colab.txt (line 2)) (1.3.1)\n",
            "Collecting pillow>=8.3.2\n",
            "  Downloading Pillow-9.0.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.3 MB 51.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.10->ipython==6.4.0->-r requirements_colab.txt (line 5)) (0.8.3)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard==2.3.0->-r requirements_colab.txt (line 2)) (4.10.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard==2.3.0->-r requirements_colab.txt (line 2)) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard==2.3.0->-r requirements_colab.txt (line 2)) (3.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.15->ipython==6.4.0->-r requirements_colab.txt (line 5)) (0.2.5)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard==2.3.0->-r requirements_colab.txt (line 2)) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard==2.3.0->-r requirements_colab.txt (line 2)) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard==2.3.0->-r requirements_colab.txt (line 2)) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard==2.3.0->-r requirements_colab.txt (line 2)) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard==2.3.0->-r requirements_colab.txt (line 2)) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard==2.3.0->-r requirements_colab.txt (line 2)) (3.2.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython==6.4.0->-r requirements_colab.txt (line 5)) (0.7.0)\n",
            "Building wheels for collected packages: gym, moviepy, ipdb, proglog\n",
            "  Building wheel for gym (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym: filename=gym-0.17.2-py3-none-any.whl size=1650890 sha256=a0120f6744c5cb3aa4b6221eecf0417199f2a9acc216747cbac12202cf7a259d\n",
            "  Stored in directory: /root/.cache/pip/wheels/18/e1/58/89a2aa24e6c2cc800204fc02010612afdf200926c4d6bfe315\n",
            "  Building wheel for moviepy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for moviepy: filename=moviepy-1.0.0-py3-none-any.whl size=131387 sha256=16252602ba77009d03f731aad81c7bf25943e4328e020cafd64e31f382f7beca\n",
            "  Stored in directory: /root/.cache/pip/wheels/de/c1/e6/2ca4ff00d07d206bf2d5d19056fa530c4e54ecd1b2f6fcfcdb\n",
            "  Building wheel for ipdb (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ipdb: filename=ipdb-0.13.3-py3-none-any.whl size=10875 sha256=3b26b2ff4790db0306d097e6127beb046bdd1dff9d1297e5ad21fbf3b22fb698\n",
            "  Stored in directory: /root/.cache/pip/wheels/b1/2b/e0/4932698c94c886d9d476e90916b43af63d5e708e146eb8b273\n",
            "  Building wheel for proglog (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for proglog: filename=proglog-0.1.9-py3-none-any.whl size=6157 sha256=d1cbe53505471e68300fef594d46f54a8671ea2274be011b52357c416e9136fa\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/36/1f/dc61e6ac10781d63cf6fa045eb09fa613a667384e12cb6e6e0\n",
            "Successfully built gym moviepy ipdb proglog\n",
            "Installing collected packages: pillow, proglog, ipython, imageio-ffmpeg, imageio, EasyProcess, torch, tensorboardX, tensorboard, pyvirtualdisplay, opencv-python, moviepy, matplotlib, ipdb, gym, box2d-py\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: Pillow 7.1.2\n",
            "    Uninstalling Pillow-7.1.2:\n",
            "      Successfully uninstalled Pillow-7.1.2\n",
            "  Attempting uninstall: ipython\n",
            "    Found existing installation: ipython 5.5.0\n",
            "    Uninstalling ipython-5.5.0:\n",
            "      Successfully uninstalled ipython-5.5.0\n",
            "  Attempting uninstall: imageio\n",
            "    Found existing installation: imageio 2.4.1\n",
            "    Uninstalling imageio-2.4.1:\n",
            "      Successfully uninstalled imageio-2.4.1\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.10.0+cu111\n",
            "    Uninstalling torch-1.10.0+cu111:\n",
            "      Successfully uninstalled torch-1.10.0+cu111\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.7.0\n",
            "    Uninstalling tensorboard-2.7.0:\n",
            "      Successfully uninstalled tensorboard-2.7.0\n",
            "  Attempting uninstall: opencv-python\n",
            "    Found existing installation: opencv-python 4.1.2.30\n",
            "    Uninstalling opencv-python-4.1.2.30:\n",
            "      Successfully uninstalled opencv-python-4.1.2.30\n",
            "  Attempting uninstall: moviepy\n",
            "    Found existing installation: moviepy 0.2.3.5\n",
            "    Uninstalling moviepy-0.2.3.5:\n",
            "      Successfully uninstalled moviepy-0.2.3.5\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.2.2\n",
            "    Uninstalling matplotlib-3.2.2:\n",
            "      Successfully uninstalled matplotlib-3.2.2\n",
            "  Attempting uninstall: gym\n",
            "    Found existing installation: gym 0.17.3\n",
            "    Uninstalling gym-0.17.3:\n",
            "      Successfully uninstalled gym-0.17.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.11.1+cu111 requires torch==1.10.0, but you have torch 1.6.0 which is incompatible.\n",
            "torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.6.0 which is incompatible.\n",
            "torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.6.0 which is incompatible.\n",
            "tensorflow 2.7.0 requires tensorboard~=2.6, but you have tensorboard 2.3.0 which is incompatible.\n",
            "plotnine 0.6.0 requires matplotlib>=3.1.1, but you have matplotlib 2.2.2 which is incompatible.\n",
            "mizani 0.6.0 requires matplotlib>=3.1.1, but you have matplotlib 2.2.2 which is incompatible.\n",
            "google-colab 1.0.0 requires ipython~=5.5.0, but you have ipython 6.4.0 which is incompatible.\n",
            "arviz 0.11.4 requires matplotlib>=3.0, but you have matplotlib 2.2.2 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed EasyProcess-1.1 box2d-py-2.3.8 gym-0.17.2 imageio-2.15.0 imageio-ffmpeg-0.4.5 ipdb-0.13.3 ipython-6.4.0 matplotlib-2.2.2 moviepy-1.0.0 opencv-python-4.4.0.42 pillow-9.0.1 proglog-0.1.9 pyvirtualdisplay-1.3.2 tensorboard-2.3.0 tensorboardX-1.8 torch-1.6.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "IPython",
                  "PIL",
                  "matplotlib",
                  "mpl_toolkits"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining file:///content/gdrive/My%20Drive/cs285_f2021/DRL_policy_grads\n",
            "Installing collected packages: cs285\n",
            "  Running setup.py develop for cs285\n",
            "Successfully installed cs285-0.1.0\n"
          ]
        }
      ],
      "source": [
        "#@title clone homework repo\n",
        "#@markdown Note that this is the same codebase from homework 1,\n",
        "#@markdown so you may need to move your old `homework_fall2021`\n",
        "#@markdown folder in order to clone the repo again.\n",
        "\n",
        "#@markdown **Don't delete your old work though!**\n",
        "#@markdown You will need it for this assignment.\n",
        "\n",
        "%cd $SYM_PATH\n",
        "!git clone https://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@github.com/ChihabEddine98/DRL_policy_grads.git\n",
        "%cd DRL_policy_grads\n",
        "%pip install -r requirements_colab.txt\n",
        "%pip install -e ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4cHNC4hu4QDU",
        "outputId": "2493e332-610a-45b4-f432-3c037f72d51b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mujoco-py==2.0.2.2\n",
            "  Downloading mujoco-py-2.0.2.2.tar.gz (771 kB)\n",
            "\u001b[K     |████████████████████████████████| 771 kB 17.6 MB/s \n",
            "\u001b[?25hCollecting glfw>=1.4.0\n",
            "  Downloading glfw-2.5.0-py2.py27.py3.py30.py31.py32.py33.py34.py35.py36.py37.py38-none-manylinux2014_x86_64.whl (205 kB)\n",
            "\u001b[K     |████████████████████████████████| 205 kB 48.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from mujoco-py==2.0.2.2) (1.19.5)\n",
            "Requirement already satisfied: Cython>=0.27.2 in /usr/local/lib/python3.7/dist-packages (from mujoco-py==2.0.2.2) (0.29.27)\n",
            "Requirement already satisfied: imageio>=2.1.2 in /usr/local/lib/python3.7/dist-packages (from mujoco-py==2.0.2.2) (2.15.0)\n",
            "Requirement already satisfied: cffi>=1.10 in /usr/local/lib/python3.7/dist-packages (from mujoco-py==2.0.2.2) (1.15.0)\n",
            "Collecting lockfile>=0.12.2\n",
            "  Downloading lockfile-0.12.2-py2.py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.10->mujoco-py==2.0.2.2) (2.21)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.7/dist-packages (from imageio>=2.1.2->mujoco-py==2.0.2.2) (9.0.1)\n",
            "Building wheels for collected packages: mujoco-py\n",
            "  Building wheel for mujoco-py (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for mujoco-py\u001b[0m\n",
            "\u001b[?25h  Running setup.py clean for mujoco-py\n",
            "Failed to build mujoco-py\n",
            "Installing collected packages: lockfile, glfw, mujoco-py\n",
            "    Running setup.py install for mujoco-py ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33m  DEPRECATION: mujoco-py was installed using the legacy 'setup.py install' method, because a wheel could not be built for it. A possible replacement is to fix the wheel build issue reported above. You can find discussion regarding this at https://github.com/pypa/pip/issues/8368.\u001b[0m\n",
            "Successfully installed glfw-2.5.0 lockfile-0.12.2 mujoco-py-2.0.2.2\n"
          ]
        }
      ],
      "source": [
        "#@title clone and install mujoco-py\n",
        "\n",
        "!pip install mujoco-py==2.0.2.2\n",
        "\n",
        "## cythonize at the first import\n",
        "import mujoco_py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "noinfUbHiHW2",
        "outputId": "9ee08b69-2c22-4681-96b4-59f8b59612d1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<pyvirtualdisplay.display.Display at 0x7fc32cdc9c90>"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#@title set up virtual display\n",
        "\n",
        "from pyvirtualdisplay import Display\n",
        "\n",
        "display = Display(visible=0, size=(1400, 900))\n",
        "display.start()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "COqsZLeliU9Y",
        "outputId": "bd30b559-7a2f-448d-bcf9-3418c41bc62f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading video...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<video alt=\"test\" autoplay \n",
              "                loop controls style=\"height: 400px;\">\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#@title test virtual display\n",
        "\n",
        "#@markdown If you see a video of a four-legged ant fumbling about, setup is complete!\n",
        "\n",
        "import gym\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "from cs285.infrastructure.colab_utils import (\n",
        "    wrap_env,\n",
        "    show_video\n",
        ")\n",
        "\n",
        "env = wrap_env(gym.make(\"CartPole-v0\"))\n",
        "\n",
        "observation = env.reset()\n",
        "for i in range(100):\n",
        "    env.render(mode='rgb_array')\n",
        "    obs, rew, term, _ = env.step(env.action_space.sample() ) \n",
        "    if term:\n",
        "      break;\n",
        "            \n",
        "env.close()\n",
        "print('Loading video...')\n",
        "show_video()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygs968BbiYHr"
      },
      "source": [
        "## Editing Code\n",
        "\n",
        "To edit code, click the folder icon on the left menu. Navigate to the corresponding file (`cs285_f2021/...`). Double click a file to open an editor. There is a timeout of about ~12 hours with Colab while it is active (and less if you close your browser window). We sync your edits to Google Drive so that you won't lose your work in the event of an instance timeout, but you will need to re-mount your Google Drive and re-install packages with every new instance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qUmV93fif6S"
      },
      "source": [
        "## Run Policy Gradients"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "lN-gZkqiijnR"
      },
      "outputs": [],
      "source": [
        "#@title imports\n",
        "\n",
        "import os\n",
        "import time\n",
        "\n",
        "from cs285.infrastructure.rl_trainer import RL_Trainer\n",
        "from cs285.agents.pg_agent import PGAgent\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Q6NaOWhOinnU"
      },
      "outputs": [],
      "source": [
        "#@title runtime arguments\n",
        "\n",
        "class Args:\n",
        "\n",
        "  def __getitem__(self, key):\n",
        "    return getattr(self, key)\n",
        "\n",
        "  def __setitem__(self, key, val):\n",
        "    setattr(self, key, val)\n",
        "\n",
        "  def __contains__(self, key):\n",
        "    return hasattr(self, key)\n",
        "\n",
        "  env_name = 'CartPole-v0' #@param\n",
        "  exp_name = 'q1_sb_rtg_na' #@param\n",
        "  #@markdown main parameters of interest\n",
        "  n_iter = 100 #@param {type: \"integer\"}\n",
        "\n",
        "  ## PDF will tell you how to set ep_len\n",
        "  ## and discount for each environment\n",
        "  ep_len = 200 #@param {type: \"integer\"}\n",
        "  discount = 0.95 #@param {type: \"number\"}\n",
        "\n",
        "  reward_to_go = True #@param {type: \"boolean\"}\n",
        "  nn_baseline = False #@param {type: \"boolean\"}\n",
        "  gae_lambda = 0.01 #@param {type: \"number\"}\n",
        "  dont_standardize_advantages = False #@param {type: \"boolean\"}\n",
        "\n",
        "  #@markdown batches and steps\n",
        "  batch_size = 1000 #@param {type: \"integer\"}\n",
        "  eval_batch_size = 400 #@param {type: \"integer\"}\n",
        "\n",
        "  num_agent_train_steps_per_iter = 1 #@param {type: \"integer\"}\n",
        "  learning_rate =  5e-3 #@param {type: \"number\"}\n",
        "\n",
        "  #@markdown MLP parameters\n",
        "  n_layers = 2 #@param {type: \"integer\"}\n",
        "  size = 64 #@param {type: \"integer\"}\n",
        "\n",
        "  #@markdown system\n",
        "  save_params = False #@param {type: \"boolean\"}\n",
        "  no_gpu = False #@param {type: \"boolean\"}\n",
        "  which_gpu = 0 #@param {type: \"integer\"}\n",
        "  seed = 1 #@param {type: \"integer\"}\n",
        "    \n",
        "  action_noise_std = 0 #@param {type: \"number\"}\n",
        "\n",
        "  #@markdown logging\n",
        "  ## default is to not log video so\n",
        "  ## that logs are small enough to be\n",
        "  ## uploaded to gradscope\n",
        "  video_log_freq =  -1#@param {type: \"integer\"}\n",
        "  scalar_log_freq =  1#@param {type: \"integer\"}\n",
        "\n",
        "\n",
        "args = Args()\n",
        "\n",
        "## ensure compatibility with hw1 code\n",
        "args['train_batch_size'] = args['batch_size']\n",
        "\n",
        "if args['video_log_freq'] > 0:\n",
        "  import warnings\n",
        "  warnings.warn(\n",
        "      '''\\nLogging videos will make eventfiles too'''\n",
        "      '''\\nlarge for the autograder. Set video_log_freq = -1'''\n",
        "      '''\\nfor the runs you intend to submit.''')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "eScWwHhnsYkd"
      },
      "outputs": [],
      "source": [
        "#@title create directory for logging\n",
        "\n",
        "data_path = '''/content/cs285_f2021/''' \\\n",
        "            '''DRL_policy_grads/data'''\n",
        "\n",
        "if not (os.path.exists(data_path)):\n",
        "    os.makedirs(data_path)\n",
        "\n",
        "logdir = args.exp_name + '_' + args.env_name + '_' + time.strftime(\"%d-%m-%Y_%H-%M-%S\")\n",
        "logdir = os.path.join(data_path, logdir)\n",
        "args['logdir'] = logdir\n",
        "if not(os.path.exists(logdir)):\n",
        "    os.makedirs(logdir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "aljzrLdAsvNu"
      },
      "outputs": [],
      "source": [
        "## define policy gradient trainer\n",
        "\n",
        "class PG_Trainer(object):\n",
        "\n",
        "    def __init__(self, params):\n",
        "\n",
        "        #####################\n",
        "        ## SET AGENT PARAMS\n",
        "        #####################\n",
        "\n",
        "        computation_graph_args = {\n",
        "            'n_layers': params['n_layers'],\n",
        "            'size': params['size'],\n",
        "            'learning_rate': params['learning_rate'],\n",
        "            }\n",
        "\n",
        "        estimate_advantage_args = {\n",
        "            'gamma': params['discount'],\n",
        "            'standardize_advantages': not(params['dont_standardize_advantages']),\n",
        "            'reward_to_go': params['reward_to_go'],\n",
        "            'nn_baseline': params['nn_baseline'],\n",
        "            'gae_lambda': params['gae_lambda'],\n",
        "        }\n",
        "\n",
        "        train_args = {\n",
        "            'num_agent_train_steps_per_iter': params['num_agent_train_steps_per_iter'],\n",
        "        }\n",
        "\n",
        "        agent_params = {**computation_graph_args, **estimate_advantage_args, **train_args}\n",
        "\n",
        "        self.params = params\n",
        "        self.params['agent_class'] = PGAgent\n",
        "        self.params['agent_params'] = agent_params\n",
        "        self.params['batch_size_initial'] = self.params['batch_size']\n",
        "\n",
        "        ################\n",
        "        ## RL TRAINER\n",
        "        ################\n",
        "\n",
        "        self.rl_trainer = RL_Trainer(self.params)\n",
        "\n",
        "    def run_training_loop(self):\n",
        "\n",
        "        self.rl_trainer.run_training_loop(\n",
        "            self.params['n_iter'],\n",
        "            collect_policy = self.rl_trainer.agent.actor,\n",
        "            eval_policy = self.rl_trainer.agent.actor,\n",
        "            )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KZaumnvm3Qr"
      },
      "source": [
        "#Experiment 1 (CartPole_v0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6TB423e-8-A",
        "outputId": "25a95928-a0e6-435e-a147-90d37ff9fc35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "########################\n",
            "logging outputs to  /content/gdrive/My Drive/cs285_f2021/DRL_policy_grads/cs285/scripts/../../data/q2_pg_q1_sb_no_rtg_dsa_CartPole-v0_04-02-2022_16-37-40\n",
            "########################\n",
            "Using GPU id 0\n",
            "\n",
            "\n",
            "********** Iteration 0 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 31.153846740722656\n",
            "Eval_StdReturn : 15.917315483093262\n",
            "Eval_MaxReturn : 77.0\n",
            "Eval_MinReturn : 12.0\n",
            "Eval_AverageEpLen : 31.153846153846153\n",
            "Train_AverageReturn : 27.648649215698242\n",
            "Train_StdReturn : 12.643160820007324\n",
            "Train_MaxReturn : 65.0\n",
            "Train_MinReturn : 11.0\n",
            "Train_AverageEpLen : 27.64864864864865\n",
            "Train_EnvstepsSoFar : 1023\n",
            "TimeSinceStart : 1.4175140857696533\n",
            "Training Loss : 23544.501953125\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 1 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 37.45454406738281\n",
            "Eval_StdReturn : 17.773134231567383\n",
            "Eval_MaxReturn : 71.0\n",
            "Eval_MinReturn : 12.0\n",
            "Eval_AverageEpLen : 37.45454545454545\n",
            "Train_AverageReturn : 38.46154022216797\n",
            "Train_StdReturn : 25.42595672607422\n",
            "Train_MaxReturn : 98.0\n",
            "Train_MinReturn : 11.0\n",
            "Train_AverageEpLen : 38.46153846153846\n",
            "Train_EnvstepsSoFar : 2023\n",
            "TimeSinceStart : 2.7895359992980957\n",
            "Training Loss : 36905.1328125\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 2 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 70.16666412353516\n",
            "Eval_StdReturn : 29.29969596862793\n",
            "Eval_MaxReturn : 112.0\n",
            "Eval_MinReturn : 16.0\n",
            "Eval_AverageEpLen : 70.16666666666667\n",
            "Train_AverageReturn : 38.88888931274414\n",
            "Train_StdReturn : 26.084383010864258\n",
            "Train_MaxReturn : 108.0\n",
            "Train_MinReturn : 12.0\n",
            "Train_AverageEpLen : 38.888888888888886\n",
            "Train_EnvstepsSoFar : 3073\n",
            "TimeSinceStart : 4.297277927398682\n",
            "Training Loss : 37563.1015625\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 3 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 61.85714340209961\n",
            "Eval_StdReturn : 27.513261795043945\n",
            "Eval_MaxReturn : 101.0\n",
            "Eval_MinReturn : 27.0\n",
            "Eval_AverageEpLen : 61.857142857142854\n",
            "Train_AverageReturn : 50.25\n",
            "Train_StdReturn : 23.134119033813477\n",
            "Train_MaxReturn : 109.0\n",
            "Train_MinReturn : 18.0\n",
            "Train_AverageEpLen : 50.25\n",
            "Train_EnvstepsSoFar : 4078\n",
            "TimeSinceStart : 5.753105640411377\n",
            "Training Loss : 38431.3828125\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 4 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 76.57142639160156\n",
            "Eval_StdReturn : 32.28824234008789\n",
            "Eval_MaxReturn : 150.0\n",
            "Eval_MinReturn : 39.0\n",
            "Eval_AverageEpLen : 76.57142857142857\n",
            "Train_AverageReturn : 48.904762268066406\n",
            "Train_StdReturn : 23.36644744873047\n",
            "Train_MaxReturn : 98.0\n",
            "Train_MinReturn : 18.0\n",
            "Train_AverageEpLen : 48.904761904761905\n",
            "Train_EnvstepsSoFar : 5105\n",
            "TimeSinceStart : 7.343592166900635\n",
            "Training Loss : 38461.76171875\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 5 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 67.16666412353516\n",
            "Eval_StdReturn : 14.814594268798828\n",
            "Eval_MaxReturn : 85.0\n",
            "Eval_MinReturn : 39.0\n",
            "Eval_AverageEpLen : 67.16666666666667\n",
            "Train_AverageReturn : 57.05555725097656\n",
            "Train_StdReturn : 15.970361709594727\n",
            "Train_MaxReturn : 88.0\n",
            "Train_MinReturn : 31.0\n",
            "Train_AverageEpLen : 57.05555555555556\n",
            "Train_EnvstepsSoFar : 6132\n",
            "TimeSinceStart : 8.754396915435791\n",
            "Training Loss : 38407.1484375\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 6 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 63.71428680419922\n",
            "Eval_StdReturn : 16.619388580322266\n",
            "Eval_MaxReturn : 92.0\n",
            "Eval_MinReturn : 43.0\n",
            "Eval_AverageEpLen : 63.714285714285715\n",
            "Train_AverageReturn : 56.38888931274414\n",
            "Train_StdReturn : 24.774850845336914\n",
            "Train_MaxReturn : 104.0\n",
            "Train_MinReturn : 29.0\n",
            "Train_AverageEpLen : 56.388888888888886\n",
            "Train_EnvstepsSoFar : 7147\n",
            "TimeSinceStart : 10.428910255432129\n",
            "Training Loss : 40664.421875\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 7 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 52.33333206176758\n",
            "Eval_StdReturn : 19.675140380859375\n",
            "Eval_MaxReturn : 88.0\n",
            "Eval_MinReturn : 26.0\n",
            "Eval_AverageEpLen : 52.333333333333336\n",
            "Train_AverageReturn : 58.82352828979492\n",
            "Train_StdReturn : 26.535736083984375\n",
            "Train_MaxReturn : 142.0\n",
            "Train_MinReturn : 24.0\n",
            "Train_AverageEpLen : 58.8235294117647\n",
            "Train_EnvstepsSoFar : 8147\n",
            "TimeSinceStart : 11.96250867843628\n",
            "Training Loss : 40998.6875\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 8 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 38.6363639831543\n",
            "Eval_StdReturn : 11.039373397827148\n",
            "Eval_MaxReturn : 61.0\n",
            "Eval_MinReturn : 26.0\n",
            "Eval_AverageEpLen : 38.63636363636363\n",
            "Train_AverageReturn : 55.05263137817383\n",
            "Train_StdReturn : 19.176393508911133\n",
            "Train_MaxReturn : 104.0\n",
            "Train_MinReturn : 33.0\n",
            "Train_AverageEpLen : 55.05263157894737\n",
            "Train_EnvstepsSoFar : 9193\n",
            "TimeSinceStart : 13.465378761291504\n",
            "Training Loss : 36320.90234375\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 9 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 46.66666793823242\n",
            "Eval_StdReturn : 18.11077117919922\n",
            "Eval_MaxReturn : 92.0\n",
            "Eval_MinReturn : 31.0\n",
            "Eval_AverageEpLen : 46.666666666666664\n",
            "Train_AverageReturn : 48.14285659790039\n",
            "Train_StdReturn : 19.292943954467773\n",
            "Train_MaxReturn : 110.0\n",
            "Train_MinReturn : 22.0\n",
            "Train_AverageEpLen : 48.142857142857146\n",
            "Train_EnvstepsSoFar : 10204\n",
            "TimeSinceStart : 14.914441347122192\n",
            "Training Loss : 32450.06640625\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 10 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 78.33333587646484\n",
            "Eval_StdReturn : 48.77043914794922\n",
            "Eval_MaxReturn : 183.0\n",
            "Eval_MinReturn : 47.0\n",
            "Eval_AverageEpLen : 78.33333333333333\n",
            "Train_AverageReturn : 52.099998474121094\n",
            "Train_StdReturn : 23.379262924194336\n",
            "Train_MaxReturn : 130.0\n",
            "Train_MinReturn : 22.0\n",
            "Train_AverageEpLen : 52.1\n",
            "Train_EnvstepsSoFar : 11246\n",
            "TimeSinceStart : 16.430760145187378\n",
            "Training Loss : 37427.5859375\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 11 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 53.375\n",
            "Eval_StdReturn : 13.591702461242676\n",
            "Eval_MaxReturn : 79.0\n",
            "Eval_MinReturn : 32.0\n",
            "Eval_AverageEpLen : 53.375\n",
            "Train_AverageReturn : 55.77777862548828\n",
            "Train_StdReturn : 19.65410804748535\n",
            "Train_MaxReturn : 106.0\n",
            "Train_MinReturn : 29.0\n",
            "Train_AverageEpLen : 55.77777777777778\n",
            "Train_EnvstepsSoFar : 12250\n",
            "TimeSinceStart : 18.201220512390137\n",
            "Training Loss : 34437.87890625\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 12 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 59.28571319580078\n",
            "Eval_StdReturn : 25.098175048828125\n",
            "Eval_MaxReturn : 93.0\n",
            "Eval_MinReturn : 19.0\n",
            "Eval_AverageEpLen : 59.285714285714285\n",
            "Train_AverageReturn : 61.29411697387695\n",
            "Train_StdReturn : 30.764312744140625\n",
            "Train_MaxReturn : 139.0\n",
            "Train_MinReturn : 30.0\n",
            "Train_AverageEpLen : 61.294117647058826\n",
            "Train_EnvstepsSoFar : 13292\n",
            "TimeSinceStart : 19.670225620269775\n",
            "Training Loss : 43861.05859375\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 13 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 85.5999984741211\n",
            "Eval_StdReturn : 58.32186508178711\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 39.0\n",
            "Eval_AverageEpLen : 85.6\n",
            "Train_AverageReturn : 68.4000015258789\n",
            "Train_StdReturn : 36.60018539428711\n",
            "Train_MaxReturn : 171.0\n",
            "Train_MinReturn : 29.0\n",
            "Train_AverageEpLen : 68.4\n",
            "Train_EnvstepsSoFar : 14318\n",
            "TimeSinceStart : 21.53205704689026\n",
            "Training Loss : 49319.6484375\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 14 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 78.5\n",
            "Eval_StdReturn : 23.048860549926758\n",
            "Eval_MaxReturn : 118.0\n",
            "Eval_MinReturn : 44.0\n",
            "Eval_AverageEpLen : 78.5\n",
            "Train_AverageReturn : 62.82352828979492\n",
            "Train_StdReturn : 20.697357177734375\n",
            "Train_MaxReturn : 104.0\n",
            "Train_MinReturn : 31.0\n",
            "Train_AverageEpLen : 62.8235294117647\n",
            "Train_EnvstepsSoFar : 15386\n",
            "TimeSinceStart : 23.041168451309204\n",
            "Training Loss : 37801.0078125\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 15 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 60.71428680419922\n",
            "Eval_StdReturn : 10.779799461364746\n",
            "Eval_MaxReturn : 75.0\n",
            "Eval_MinReturn : 45.0\n",
            "Eval_AverageEpLen : 60.714285714285715\n",
            "Train_AverageReturn : 72.35713958740234\n",
            "Train_StdReturn : 32.12610626220703\n",
            "Train_MaxReturn : 153.0\n",
            "Train_MinReturn : 36.0\n",
            "Train_AverageEpLen : 72.35714285714286\n",
            "Train_EnvstepsSoFar : 16399\n",
            "TimeSinceStart : 24.477938175201416\n",
            "Training Loss : 46159.68359375\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 16 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 70.57142639160156\n",
            "Eval_StdReturn : 29.7314510345459\n",
            "Eval_MaxReturn : 127.0\n",
            "Eval_MinReturn : 30.0\n",
            "Eval_AverageEpLen : 70.57142857142857\n",
            "Train_AverageReturn : 71.66666412353516\n",
            "Train_StdReturn : 25.880924224853516\n",
            "Train_MaxReturn : 132.0\n",
            "Train_MinReturn : 38.0\n",
            "Train_AverageEpLen : 71.66666666666667\n",
            "Train_EnvstepsSoFar : 17474\n",
            "TimeSinceStart : 26.046114683151245\n",
            "Training Loss : 45836.3671875\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 17 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 70.83333587646484\n",
            "Eval_StdReturn : 27.78738784790039\n",
            "Eval_MaxReturn : 122.0\n",
            "Eval_MinReturn : 48.0\n",
            "Eval_AverageEpLen : 70.83333333333333\n",
            "Train_AverageReturn : 73.71428680419922\n",
            "Train_StdReturn : 20.67237091064453\n",
            "Train_MaxReturn : 99.0\n",
            "Train_MinReturn : 34.0\n",
            "Train_AverageEpLen : 73.71428571428571\n",
            "Train_EnvstepsSoFar : 18506\n",
            "TimeSinceStart : 27.775652170181274\n",
            "Training Loss : 42211.33203125\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 18 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 83.5999984741211\n",
            "Eval_StdReturn : 34.6963996887207\n",
            "Eval_MaxReturn : 129.0\n",
            "Eval_MinReturn : 35.0\n",
            "Eval_AverageEpLen : 83.6\n",
            "Train_AverageReturn : 74.78571319580078\n",
            "Train_StdReturn : 33.89727783203125\n",
            "Train_MaxReturn : 145.0\n",
            "Train_MinReturn : 44.0\n",
            "Train_AverageEpLen : 74.78571428571429\n",
            "Train_EnvstepsSoFar : 19553\n",
            "TimeSinceStart : 29.37753653526306\n",
            "Training Loss : 47848.28515625\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 19 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 67.66666412353516\n",
            "Eval_StdReturn : 23.633779525756836\n",
            "Eval_MaxReturn : 105.0\n",
            "Eval_MinReturn : 28.0\n",
            "Eval_AverageEpLen : 67.66666666666667\n",
            "Train_AverageReturn : 94.09091186523438\n",
            "Train_StdReturn : 31.534841537475586\n",
            "Train_MaxReturn : 154.0\n",
            "Train_MinReturn : 52.0\n",
            "Train_AverageEpLen : 94.0909090909091\n",
            "Train_EnvstepsSoFar : 20588\n",
            "TimeSinceStart : 31.035971879959106\n",
            "Training Loss : 54826.46875\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 20 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 62.14285659790039\n",
            "Eval_StdReturn : 19.006980895996094\n",
            "Eval_MaxReturn : 83.0\n",
            "Eval_MinReturn : 39.0\n",
            "Eval_AverageEpLen : 62.142857142857146\n",
            "Train_AverageReturn : 71.33333587646484\n",
            "Train_StdReturn : 24.743125915527344\n",
            "Train_MaxReturn : 132.0\n",
            "Train_MinReturn : 32.0\n",
            "Train_AverageEpLen : 71.33333333333333\n",
            "Train_EnvstepsSoFar : 21658\n",
            "TimeSinceStart : 32.55814051628113\n",
            "Training Loss : 39803.07421875\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 21 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 67.5\n",
            "Eval_StdReturn : 25.630386352539062\n",
            "Eval_MaxReturn : 107.0\n",
            "Eval_MinReturn : 30.0\n",
            "Eval_AverageEpLen : 67.5\n",
            "Train_AverageReturn : 67.19999694824219\n",
            "Train_StdReturn : 26.523448944091797\n",
            "Train_MaxReturn : 131.0\n",
            "Train_MinReturn : 42.0\n",
            "Train_AverageEpLen : 67.2\n",
            "Train_EnvstepsSoFar : 22666\n",
            "TimeSinceStart : 34.12749648094177\n",
            "Training Loss : 37556.5625\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 22 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 67.66666412353516\n",
            "Eval_StdReturn : 13.695091247558594\n",
            "Eval_MaxReturn : 96.0\n",
            "Eval_MinReturn : 51.0\n",
            "Eval_AverageEpLen : 67.66666666666667\n",
            "Train_AverageReturn : 68.86666870117188\n",
            "Train_StdReturn : 28.892597198486328\n",
            "Train_MaxReturn : 130.0\n",
            "Train_MinReturn : 32.0\n",
            "Train_AverageEpLen : 68.86666666666666\n",
            "Train_EnvstepsSoFar : 23699\n",
            "TimeSinceStart : 35.72400212287903\n",
            "Training Loss : 38747.1484375\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 23 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 67.0\n",
            "Eval_StdReturn : 27.766887664794922\n",
            "Eval_MaxReturn : 107.0\n",
            "Eval_MinReturn : 32.0\n",
            "Eval_AverageEpLen : 67.0\n",
            "Train_AverageReturn : 100.5999984741211\n",
            "Train_StdReturn : 37.427799224853516\n",
            "Train_MaxReturn : 167.0\n",
            "Train_MinReturn : 47.0\n",
            "Train_AverageEpLen : 100.6\n",
            "Train_EnvstepsSoFar : 24705\n",
            "TimeSinceStart : 37.19745445251465\n",
            "Training Loss : 55167.54296875\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 24 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 73.83333587646484\n",
            "Eval_StdReturn : 17.78029441833496\n",
            "Eval_MaxReturn : 99.0\n",
            "Eval_MinReturn : 48.0\n",
            "Eval_AverageEpLen : 73.83333333333333\n",
            "Train_AverageReturn : 86.15384674072266\n",
            "Train_StdReturn : 31.01822280883789\n",
            "Train_MaxReturn : 156.0\n",
            "Train_MinReturn : 48.0\n",
            "Train_AverageEpLen : 86.15384615384616\n",
            "Train_EnvstepsSoFar : 25825\n",
            "TimeSinceStart : 38.75237560272217\n",
            "Training Loss : 46895.125\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 25 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 73.5\n",
            "Eval_StdReturn : 23.73288917541504\n",
            "Eval_MaxReturn : 121.0\n",
            "Eval_MinReturn : 46.0\n",
            "Eval_AverageEpLen : 73.5\n",
            "Train_AverageReturn : 101.80000305175781\n",
            "Train_StdReturn : 38.52998733520508\n",
            "Train_MaxReturn : 191.0\n",
            "Train_MinReturn : 49.0\n",
            "Train_AverageEpLen : 101.8\n",
            "Train_EnvstepsSoFar : 26843\n",
            "TimeSinceStart : 40.22607111930847\n",
            "Training Loss : 53013.3671875\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 26 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 77.16666412353516\n",
            "Eval_StdReturn : 18.040849685668945\n",
            "Eval_MaxReturn : 115.0\n",
            "Eval_MinReturn : 65.0\n",
            "Eval_AverageEpLen : 77.16666666666667\n",
            "Train_AverageReturn : 82.69230651855469\n",
            "Train_StdReturn : 20.25371742248535\n",
            "Train_MaxReturn : 119.0\n",
            "Train_MinReturn : 52.0\n",
            "Train_AverageEpLen : 82.6923076923077\n",
            "Train_EnvstepsSoFar : 27918\n",
            "TimeSinceStart : 41.753974199295044\n",
            "Training Loss : 40478.1484375\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 27 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 89.0\n",
            "Eval_StdReturn : 23.93324089050293\n",
            "Eval_MaxReturn : 128.0\n",
            "Eval_MinReturn : 58.0\n",
            "Eval_AverageEpLen : 89.0\n",
            "Train_AverageReturn : 79.21428680419922\n",
            "Train_StdReturn : 15.88880443572998\n",
            "Train_MaxReturn : 117.0\n",
            "Train_MinReturn : 54.0\n",
            "Train_AverageEpLen : 79.21428571428571\n",
            "Train_EnvstepsSoFar : 29027\n",
            "TimeSinceStart : 43.274781227111816\n",
            "Training Loss : 36380.39453125\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 28 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 72.16666412353516\n",
            "Eval_StdReturn : 24.08607292175293\n",
            "Eval_MaxReturn : 122.0\n",
            "Eval_MinReturn : 51.0\n",
            "Eval_AverageEpLen : 72.16666666666667\n",
            "Train_AverageReturn : 101.80000305175781\n",
            "Train_StdReturn : 36.646419525146484\n",
            "Train_MaxReturn : 167.0\n",
            "Train_MinReturn : 68.0\n",
            "Train_AverageEpLen : 101.8\n",
            "Train_EnvstepsSoFar : 30045\n",
            "TimeSinceStart : 44.88069987297058\n",
            "Training Loss : 49382.296875\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 29 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 71.66666412353516\n",
            "Eval_StdReturn : 21.692293167114258\n",
            "Eval_MaxReturn : 118.0\n",
            "Eval_MinReturn : 49.0\n",
            "Eval_AverageEpLen : 71.66666666666667\n",
            "Train_AverageReturn : 100.9000015258789\n",
            "Train_StdReturn : 40.29007339477539\n",
            "Train_MaxReturn : 175.0\n",
            "Train_MinReturn : 56.0\n",
            "Train_AverageEpLen : 100.9\n",
            "Train_EnvstepsSoFar : 31054\n",
            "TimeSinceStart : 46.57045269012451\n",
            "Training Loss : 46538.109375\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 30 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 56.375\n",
            "Eval_StdReturn : 10.17272663116455\n",
            "Eval_MaxReturn : 76.0\n",
            "Eval_MinReturn : 42.0\n",
            "Eval_AverageEpLen : 56.375\n",
            "Train_AverageReturn : 73.92857360839844\n",
            "Train_StdReturn : 21.359054565429688\n",
            "Train_MaxReturn : 125.0\n",
            "Train_MinReturn : 46.0\n",
            "Train_AverageEpLen : 73.92857142857143\n",
            "Train_EnvstepsSoFar : 32089\n",
            "TimeSinceStart : 48.07903575897217\n",
            "Training Loss : 30514.20703125\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 31 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 64.85713958740234\n",
            "Eval_StdReturn : 15.596964836120605\n",
            "Eval_MaxReturn : 95.0\n",
            "Eval_MinReturn : 43.0\n",
            "Eval_AverageEpLen : 64.85714285714286\n",
            "Train_AverageReturn : 68.26667022705078\n",
            "Train_StdReturn : 12.850248336791992\n",
            "Train_MaxReturn : 98.0\n",
            "Train_MinReturn : 54.0\n",
            "Train_AverageEpLen : 68.26666666666667\n",
            "Train_EnvstepsSoFar : 33113\n",
            "TimeSinceStart : 49.56735968589783\n",
            "Training Loss : 27221.8984375\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 32 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 67.33333587646484\n",
            "Eval_StdReturn : 10.40299129486084\n",
            "Eval_MaxReturn : 82.0\n",
            "Eval_MinReturn : 53.0\n",
            "Eval_AverageEpLen : 67.33333333333333\n",
            "Train_AverageReturn : 64.75\n",
            "Train_StdReturn : 20.59581184387207\n",
            "Train_MaxReturn : 122.0\n",
            "Train_MinReturn : 42.0\n",
            "Train_AverageEpLen : 64.75\n",
            "Train_EnvstepsSoFar : 34149\n",
            "TimeSinceStart : 51.02840280532837\n",
            "Training Loss : 27548.029296875\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 33 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 78.66666412353516\n",
            "Eval_StdReturn : 13.936363220214844\n",
            "Eval_MaxReturn : 102.0\n",
            "Eval_MinReturn : 56.0\n",
            "Eval_AverageEpLen : 78.66666666666667\n",
            "Train_AverageReturn : 84.38461303710938\n",
            "Train_StdReturn : 35.855560302734375\n",
            "Train_MaxReturn : 177.0\n",
            "Train_MinReturn : 51.0\n",
            "Train_AverageEpLen : 84.38461538461539\n",
            "Train_EnvstepsSoFar : 35246\n",
            "TimeSinceStart : 52.60971760749817\n",
            "Training Loss : 36655.1328125\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 34 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 88.80000305175781\n",
            "Eval_StdReturn : 38.3009147644043\n",
            "Eval_MaxReturn : 163.0\n",
            "Eval_MinReturn : 56.0\n",
            "Eval_AverageEpLen : 88.8\n",
            "Train_AverageReturn : 83.58333587646484\n",
            "Train_StdReturn : 38.45226287841797\n",
            "Train_MaxReturn : 199.0\n",
            "Train_MinReturn : 50.0\n",
            "Train_AverageEpLen : 83.58333333333333\n",
            "Train_EnvstepsSoFar : 36249\n",
            "TimeSinceStart : 54.0604465007782\n",
            "Training Loss : 34689.671875\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 35 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 92.0\n",
            "Eval_StdReturn : 20.57182502746582\n",
            "Eval_MaxReturn : 124.0\n",
            "Eval_MinReturn : 67.0\n",
            "Eval_AverageEpLen : 92.0\n",
            "Train_AverageReturn : 104.5999984741211\n",
            "Train_StdReturn : 42.46221923828125\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 50.0\n",
            "Train_AverageEpLen : 104.6\n",
            "Train_EnvstepsSoFar : 37295\n",
            "TimeSinceStart : 55.59060025215149\n",
            "Training Loss : 44356.3046875\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 36 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 100.0\n",
            "Eval_StdReturn : 25.01999282836914\n",
            "Eval_MaxReturn : 134.0\n",
            "Eval_MinReturn : 72.0\n",
            "Eval_AverageEpLen : 100.0\n",
            "Train_AverageReturn : 93.58333587646484\n",
            "Train_StdReturn : 26.750259399414062\n",
            "Train_MaxReturn : 152.0\n",
            "Train_MinReturn : 60.0\n",
            "Train_AverageEpLen : 93.58333333333333\n",
            "Train_EnvstepsSoFar : 38418\n",
            "TimeSinceStart : 57.20842623710632\n",
            "Training Loss : 35860.89453125\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 37 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 137.6666717529297\n",
            "Eval_StdReturn : 29.46561050415039\n",
            "Eval_MaxReturn : 159.0\n",
            "Eval_MinReturn : 96.0\n",
            "Eval_AverageEpLen : 137.66666666666666\n",
            "Train_AverageReturn : 111.11111450195312\n",
            "Train_StdReturn : 41.90583419799805\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 60.0\n",
            "Train_AverageEpLen : 111.11111111111111\n",
            "Train_EnvstepsSoFar : 39418\n",
            "TimeSinceStart : 58.63809156417847\n",
            "Training Loss : 43313.19140625\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 38 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 114.80000305175781\n",
            "Eval_StdReturn : 43.90626525878906\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 75.0\n",
            "Eval_AverageEpLen : 114.8\n",
            "Train_AverageReturn : 116.55555725097656\n",
            "Train_StdReturn : 40.0890998840332\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 73.0\n",
            "Train_AverageEpLen : 116.55555555555556\n",
            "Train_EnvstepsSoFar : 40467\n",
            "TimeSinceStart : 60.263720750808716\n",
            "Training Loss : 44359.29296875\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 39 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 113.5\n",
            "Eval_StdReturn : 15.913830757141113\n",
            "Eval_MaxReturn : 136.0\n",
            "Eval_MinReturn : 93.0\n",
            "Eval_AverageEpLen : 113.5\n",
            "Train_AverageReturn : 101.5999984741211\n",
            "Train_StdReturn : 20.943735122680664\n",
            "Train_MaxReturn : 138.0\n",
            "Train_MinReturn : 67.0\n",
            "Train_AverageEpLen : 101.6\n",
            "Train_EnvstepsSoFar : 41483\n",
            "TimeSinceStart : 61.71479845046997\n",
            "Training Loss : 34236.078125\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 40 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 111.5\n",
            "Eval_StdReturn : 7.697402000427246\n",
            "Eval_MaxReturn : 120.0\n",
            "Eval_MinReturn : 99.0\n",
            "Eval_AverageEpLen : 111.5\n",
            "Train_AverageReturn : 118.77777862548828\n",
            "Train_StdReturn : 27.45006561279297\n",
            "Train_MaxReturn : 173.0\n",
            "Train_MinReturn : 80.0\n",
            "Train_AverageEpLen : 118.77777777777777\n",
            "Train_EnvstepsSoFar : 42552\n",
            "TimeSinceStart : 63.221877336502075\n",
            "Training Loss : 40729.2890625\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 41 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 83.5999984741211\n",
            "Eval_StdReturn : 15.094369888305664\n",
            "Eval_MaxReturn : 109.0\n",
            "Eval_MinReturn : 63.0\n",
            "Eval_AverageEpLen : 83.6\n",
            "Train_AverageReturn : 113.11111450195312\n",
            "Train_StdReturn : 24.73613929748535\n",
            "Train_MaxReturn : 160.0\n",
            "Train_MinReturn : 70.0\n",
            "Train_AverageEpLen : 113.11111111111111\n",
            "Train_EnvstepsSoFar : 43570\n",
            "TimeSinceStart : 64.67710185050964\n",
            "Training Loss : 38506.0859375\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 42 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 123.75\n",
            "Eval_StdReturn : 37.432437896728516\n",
            "Eval_MaxReturn : 184.0\n",
            "Eval_MinReturn : 85.0\n",
            "Eval_AverageEpLen : 123.75\n",
            "Train_AverageReturn : 118.55555725097656\n",
            "Train_StdReturn : 45.57804489135742\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 76.0\n",
            "Train_AverageEpLen : 118.55555555555556\n",
            "Train_EnvstepsSoFar : 44637\n",
            "TimeSinceStart : 66.26321625709534\n",
            "Training Loss : 44039.6171875\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 43 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 97.80000305175781\n",
            "Eval_StdReturn : 18.861600875854492\n",
            "Eval_MaxReturn : 115.0\n",
            "Eval_MinReturn : 68.0\n",
            "Eval_AverageEpLen : 97.8\n",
            "Train_AverageReturn : 108.45454406738281\n",
            "Train_StdReturn : 32.02942657470703\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 79.0\n",
            "Train_AverageEpLen : 108.45454545454545\n",
            "Train_EnvstepsSoFar : 45830\n",
            "TimeSinceStart : 67.93895435333252\n",
            "Training Loss : 42177.4453125\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 44 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 133.6666717529297\n",
            "Eval_StdReturn : 48.21018981933594\n",
            "Eval_MaxReturn : 194.0\n",
            "Eval_MinReturn : 76.0\n",
            "Eval_AverageEpLen : 133.66666666666666\n",
            "Train_AverageReturn : 101.69999694824219\n",
            "Train_StdReturn : 26.05014419555664\n",
            "Train_MaxReturn : 148.0\n",
            "Train_MinReturn : 68.0\n",
            "Train_AverageEpLen : 101.7\n",
            "Train_EnvstepsSoFar : 46847\n",
            "TimeSinceStart : 69.3866810798645\n",
            "Training Loss : 31440.57421875\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 45 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 138.6666717529297\n",
            "Eval_StdReturn : 39.36439514160156\n",
            "Eval_MaxReturn : 193.0\n",
            "Eval_MinReturn : 101.0\n",
            "Eval_AverageEpLen : 138.66666666666666\n",
            "Train_AverageReturn : 116.69999694824219\n",
            "Train_StdReturn : 29.80956268310547\n",
            "Train_MaxReturn : 171.0\n",
            "Train_MinReturn : 63.0\n",
            "Train_AverageEpLen : 116.7\n",
            "Train_EnvstepsSoFar : 48014\n",
            "TimeSinceStart : 71.06908535957336\n",
            "Training Loss : 38445.9375\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 46 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 183.3333282470703\n",
            "Eval_StdReturn : 12.036980628967285\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 172.0\n",
            "Eval_AverageEpLen : 183.33333333333334\n",
            "Train_AverageReturn : 143.14285278320312\n",
            "Train_StdReturn : 30.130329132080078\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 90.0\n",
            "Train_AverageEpLen : 143.14285714285714\n",
            "Train_EnvstepsSoFar : 49016\n",
            "TimeSinceStart : 72.61893677711487\n",
            "Training Loss : 42117.9765625\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 47 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 197.6666717529297\n",
            "Eval_StdReturn : 3.2998316287994385\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 193.0\n",
            "Eval_AverageEpLen : 197.66666666666666\n",
            "Train_AverageReturn : 169.5\n",
            "Train_StdReturn : 15.924300193786621\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 149.0\n",
            "Train_AverageEpLen : 169.5\n",
            "Train_EnvstepsSoFar : 50033\n",
            "TimeSinceStart : 74.25000953674316\n",
            "Training Loss : 53257.625\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 48 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 140.6666717529297\n",
            "Eval_StdReturn : 10.624918937683105\n",
            "Eval_MaxReturn : 154.0\n",
            "Eval_MinReturn : 128.0\n",
            "Eval_AverageEpLen : 140.66666666666666\n",
            "Train_AverageReturn : 167.3333282470703\n",
            "Train_StdReturn : 23.371397018432617\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 140.0\n",
            "Train_AverageEpLen : 167.33333333333334\n",
            "Train_EnvstepsSoFar : 51037\n",
            "TimeSinceStart : 75.7053234577179\n",
            "Training Loss : 52565.45703125\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 49 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 168.0\n",
            "Train_StdReturn : 22.24110221862793\n",
            "Train_MaxReturn : 195.0\n",
            "Train_MinReturn : 125.0\n",
            "Train_AverageEpLen : 168.0\n",
            "Train_EnvstepsSoFar : 52045\n",
            "TimeSinceStart : 77.13764023780823\n",
            "Training Loss : 50781.578125\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 50 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 166.6666717529297\n",
            "Eval_StdReturn : 20.677417755126953\n",
            "Eval_MaxReturn : 186.0\n",
            "Eval_MinReturn : 138.0\n",
            "Eval_AverageEpLen : 166.66666666666666\n",
            "Train_AverageReturn : 159.85714721679688\n",
            "Train_StdReturn : 28.772153854370117\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 121.0\n",
            "Train_AverageEpLen : 159.85714285714286\n",
            "Train_EnvstepsSoFar : 53164\n",
            "TimeSinceStart : 78.74933648109436\n",
            "Training Loss : 49121.06640625\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 51 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 172.3333282470703\n",
            "Eval_StdReturn : 32.96799850463867\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 126.0\n",
            "Eval_AverageEpLen : 172.33333333333334\n",
            "Train_AverageReturn : 147.75\n",
            "Train_StdReturn : 29.350255966186523\n",
            "Train_MaxReturn : 189.0\n",
            "Train_MinReturn : 83.0\n",
            "Train_AverageEpLen : 147.75\n",
            "Train_EnvstepsSoFar : 54346\n",
            "TimeSinceStart : 80.63382387161255\n",
            "Training Loss : 43719.0234375\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 52 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 176.6666717529297\n",
            "Train_StdReturn : 21.00528907775879\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 136.0\n",
            "Train_AverageEpLen : 176.66666666666666\n",
            "Train_EnvstepsSoFar : 55406\n",
            "TimeSinceStart : 82.11880683898926\n",
            "Training Loss : 49435.5859375\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 53 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 151.3333282470703\n",
            "Eval_StdReturn : 34.499595642089844\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 124.0\n",
            "Eval_AverageEpLen : 151.33333333333334\n",
            "Train_AverageReturn : 139.0\n",
            "Train_StdReturn : 32.855743408203125\n",
            "Train_MaxReturn : 182.0\n",
            "Train_MinReturn : 92.0\n",
            "Train_AverageEpLen : 139.0\n",
            "Train_EnvstepsSoFar : 56518\n",
            "TimeSinceStart : 83.70603156089783\n",
            "Training Loss : 38642.8125\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 54 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 160.6666717529297\n",
            "Eval_StdReturn : 37.606143951416016\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 110.0\n",
            "Eval_AverageEpLen : 160.66666666666666\n",
            "Train_AverageReturn : 133.125\n",
            "Train_StdReturn : 37.29087448120117\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 89.0\n",
            "Train_AverageEpLen : 133.125\n",
            "Train_EnvstepsSoFar : 57583\n",
            "TimeSinceStart : 85.33667492866516\n",
            "Training Loss : 38107.09765625\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 55 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 134.3333282470703\n",
            "Eval_StdReturn : 24.904260635375977\n",
            "Eval_MaxReturn : 165.0\n",
            "Eval_MinReturn : 104.0\n",
            "Eval_AverageEpLen : 134.33333333333334\n",
            "Train_AverageReturn : 168.0\n",
            "Train_StdReturn : 33.63034439086914\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 116.0\n",
            "Train_AverageEpLen : 168.0\n",
            "Train_EnvstepsSoFar : 58591\n",
            "TimeSinceStart : 86.77319622039795\n",
            "Training Loss : 39980.37890625\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 56 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 143.3333282470703\n",
            "Eval_StdReturn : 41.249916076660156\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 103.0\n",
            "Eval_AverageEpLen : 143.33333333333334\n",
            "Train_AverageReturn : 129.625\n",
            "Train_StdReturn : 48.197349548339844\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 78.0\n",
            "Train_AverageEpLen : 129.625\n",
            "Train_EnvstepsSoFar : 59628\n",
            "TimeSinceStart : 88.26236701011658\n",
            "Training Loss : 36071.6328125\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 57 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 172.0\n",
            "Eval_StdReturn : 19.815818786621094\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 157.0\n",
            "Eval_AverageEpLen : 172.0\n",
            "Train_AverageReturn : 138.5\n",
            "Train_StdReturn : 30.385028839111328\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 104.0\n",
            "Train_AverageEpLen : 138.5\n",
            "Train_EnvstepsSoFar : 60736\n",
            "TimeSinceStart : 89.95921540260315\n",
            "Training Loss : 42584.19921875\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 58 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 151.6666717529297\n",
            "Eval_StdReturn : 4.189935207366943\n",
            "Eval_MaxReturn : 156.0\n",
            "Eval_MinReturn : 146.0\n",
            "Eval_AverageEpLen : 151.66666666666666\n",
            "Train_AverageReturn : 164.2857208251953\n",
            "Train_StdReturn : 22.249971389770508\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 132.0\n",
            "Train_AverageEpLen : 164.28571428571428\n",
            "Train_EnvstepsSoFar : 61886\n",
            "TimeSinceStart : 91.93483352661133\n",
            "Training Loss : 42280.13671875\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 59 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 118.5\n",
            "Eval_StdReturn : 26.253570556640625\n",
            "Eval_MaxReturn : 152.0\n",
            "Eval_MinReturn : 81.0\n",
            "Eval_AverageEpLen : 118.5\n",
            "Train_AverageReturn : 148.85714721679688\n",
            "Train_StdReturn : 35.65080261230469\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 100.0\n",
            "Train_AverageEpLen : 148.85714285714286\n",
            "Train_EnvstepsSoFar : 62928\n",
            "TimeSinceStart : 93.45658755302429\n",
            "Training Loss : 34493.97265625\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 60 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 124.0\n",
            "Eval_StdReturn : 30.02499008178711\n",
            "Eval_MaxReturn : 169.0\n",
            "Eval_MinReturn : 86.0\n",
            "Eval_AverageEpLen : 124.0\n",
            "Train_AverageReturn : 119.66666412353516\n",
            "Train_StdReturn : 31.67192840576172\n",
            "Train_MaxReturn : 178.0\n",
            "Train_MinReturn : 72.0\n",
            "Train_AverageEpLen : 119.66666666666667\n",
            "Train_EnvstepsSoFar : 64005\n",
            "TimeSinceStart : 95.2488842010498\n",
            "Training Loss : 34092.26171875\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 61 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 97.80000305175781\n",
            "Eval_StdReturn : 11.68588924407959\n",
            "Eval_MaxReturn : 109.0\n",
            "Eval_MinReturn : 76.0\n",
            "Eval_AverageEpLen : 97.8\n",
            "Train_AverageReturn : 107.80000305175781\n",
            "Train_StdReturn : 33.2950439453125\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 75.0\n",
            "Train_AverageEpLen : 107.8\n",
            "Train_EnvstepsSoFar : 65083\n",
            "TimeSinceStart : 96.87178182601929\n",
            "Training Loss : 26004.28125\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 62 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 104.75\n",
            "Eval_StdReturn : 33.063385009765625\n",
            "Eval_MaxReturn : 145.0\n",
            "Eval_MinReturn : 66.0\n",
            "Eval_AverageEpLen : 104.75\n",
            "Train_AverageReturn : 87.5\n",
            "Train_StdReturn : 11.842719078063965\n",
            "Train_MaxReturn : 111.0\n",
            "Train_MinReturn : 71.0\n",
            "Train_AverageEpLen : 87.5\n",
            "Train_EnvstepsSoFar : 66133\n",
            "TimeSinceStart : 98.35782313346863\n",
            "Training Loss : 20421.919921875\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 63 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 87.19999694824219\n",
            "Eval_StdReturn : 16.1666316986084\n",
            "Eval_MaxReturn : 117.0\n",
            "Eval_MinReturn : 72.0\n",
            "Eval_AverageEpLen : 87.2\n",
            "Train_AverageReturn : 114.88888549804688\n",
            "Train_StdReturn : 33.03346633911133\n",
            "Train_MaxReturn : 181.0\n",
            "Train_MinReturn : 66.0\n",
            "Train_AverageEpLen : 114.88888888888889\n",
            "Train_EnvstepsSoFar : 67167\n",
            "TimeSinceStart : 99.84456014633179\n",
            "Training Loss : 28963.173828125\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 64 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 72.33333587646484\n",
            "Eval_StdReturn : 11.64283275604248\n",
            "Eval_MaxReturn : 88.0\n",
            "Eval_MinReturn : 54.0\n",
            "Eval_AverageEpLen : 72.33333333333333\n",
            "Train_AverageReturn : 92.2727279663086\n",
            "Train_StdReturn : 32.01729965209961\n",
            "Train_MaxReturn : 157.0\n",
            "Train_MinReturn : 57.0\n",
            "Train_AverageEpLen : 92.27272727272727\n",
            "Train_EnvstepsSoFar : 68182\n",
            "TimeSinceStart : 101.3262345790863\n",
            "Training Loss : 21878.671875\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 65 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 69.0\n",
            "Eval_StdReturn : 18.583147048950195\n",
            "Eval_MaxReturn : 108.0\n",
            "Eval_MinReturn : 54.0\n",
            "Eval_AverageEpLen : 69.0\n",
            "Train_AverageReturn : 79.53845977783203\n",
            "Train_StdReturn : 17.946996688842773\n",
            "Train_MaxReturn : 111.0\n",
            "Train_MinReturn : 48.0\n",
            "Train_AverageEpLen : 79.53846153846153\n",
            "Train_EnvstepsSoFar : 69216\n",
            "TimeSinceStart : 102.92574572563171\n",
            "Training Loss : 17207.140625\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 66 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 73.0\n",
            "Eval_StdReturn : 16.031219482421875\n",
            "Eval_MaxReturn : 94.0\n",
            "Eval_MinReturn : 48.0\n",
            "Eval_AverageEpLen : 73.0\n",
            "Train_AverageReturn : 70.93333435058594\n",
            "Train_StdReturn : 15.804923057556152\n",
            "Train_MaxReturn : 114.0\n",
            "Train_MinReturn : 52.0\n",
            "Train_AverageEpLen : 70.93333333333334\n",
            "Train_EnvstepsSoFar : 70280\n",
            "TimeSinceStart : 104.5452151298523\n",
            "Training Loss : 14724.052734375\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 67 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 61.42856979370117\n",
            "Eval_StdReturn : 7.027642250061035\n",
            "Eval_MaxReturn : 72.0\n",
            "Eval_MinReturn : 49.0\n",
            "Eval_AverageEpLen : 61.42857142857143\n",
            "Train_AverageReturn : 65.375\n",
            "Train_StdReturn : 16.859251022338867\n",
            "Train_MaxReturn : 109.0\n",
            "Train_MinReturn : 47.0\n",
            "Train_AverageEpLen : 65.375\n",
            "Train_EnvstepsSoFar : 71326\n",
            "TimeSinceStart : 106.08674025535583\n",
            "Training Loss : 15721.38671875\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 68 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 65.14286041259766\n",
            "Eval_StdReturn : 10.232003211975098\n",
            "Eval_MaxReturn : 84.0\n",
            "Eval_MinReturn : 49.0\n",
            "Eval_AverageEpLen : 65.14285714285714\n",
            "Train_AverageReturn : 65.5625\n",
            "Train_StdReturn : 17.237201690673828\n",
            "Train_MaxReturn : 97.0\n",
            "Train_MinReturn : 39.0\n",
            "Train_AverageEpLen : 65.5625\n",
            "Train_EnvstepsSoFar : 72375\n",
            "TimeSinceStart : 107.82336521148682\n",
            "Training Loss : 15436.0966796875\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 69 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 64.0\n",
            "Eval_StdReturn : 11.964232444763184\n",
            "Eval_MaxReturn : 84.0\n",
            "Eval_MinReturn : 48.0\n",
            "Eval_AverageEpLen : 64.0\n",
            "Train_AverageReturn : 65.0625\n",
            "Train_StdReturn : 13.658645629882812\n",
            "Train_MaxReturn : 97.0\n",
            "Train_MinReturn : 46.0\n",
            "Train_AverageEpLen : 65.0625\n",
            "Train_EnvstepsSoFar : 73416\n",
            "TimeSinceStart : 109.34491419792175\n",
            "Training Loss : 13700.861328125\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 70 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 62.71428680419922\n",
            "Eval_StdReturn : 10.38837718963623\n",
            "Eval_MaxReturn : 81.0\n",
            "Eval_MinReturn : 48.0\n",
            "Eval_AverageEpLen : 62.714285714285715\n",
            "Train_AverageReturn : 60.82352828979492\n",
            "Train_StdReturn : 13.844664573669434\n",
            "Train_MaxReturn : 97.0\n",
            "Train_MinReturn : 43.0\n",
            "Train_AverageEpLen : 60.8235294117647\n",
            "Train_EnvstepsSoFar : 74450\n",
            "TimeSinceStart : 110.81994819641113\n",
            "Training Loss : 16286.037109375\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 71 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 64.28571319580078\n",
            "Eval_StdReturn : 17.67738151550293\n",
            "Eval_MaxReturn : 93.0\n",
            "Eval_MinReturn : 46.0\n",
            "Eval_AverageEpLen : 64.28571428571429\n",
            "Train_AverageReturn : 62.9375\n",
            "Train_StdReturn : 17.397804260253906\n",
            "Train_MaxReturn : 97.0\n",
            "Train_MinReturn : 39.0\n",
            "Train_AverageEpLen : 62.9375\n",
            "Train_EnvstepsSoFar : 75457\n",
            "TimeSinceStart : 112.31887340545654\n",
            "Training Loss : 15720.544921875\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 72 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 60.71428680419922\n",
            "Eval_StdReturn : 11.335333824157715\n",
            "Eval_MaxReturn : 81.0\n",
            "Eval_MinReturn : 50.0\n",
            "Eval_AverageEpLen : 60.714285714285715\n",
            "Train_AverageReturn : 62.764705657958984\n",
            "Train_StdReturn : 15.603655815124512\n",
            "Train_MaxReturn : 100.0\n",
            "Train_MinReturn : 42.0\n",
            "Train_AverageEpLen : 62.76470588235294\n",
            "Train_EnvstepsSoFar : 76524\n",
            "TimeSinceStart : 113.81249523162842\n",
            "Training Loss : 12523.8603515625\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 73 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 69.42857360839844\n",
            "Eval_StdReturn : 18.204059600830078\n",
            "Eval_MaxReturn : 102.0\n",
            "Eval_MinReturn : 50.0\n",
            "Eval_AverageEpLen : 69.42857142857143\n",
            "Train_AverageReturn : 63.29411697387695\n",
            "Train_StdReturn : 12.759147644042969\n",
            "Train_MaxReturn : 91.0\n",
            "Train_MinReturn : 47.0\n",
            "Train_AverageEpLen : 63.294117647058826\n",
            "Train_EnvstepsSoFar : 77600\n",
            "TimeSinceStart : 115.39635848999023\n",
            "Training Loss : 13618.05078125\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 74 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 78.16666412353516\n",
            "Eval_StdReturn : 23.989002227783203\n",
            "Eval_MaxReturn : 114.0\n",
            "Eval_MinReturn : 50.0\n",
            "Eval_AverageEpLen : 78.16666666666667\n",
            "Train_AverageReturn : 68.0\n",
            "Train_StdReturn : 11.7189302444458\n",
            "Train_MaxReturn : 96.0\n",
            "Train_MinReturn : 52.0\n",
            "Train_AverageEpLen : 68.0\n",
            "Train_EnvstepsSoFar : 78620\n",
            "TimeSinceStart : 116.94183158874512\n",
            "Training Loss : 16177.3896484375\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 75 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 71.16666412353516\n",
            "Eval_StdReturn : 20.061710357666016\n",
            "Eval_MaxReturn : 99.0\n",
            "Eval_MinReturn : 50.0\n",
            "Eval_AverageEpLen : 71.16666666666667\n",
            "Train_AverageReturn : 71.57142639160156\n",
            "Train_StdReturn : 19.249170303344727\n",
            "Train_MaxReturn : 106.0\n",
            "Train_MinReturn : 49.0\n",
            "Train_AverageEpLen : 71.57142857142857\n",
            "Train_EnvstepsSoFar : 79622\n",
            "TimeSinceStart : 118.39671683311462\n",
            "Training Loss : 15231.0576171875\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 76 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 66.57142639160156\n",
            "Eval_StdReturn : 10.55403995513916\n",
            "Eval_MaxReturn : 88.0\n",
            "Eval_MinReturn : 52.0\n",
            "Eval_AverageEpLen : 66.57142857142857\n",
            "Train_AverageReturn : 65.375\n",
            "Train_StdReturn : 15.579935073852539\n",
            "Train_MaxReturn : 98.0\n",
            "Train_MinReturn : 44.0\n",
            "Train_AverageEpLen : 65.375\n",
            "Train_EnvstepsSoFar : 80668\n",
            "TimeSinceStart : 119.93588781356812\n",
            "Training Loss : 15278.583984375\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 77 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 67.0\n",
            "Eval_StdReturn : 13.089435577392578\n",
            "Eval_MaxReturn : 93.0\n",
            "Eval_MinReturn : 54.0\n",
            "Eval_AverageEpLen : 67.0\n",
            "Train_AverageReturn : 63.5625\n",
            "Train_StdReturn : 12.06735610961914\n",
            "Train_MaxReturn : 87.0\n",
            "Train_MinReturn : 49.0\n",
            "Train_AverageEpLen : 63.5625\n",
            "Train_EnvstepsSoFar : 81685\n",
            "TimeSinceStart : 121.38455200195312\n",
            "Training Loss : 13168.5029296875\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 78 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 75.66666412353516\n",
            "Eval_StdReturn : 12.77584457397461\n",
            "Eval_MaxReturn : 93.0\n",
            "Eval_MinReturn : 60.0\n",
            "Eval_AverageEpLen : 75.66666666666667\n",
            "Train_AverageReturn : 68.19999694824219\n",
            "Train_StdReturn : 20.30500602722168\n",
            "Train_MaxReturn : 128.0\n",
            "Train_MinReturn : 45.0\n",
            "Train_AverageEpLen : 68.2\n",
            "Train_EnvstepsSoFar : 82708\n",
            "TimeSinceStart : 122.89111185073853\n",
            "Training Loss : 16208.5029296875\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 79 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 90.0\n",
            "Eval_StdReturn : 24.62519073486328\n",
            "Eval_MaxReturn : 121.0\n",
            "Eval_MinReturn : 61.0\n",
            "Eval_AverageEpLen : 90.0\n",
            "Train_AverageReturn : 79.15384674072266\n",
            "Train_StdReturn : 23.585674285888672\n",
            "Train_MaxReturn : 129.0\n",
            "Train_MinReturn : 53.0\n",
            "Train_AverageEpLen : 79.15384615384616\n",
            "Train_EnvstepsSoFar : 83737\n",
            "TimeSinceStart : 124.41793417930603\n",
            "Training Loss : 19240.0546875\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 80 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 86.80000305175781\n",
            "Eval_StdReturn : 21.37662124633789\n",
            "Eval_MaxReturn : 124.0\n",
            "Eval_MinReturn : 63.0\n",
            "Eval_AverageEpLen : 86.8\n",
            "Train_AverageReturn : 78.21428680419922\n",
            "Train_StdReturn : 17.101287841796875\n",
            "Train_MaxReturn : 111.0\n",
            "Train_MinReturn : 57.0\n",
            "Train_AverageEpLen : 78.21428571428571\n",
            "Train_EnvstepsSoFar : 84832\n",
            "TimeSinceStart : 125.96143245697021\n",
            "Training Loss : 16446.91015625\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 81 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 82.0\n",
            "Eval_StdReturn : 17.729448318481445\n",
            "Eval_MaxReturn : 109.0\n",
            "Eval_MinReturn : 60.0\n",
            "Eval_AverageEpLen : 82.0\n",
            "Train_AverageReturn : 86.91666412353516\n",
            "Train_StdReturn : 25.02151870727539\n",
            "Train_MaxReturn : 135.0\n",
            "Train_MinReturn : 64.0\n",
            "Train_AverageEpLen : 86.91666666666667\n",
            "Train_EnvstepsSoFar : 85875\n",
            "TimeSinceStart : 127.52613997459412\n",
            "Training Loss : 19173.05078125\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 82 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 108.5\n",
            "Eval_StdReturn : 27.941904067993164\n",
            "Eval_MaxReturn : 146.0\n",
            "Eval_MinReturn : 76.0\n",
            "Eval_AverageEpLen : 108.5\n",
            "Train_AverageReturn : 85.25\n",
            "Train_StdReturn : 31.92210578918457\n",
            "Train_MaxReturn : 180.0\n",
            "Train_MinReturn : 58.0\n",
            "Train_AverageEpLen : 85.25\n",
            "Train_EnvstepsSoFar : 86898\n",
            "TimeSinceStart : 129.06602787971497\n",
            "Training Loss : 20401.25\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 83 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 107.25\n",
            "Eval_StdReturn : 45.9367790222168\n",
            "Eval_MaxReturn : 185.0\n",
            "Eval_MinReturn : 71.0\n",
            "Eval_AverageEpLen : 107.25\n",
            "Train_AverageReturn : 87.16666412353516\n",
            "Train_StdReturn : 23.995946884155273\n",
            "Train_MaxReturn : 144.0\n",
            "Train_MinReturn : 55.0\n",
            "Train_AverageEpLen : 87.16666666666667\n",
            "Train_EnvstepsSoFar : 87944\n",
            "TimeSinceStart : 130.55869841575623\n",
            "Training Loss : 21349.810546875\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 84 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 112.5\n",
            "Eval_StdReturn : 23.900836944580078\n",
            "Eval_MaxReturn : 153.0\n",
            "Eval_MinReturn : 91.0\n",
            "Eval_AverageEpLen : 112.5\n",
            "Train_AverageReturn : 101.30000305175781\n",
            "Train_StdReturn : 31.59129524230957\n",
            "Train_MaxReturn : 189.0\n",
            "Train_MinReturn : 76.0\n",
            "Train_AverageEpLen : 101.3\n",
            "Train_EnvstepsSoFar : 88957\n",
            "TimeSinceStart : 132.21210718154907\n",
            "Training Loss : 24094.08203125\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 85 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 158.0\n",
            "Eval_StdReturn : 32.124755859375\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 122.0\n",
            "Eval_AverageEpLen : 158.0\n",
            "Train_AverageReturn : 102.7272720336914\n",
            "Train_StdReturn : 24.976682662963867\n",
            "Train_MaxReturn : 149.0\n",
            "Train_MinReturn : 70.0\n",
            "Train_AverageEpLen : 102.72727272727273\n",
            "Train_EnvstepsSoFar : 90087\n",
            "TimeSinceStart : 134.14071774482727\n",
            "Training Loss : 27077.05859375\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 86 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 140.3333282470703\n",
            "Eval_StdReturn : 29.555971145629883\n",
            "Eval_MaxReturn : 170.0\n",
            "Eval_MinReturn : 100.0\n",
            "Eval_AverageEpLen : 140.33333333333334\n",
            "Train_AverageReturn : 131.125\n",
            "Train_StdReturn : 46.182891845703125\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 83.0\n",
            "Train_AverageEpLen : 131.125\n",
            "Train_EnvstepsSoFar : 91136\n",
            "TimeSinceStart : 135.6269416809082\n",
            "Training Loss : 37379.015625\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 87 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 110.5\n",
            "Eval_StdReturn : 20.71834945678711\n",
            "Eval_MaxReturn : 138.0\n",
            "Eval_MinReturn : 89.0\n",
            "Eval_AverageEpLen : 110.5\n",
            "Train_AverageReturn : 117.0\n",
            "Train_StdReturn : 22.181072235107422\n",
            "Train_MaxReturn : 158.0\n",
            "Train_MinReturn : 90.0\n",
            "Train_AverageEpLen : 117.0\n",
            "Train_EnvstepsSoFar : 92189\n",
            "TimeSinceStart : 137.16696691513062\n",
            "Training Loss : 26915.986328125\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 88 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 163.3333282470703\n",
            "Eval_StdReturn : 28.015867233276367\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 132.0\n",
            "Eval_AverageEpLen : 163.33333333333334\n",
            "Train_AverageReturn : 126.125\n",
            "Train_StdReturn : 23.040386199951172\n",
            "Train_MaxReturn : 172.0\n",
            "Train_MinReturn : 99.0\n",
            "Train_AverageEpLen : 126.125\n",
            "Train_EnvstepsSoFar : 93198\n",
            "TimeSinceStart : 138.67359328269958\n",
            "Training Loss : 28523.3671875\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 89 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 183.6666717529297\n",
            "Eval_StdReturn : 23.09882164001465\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 151.0\n",
            "Eval_AverageEpLen : 183.66666666666666\n",
            "Train_AverageReturn : 154.0\n",
            "Train_StdReturn : 30.78032875061035\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 119.0\n",
            "Train_AverageEpLen : 154.0\n",
            "Train_EnvstepsSoFar : 94276\n",
            "TimeSinceStart : 140.3275785446167\n",
            "Training Loss : 41716.375\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 90 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 168.0\n",
            "Eval_StdReturn : 28.390138626098633\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 131.0\n",
            "Eval_AverageEpLen : 168.0\n",
            "Train_AverageReturn : 160.0\n",
            "Train_StdReturn : 32.33750534057617\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 110.0\n",
            "Train_AverageEpLen : 160.0\n",
            "Train_EnvstepsSoFar : 95396\n",
            "TimeSinceStart : 142.02158284187317\n",
            "Training Loss : 42804.765625\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 91 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 145.0\n",
            "Eval_StdReturn : 39.25132751464844\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 111.0\n",
            "Eval_AverageEpLen : 145.0\n",
            "Train_AverageReturn : 154.0\n",
            "Train_StdReturn : 37.205989837646484\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 104.0\n",
            "Train_AverageEpLen : 154.0\n",
            "Train_EnvstepsSoFar : 96474\n",
            "TimeSinceStart : 143.5800426006317\n",
            "Training Loss : 39781.8515625\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 92 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 154.6666717529297\n",
            "Eval_StdReturn : 33.76717758178711\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 119.0\n",
            "Eval_AverageEpLen : 154.66666666666666\n",
            "Train_AverageReturn : 138.125\n",
            "Train_StdReturn : 42.48069381713867\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 73.0\n",
            "Train_AverageEpLen : 138.125\n",
            "Train_EnvstepsSoFar : 97579\n",
            "TimeSinceStart : 145.46145868301392\n",
            "Training Loss : 42927.484375\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 93 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 180.0\n",
            "Eval_StdReturn : 20.39607810974121\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 152.0\n",
            "Eval_AverageEpLen : 180.0\n",
            "Train_AverageReturn : 144.75\n",
            "Train_StdReturn : 33.703670501708984\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 111.0\n",
            "Train_AverageEpLen : 144.75\n",
            "Train_EnvstepsSoFar : 98737\n",
            "TimeSinceStart : 147.20490980148315\n",
            "Training Loss : 41273.3828125\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 94 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 164.0\n",
            "Eval_StdReturn : 28.994253158569336\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 129.0\n",
            "Eval_AverageEpLen : 164.0\n",
            "Train_AverageReturn : 162.0\n",
            "Train_StdReturn : 25.286924362182617\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 123.0\n",
            "Train_AverageEpLen : 162.0\n",
            "Train_EnvstepsSoFar : 99871\n",
            "TimeSinceStart : 148.83004879951477\n",
            "Training Loss : 49403.0859375\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 95 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 169.3333282470703\n",
            "Eval_StdReturn : 6.12825870513916\n",
            "Eval_MaxReturn : 177.0\n",
            "Eval_MinReturn : 162.0\n",
            "Eval_AverageEpLen : 169.33333333333334\n",
            "Train_AverageReturn : 170.0\n",
            "Train_StdReturn : 22.41279411315918\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 141.0\n",
            "Train_AverageEpLen : 170.0\n",
            "Train_EnvstepsSoFar : 100891\n",
            "TimeSinceStart : 150.36718320846558\n",
            "Training Loss : 43222.26171875\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 96 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 178.0\n",
            "Eval_StdReturn : 25.66450309753418\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 142.0\n",
            "Eval_AverageEpLen : 178.0\n",
            "Train_AverageReturn : 170.1666717529297\n",
            "Train_StdReturn : 29.655895233154297\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 120.0\n",
            "Train_AverageEpLen : 170.16666666666666\n",
            "Train_EnvstepsSoFar : 101912\n",
            "TimeSinceStart : 151.92362427711487\n",
            "Training Loss : 51011.51953125\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 97 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 156.0\n",
            "Eval_StdReturn : 31.790985107421875\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 126.0\n",
            "Eval_AverageEpLen : 156.0\n",
            "Train_AverageReturn : 169.8333282470703\n",
            "Train_StdReturn : 22.952245712280273\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 137.0\n",
            "Train_AverageEpLen : 169.83333333333334\n",
            "Train_EnvstepsSoFar : 102931\n",
            "TimeSinceStart : 153.42232966423035\n",
            "Training Loss : 49788.3828125\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 98 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 192.0\n",
            "Eval_StdReturn : 11.313708305358887\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 176.0\n",
            "Eval_AverageEpLen : 192.0\n",
            "Train_AverageReturn : 175.8333282470703\n",
            "Train_StdReturn : 23.36248207092285\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 141.0\n",
            "Train_AverageEpLen : 175.83333333333334\n",
            "Train_EnvstepsSoFar : 103986\n",
            "TimeSinceStart : 155.0846095085144\n",
            "Training Loss : 53168.3359375\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 99 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 181.0\n",
            "Eval_StdReturn : 16.391054153442383\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 160.0\n",
            "Eval_AverageEpLen : 181.0\n",
            "Train_AverageReturn : 185.1666717529297\n",
            "Train_StdReturn : 22.80655288696289\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 140.0\n",
            "Train_AverageEpLen : 185.16666666666666\n",
            "Train_EnvstepsSoFar : 105097\n",
            "TimeSinceStart : 156.7479808330536\n",
            "Training Loss : 57939.0\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python cs285/scripts/run_hw2.py --env_name CartPole-v0 -n 100 -b 1000 \\\n",
        "-dsa --exp_name q1_sb_no_rtg_dsa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "psW_aBlMmWfZ",
        "outputId": "6a4d19e5-8dea-49b1-aefd-4467f6782065"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "########################\n",
            "logging outputs to  /content/gdrive/My Drive/cs285_f2021/DRL_policy_grads/cs285/scripts/../../data/q2_pg_q1_sb_rtg_dsa_CartPole-v0_04-02-2022_16-40-57\n",
            "########################\n",
            "Using GPU id 0\n",
            "\n",
            "\n",
            "********** Iteration 0 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 28.85714340209961\n",
            "Eval_StdReturn : 13.579696655273438\n",
            "Eval_MaxReturn : 59.0\n",
            "Eval_MinReturn : 12.0\n",
            "Eval_AverageEpLen : 28.857142857142858\n",
            "Train_AverageReturn : 27.648649215698242\n",
            "Train_StdReturn : 12.643160820007324\n",
            "Train_MaxReturn : 65.0\n",
            "Train_MinReturn : 11.0\n",
            "Train_AverageEpLen : 27.64864864864865\n",
            "Train_EnvstepsSoFar : 1023\n",
            "TimeSinceStart : 1.5118110179901123\n",
            "Training Loss : 22864.16796875\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 1 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 35.75\n",
            "Eval_StdReturn : 18.828723907470703\n",
            "Eval_MaxReturn : 84.0\n",
            "Eval_MinReturn : 17.0\n",
            "Eval_AverageEpLen : 35.75\n",
            "Train_AverageReturn : 34.517242431640625\n",
            "Train_StdReturn : 24.89650535583496\n",
            "Train_MaxReturn : 124.0\n",
            "Train_MinReturn : 10.0\n",
            "Train_AverageEpLen : 34.51724137931034\n",
            "Train_EnvstepsSoFar : 2024\n",
            "TimeSinceStart : 2.9677908420562744\n",
            "Training Loss : 34364.06640625\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 2 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 45.77777862548828\n",
            "Eval_StdReturn : 21.760196685791016\n",
            "Eval_MaxReturn : 86.0\n",
            "Eval_MinReturn : 17.0\n",
            "Eval_AverageEpLen : 45.77777777777778\n",
            "Train_AverageReturn : 36.60714340209961\n",
            "Train_StdReturn : 19.032564163208008\n",
            "Train_MaxReturn : 80.0\n",
            "Train_MinReturn : 11.0\n",
            "Train_AverageEpLen : 36.607142857142854\n",
            "Train_EnvstepsSoFar : 3049\n",
            "TimeSinceStart : 4.5085344314575195\n",
            "Training Loss : 30112.818359375\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 3 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 50.375\n",
            "Eval_StdReturn : 21.885711669921875\n",
            "Eval_MaxReturn : 96.0\n",
            "Eval_MinReturn : 24.0\n",
            "Eval_AverageEpLen : 50.375\n",
            "Train_AverageReturn : 48.619049072265625\n",
            "Train_StdReturn : 26.29227066040039\n",
            "Train_MaxReturn : 121.0\n",
            "Train_MinReturn : 17.0\n",
            "Train_AverageEpLen : 48.61904761904762\n",
            "Train_EnvstepsSoFar : 4070\n",
            "TimeSinceStart : 6.022811412811279\n",
            "Training Loss : 39109.4453125\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 4 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 72.71428680419922\n",
            "Eval_StdReturn : 34.927330017089844\n",
            "Eval_MaxReturn : 155.0\n",
            "Eval_MinReturn : 45.0\n",
            "Eval_AverageEpLen : 72.71428571428571\n",
            "Train_AverageReturn : 59.82352828979492\n",
            "Train_StdReturn : 25.2452335357666\n",
            "Train_MaxReturn : 104.0\n",
            "Train_MinReturn : 25.0\n",
            "Train_AverageEpLen : 59.8235294117647\n",
            "Train_EnvstepsSoFar : 5087\n",
            "TimeSinceStart : 7.630367279052734\n",
            "Training Loss : 43453.75390625\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 5 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 58.42856979370117\n",
            "Eval_StdReturn : 24.10013198852539\n",
            "Eval_MaxReturn : 104.0\n",
            "Eval_MinReturn : 36.0\n",
            "Eval_AverageEpLen : 58.42857142857143\n",
            "Train_AverageReturn : 52.29999923706055\n",
            "Train_StdReturn : 16.392375946044922\n",
            "Train_MaxReturn : 100.0\n",
            "Train_MinReturn : 30.0\n",
            "Train_AverageEpLen : 52.3\n",
            "Train_EnvstepsSoFar : 6133\n",
            "TimeSinceStart : 9.150901079177856\n",
            "Training Loss : 35003.265625\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 6 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 56.5\n",
            "Eval_StdReturn : 14.124446868896484\n",
            "Eval_MaxReturn : 86.0\n",
            "Eval_MinReturn : 37.0\n",
            "Eval_AverageEpLen : 56.5\n",
            "Train_AverageReturn : 81.30769348144531\n",
            "Train_StdReturn : 47.0178108215332\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 29.0\n",
            "Train_AverageEpLen : 81.3076923076923\n",
            "Train_EnvstepsSoFar : 7190\n",
            "TimeSinceStart : 10.71634817123413\n",
            "Training Loss : 67057.5078125\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 7 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 63.57143020629883\n",
            "Eval_StdReturn : 20.638778686523438\n",
            "Eval_MaxReturn : 96.0\n",
            "Eval_MinReturn : 33.0\n",
            "Eval_AverageEpLen : 63.57142857142857\n",
            "Train_AverageReturn : 55.94444274902344\n",
            "Train_StdReturn : 17.19971466064453\n",
            "Train_MaxReturn : 97.0\n",
            "Train_MinReturn : 19.0\n",
            "Train_AverageEpLen : 55.94444444444444\n",
            "Train_EnvstepsSoFar : 8197\n",
            "TimeSinceStart : 12.262415885925293\n",
            "Training Loss : 34342.21875\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 8 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 51.5\n",
            "Eval_StdReturn : 21.05944061279297\n",
            "Eval_MaxReturn : 86.0\n",
            "Eval_MinReturn : 29.0\n",
            "Eval_AverageEpLen : 51.5\n",
            "Train_AverageReturn : 71.80000305175781\n",
            "Train_StdReturn : 31.726329803466797\n",
            "Train_MaxReturn : 154.0\n",
            "Train_MinReturn : 29.0\n",
            "Train_AverageEpLen : 71.8\n",
            "Train_EnvstepsSoFar : 9274\n",
            "TimeSinceStart : 13.849619388580322\n",
            "Training Loss : 52076.828125\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 9 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 108.5999984741211\n",
            "Eval_StdReturn : 53.40262222290039\n",
            "Eval_MaxReturn : 182.0\n",
            "Eval_MinReturn : 60.0\n",
            "Eval_AverageEpLen : 108.6\n",
            "Train_AverageReturn : 77.76923370361328\n",
            "Train_StdReturn : 40.89226531982422\n",
            "Train_MaxReturn : 164.0\n",
            "Train_MinReturn : 28.0\n",
            "Train_AverageEpLen : 77.76923076923077\n",
            "Train_EnvstepsSoFar : 10285\n",
            "TimeSinceStart : 15.472671747207642\n",
            "Training Loss : 55494.92578125\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 10 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 115.0\n",
            "Eval_StdReturn : 51.951900482177734\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 64.0\n",
            "Eval_AverageEpLen : 115.0\n",
            "Train_AverageReturn : 77.64286041259766\n",
            "Train_StdReturn : 33.064022064208984\n",
            "Train_MaxReturn : 183.0\n",
            "Train_MinReturn : 43.0\n",
            "Train_AverageEpLen : 77.64285714285714\n",
            "Train_EnvstepsSoFar : 11372\n",
            "TimeSinceStart : 17.051501750946045\n",
            "Training Loss : 52937.6484375\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 11 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 69.66666412353516\n",
            "Eval_StdReturn : 33.34499740600586\n",
            "Eval_MaxReturn : 139.0\n",
            "Eval_MinReturn : 34.0\n",
            "Eval_AverageEpLen : 69.66666666666667\n",
            "Train_AverageReturn : 89.66666412353516\n",
            "Train_StdReturn : 35.96139907836914\n",
            "Train_MaxReturn : 172.0\n",
            "Train_MinReturn : 41.0\n",
            "Train_AverageEpLen : 89.66666666666667\n",
            "Train_EnvstepsSoFar : 12448\n",
            "TimeSinceStart : 18.61513066291809\n",
            "Training Loss : 59370.328125\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 12 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 56.625\n",
            "Eval_StdReturn : 28.77037239074707\n",
            "Eval_MaxReturn : 119.0\n",
            "Eval_MinReturn : 26.0\n",
            "Eval_AverageEpLen : 56.625\n",
            "Train_AverageReturn : 78.73332977294922\n",
            "Train_StdReturn : 44.299686431884766\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 29.0\n",
            "Train_AverageEpLen : 78.73333333333333\n",
            "Train_EnvstepsSoFar : 13629\n",
            "TimeSinceStart : 20.330328464508057\n",
            "Training Loss : 58097.31640625\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 13 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 82.33333587646484\n",
            "Eval_StdReturn : 19.473628997802734\n",
            "Eval_MaxReturn : 111.0\n",
            "Eval_MinReturn : 45.0\n",
            "Eval_AverageEpLen : 82.33333333333333\n",
            "Train_AverageReturn : 68.80000305175781\n",
            "Train_StdReturn : 37.54322052001953\n",
            "Train_MaxReturn : 185.0\n",
            "Train_MinReturn : 29.0\n",
            "Train_AverageEpLen : 68.8\n",
            "Train_EnvstepsSoFar : 14661\n",
            "TimeSinceStart : 21.91715359687805\n",
            "Training Loss : 48788.4609375\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 14 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 86.0\n",
            "Eval_StdReturn : 31.83080291748047\n",
            "Eval_MaxReturn : 124.0\n",
            "Eval_MinReturn : 42.0\n",
            "Eval_AverageEpLen : 86.0\n",
            "Train_AverageReturn : 81.15384674072266\n",
            "Train_StdReturn : 26.749107360839844\n",
            "Train_MaxReturn : 129.0\n",
            "Train_MinReturn : 42.0\n",
            "Train_AverageEpLen : 81.15384615384616\n",
            "Train_EnvstepsSoFar : 15716\n",
            "TimeSinceStart : 23.482585906982422\n",
            "Training Loss : 48838.5703125\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 15 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 129.5\n",
            "Eval_StdReturn : 28.674901962280273\n",
            "Eval_MaxReturn : 163.0\n",
            "Eval_MinReturn : 84.0\n",
            "Eval_AverageEpLen : 129.5\n",
            "Train_AverageReturn : 88.16666412353516\n",
            "Train_StdReturn : 20.18593978881836\n",
            "Train_MaxReturn : 116.0\n",
            "Train_MinReturn : 51.0\n",
            "Train_AverageEpLen : 88.16666666666667\n",
            "Train_EnvstepsSoFar : 16774\n",
            "TimeSinceStart : 25.11539626121521\n",
            "Training Loss : 48618.046875\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 16 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 148.3333282470703\n",
            "Eval_StdReturn : 20.677417755126953\n",
            "Eval_MaxReturn : 177.0\n",
            "Eval_MinReturn : 129.0\n",
            "Eval_AverageEpLen : 148.33333333333334\n",
            "Train_AverageReturn : 113.4000015258789\n",
            "Train_StdReturn : 43.968624114990234\n",
            "Train_MaxReturn : 190.0\n",
            "Train_MinReturn : 44.0\n",
            "Train_AverageEpLen : 113.4\n",
            "Train_EnvstepsSoFar : 17908\n",
            "TimeSinceStart : 26.730021476745605\n",
            "Training Loss : 73504.796875\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 17 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 156.3333282470703\n",
            "Eval_StdReturn : 22.42518424987793\n",
            "Eval_MaxReturn : 187.0\n",
            "Eval_MinReturn : 134.0\n",
            "Eval_AverageEpLen : 156.33333333333334\n",
            "Train_AverageReturn : 147.57142639160156\n",
            "Train_StdReturn : 35.516021728515625\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 93.0\n",
            "Train_AverageEpLen : 147.57142857142858\n",
            "Train_EnvstepsSoFar : 18941\n",
            "TimeSinceStart : 28.30425715446472\n",
            "Training Loss : 76735.21875\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 18 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 100.19999694824219\n",
            "Eval_StdReturn : 40.40494918823242\n",
            "Eval_MaxReturn : 173.0\n",
            "Eval_MinReturn : 60.0\n",
            "Eval_AverageEpLen : 100.2\n",
            "Train_AverageReturn : 127.625\n",
            "Train_StdReturn : 37.9306526184082\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 74.0\n",
            "Train_AverageEpLen : 127.625\n",
            "Train_EnvstepsSoFar : 19962\n",
            "TimeSinceStart : 29.96126389503479\n",
            "Training Loss : 69618.6875\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 19 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 110.75\n",
            "Eval_StdReturn : 14.618053436279297\n",
            "Eval_MaxReturn : 125.0\n",
            "Eval_MinReturn : 90.0\n",
            "Eval_AverageEpLen : 110.75\n",
            "Train_AverageReturn : 110.19999694824219\n",
            "Train_StdReturn : 36.049407958984375\n",
            "Train_MaxReturn : 158.0\n",
            "Train_MinReturn : 41.0\n",
            "Train_AverageEpLen : 110.2\n",
            "Train_EnvstepsSoFar : 21064\n",
            "TimeSinceStart : 31.569462537765503\n",
            "Training Loss : 57578.00390625\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 20 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 101.75\n",
            "Eval_StdReturn : 16.990806579589844\n",
            "Eval_MaxReturn : 125.0\n",
            "Eval_MinReturn : 85.0\n",
            "Eval_AverageEpLen : 101.75\n",
            "Train_AverageReturn : 98.0\n",
            "Train_StdReturn : 36.91020965576172\n",
            "Train_MaxReturn : 189.0\n",
            "Train_MinReturn : 52.0\n",
            "Train_AverageEpLen : 98.0\n",
            "Train_EnvstepsSoFar : 22142\n",
            "TimeSinceStart : 33.15805983543396\n",
            "Training Loss : 55245.87109375\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 21 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 87.0\n",
            "Eval_StdReturn : 10.825894355773926\n",
            "Eval_MaxReturn : 104.0\n",
            "Eval_MinReturn : 70.0\n",
            "Eval_AverageEpLen : 87.0\n",
            "Train_AverageReturn : 79.61538696289062\n",
            "Train_StdReturn : 21.759307861328125\n",
            "Train_MaxReturn : 126.0\n",
            "Train_MinReturn : 42.0\n",
            "Train_AverageEpLen : 79.61538461538461\n",
            "Train_EnvstepsSoFar : 23177\n",
            "TimeSinceStart : 34.917468309402466\n",
            "Training Loss : 41048.734375\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 22 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 87.80000305175781\n",
            "Eval_StdReturn : 46.60643768310547\n",
            "Eval_MaxReturn : 179.0\n",
            "Eval_MinReturn : 55.0\n",
            "Eval_AverageEpLen : 87.8\n",
            "Train_AverageReturn : 91.45454406738281\n",
            "Train_StdReturn : 26.081562042236328\n",
            "Train_MaxReturn : 146.0\n",
            "Train_MinReturn : 49.0\n",
            "Train_AverageEpLen : 91.45454545454545\n",
            "Train_EnvstepsSoFar : 24183\n",
            "TimeSinceStart : 36.382792711257935\n",
            "Training Loss : 45279.5234375\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 23 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 111.0\n",
            "Eval_StdReturn : 38.190311431884766\n",
            "Eval_MaxReturn : 177.0\n",
            "Eval_MinReturn : 86.0\n",
            "Eval_AverageEpLen : 111.0\n",
            "Train_AverageReturn : 100.4000015258789\n",
            "Train_StdReturn : 37.21881103515625\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 53.0\n",
            "Train_AverageEpLen : 100.4\n",
            "Train_EnvstepsSoFar : 25187\n",
            "TimeSinceStart : 37.84831190109253\n",
            "Training Loss : 51114.140625\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 24 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 101.4000015258789\n",
            "Eval_StdReturn : 16.632497787475586\n",
            "Eval_MaxReturn : 123.0\n",
            "Eval_MinReturn : 72.0\n",
            "Eval_AverageEpLen : 101.4\n",
            "Train_AverageReturn : 101.45454406738281\n",
            "Train_StdReturn : 43.34505081176758\n",
            "Train_MaxReturn : 194.0\n",
            "Train_MinReturn : 62.0\n",
            "Train_AverageEpLen : 101.45454545454545\n",
            "Train_EnvstepsSoFar : 26303\n",
            "TimeSinceStart : 39.52528500556946\n",
            "Training Loss : 53436.90625\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 25 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 120.25\n",
            "Eval_StdReturn : 31.89337730407715\n",
            "Eval_MaxReturn : 164.0\n",
            "Eval_MinReturn : 74.0\n",
            "Eval_AverageEpLen : 120.25\n",
            "Train_AverageReturn : 98.45454406738281\n",
            "Train_StdReturn : 38.80572509765625\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 58.0\n",
            "Train_AverageEpLen : 98.45454545454545\n",
            "Train_EnvstepsSoFar : 27386\n",
            "TimeSinceStart : 41.15051198005676\n",
            "Training Loss : 52446.5625\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 26 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 161.0\n",
            "Eval_StdReturn : 47.58851623535156\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 94.0\n",
            "Eval_AverageEpLen : 161.0\n",
            "Train_AverageReturn : 112.11111450195312\n",
            "Train_StdReturn : 44.920780181884766\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 51.0\n",
            "Train_AverageEpLen : 112.11111111111111\n",
            "Train_EnvstepsSoFar : 28395\n",
            "TimeSinceStart : 42.813037157058716\n",
            "Training Loss : 52149.01953125\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 27 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 134.6666717529297\n",
            "Eval_StdReturn : 35.70558547973633\n",
            "Eval_MaxReturn : 185.0\n",
            "Eval_MinReturn : 106.0\n",
            "Eval_AverageEpLen : 134.66666666666666\n",
            "Train_AverageReturn : 125.125\n",
            "Train_StdReturn : 38.49168014526367\n",
            "Train_MaxReturn : 189.0\n",
            "Train_MinReturn : 86.0\n",
            "Train_AverageEpLen : 125.125\n",
            "Train_EnvstepsSoFar : 29396\n",
            "TimeSinceStart : 44.307852029800415\n",
            "Training Loss : 59813.3671875\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 28 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 153.3333282470703\n",
            "Eval_StdReturn : 51.23366928100586\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 82.0\n",
            "Eval_AverageEpLen : 153.33333333333334\n",
            "Train_AverageReturn : 135.5\n",
            "Train_StdReturn : 41.596275329589844\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 87.0\n",
            "Train_AverageEpLen : 135.5\n",
            "Train_EnvstepsSoFar : 30480\n",
            "TimeSinceStart : 45.91549849510193\n",
            "Training Loss : 69103.984375\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 29 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 115.75\n",
            "Eval_StdReturn : 21.878929138183594\n",
            "Eval_MaxReturn : 151.0\n",
            "Eval_MinReturn : 96.0\n",
            "Eval_AverageEpLen : 115.75\n",
            "Train_AverageReturn : 115.4000015258789\n",
            "Train_StdReturn : 44.340049743652344\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 68.0\n",
            "Train_AverageEpLen : 115.4\n",
            "Train_EnvstepsSoFar : 31634\n",
            "TimeSinceStart : 47.55087184906006\n",
            "Training Loss : 59027.1328125\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 30 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 109.25\n",
            "Eval_StdReturn : 21.545011520385742\n",
            "Eval_MaxReturn : 146.0\n",
            "Eval_MinReturn : 91.0\n",
            "Eval_AverageEpLen : 109.25\n",
            "Train_AverageReturn : 115.0\n",
            "Train_StdReturn : 31.162654876708984\n",
            "Train_MaxReturn : 187.0\n",
            "Train_MinReturn : 72.0\n",
            "Train_AverageEpLen : 115.0\n",
            "Train_EnvstepsSoFar : 32669\n",
            "TimeSinceStart : 49.04507517814636\n",
            "Training Loss : 54913.578125\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 31 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 121.75\n",
            "Eval_StdReturn : 45.974857330322266\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 83.0\n",
            "Eval_AverageEpLen : 121.75\n",
            "Train_AverageReturn : 128.375\n",
            "Train_StdReturn : 28.1422176361084\n",
            "Train_MaxReturn : 169.0\n",
            "Train_MinReturn : 71.0\n",
            "Train_AverageEpLen : 128.375\n",
            "Train_EnvstepsSoFar : 33696\n",
            "TimeSinceStart : 50.60121965408325\n",
            "Training Loss : 53040.6953125\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 32 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 117.25\n",
            "Eval_StdReturn : 32.26743698120117\n",
            "Eval_MaxReturn : 163.0\n",
            "Eval_MinReturn : 80.0\n",
            "Eval_AverageEpLen : 117.25\n",
            "Train_AverageReturn : 107.30000305175781\n",
            "Train_StdReturn : 20.13976287841797\n",
            "Train_MaxReturn : 145.0\n",
            "Train_MinReturn : 80.0\n",
            "Train_AverageEpLen : 107.3\n",
            "Train_EnvstepsSoFar : 34769\n",
            "TimeSinceStart : 52.197068214416504\n",
            "Training Loss : 46948.43359375\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 33 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 111.4000015258789\n",
            "Eval_StdReturn : 36.02554702758789\n",
            "Eval_MaxReturn : 169.0\n",
            "Eval_MinReturn : 67.0\n",
            "Eval_AverageEpLen : 111.4\n",
            "Train_AverageReturn : 117.77777862548828\n",
            "Train_StdReturn : 38.5595588684082\n",
            "Train_MaxReturn : 199.0\n",
            "Train_MinReturn : 83.0\n",
            "Train_AverageEpLen : 117.77777777777777\n",
            "Train_EnvstepsSoFar : 35829\n",
            "TimeSinceStart : 53.91147494316101\n",
            "Training Loss : 56773.71875\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 34 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 126.44444274902344\n",
            "Train_StdReturn : 54.60995101928711\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 57.0\n",
            "Train_AverageEpLen : 126.44444444444444\n",
            "Train_EnvstepsSoFar : 36967\n",
            "TimeSinceStart : 55.48844623565674\n",
            "Training Loss : 68398.28125\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 35 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 134.6666717529297\n",
            "Eval_StdReturn : 18.803071975708008\n",
            "Eval_MaxReturn : 157.0\n",
            "Eval_MinReturn : 111.0\n",
            "Eval_AverageEpLen : 134.66666666666666\n",
            "Train_AverageReturn : 105.4000015258789\n",
            "Train_StdReturn : 29.88711929321289\n",
            "Train_MaxReturn : 159.0\n",
            "Train_MinReturn : 61.0\n",
            "Train_AverageEpLen : 105.4\n",
            "Train_EnvstepsSoFar : 38021\n",
            "TimeSinceStart : 56.9871461391449\n",
            "Training Loss : 47882.796875\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 36 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 99.4000015258789\n",
            "Eval_StdReturn : 7.7097344398498535\n",
            "Eval_MaxReturn : 107.0\n",
            "Eval_MinReturn : 90.0\n",
            "Eval_AverageEpLen : 99.4\n",
            "Train_AverageReturn : 145.0\n",
            "Train_StdReturn : 39.0164794921875\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 100.0\n",
            "Train_AverageEpLen : 145.0\n",
            "Train_EnvstepsSoFar : 39036\n",
            "TimeSinceStart : 58.904369831085205\n",
            "Training Loss : 63972.3515625\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 37 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 109.0\n",
            "Eval_StdReturn : 17.50714111328125\n",
            "Eval_MaxReturn : 134.0\n",
            "Eval_MinReturn : 85.0\n",
            "Eval_AverageEpLen : 109.0\n",
            "Train_AverageReturn : 123.33333587646484\n",
            "Train_StdReturn : 46.15673828125\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 63.0\n",
            "Train_AverageEpLen : 123.33333333333333\n",
            "Train_EnvstepsSoFar : 40146\n",
            "TimeSinceStart : 60.4733567237854\n",
            "Training Loss : 56802.6953125\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 38 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 126.25\n",
            "Eval_StdReturn : 43.819942474365234\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 86.0\n",
            "Eval_AverageEpLen : 126.25\n",
            "Train_AverageReturn : 104.9000015258789\n",
            "Train_StdReturn : 39.414337158203125\n",
            "Train_MaxReturn : 186.0\n",
            "Train_MinReturn : 65.0\n",
            "Train_AverageEpLen : 104.9\n",
            "Train_EnvstepsSoFar : 41195\n",
            "TimeSinceStart : 62.06711935997009\n",
            "Training Loss : 47673.984375\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 39 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 156.0\n",
            "Eval_StdReturn : 31.496030807495117\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 128.0\n",
            "Eval_AverageEpLen : 156.0\n",
            "Train_AverageReturn : 114.33333587646484\n",
            "Train_StdReturn : 49.51543045043945\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 61.0\n",
            "Train_AverageEpLen : 114.33333333333333\n",
            "Train_EnvstepsSoFar : 42224\n",
            "TimeSinceStart : 63.63339972496033\n",
            "Training Loss : 51469.09765625\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 40 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 67.0\n",
            "Eval_StdReturn : 15.620499610900879\n",
            "Eval_MaxReturn : 90.0\n",
            "Eval_MinReturn : 46.0\n",
            "Eval_AverageEpLen : 67.0\n",
            "Train_AverageReturn : 91.2727279663086\n",
            "Train_StdReturn : 27.001989364624023\n",
            "Train_MaxReturn : 141.0\n",
            "Train_MinReturn : 51.0\n",
            "Train_AverageEpLen : 91.27272727272727\n",
            "Train_EnvstepsSoFar : 43228\n",
            "TimeSinceStart : 65.15559530258179\n",
            "Training Loss : 38675.30078125\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 41 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 83.4000015258789\n",
            "Eval_StdReturn : 22.240503311157227\n",
            "Eval_MaxReturn : 105.0\n",
            "Eval_MinReturn : 52.0\n",
            "Eval_AverageEpLen : 83.4\n",
            "Train_AverageReturn : 85.75\n",
            "Train_StdReturn : 26.089988708496094\n",
            "Train_MaxReturn : 150.0\n",
            "Train_MinReturn : 53.0\n",
            "Train_AverageEpLen : 85.75\n",
            "Train_EnvstepsSoFar : 44257\n",
            "TimeSinceStart : 66.6373987197876\n",
            "Training Loss : 36064.9765625\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 42 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 60.57143020629883\n",
            "Eval_StdReturn : 17.990928649902344\n",
            "Eval_MaxReturn : 103.0\n",
            "Eval_MinReturn : 47.0\n",
            "Eval_AverageEpLen : 60.57142857142857\n",
            "Train_AverageReturn : 85.41666412353516\n",
            "Train_StdReturn : 29.1732120513916\n",
            "Train_MaxReturn : 166.0\n",
            "Train_MinReturn : 48.0\n",
            "Train_AverageEpLen : 85.41666666666667\n",
            "Train_EnvstepsSoFar : 45282\n",
            "TimeSinceStart : 68.10505294799805\n",
            "Training Loss : 37104.0234375\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 43 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 75.5\n",
            "Eval_StdReturn : 28.871843338012695\n",
            "Eval_MaxReturn : 139.0\n",
            "Eval_MinReturn : 59.0\n",
            "Eval_AverageEpLen : 75.5\n",
            "Train_AverageReturn : 77.0\n",
            "Train_StdReturn : 34.86457443237305\n",
            "Train_MaxReturn : 186.0\n",
            "Train_MinReturn : 43.0\n",
            "Train_AverageEpLen : 77.0\n",
            "Train_EnvstepsSoFar : 46283\n",
            "TimeSinceStart : 69.57561373710632\n",
            "Training Loss : 34063.05078125\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 44 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 61.0\n",
            "Eval_StdReturn : 11.364103317260742\n",
            "Eval_MaxReturn : 75.0\n",
            "Eval_MinReturn : 41.0\n",
            "Eval_AverageEpLen : 61.0\n",
            "Train_AverageReturn : 74.64286041259766\n",
            "Train_StdReturn : 24.426586151123047\n",
            "Train_MaxReturn : 127.0\n",
            "Train_MinReturn : 46.0\n",
            "Train_AverageEpLen : 74.64285714285714\n",
            "Train_EnvstepsSoFar : 47328\n",
            "TimeSinceStart : 71.07812976837158\n",
            "Training Loss : 29440.87109375\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 45 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 63.57143020629883\n",
            "Eval_StdReturn : 15.728565216064453\n",
            "Eval_MaxReturn : 99.0\n",
            "Eval_MinReturn : 51.0\n",
            "Eval_AverageEpLen : 63.57142857142857\n",
            "Train_AverageReturn : 79.14286041259766\n",
            "Train_StdReturn : 20.914304733276367\n",
            "Train_MaxReturn : 133.0\n",
            "Train_MinReturn : 51.0\n",
            "Train_AverageEpLen : 79.14285714285714\n",
            "Train_EnvstepsSoFar : 48436\n",
            "TimeSinceStart : 72.6823194026947\n",
            "Training Loss : 29792.16796875\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 46 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 92.19999694824219\n",
            "Eval_StdReturn : 26.693819046020508\n",
            "Eval_MaxReturn : 128.0\n",
            "Eval_MinReturn : 67.0\n",
            "Eval_AverageEpLen : 92.2\n",
            "Train_AverageReturn : 83.41666412353516\n",
            "Train_StdReturn : 29.739028930664062\n",
            "Train_MaxReturn : 159.0\n",
            "Train_MinReturn : 47.0\n",
            "Train_AverageEpLen : 83.41666666666667\n",
            "Train_EnvstepsSoFar : 49437\n",
            "TimeSinceStart : 74.18772387504578\n",
            "Training Loss : 31763.5234375\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 47 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 115.25\n",
            "Eval_StdReturn : 40.499229431152344\n",
            "Eval_MaxReturn : 159.0\n",
            "Eval_MinReturn : 59.0\n",
            "Eval_AverageEpLen : 115.25\n",
            "Train_AverageReturn : 76.0\n",
            "Train_StdReturn : 29.51512908935547\n",
            "Train_MaxReturn : 175.0\n",
            "Train_MinReturn : 52.0\n",
            "Train_AverageEpLen : 76.0\n",
            "Train_EnvstepsSoFar : 50501\n",
            "TimeSinceStart : 75.73212504386902\n",
            "Training Loss : 30211.6796875\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 48 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 114.75\n",
            "Eval_StdReturn : 32.321624755859375\n",
            "Eval_MaxReturn : 164.0\n",
            "Eval_MinReturn : 82.0\n",
            "Eval_AverageEpLen : 114.75\n",
            "Train_AverageReturn : 85.16666412353516\n",
            "Train_StdReturn : 20.260112762451172\n",
            "Train_MaxReturn : 129.0\n",
            "Train_MinReturn : 60.0\n",
            "Train_AverageEpLen : 85.16666666666667\n",
            "Train_EnvstepsSoFar : 51523\n",
            "TimeSinceStart : 77.30703377723694\n",
            "Training Loss : 29879.25\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 49 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 71.16666412353516\n",
            "Eval_StdReturn : 12.615026473999023\n",
            "Eval_MaxReturn : 92.0\n",
            "Eval_MinReturn : 55.0\n",
            "Eval_AverageEpLen : 71.16666666666667\n",
            "Train_AverageReturn : 82.69230651855469\n",
            "Train_StdReturn : 29.50719451904297\n",
            "Train_MaxReturn : 162.0\n",
            "Train_MinReturn : 57.0\n",
            "Train_AverageEpLen : 82.6923076923077\n",
            "Train_EnvstepsSoFar : 52598\n",
            "TimeSinceStart : 78.80981183052063\n",
            "Training Loss : 29206.333984375\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 50 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 116.0\n",
            "Eval_StdReturn : 22.315914154052734\n",
            "Eval_MaxReturn : 142.0\n",
            "Eval_MinReturn : 82.0\n",
            "Eval_AverageEpLen : 116.0\n",
            "Train_AverageReturn : 100.81818389892578\n",
            "Train_StdReturn : 31.45796012878418\n",
            "Train_MaxReturn : 167.0\n",
            "Train_MinReturn : 65.0\n",
            "Train_AverageEpLen : 100.81818181818181\n",
            "Train_EnvstepsSoFar : 53707\n",
            "TimeSinceStart : 80.42752838134766\n",
            "Training Loss : 39200.76953125\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 51 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 101.75\n",
            "Eval_StdReturn : 27.00347137451172\n",
            "Eval_MaxReturn : 130.0\n",
            "Eval_MinReturn : 58.0\n",
            "Eval_AverageEpLen : 101.75\n",
            "Train_AverageReturn : 125.75\n",
            "Train_StdReturn : 35.070465087890625\n",
            "Train_MaxReturn : 182.0\n",
            "Train_MinReturn : 80.0\n",
            "Train_AverageEpLen : 125.75\n",
            "Train_EnvstepsSoFar : 54713\n",
            "TimeSinceStart : 81.88776063919067\n",
            "Training Loss : 44263.92578125\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 52 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 123.25\n",
            "Eval_StdReturn : 10.009370803833008\n",
            "Eval_MaxReturn : 132.0\n",
            "Eval_MinReturn : 107.0\n",
            "Eval_AverageEpLen : 123.25\n",
            "Train_AverageReturn : 100.0999984741211\n",
            "Train_StdReturn : 24.097509384155273\n",
            "Train_MaxReturn : 154.0\n",
            "Train_MinReturn : 73.0\n",
            "Train_AverageEpLen : 100.1\n",
            "Train_EnvstepsSoFar : 55714\n",
            "TimeSinceStart : 83.39798593521118\n",
            "Training Loss : 30505.16796875\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 53 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 109.5\n",
            "Eval_StdReturn : 22.028390884399414\n",
            "Eval_MaxReturn : 132.0\n",
            "Eval_MinReturn : 73.0\n",
            "Eval_AverageEpLen : 109.5\n",
            "Train_AverageReturn : 96.0\n",
            "Train_StdReturn : 17.135820388793945\n",
            "Train_MaxReturn : 125.0\n",
            "Train_MinReturn : 68.0\n",
            "Train_AverageEpLen : 96.0\n",
            "Train_EnvstepsSoFar : 56770\n",
            "TimeSinceStart : 84.96865701675415\n",
            "Training Loss : 30808.68359375\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 54 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 92.4000015258789\n",
            "Eval_StdReturn : 8.685620307922363\n",
            "Eval_MaxReturn : 106.0\n",
            "Eval_MinReturn : 80.0\n",
            "Eval_AverageEpLen : 92.4\n",
            "Train_AverageReturn : 112.55555725097656\n",
            "Train_StdReturn : 39.72715377807617\n",
            "Train_MaxReturn : 179.0\n",
            "Train_MinReturn : 72.0\n",
            "Train_AverageEpLen : 112.55555555555556\n",
            "Train_EnvstepsSoFar : 57783\n",
            "TimeSinceStart : 86.5084936618805\n",
            "Training Loss : 40575.5\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 55 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 141.3333282470703\n",
            "Eval_StdReturn : 35.93821716308594\n",
            "Eval_MaxReturn : 186.0\n",
            "Eval_MinReturn : 98.0\n",
            "Eval_AverageEpLen : 141.33333333333334\n",
            "Train_AverageReturn : 111.44444274902344\n",
            "Train_StdReturn : 28.07177734375\n",
            "Train_MaxReturn : 150.0\n",
            "Train_MinReturn : 72.0\n",
            "Train_AverageEpLen : 111.44444444444444\n",
            "Train_EnvstepsSoFar : 58786\n",
            "TimeSinceStart : 87.97345995903015\n",
            "Training Loss : 34240.72265625\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 56 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 143.0\n",
            "Eval_StdReturn : 13.490737915039062\n",
            "Eval_MaxReturn : 159.0\n",
            "Eval_MinReturn : 126.0\n",
            "Eval_AverageEpLen : 143.0\n",
            "Train_AverageReturn : 108.19999694824219\n",
            "Train_StdReturn : 21.479291915893555\n",
            "Train_MaxReturn : 145.0\n",
            "Train_MinReturn : 74.0\n",
            "Train_AverageEpLen : 108.2\n",
            "Train_EnvstepsSoFar : 59868\n",
            "TimeSinceStart : 89.52618455886841\n",
            "Training Loss : 33661.2421875\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 57 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 100.25\n",
            "Eval_StdReturn : 28.19906997680664\n",
            "Eval_MaxReturn : 143.0\n",
            "Eval_MinReturn : 72.0\n",
            "Eval_AverageEpLen : 100.25\n",
            "Train_AverageReturn : 95.0\n",
            "Train_StdReturn : 31.614151000976562\n",
            "Train_MaxReturn : 167.0\n",
            "Train_MinReturn : 54.0\n",
            "Train_AverageEpLen : 95.0\n",
            "Train_EnvstepsSoFar : 60913\n",
            "TimeSinceStart : 91.00353026390076\n",
            "Training Loss : 33620.6640625\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 58 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 89.0\n",
            "Eval_StdReturn : 8.508818626403809\n",
            "Eval_MaxReturn : 103.0\n",
            "Eval_MinReturn : 79.0\n",
            "Eval_AverageEpLen : 89.0\n",
            "Train_AverageReturn : 89.5\n",
            "Train_StdReturn : 22.518510818481445\n",
            "Train_MaxReturn : 133.0\n",
            "Train_MinReturn : 61.0\n",
            "Train_AverageEpLen : 89.5\n",
            "Train_EnvstepsSoFar : 61987\n",
            "TimeSinceStart : 92.58937644958496\n",
            "Training Loss : 27648.66796875\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 59 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 80.16666412353516\n",
            "Eval_StdReturn : 9.990272521972656\n",
            "Eval_MaxReturn : 94.0\n",
            "Eval_MinReturn : 68.0\n",
            "Eval_AverageEpLen : 80.16666666666667\n",
            "Train_AverageReturn : 103.54545593261719\n",
            "Train_StdReturn : 34.989253997802734\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 63.0\n",
            "Train_AverageEpLen : 103.54545454545455\n",
            "Train_EnvstepsSoFar : 63126\n",
            "TimeSinceStart : 94.29084897041321\n",
            "Training Loss : 32528.248046875\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 60 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 104.0\n",
            "Eval_StdReturn : 21.250883102416992\n",
            "Eval_MaxReturn : 135.0\n",
            "Eval_MinReturn : 78.0\n",
            "Eval_AverageEpLen : 104.0\n",
            "Train_AverageReturn : 100.9000015258789\n",
            "Train_StdReturn : 33.901180267333984\n",
            "Train_MaxReturn : 170.0\n",
            "Train_MinReturn : 60.0\n",
            "Train_AverageEpLen : 100.9\n",
            "Train_EnvstepsSoFar : 64135\n",
            "TimeSinceStart : 95.85725522041321\n",
            "Training Loss : 30457.171875\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 61 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 107.5\n",
            "Eval_StdReturn : 26.34862518310547\n",
            "Eval_MaxReturn : 137.0\n",
            "Eval_MinReturn : 66.0\n",
            "Eval_AverageEpLen : 107.5\n",
            "Train_AverageReturn : 109.4000015258789\n",
            "Train_StdReturn : 34.18537521362305\n",
            "Train_MaxReturn : 175.0\n",
            "Train_MinReturn : 68.0\n",
            "Train_AverageEpLen : 109.4\n",
            "Train_EnvstepsSoFar : 65229\n",
            "TimeSinceStart : 97.42751455307007\n",
            "Training Loss : 35601.66796875\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 62 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 123.0\n",
            "Eval_StdReturn : 41.176448822021484\n",
            "Eval_MaxReturn : 189.0\n",
            "Eval_MinReturn : 80.0\n",
            "Eval_AverageEpLen : 123.0\n",
            "Train_AverageReturn : 108.5999984741211\n",
            "Train_StdReturn : 32.63801574707031\n",
            "Train_MaxReturn : 181.0\n",
            "Train_MinReturn : 74.0\n",
            "Train_AverageEpLen : 108.6\n",
            "Train_EnvstepsSoFar : 66315\n",
            "TimeSinceStart : 99.01613759994507\n",
            "Training Loss : 35532.703125\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 63 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 114.25\n",
            "Eval_StdReturn : 11.211043357849121\n",
            "Eval_MaxReturn : 123.0\n",
            "Eval_MinReturn : 95.0\n",
            "Eval_AverageEpLen : 114.25\n",
            "Train_AverageReturn : 116.11111450195312\n",
            "Train_StdReturn : 24.98641586303711\n",
            "Train_MaxReturn : 173.0\n",
            "Train_MinReturn : 84.0\n",
            "Train_AverageEpLen : 116.11111111111111\n",
            "Train_EnvstepsSoFar : 67360\n",
            "TimeSinceStart : 100.56693720817566\n",
            "Training Loss : 40594.05078125\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 64 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 101.75\n",
            "Eval_StdReturn : 27.634897232055664\n",
            "Eval_MaxReturn : 148.0\n",
            "Eval_MinReturn : 77.0\n",
            "Eval_AverageEpLen : 101.75\n",
            "Train_AverageReturn : 109.5\n",
            "Train_StdReturn : 24.699190139770508\n",
            "Train_MaxReturn : 157.0\n",
            "Train_MinReturn : 77.0\n",
            "Train_AverageEpLen : 109.5\n",
            "Train_EnvstepsSoFar : 68455\n",
            "TimeSinceStart : 102.1241843700409\n",
            "Training Loss : 30045.8515625\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 65 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 132.25\n",
            "Eval_StdReturn : 32.452850341796875\n",
            "Eval_MaxReturn : 182.0\n",
            "Eval_MinReturn : 91.0\n",
            "Eval_AverageEpLen : 132.25\n",
            "Train_AverageReturn : 122.11111450195312\n",
            "Train_StdReturn : 31.409284591674805\n",
            "Train_MaxReturn : 178.0\n",
            "Train_MinReturn : 85.0\n",
            "Train_AverageEpLen : 122.11111111111111\n",
            "Train_EnvstepsSoFar : 69554\n",
            "TimeSinceStart : 103.79762268066406\n",
            "Training Loss : 36681.58984375\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 66 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 84.80000305175781\n",
            "Eval_StdReturn : 22.73675537109375\n",
            "Eval_MaxReturn : 117.0\n",
            "Eval_MinReturn : 59.0\n",
            "Eval_AverageEpLen : 84.8\n",
            "Train_AverageReturn : 131.625\n",
            "Train_StdReturn : 42.517459869384766\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 81.0\n",
            "Train_AverageEpLen : 131.625\n",
            "Train_EnvstepsSoFar : 70607\n",
            "TimeSinceStart : 105.33971929550171\n",
            "Training Loss : 39372.9375\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 67 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 116.0\n",
            "Eval_StdReturn : 29.52117919921875\n",
            "Eval_MaxReturn : 165.0\n",
            "Eval_MinReturn : 86.0\n",
            "Eval_AverageEpLen : 116.0\n",
            "Train_AverageReturn : 117.88888549804688\n",
            "Train_StdReturn : 38.9770393371582\n",
            "Train_MaxReturn : 194.0\n",
            "Train_MinReturn : 77.0\n",
            "Train_AverageEpLen : 117.88888888888889\n",
            "Train_EnvstepsSoFar : 71668\n",
            "TimeSinceStart : 106.91438317298889\n",
            "Training Loss : 37225.078125\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 68 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 116.25\n",
            "Eval_StdReturn : 13.348689079284668\n",
            "Eval_MaxReturn : 136.0\n",
            "Eval_MinReturn : 104.0\n",
            "Eval_AverageEpLen : 116.25\n",
            "Train_AverageReturn : 113.66666412353516\n",
            "Train_StdReturn : 37.34523391723633\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 81.0\n",
            "Train_AverageEpLen : 113.66666666666667\n",
            "Train_EnvstepsSoFar : 72691\n",
            "TimeSinceStart : 108.4263391494751\n",
            "Training Loss : 31246.77734375\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 69 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 106.0\n",
            "Eval_StdReturn : 13.964240074157715\n",
            "Eval_MaxReturn : 129.0\n",
            "Eval_MinReturn : 93.0\n",
            "Eval_AverageEpLen : 106.0\n",
            "Train_AverageReturn : 109.0\n",
            "Train_StdReturn : 18.957847595214844\n",
            "Train_MaxReturn : 143.0\n",
            "Train_MinReturn : 87.0\n",
            "Train_AverageEpLen : 109.0\n",
            "Train_EnvstepsSoFar : 73781\n",
            "TimeSinceStart : 110.02022671699524\n",
            "Training Loss : 33570.17578125\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 70 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 138.6666717529297\n",
            "Eval_StdReturn : 29.533409118652344\n",
            "Eval_MaxReturn : 162.0\n",
            "Eval_MinReturn : 97.0\n",
            "Eval_AverageEpLen : 138.66666666666666\n",
            "Train_AverageReturn : 129.875\n",
            "Train_StdReturn : 42.630496978759766\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 80.0\n",
            "Train_AverageEpLen : 129.875\n",
            "Train_EnvstepsSoFar : 74820\n",
            "TimeSinceStart : 111.55630421638489\n",
            "Training Loss : 43896.31640625\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 71 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 115.75\n",
            "Eval_StdReturn : 4.710361003875732\n",
            "Eval_MaxReturn : 123.0\n",
            "Eval_MinReturn : 110.0\n",
            "Eval_AverageEpLen : 115.75\n",
            "Train_AverageReturn : 118.55555725097656\n",
            "Train_StdReturn : 33.552978515625\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 73.0\n",
            "Train_AverageEpLen : 118.55555555555556\n",
            "Train_EnvstepsSoFar : 75887\n",
            "TimeSinceStart : 113.13336157798767\n",
            "Training Loss : 33990.9921875\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 72 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 104.5\n",
            "Eval_StdReturn : 18.241436004638672\n",
            "Eval_MaxReturn : 131.0\n",
            "Eval_MinReturn : 81.0\n",
            "Eval_AverageEpLen : 104.5\n",
            "Train_AverageReturn : 119.0\n",
            "Train_StdReturn : 33.536048889160156\n",
            "Train_MaxReturn : 177.0\n",
            "Train_MinReturn : 62.0\n",
            "Train_AverageEpLen : 119.0\n",
            "Train_EnvstepsSoFar : 76958\n",
            "TimeSinceStart : 114.67201280593872\n",
            "Training Loss : 36444.30078125\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 73 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 102.0\n",
            "Eval_StdReturn : 7.5828752517700195\n",
            "Eval_MaxReturn : 115.0\n",
            "Eval_MinReturn : 96.0\n",
            "Eval_AverageEpLen : 102.0\n",
            "Train_AverageReturn : 125.375\n",
            "Train_StdReturn : 29.042802810668945\n",
            "Train_MaxReturn : 187.0\n",
            "Train_MinReturn : 92.0\n",
            "Train_AverageEpLen : 125.375\n",
            "Train_EnvstepsSoFar : 77961\n",
            "TimeSinceStart : 116.12470746040344\n",
            "Training Loss : 32125.142578125\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 74 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 102.0\n",
            "Eval_StdReturn : 14.230249404907227\n",
            "Eval_MaxReturn : 119.0\n",
            "Eval_MinReturn : 86.0\n",
            "Eval_AverageEpLen : 102.0\n",
            "Train_AverageReturn : 104.80000305175781\n",
            "Train_StdReturn : 13.658697128295898\n",
            "Train_MaxReturn : 134.0\n",
            "Train_MinReturn : 87.0\n",
            "Train_AverageEpLen : 104.8\n",
            "Train_EnvstepsSoFar : 79009\n",
            "TimeSinceStart : 117.63735699653625\n",
            "Training Loss : 27848.38671875\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 75 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 76.33333587646484\n",
            "Eval_StdReturn : 5.617433547973633\n",
            "Eval_MaxReturn : 83.0\n",
            "Eval_MinReturn : 69.0\n",
            "Eval_AverageEpLen : 76.33333333333333\n",
            "Train_AverageReturn : 98.18181610107422\n",
            "Train_StdReturn : 23.976572036743164\n",
            "Train_MaxReturn : 144.0\n",
            "Train_MinReturn : 64.0\n",
            "Train_AverageEpLen : 98.18181818181819\n",
            "Train_EnvstepsSoFar : 80089\n",
            "TimeSinceStart : 119.2329306602478\n",
            "Training Loss : 28167.673828125\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 76 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 86.0\n",
            "Eval_StdReturn : 13.145341873168945\n",
            "Eval_MaxReturn : 111.0\n",
            "Eval_MinReturn : 72.0\n",
            "Eval_AverageEpLen : 86.0\n",
            "Train_AverageReturn : 89.08333587646484\n",
            "Train_StdReturn : 15.702750205993652\n",
            "Train_MaxReturn : 111.0\n",
            "Train_MinReturn : 65.0\n",
            "Train_AverageEpLen : 89.08333333333333\n",
            "Train_EnvstepsSoFar : 81158\n",
            "TimeSinceStart : 120.758131980896\n",
            "Training Loss : 25720.181640625\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 77 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 81.16666412353516\n",
            "Eval_StdReturn : 11.393223762512207\n",
            "Eval_MaxReturn : 98.0\n",
            "Eval_MinReturn : 68.0\n",
            "Eval_AverageEpLen : 81.16666666666667\n",
            "Train_AverageReturn : 91.81818389892578\n",
            "Train_StdReturn : 13.415175437927246\n",
            "Train_MaxReturn : 114.0\n",
            "Train_MinReturn : 73.0\n",
            "Train_AverageEpLen : 91.81818181818181\n",
            "Train_EnvstepsSoFar : 82168\n",
            "TimeSinceStart : 122.30832147598267\n",
            "Training Loss : 24493.56640625\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 78 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 81.19999694824219\n",
            "Eval_StdReturn : 18.214279174804688\n",
            "Eval_MaxReturn : 111.0\n",
            "Eval_MinReturn : 56.0\n",
            "Eval_AverageEpLen : 81.2\n",
            "Train_AverageReturn : 89.08333587646484\n",
            "Train_StdReturn : 10.742892265319824\n",
            "Train_MaxReturn : 103.0\n",
            "Train_MinReturn : 67.0\n",
            "Train_AverageEpLen : 89.08333333333333\n",
            "Train_EnvstepsSoFar : 83237\n",
            "TimeSinceStart : 123.85911655426025\n",
            "Training Loss : 22153.42578125\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 79 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 90.4000015258789\n",
            "Eval_StdReturn : 25.819372177124023\n",
            "Eval_MaxReturn : 116.0\n",
            "Eval_MinReturn : 50.0\n",
            "Eval_AverageEpLen : 90.4\n",
            "Train_AverageReturn : 97.45454406738281\n",
            "Train_StdReturn : 16.66440773010254\n",
            "Train_MaxReturn : 131.0\n",
            "Train_MinReturn : 74.0\n",
            "Train_AverageEpLen : 97.45454545454545\n",
            "Train_EnvstepsSoFar : 84309\n",
            "TimeSinceStart : 125.46178460121155\n",
            "Training Loss : 29586.88671875\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 80 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 111.0\n",
            "Eval_StdReturn : 21.610183715820312\n",
            "Eval_MaxReturn : 144.0\n",
            "Eval_MinReturn : 84.0\n",
            "Eval_AverageEpLen : 111.0\n",
            "Train_AverageReturn : 100.5999984741211\n",
            "Train_StdReturn : 19.226022720336914\n",
            "Train_MaxReturn : 138.0\n",
            "Train_MinReturn : 73.0\n",
            "Train_AverageEpLen : 100.6\n",
            "Train_EnvstepsSoFar : 85315\n",
            "TimeSinceStart : 126.94546270370483\n",
            "Training Loss : 27407.228515625\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 81 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 124.25\n",
            "Eval_StdReturn : 17.397916793823242\n",
            "Eval_MaxReturn : 153.0\n",
            "Eval_MinReturn : 109.0\n",
            "Eval_AverageEpLen : 124.25\n",
            "Train_AverageReturn : 122.66666412353516\n",
            "Train_StdReturn : 11.105554580688477\n",
            "Train_MaxReturn : 139.0\n",
            "Train_MinReturn : 103.0\n",
            "Train_AverageEpLen : 122.66666666666667\n",
            "Train_EnvstepsSoFar : 86419\n",
            "TimeSinceStart : 128.63631129264832\n",
            "Training Loss : 35272.87109375\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 82 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 118.75\n",
            "Eval_StdReturn : 13.479150772094727\n",
            "Eval_MaxReturn : 142.0\n",
            "Eval_MinReturn : 109.0\n",
            "Eval_AverageEpLen : 118.75\n",
            "Train_AverageReturn : 125.875\n",
            "Train_StdReturn : 11.645143508911133\n",
            "Train_MaxReturn : 146.0\n",
            "Train_MinReturn : 105.0\n",
            "Train_AverageEpLen : 125.875\n",
            "Train_EnvstepsSoFar : 87426\n",
            "TimeSinceStart : 130.18591380119324\n",
            "Training Loss : 33784.7109375\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 83 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 133.0\n",
            "Eval_StdReturn : 2.5495097637176514\n",
            "Eval_MaxReturn : 136.0\n",
            "Eval_MinReturn : 129.0\n",
            "Eval_AverageEpLen : 133.0\n",
            "Train_AverageReturn : 124.44444274902344\n",
            "Train_StdReturn : 8.65526294708252\n",
            "Train_MaxReturn : 136.0\n",
            "Train_MinReturn : 109.0\n",
            "Train_AverageEpLen : 124.44444444444444\n",
            "Train_EnvstepsSoFar : 88546\n",
            "TimeSinceStart : 131.940571308136\n",
            "Training Loss : 37183.46875\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 84 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 122.25\n",
            "Eval_StdReturn : 9.756407737731934\n",
            "Eval_MaxReturn : 132.0\n",
            "Eval_MinReturn : 112.0\n",
            "Eval_AverageEpLen : 122.25\n",
            "Train_AverageReturn : 125.22222137451172\n",
            "Train_StdReturn : 10.809232711791992\n",
            "Train_MaxReturn : 140.0\n",
            "Train_MinReturn : 113.0\n",
            "Train_AverageEpLen : 125.22222222222223\n",
            "Train_EnvstepsSoFar : 89673\n",
            "TimeSinceStart : 133.5872986316681\n",
            "Training Loss : 35397.828125\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 85 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 133.25\n",
            "Eval_StdReturn : 7.395099639892578\n",
            "Eval_MaxReturn : 145.0\n",
            "Eval_MinReturn : 126.0\n",
            "Eval_AverageEpLen : 133.25\n",
            "Train_AverageReturn : 138.625\n",
            "Train_StdReturn : 21.153825759887695\n",
            "Train_MaxReturn : 168.0\n",
            "Train_MinReturn : 114.0\n",
            "Train_AverageEpLen : 138.625\n",
            "Train_EnvstepsSoFar : 90782\n",
            "TimeSinceStart : 135.26157069206238\n",
            "Training Loss : 38330.4296875\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 86 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 149.0\n",
            "Eval_StdReturn : 14.514360427856445\n",
            "Eval_MaxReturn : 169.0\n",
            "Eval_MinReturn : 135.0\n",
            "Eval_AverageEpLen : 149.0\n",
            "Train_AverageReturn : 138.5\n",
            "Train_StdReturn : 14.645818710327148\n",
            "Train_MaxReturn : 166.0\n",
            "Train_MinReturn : 117.0\n",
            "Train_AverageEpLen : 138.5\n",
            "Train_EnvstepsSoFar : 91890\n",
            "TimeSinceStart : 136.84650254249573\n",
            "Training Loss : 40728.203125\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 87 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 147.0\n",
            "Eval_StdReturn : 11.860298156738281\n",
            "Eval_MaxReturn : 161.0\n",
            "Eval_MinReturn : 132.0\n",
            "Eval_AverageEpLen : 147.0\n",
            "Train_AverageReturn : 147.375\n",
            "Train_StdReturn : 16.40074348449707\n",
            "Train_MaxReturn : 182.0\n",
            "Train_MinReturn : 129.0\n",
            "Train_AverageEpLen : 147.375\n",
            "Train_EnvstepsSoFar : 93069\n",
            "TimeSinceStart : 138.47960758209229\n",
            "Training Loss : 39036.40234375\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 88 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 156.3333282470703\n",
            "Eval_StdReturn : 6.599663257598877\n",
            "Eval_MaxReturn : 165.0\n",
            "Eval_MinReturn : 149.0\n",
            "Eval_AverageEpLen : 156.33333333333334\n",
            "Train_AverageReturn : 167.85714721679688\n",
            "Train_StdReturn : 18.349218368530273\n",
            "Train_MaxReturn : 189.0\n",
            "Train_MinReturn : 137.0\n",
            "Train_AverageEpLen : 167.85714285714286\n",
            "Train_EnvstepsSoFar : 94244\n",
            "TimeSinceStart : 140.18725490570068\n",
            "Training Loss : 41615.5\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 89 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 171.6666717529297\n",
            "Train_StdReturn : 21.36716079711914\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 137.0\n",
            "Train_AverageEpLen : 171.66666666666666\n",
            "Train_EnvstepsSoFar : 95274\n",
            "TimeSinceStart : 141.65063667297363\n",
            "Training Loss : 53977.8359375\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 90 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 167.5\n",
            "Train_StdReturn : 14.4769926071167\n",
            "Train_MaxReturn : 193.0\n",
            "Train_MinReturn : 150.0\n",
            "Train_AverageEpLen : 167.5\n",
            "Train_EnvstepsSoFar : 96279\n",
            "TimeSinceStart : 143.10435318946838\n",
            "Training Loss : 46098.63671875\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 91 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 97279\n",
            "TimeSinceStart : 144.55838751792908\n",
            "Training Loss : 48698.1328125\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 92 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 98279\n",
            "TimeSinceStart : 146.01002740859985\n",
            "Training Loss : 46992.765625\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 93 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 99279\n",
            "TimeSinceStart : 147.48020339012146\n",
            "Training Loss : 55944.07421875\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 94 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 100279\n",
            "TimeSinceStart : 148.91721773147583\n",
            "Training Loss : 52373.6171875\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 95 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 101279\n",
            "TimeSinceStart : 150.36960744857788\n",
            "Training Loss : 54789.34765625\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 96 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 102279\n",
            "TimeSinceStart : 151.80850791931152\n",
            "Training Loss : 52195.921875\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 97 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 175.6666717529297\n",
            "Eval_StdReturn : 15.173075675964355\n",
            "Eval_MaxReturn : 197.0\n",
            "Eval_MinReturn : 163.0\n",
            "Eval_AverageEpLen : 175.66666666666666\n",
            "Train_AverageReturn : 195.8333282470703\n",
            "Train_StdReturn : 9.316949844360352\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 175.0\n",
            "Train_AverageEpLen : 195.83333333333334\n",
            "Train_EnvstepsSoFar : 103454\n",
            "TimeSinceStart : 153.56246280670166\n",
            "Training Loss : 67411.0859375\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 98 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 133.3333282470703\n",
            "Eval_StdReturn : 8.653837203979492\n",
            "Eval_MaxReturn : 143.0\n",
            "Eval_MinReturn : 122.0\n",
            "Eval_AverageEpLen : 133.33333333333334\n",
            "Train_AverageReturn : 154.57142639160156\n",
            "Train_StdReturn : 9.7666654586792\n",
            "Train_MaxReturn : 170.0\n",
            "Train_MinReturn : 141.0\n",
            "Train_AverageEpLen : 154.57142857142858\n",
            "Train_EnvstepsSoFar : 104536\n",
            "TimeSinceStart : 155.1153702735901\n",
            "Training Loss : 47959.953125\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 99 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 120.75\n",
            "Eval_StdReturn : 3.3447721004486084\n",
            "Eval_MaxReturn : 123.0\n",
            "Eval_MinReturn : 115.0\n",
            "Eval_AverageEpLen : 120.75\n",
            "Train_AverageReturn : 125.25\n",
            "Train_StdReturn : 8.584142684936523\n",
            "Train_MaxReturn : 140.0\n",
            "Train_MinReturn : 114.0\n",
            "Train_AverageEpLen : 125.25\n",
            "Train_EnvstepsSoFar : 105538\n",
            "TimeSinceStart : 156.61593580245972\n",
            "Training Loss : 34411.1171875\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python cs285/scripts/run_hw2.py --env_name CartPole-v0 -n 100 -b 1000 \\\n",
        "-rtg -dsa --exp_name q1_sb_rtg_dsa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Nikg_nQmY9c",
        "outputId": "3d7a63bc-71eb-4010-faab-3080429a3f38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "########################\n",
            "logging outputs to  /content/gdrive/My Drive/cs285_f2021/DRL_policy_grads/cs285/scripts/../../data/q2_pg_q1_sb_rtg_na_CartPole-v0_04-02-2022_16-43-37\n",
            "########################\n",
            "Using GPU id 0\n",
            "\n",
            "\n",
            "********** Iteration 0 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 28.733333587646484\n",
            "Eval_StdReturn : 14.401233673095703\n",
            "Eval_MaxReturn : 67.0\n",
            "Eval_MinReturn : 13.0\n",
            "Eval_AverageEpLen : 28.733333333333334\n",
            "Train_AverageReturn : 27.648649215698242\n",
            "Train_StdReturn : 12.643160820007324\n",
            "Train_MaxReturn : 65.0\n",
            "Train_MinReturn : 11.0\n",
            "Train_AverageEpLen : 27.64864864864865\n",
            "Train_EnvstepsSoFar : 1023\n",
            "TimeSinceStart : 1.370870590209961\n",
            "Training Loss : -3.9271583557128906\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 1 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 37.181819915771484\n",
            "Eval_StdReturn : 16.878271102905273\n",
            "Eval_MaxReturn : 80.0\n",
            "Eval_MinReturn : 19.0\n",
            "Eval_AverageEpLen : 37.18181818181818\n",
            "Train_AverageReturn : 28.30555534362793\n",
            "Train_StdReturn : 15.314879417419434\n",
            "Train_MaxReturn : 79.0\n",
            "Train_MinReturn : 10.0\n",
            "Train_AverageEpLen : 28.305555555555557\n",
            "Train_EnvstepsSoFar : 2042\n",
            "TimeSinceStart : 2.787846326828003\n",
            "Training Loss : -1.3636932373046875\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 2 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 50.11111068725586\n",
            "Eval_StdReturn : 25.23861312866211\n",
            "Eval_MaxReturn : 91.0\n",
            "Eval_MinReturn : 20.0\n",
            "Eval_AverageEpLen : 50.111111111111114\n",
            "Train_AverageReturn : 35.400001525878906\n",
            "Train_StdReturn : 19.6224365234375\n",
            "Train_MaxReturn : 80.0\n",
            "Train_MinReturn : 12.0\n",
            "Train_AverageEpLen : 35.4\n",
            "Train_EnvstepsSoFar : 3104\n",
            "TimeSinceStart : 4.264931678771973\n",
            "Training Loss : -17.9229793548584\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 3 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 36.08333206176758\n",
            "Eval_StdReturn : 14.619953155517578\n",
            "Eval_MaxReturn : 66.0\n",
            "Eval_MinReturn : 13.0\n",
            "Eval_AverageEpLen : 36.083333333333336\n",
            "Train_AverageReturn : 39.846153259277344\n",
            "Train_StdReturn : 9.606456756591797\n",
            "Train_MaxReturn : 60.0\n",
            "Train_MinReturn : 24.0\n",
            "Train_AverageEpLen : 39.84615384615385\n",
            "Train_EnvstepsSoFar : 4140\n",
            "TimeSinceStart : 5.708150863647461\n",
            "Training Loss : 3.777252197265625\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 4 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 40.900001525878906\n",
            "Eval_StdReturn : 34.209503173828125\n",
            "Eval_MaxReturn : 140.0\n",
            "Eval_MinReturn : 16.0\n",
            "Eval_AverageEpLen : 40.9\n",
            "Train_AverageReturn : 41.70833206176758\n",
            "Train_StdReturn : 24.51271629333496\n",
            "Train_MaxReturn : 137.0\n",
            "Train_MinReturn : 18.0\n",
            "Train_AverageEpLen : 41.708333333333336\n",
            "Train_EnvstepsSoFar : 5141\n",
            "TimeSinceStart : 7.1086413860321045\n",
            "Training Loss : 6.898922920227051\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 5 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 41.29999923706055\n",
            "Eval_StdReturn : 14.227087020874023\n",
            "Eval_MaxReturn : 76.0\n",
            "Eval_MinReturn : 28.0\n",
            "Eval_AverageEpLen : 41.3\n",
            "Train_AverageReturn : 43.04166793823242\n",
            "Train_StdReturn : 22.17633819580078\n",
            "Train_MaxReturn : 105.0\n",
            "Train_MinReturn : 18.0\n",
            "Train_AverageEpLen : 43.041666666666664\n",
            "Train_EnvstepsSoFar : 6174\n",
            "TimeSinceStart : 8.553456783294678\n",
            "Training Loss : 0.5188722610473633\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 6 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 59.125\n",
            "Eval_StdReturn : 24.962158203125\n",
            "Eval_MaxReturn : 105.0\n",
            "Eval_MinReturn : 21.0\n",
            "Eval_AverageEpLen : 59.125\n",
            "Train_AverageReturn : 39.57692337036133\n",
            "Train_StdReturn : 19.29561996459961\n",
            "Train_MaxReturn : 104.0\n",
            "Train_MinReturn : 21.0\n",
            "Train_AverageEpLen : 39.57692307692308\n",
            "Train_EnvstepsSoFar : 7203\n",
            "TimeSinceStart : 10.031347274780273\n",
            "Training Loss : 3.894865036010742\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 7 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 66.57142639160156\n",
            "Eval_StdReturn : 11.043513298034668\n",
            "Eval_MaxReturn : 90.0\n",
            "Eval_MinReturn : 54.0\n",
            "Eval_AverageEpLen : 66.57142857142857\n",
            "Train_AverageReturn : 65.3125\n",
            "Train_StdReturn : 22.05027961730957\n",
            "Train_MaxReturn : 99.0\n",
            "Train_MinReturn : 30.0\n",
            "Train_AverageEpLen : 65.3125\n",
            "Train_EnvstepsSoFar : 8248\n",
            "TimeSinceStart : 11.567851781845093\n",
            "Training Loss : -0.26949119567871094\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 8 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 56.25\n",
            "Eval_StdReturn : 20.698732376098633\n",
            "Eval_MaxReturn : 97.0\n",
            "Eval_MinReturn : 34.0\n",
            "Eval_AverageEpLen : 56.25\n",
            "Train_AverageReturn : 69.4000015258789\n",
            "Train_StdReturn : 23.767765045166016\n",
            "Train_MaxReturn : 116.0\n",
            "Train_MinReturn : 30.0\n",
            "Train_AverageEpLen : 69.4\n",
            "Train_EnvstepsSoFar : 9289\n",
            "TimeSinceStart : 13.017677545547485\n",
            "Training Loss : -13.054889678955078\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 9 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 47.33333206176758\n",
            "Eval_StdReturn : 12.771495819091797\n",
            "Eval_MaxReturn : 73.0\n",
            "Eval_MinReturn : 32.0\n",
            "Eval_AverageEpLen : 47.333333333333336\n",
            "Train_AverageReturn : 75.07142639160156\n",
            "Train_StdReturn : 26.143733978271484\n",
            "Train_MaxReturn : 127.0\n",
            "Train_MinReturn : 42.0\n",
            "Train_AverageEpLen : 75.07142857142857\n",
            "Train_EnvstepsSoFar : 10340\n",
            "TimeSinceStart : 14.48916482925415\n",
            "Training Loss : 3.9574317932128906\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 10 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 51.0\n",
            "Eval_StdReturn : 4.9749369621276855\n",
            "Eval_MaxReturn : 58.0\n",
            "Eval_MinReturn : 41.0\n",
            "Eval_AverageEpLen : 51.0\n",
            "Train_AverageReturn : 51.45000076293945\n",
            "Train_StdReturn : 16.098058700561523\n",
            "Train_MaxReturn : 97.0\n",
            "Train_MinReturn : 30.0\n",
            "Train_AverageEpLen : 51.45\n",
            "Train_EnvstepsSoFar : 11369\n",
            "TimeSinceStart : 15.919778823852539\n",
            "Training Loss : -9.672157287597656\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 11 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 51.75\n",
            "Eval_StdReturn : 17.311485290527344\n",
            "Eval_MaxReturn : 78.0\n",
            "Eval_MinReturn : 28.0\n",
            "Eval_AverageEpLen : 51.75\n",
            "Train_AverageReturn : 46.6363639831543\n",
            "Train_StdReturn : 18.675567626953125\n",
            "Train_MaxReturn : 106.0\n",
            "Train_MinReturn : 27.0\n",
            "Train_AverageEpLen : 46.63636363636363\n",
            "Train_EnvstepsSoFar : 12395\n",
            "TimeSinceStart : 17.32117509841919\n",
            "Training Loss : -6.167761325836182\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 12 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 74.83333587646484\n",
            "Eval_StdReturn : 39.426795959472656\n",
            "Eval_MaxReturn : 160.0\n",
            "Eval_MinReturn : 39.0\n",
            "Eval_AverageEpLen : 74.83333333333333\n",
            "Train_AverageReturn : 61.38888931274414\n",
            "Train_StdReturn : 27.998292922973633\n",
            "Train_MaxReturn : 126.0\n",
            "Train_MinReturn : 28.0\n",
            "Train_AverageEpLen : 61.388888888888886\n",
            "Train_EnvstepsSoFar : 13500\n",
            "TimeSinceStart : 18.811023235321045\n",
            "Training Loss : -1.9805831909179688\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 13 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 57.14285659790039\n",
            "Eval_StdReturn : 26.035297393798828\n",
            "Eval_MaxReturn : 104.0\n",
            "Eval_MinReturn : 30.0\n",
            "Eval_AverageEpLen : 57.142857142857146\n",
            "Train_AverageReturn : 69.53333282470703\n",
            "Train_StdReturn : 39.93639373779297\n",
            "Train_MaxReturn : 183.0\n",
            "Train_MinReturn : 24.0\n",
            "Train_AverageEpLen : 69.53333333333333\n",
            "Train_EnvstepsSoFar : 14543\n",
            "TimeSinceStart : 20.237784147262573\n",
            "Training Loss : 15.10614013671875\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 14 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 80.19999694824219\n",
            "Eval_StdReturn : 9.195651054382324\n",
            "Eval_MaxReturn : 90.0\n",
            "Eval_MinReturn : 65.0\n",
            "Eval_AverageEpLen : 80.2\n",
            "Train_AverageReturn : 82.53845977783203\n",
            "Train_StdReturn : 44.26774215698242\n",
            "Train_MaxReturn : 188.0\n",
            "Train_MinReturn : 35.0\n",
            "Train_AverageEpLen : 82.53846153846153\n",
            "Train_EnvstepsSoFar : 15616\n",
            "TimeSinceStart : 21.68943190574646\n",
            "Training Loss : -4.1357421875\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 15 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 76.83333587646484\n",
            "Eval_StdReturn : 25.082639694213867\n",
            "Eval_MaxReturn : 123.0\n",
            "Eval_MinReturn : 47.0\n",
            "Eval_AverageEpLen : 76.83333333333333\n",
            "Train_AverageReturn : 95.54545593261719\n",
            "Train_StdReturn : 27.460264205932617\n",
            "Train_MaxReturn : 143.0\n",
            "Train_MinReturn : 60.0\n",
            "Train_AverageEpLen : 95.54545454545455\n",
            "Train_EnvstepsSoFar : 16667\n",
            "TimeSinceStart : 23.171478509902954\n",
            "Training Loss : -3.827620506286621\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 16 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 74.0\n",
            "Eval_StdReturn : 27.300792694091797\n",
            "Eval_MaxReturn : 114.0\n",
            "Eval_MinReturn : 40.0\n",
            "Eval_AverageEpLen : 74.0\n",
            "Train_AverageReturn : 72.64286041259766\n",
            "Train_StdReturn : 18.896739959716797\n",
            "Train_MaxReturn : 110.0\n",
            "Train_MinReturn : 47.0\n",
            "Train_AverageEpLen : 72.64285714285714\n",
            "Train_EnvstepsSoFar : 17684\n",
            "TimeSinceStart : 24.59265899658203\n",
            "Training Loss : -8.80021858215332\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 17 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 67.57142639160156\n",
            "Eval_StdReturn : 19.338024139404297\n",
            "Eval_MaxReturn : 100.0\n",
            "Eval_MinReturn : 40.0\n",
            "Eval_AverageEpLen : 67.57142857142857\n",
            "Train_AverageReturn : 71.85713958740234\n",
            "Train_StdReturn : 18.75731086730957\n",
            "Train_MaxReturn : 104.0\n",
            "Train_MinReturn : 42.0\n",
            "Train_AverageEpLen : 71.85714285714286\n",
            "Train_EnvstepsSoFar : 18690\n",
            "TimeSinceStart : 26.01059865951538\n",
            "Training Loss : -8.92135238647461\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 18 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 62.42856979370117\n",
            "Eval_StdReturn : 12.860318183898926\n",
            "Eval_MaxReturn : 84.0\n",
            "Eval_MinReturn : 46.0\n",
            "Eval_AverageEpLen : 62.42857142857143\n",
            "Train_AverageReturn : 86.83333587646484\n",
            "Train_StdReturn : 41.18825149536133\n",
            "Train_MaxReturn : 183.0\n",
            "Train_MinReturn : 46.0\n",
            "Train_AverageEpLen : 86.83333333333333\n",
            "Train_EnvstepsSoFar : 19732\n",
            "TimeSinceStart : 27.472663164138794\n",
            "Training Loss : -3.276508331298828\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 19 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 100.25\n",
            "Eval_StdReturn : 58.640323638916016\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 57.0\n",
            "Eval_AverageEpLen : 100.25\n",
            "Train_AverageReturn : 100.0\n",
            "Train_StdReturn : 23.74868392944336\n",
            "Train_MaxReturn : 135.0\n",
            "Train_MinReturn : 58.0\n",
            "Train_AverageEpLen : 100.0\n",
            "Train_EnvstepsSoFar : 20732\n",
            "TimeSinceStart : 28.816946268081665\n",
            "Training Loss : -7.134197235107422\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 20 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 136.0\n",
            "Eval_StdReturn : 40.82278823852539\n",
            "Eval_MaxReturn : 189.0\n",
            "Eval_MinReturn : 78.0\n",
            "Eval_AverageEpLen : 136.0\n",
            "Train_AverageReturn : 97.0\n",
            "Train_StdReturn : 34.28490447998047\n",
            "Train_MaxReturn : 197.0\n",
            "Train_MinReturn : 56.0\n",
            "Train_AverageEpLen : 97.0\n",
            "Train_EnvstepsSoFar : 21799\n",
            "TimeSinceStart : 30.43562960624695\n",
            "Training Loss : 2.775402069091797\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 21 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 113.75\n",
            "Eval_StdReturn : 35.08115768432617\n",
            "Eval_MaxReturn : 173.0\n",
            "Eval_MinReturn : 83.0\n",
            "Eval_AverageEpLen : 113.75\n",
            "Train_AverageReturn : 113.0\n",
            "Train_StdReturn : 43.553287506103516\n",
            "Train_MaxReturn : 193.0\n",
            "Train_MinReturn : 66.0\n",
            "Train_AverageEpLen : 113.0\n",
            "Train_EnvstepsSoFar : 22816\n",
            "TimeSinceStart : 31.82199192047119\n",
            "Training Loss : -1.7644195556640625\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 22 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 169.3333282470703\n",
            "Eval_StdReturn : 21.699975967407227\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 153.0\n",
            "Eval_AverageEpLen : 169.33333333333334\n",
            "Train_AverageReturn : 156.0\n",
            "Train_StdReturn : 41.06788635253906\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 82.0\n",
            "Train_AverageEpLen : 156.0\n",
            "Train_EnvstepsSoFar : 23908\n",
            "TimeSinceStart : 33.34596395492554\n",
            "Training Loss : 10.612316131591797\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 23 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 143.6666717529297\n",
            "Eval_StdReturn : 47.86323165893555\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 83.0\n",
            "Eval_AverageEpLen : 143.66666666666666\n",
            "Train_AverageReturn : 121.44444274902344\n",
            "Train_StdReturn : 24.85563087463379\n",
            "Train_MaxReturn : 154.0\n",
            "Train_MinReturn : 79.0\n",
            "Train_AverageEpLen : 121.44444444444444\n",
            "Train_EnvstepsSoFar : 25001\n",
            "TimeSinceStart : 34.78277945518494\n",
            "Training Loss : -9.6474609375\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 24 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 134.0\n",
            "Eval_StdReturn : 9.416297912597656\n",
            "Eval_MaxReturn : 146.0\n",
            "Eval_MinReturn : 123.0\n",
            "Eval_AverageEpLen : 134.0\n",
            "Train_AverageReturn : 118.33333587646484\n",
            "Train_StdReturn : 35.238868713378906\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 69.0\n",
            "Train_AverageEpLen : 118.33333333333333\n",
            "Train_EnvstepsSoFar : 26066\n",
            "TimeSinceStart : 36.19151544570923\n",
            "Training Loss : 11.47061538696289\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 25 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 156.6666717529297\n",
            "Eval_StdReturn : 55.72153091430664\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 78.0\n",
            "Eval_AverageEpLen : 156.66666666666666\n",
            "Train_AverageReturn : 156.0\n",
            "Train_StdReturn : 29.237939834594727\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 117.0\n",
            "Train_AverageEpLen : 156.0\n",
            "Train_EnvstepsSoFar : 27158\n",
            "TimeSinceStart : 37.69582676887512\n",
            "Training Loss : 30.609756469726562\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 26 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 184.3333282470703\n",
            "Eval_StdReturn : 22.1560115814209\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 153.0\n",
            "Eval_AverageEpLen : 184.33333333333334\n",
            "Train_AverageReturn : 164.2857208251953\n",
            "Train_StdReturn : 33.238162994384766\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 109.0\n",
            "Train_AverageEpLen : 164.28571428571428\n",
            "Train_EnvstepsSoFar : 28308\n",
            "TimeSinceStart : 39.31538414955139\n",
            "Training Loss : -14.871077537536621\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 27 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 177.0\n",
            "Train_StdReturn : 14.537307739257812\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 161.0\n",
            "Train_AverageEpLen : 177.0\n",
            "Train_EnvstepsSoFar : 29370\n",
            "TimeSinceStart : 40.76681661605835\n",
            "Training Loss : 10.636945724487305\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 28 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 191.1666717529297\n",
            "Train_StdReturn : 12.889488220214844\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 168.0\n",
            "Train_AverageEpLen : 191.16666666666666\n",
            "Train_EnvstepsSoFar : 30517\n",
            "TimeSinceStart : 42.25154447555542\n",
            "Training Loss : 2.558868408203125\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 29 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 31517\n",
            "TimeSinceStart : 43.59251666069031\n",
            "Training Loss : 16.148000717163086\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 30 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 32517\n",
            "TimeSinceStart : 44.999074935913086\n",
            "Training Loss : 8.456890106201172\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 31 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 33517\n",
            "TimeSinceStart : 46.377644062042236\n",
            "Training Loss : 15.688060760498047\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 32 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 34517\n",
            "TimeSinceStart : 47.73702692985535\n",
            "Training Loss : 18.180641174316406\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 33 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 35517\n",
            "TimeSinceStart : 49.10505771636963\n",
            "Training Loss : 15.112428665161133\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 34 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 36517\n",
            "TimeSinceStart : 50.46058750152588\n",
            "Training Loss : 14.316056251525879\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 35 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 37517\n",
            "TimeSinceStart : 51.819793701171875\n",
            "Training Loss : 18.91094398498535\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 36 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 38517\n",
            "TimeSinceStart : 53.14222025871277\n",
            "Training Loss : 7.143811225891113\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 37 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 39517\n",
            "TimeSinceStart : 54.48259782791138\n",
            "Training Loss : 4.811718940734863\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 38 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 40517\n",
            "TimeSinceStart : 55.829440116882324\n",
            "Training Loss : 2.940330982208252\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 39 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 41517\n",
            "TimeSinceStart : 57.1932418346405\n",
            "Training Loss : 15.669596672058105\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 40 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 42517\n",
            "TimeSinceStart : 58.53454923629761\n",
            "Training Loss : 8.01899242401123\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 41 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 43517\n",
            "TimeSinceStart : 59.95645880699158\n",
            "Training Loss : 19.402379989624023\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 42 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 44517\n",
            "TimeSinceStart : 61.343953132629395\n",
            "Training Loss : -6.252616882324219\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 43 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 193.0\n",
            "Train_StdReturn : 15.65247631072998\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 158.0\n",
            "Train_AverageEpLen : 193.0\n",
            "Train_EnvstepsSoFar : 45675\n",
            "TimeSinceStart : 62.88024854660034\n",
            "Training Loss : -8.911588668823242\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 44 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 46675\n",
            "TimeSinceStart : 64.25604605674744\n",
            "Training Loss : -2.0607643127441406\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 45 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 47675\n",
            "TimeSinceStart : 65.60697841644287\n",
            "Training Loss : 15.652759552001953\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 46 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 48675\n",
            "TimeSinceStart : 66.94408869743347\n",
            "Training Loss : 7.253491401672363\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 47 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 49675\n",
            "TimeSinceStart : 68.30272626876831\n",
            "Training Loss : -8.817203521728516\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 48 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 50675\n",
            "TimeSinceStart : 69.63359951972961\n",
            "Training Loss : 4.465995788574219\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 49 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 51675\n",
            "TimeSinceStart : 71.00460743904114\n",
            "Training Loss : 21.93307876586914\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 50 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 52675\n",
            "TimeSinceStart : 72.35399150848389\n",
            "Training Loss : -12.459051132202148\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 51 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 53675\n",
            "TimeSinceStart : 73.72001028060913\n",
            "Training Loss : -20.37255859375\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 52 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 54675\n",
            "TimeSinceStart : 75.07551622390747\n",
            "Training Loss : -24.978042602539062\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 53 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 55675\n",
            "TimeSinceStart : 76.47079730033875\n",
            "Training Loss : -21.07861328125\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 54 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 56675\n",
            "TimeSinceStart : 77.84233808517456\n",
            "Training Loss : -10.389971733093262\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 55 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 57675\n",
            "TimeSinceStart : 79.19046425819397\n",
            "Training Loss : -29.14322280883789\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 56 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 58675\n",
            "TimeSinceStart : 80.58941102027893\n",
            "Training Loss : -1.1417598724365234\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 57 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 189.0\n",
            "Eval_StdReturn : 15.55634880065918\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 167.0\n",
            "Eval_AverageEpLen : 189.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 59675\n",
            "TimeSinceStart : 82.09799098968506\n",
            "Training Loss : -30.906396865844727\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 58 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 159.42857360839844\n",
            "Train_StdReturn : 65.87186431884766\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 30.0\n",
            "Train_AverageEpLen : 159.42857142857142\n",
            "Train_EnvstepsSoFar : 60791\n",
            "TimeSinceStart : 83.62574458122253\n",
            "Training Loss : -5.67949104309082\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 59 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 187.8333282470703\n",
            "Train_StdReturn : 27.205493927001953\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 127.0\n",
            "Train_AverageEpLen : 187.83333333333334\n",
            "Train_EnvstepsSoFar : 61918\n",
            "TimeSinceStart : 85.09844207763672\n",
            "Training Loss : -3.7501237392425537\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 60 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 62918\n",
            "TimeSinceStart : 86.49109435081482\n",
            "Training Loss : 0.25782203674316406\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 61 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 63918\n",
            "TimeSinceStart : 87.848637342453\n",
            "Training Loss : 2.6721878051757812\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 62 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 64918\n",
            "TimeSinceStart : 89.21353936195374\n",
            "Training Loss : -4.798525810241699\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 63 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 65918\n",
            "TimeSinceStart : 90.5969021320343\n",
            "Training Loss : -30.57380485534668\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 64 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 66918\n",
            "TimeSinceStart : 92.0123119354248\n",
            "Training Loss : -29.145492553710938\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 65 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 67918\n",
            "TimeSinceStart : 93.54047155380249\n",
            "Training Loss : -4.739597320556641\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 66 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 68918\n",
            "TimeSinceStart : 94.93987584114075\n",
            "Training Loss : -5.456677436828613\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 67 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 69918\n",
            "TimeSinceStart : 96.29913425445557\n",
            "Training Loss : -1.3785734176635742\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 68 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 70918\n",
            "TimeSinceStart : 97.67863440513611\n",
            "Training Loss : 12.63626480102539\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 69 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 71918\n",
            "TimeSinceStart : 99.03550553321838\n",
            "Training Loss : -24.133703231811523\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 70 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 72918\n",
            "TimeSinceStart : 100.36845064163208\n",
            "Training Loss : 20.29106903076172\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 71 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 73918\n",
            "TimeSinceStart : 101.92555618286133\n",
            "Training Loss : -15.401583671569824\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 72 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 74918\n",
            "TimeSinceStart : 103.28639268875122\n",
            "Training Loss : -9.949955940246582\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 73 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 75918\n",
            "TimeSinceStart : 104.64576506614685\n",
            "Training Loss : -4.911197662353516\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 74 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 76918\n",
            "TimeSinceStart : 106.03958868980408\n",
            "Training Loss : 5.315553665161133\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 75 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 77918\n",
            "TimeSinceStart : 107.39360761642456\n",
            "Training Loss : 18.755027770996094\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 76 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 78918\n",
            "TimeSinceStart : 108.75749158859253\n",
            "Training Loss : -4.883920192718506\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 77 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 79918\n",
            "TimeSinceStart : 110.11620998382568\n",
            "Training Loss : -12.833853721618652\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 78 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 80918\n",
            "TimeSinceStart : 111.54616451263428\n",
            "Training Loss : -22.19642448425293\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 79 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 81918\n",
            "TimeSinceStart : 112.86733961105347\n",
            "Training Loss : 10.31665325164795\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 80 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 82918\n",
            "TimeSinceStart : 114.28779530525208\n",
            "Training Loss : 27.85149383544922\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 81 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 83918\n",
            "TimeSinceStart : 115.68877458572388\n",
            "Training Loss : -23.977787017822266\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 82 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 84918\n",
            "TimeSinceStart : 117.01939010620117\n",
            "Training Loss : -24.35320281982422\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 83 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 85918\n",
            "TimeSinceStart : 118.36765789985657\n",
            "Training Loss : 2.0872135162353516\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 84 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 86918\n",
            "TimeSinceStart : 119.75475692749023\n",
            "Training Loss : -24.982194900512695\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 85 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 87918\n",
            "TimeSinceStart : 121.10181760787964\n",
            "Training Loss : -26.975908279418945\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 86 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 88918\n",
            "TimeSinceStart : 122.46347165107727\n",
            "Training Loss : -27.68096923828125\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 87 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 89918\n",
            "TimeSinceStart : 123.80997109413147\n",
            "Training Loss : -30.377281188964844\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 88 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 199.0\n",
            "Train_StdReturn : 2.2360680103302\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 194.0\n",
            "Train_AverageEpLen : 199.0\n",
            "Train_EnvstepsSoFar : 91112\n",
            "TimeSinceStart : 125.59118151664734\n",
            "Training Loss : -32.95043182373047\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 89 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 197.0\n",
            "Eval_StdReturn : 2.4494898319244385\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 194.0\n",
            "Eval_AverageEpLen : 197.0\n",
            "Train_AverageReturn : 196.6666717529297\n",
            "Train_StdReturn : 4.85340690612793\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 188.0\n",
            "Train_AverageEpLen : 196.66666666666666\n",
            "Train_EnvstepsSoFar : 92292\n",
            "TimeSinceStart : 127.54367852210999\n",
            "Training Loss : 7.8101043701171875\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 90 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 93292\n",
            "TimeSinceStart : 128.917870759964\n",
            "Training Loss : -32.55415344238281\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 91 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 94292\n",
            "TimeSinceStart : 130.30689811706543\n",
            "Training Loss : -30.243179321289062\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 92 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 95292\n",
            "TimeSinceStart : 131.7023687362671\n",
            "Training Loss : -31.502120971679688\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 93 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 96292\n",
            "TimeSinceStart : 133.06228685379028\n",
            "Training Loss : -30.745277404785156\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 94 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 97292\n",
            "TimeSinceStart : 134.44439435005188\n",
            "Training Loss : -31.59128189086914\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 95 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 98292\n",
            "TimeSinceStart : 135.83944058418274\n",
            "Training Loss : -32.123138427734375\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 96 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 99292\n",
            "TimeSinceStart : 137.19722390174866\n",
            "Training Loss : -32.346214294433594\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 97 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 100292\n",
            "TimeSinceStart : 138.573810338974\n",
            "Training Loss : -33.85414505004883\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 98 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 101292\n",
            "TimeSinceStart : 139.94185376167297\n",
            "Training Loss : -32.21722412109375\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 99 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 102292\n",
            "TimeSinceStart : 141.29269218444824\n",
            "Training Loss : -32.11923599243164\n",
            "Initial_DataCollection_AverageReturn : 27.648649215698242\n",
            "Done logging...\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python cs285/scripts/run_hw2.py --env_name CartPole-v0 -n 100 -b 1000 \\\n",
        "-rtg --exp_name q1_sb_rtg_na"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9qoaxQYqmcuu",
        "outputId": "1196a201-a0a9-4874-9e26-3cea06e9cf6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "########################\n",
            "logging outputs to  /content/gdrive/My Drive/cs285_f2021/DRL_policy_grads/cs285/scripts/../../data/q2_pg_q1_lb_no_rtg_dsa_CartPole-v0_04-02-2022_16-46-01\n",
            "########################\n",
            "Using GPU id 0\n",
            "\n",
            "\n",
            "********** Iteration 0 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 33.33333206176758\n",
            "Eval_StdReturn : 20.159090042114258\n",
            "Eval_MaxReturn : 82.0\n",
            "Eval_MinReturn : 13.0\n",
            "Eval_AverageEpLen : 33.333333333333336\n",
            "Train_AverageReturn : 25.65816307067871\n",
            "Train_StdReturn : 14.328168869018555\n",
            "Train_MaxReturn : 132.0\n",
            "Train_MinReturn : 8.0\n",
            "Train_AverageEpLen : 25.658163265306122\n",
            "Train_EnvstepsSoFar : 5029\n",
            "TimeSinceStart : 5.3799378871917725\n",
            "Training Loss : 116112.53125\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 1 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 31.538461685180664\n",
            "Eval_StdReturn : 13.624725341796875\n",
            "Eval_MaxReturn : 58.0\n",
            "Eval_MinReturn : 14.0\n",
            "Eval_AverageEpLen : 31.53846153846154\n",
            "Train_AverageReturn : 31.97452163696289\n",
            "Train_StdReturn : 17.77529525756836\n",
            "Train_MaxReturn : 105.0\n",
            "Train_MinReturn : 9.0\n",
            "Train_AverageEpLen : 31.97452229299363\n",
            "Train_EnvstepsSoFar : 10049\n",
            "TimeSinceStart : 10.843060970306396\n",
            "Training Loss : 140149.4375\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 2 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 52.5\n",
            "Eval_StdReturn : 14.396180152893066\n",
            "Eval_MaxReturn : 78.0\n",
            "Eval_MinReturn : 31.0\n",
            "Eval_AverageEpLen : 52.5\n",
            "Train_AverageReturn : 42.092437744140625\n",
            "Train_StdReturn : 21.217161178588867\n",
            "Train_MaxReturn : 121.0\n",
            "Train_MinReturn : 12.0\n",
            "Train_AverageEpLen : 42.09243697478992\n",
            "Train_EnvstepsSoFar : 15058\n",
            "TimeSinceStart : 16.205942630767822\n",
            "Training Loss : 170702.78125\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 3 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 60.85714340209961\n",
            "Eval_StdReturn : 30.870365142822266\n",
            "Eval_MaxReturn : 127.0\n",
            "Eval_MinReturn : 30.0\n",
            "Eval_AverageEpLen : 60.857142857142854\n",
            "Train_AverageReturn : 45.490909576416016\n",
            "Train_StdReturn : 19.291893005371094\n",
            "Train_MaxReturn : 108.0\n",
            "Train_MinReturn : 13.0\n",
            "Train_AverageEpLen : 45.49090909090909\n",
            "Train_EnvstepsSoFar : 20062\n",
            "TimeSinceStart : 21.627787590026855\n",
            "Training Loss : 168055.1875\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 4 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 68.83333587646484\n",
            "Eval_StdReturn : 30.878345489501953\n",
            "Eval_MaxReturn : 108.0\n",
            "Eval_MinReturn : 30.0\n",
            "Eval_AverageEpLen : 68.83333333333333\n",
            "Train_AverageReturn : 51.20408248901367\n",
            "Train_StdReturn : 26.624736785888672\n",
            "Train_MaxReturn : 174.0\n",
            "Train_MinReturn : 18.0\n",
            "Train_AverageEpLen : 51.204081632653065\n",
            "Train_EnvstepsSoFar : 25080\n",
            "TimeSinceStart : 27.036601543426514\n",
            "Training Loss : 197715.359375\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 5 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 77.5\n",
            "Eval_StdReturn : 24.472774505615234\n",
            "Eval_MaxReturn : 109.0\n",
            "Eval_MinReturn : 40.0\n",
            "Eval_AverageEpLen : 77.5\n",
            "Train_AverageReturn : 65.48052215576172\n",
            "Train_StdReturn : 23.568971633911133\n",
            "Train_MaxReturn : 139.0\n",
            "Train_MinReturn : 26.0\n",
            "Train_AverageEpLen : 65.48051948051948\n",
            "Train_EnvstepsSoFar : 30122\n",
            "TimeSinceStart : 32.592835664749146\n",
            "Training Loss : 219308.09375\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 6 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 58.28571319580078\n",
            "Eval_StdReturn : 24.010202407836914\n",
            "Eval_MaxReturn : 109.0\n",
            "Eval_MinReturn : 25.0\n",
            "Eval_AverageEpLen : 58.285714285714285\n",
            "Train_AverageReturn : 70.53520965576172\n",
            "Train_StdReturn : 32.956581115722656\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 23.0\n",
            "Train_AverageEpLen : 70.53521126760563\n",
            "Train_EnvstepsSoFar : 35130\n",
            "TimeSinceStart : 37.937633752822876\n",
            "Training Loss : 246267.4375\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 7 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 113.5\n",
            "Eval_StdReturn : 21.68524932861328\n",
            "Eval_MaxReturn : 150.0\n",
            "Eval_MinReturn : 93.0\n",
            "Eval_AverageEpLen : 113.5\n",
            "Train_AverageReturn : 77.01515197753906\n",
            "Train_StdReturn : 31.28049659729004\n",
            "Train_MaxReturn : 156.0\n",
            "Train_MinReturn : 30.0\n",
            "Train_AverageEpLen : 77.01515151515152\n",
            "Train_EnvstepsSoFar : 40213\n",
            "TimeSinceStart : 43.36684513092041\n",
            "Training Loss : 251837.375\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 8 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 92.4000015258789\n",
            "Eval_StdReturn : 10.594338417053223\n",
            "Eval_MaxReturn : 105.0\n",
            "Eval_MinReturn : 80.0\n",
            "Eval_AverageEpLen : 92.4\n",
            "Train_AverageReturn : 78.59375\n",
            "Train_StdReturn : 34.328250885009766\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 26.0\n",
            "Train_AverageEpLen : 78.59375\n",
            "Train_EnvstepsSoFar : 45243\n",
            "TimeSinceStart : 48.803605794906616\n",
            "Training Loss : 257722.203125\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 9 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 97.0\n",
            "Eval_StdReturn : 39.613128662109375\n",
            "Eval_MaxReturn : 144.0\n",
            "Eval_MinReturn : 43.0\n",
            "Eval_AverageEpLen : 97.0\n",
            "Train_AverageReturn : 98.68627166748047\n",
            "Train_StdReturn : 33.887062072753906\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 47.0\n",
            "Train_AverageEpLen : 98.68627450980392\n",
            "Train_EnvstepsSoFar : 50276\n",
            "TimeSinceStart : 54.29566740989685\n",
            "Training Loss : 292526.625\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 10 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 102.5999984741211\n",
            "Eval_StdReturn : 37.07613754272461\n",
            "Eval_MaxReturn : 167.0\n",
            "Eval_MinReturn : 54.0\n",
            "Eval_AverageEpLen : 102.6\n",
            "Train_AverageReturn : 119.95237731933594\n",
            "Train_StdReturn : 43.38803482055664\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 52.0\n",
            "Train_AverageEpLen : 119.95238095238095\n",
            "Train_EnvstepsSoFar : 55314\n",
            "TimeSinceStart : 59.841002464294434\n",
            "Training Loss : 351381.0\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 11 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 121.0\n",
            "Eval_StdReturn : 36.78994369506836\n",
            "Eval_MaxReturn : 170.0\n",
            "Eval_MinReturn : 67.0\n",
            "Eval_AverageEpLen : 121.0\n",
            "Train_AverageReturn : 141.02777099609375\n",
            "Train_StdReturn : 40.50959014892578\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 74.0\n",
            "Train_AverageEpLen : 141.02777777777777\n",
            "Train_EnvstepsSoFar : 60391\n",
            "TimeSinceStart : 65.32771420478821\n",
            "Training Loss : 399131.4375\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 12 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 173.3333282470703\n",
            "Eval_StdReturn : 20.54804801940918\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 150.0\n",
            "Eval_AverageEpLen : 173.33333333333334\n",
            "Train_AverageReturn : 148.11764526367188\n",
            "Train_StdReturn : 35.426612854003906\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 52.0\n",
            "Train_AverageEpLen : 148.11764705882354\n",
            "Train_EnvstepsSoFar : 65427\n",
            "TimeSinceStart : 70.85170364379883\n",
            "Training Loss : 398702.6875\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 13 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 164.3333282470703\n",
            "Eval_StdReturn : 28.158281326293945\n",
            "Eval_MaxReturn : 195.0\n",
            "Eval_MinReturn : 127.0\n",
            "Eval_AverageEpLen : 164.33333333333334\n",
            "Train_AverageReturn : 160.53125\n",
            "Train_StdReturn : 30.605335235595703\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 105.0\n",
            "Train_AverageEpLen : 160.53125\n",
            "Train_EnvstepsSoFar : 70564\n",
            "TimeSinceStart : 76.48421144485474\n",
            "Training Loss : 413748.9375\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 14 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 160.0\n",
            "Eval_StdReturn : 29.223278045654297\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 131.0\n",
            "Eval_AverageEpLen : 160.0\n",
            "Train_AverageReturn : 161.1875\n",
            "Train_StdReturn : 28.548683166503906\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 113.0\n",
            "Train_AverageEpLen : 161.1875\n",
            "Train_EnvstepsSoFar : 75722\n",
            "TimeSinceStart : 82.05785584449768\n",
            "Training Loss : 413998.09375\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 15 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 141.6666717529297\n",
            "Eval_StdReturn : 42.6953010559082\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 99.0\n",
            "Eval_AverageEpLen : 141.66666666666666\n",
            "Train_AverageReturn : 164.0\n",
            "Train_StdReturn : 31.81498908996582\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 98.0\n",
            "Train_AverageEpLen : 164.0\n",
            "Train_EnvstepsSoFar : 80806\n",
            "TimeSinceStart : 87.6561632156372\n",
            "Training Loss : 419875.65625\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 16 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 157.3333282470703\n",
            "Eval_StdReturn : 30.70649528503418\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 129.0\n",
            "Eval_AverageEpLen : 157.33333333333334\n",
            "Train_AverageReturn : 160.375\n",
            "Train_StdReturn : 37.891910552978516\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 94.0\n",
            "Train_AverageEpLen : 160.375\n",
            "Train_EnvstepsSoFar : 85938\n",
            "TimeSinceStart : 98.60770750045776\n",
            "Training Loss : 409889.90625\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 17 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 174.3333282470703\n",
            "Eval_StdReturn : 25.82419204711914\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 139.0\n",
            "Eval_AverageEpLen : 174.33333333333334\n",
            "Train_AverageReturn : 156.40625\n",
            "Train_StdReturn : 32.338890075683594\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 100.0\n",
            "Train_AverageEpLen : 156.40625\n",
            "Train_EnvstepsSoFar : 90943\n",
            "TimeSinceStart : 110.80741691589355\n",
            "Training Loss : 382624.75\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 18 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 167.5806427001953\n",
            "Train_StdReturn : 32.7904167175293\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 93.0\n",
            "Train_AverageEpLen : 167.58064516129033\n",
            "Train_EnvstepsSoFar : 96138\n",
            "TimeSinceStart : 116.39691209793091\n",
            "Training Loss : 416849.375\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 19 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 186.0\n",
            "Eval_StdReturn : 19.79899024963379\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 158.0\n",
            "Eval_AverageEpLen : 186.0\n",
            "Train_AverageReturn : 179.85714721679688\n",
            "Train_StdReturn : 33.210060119628906\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 92.0\n",
            "Train_AverageEpLen : 179.85714285714286\n",
            "Train_EnvstepsSoFar : 101174\n",
            "TimeSinceStart : 124.22892260551453\n",
            "Training Loss : 434347.59375\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 20 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 184.0\n",
            "Eval_StdReturn : 17.28197479248047\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 160.0\n",
            "Eval_AverageEpLen : 184.0\n",
            "Train_AverageReturn : 171.8000030517578\n",
            "Train_StdReturn : 35.56626892089844\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 102.0\n",
            "Train_AverageEpLen : 171.8\n",
            "Train_EnvstepsSoFar : 106328\n",
            "TimeSinceStart : 135.1439290046692\n",
            "Training Loss : 410455.625\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 21 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 155.0\n",
            "Eval_StdReturn : 43.59663391113281\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 96.0\n",
            "Eval_AverageEpLen : 155.0\n",
            "Train_AverageReturn : 173.03448486328125\n",
            "Train_StdReturn : 30.704914093017578\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 116.0\n",
            "Train_AverageEpLen : 173.0344827586207\n",
            "Train_EnvstepsSoFar : 111346\n",
            "TimeSinceStart : 143.814106464386\n",
            "Training Loss : 404383.1875\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 22 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 180.7857208251953\n",
            "Train_StdReturn : 28.20379638671875\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 103.0\n",
            "Train_AverageEpLen : 180.78571428571428\n",
            "Train_EnvstepsSoFar : 116408\n",
            "TimeSinceStart : 149.33673572540283\n",
            "Training Loss : 403245.0625\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 23 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 134.0\n",
            "Eval_StdReturn : 47.52543258666992\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 90.0\n",
            "Eval_AverageEpLen : 134.0\n",
            "Train_AverageReturn : 176.37930297851562\n",
            "Train_StdReturn : 30.304677963256836\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 98.0\n",
            "Train_AverageEpLen : 176.3793103448276\n",
            "Train_EnvstepsSoFar : 121523\n",
            "TimeSinceStart : 154.85067772865295\n",
            "Training Loss : 411726.75\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 24 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 138.6666717529297\n",
            "Eval_StdReturn : 6.944222450256348\n",
            "Eval_MaxReturn : 145.0\n",
            "Eval_MinReturn : 129.0\n",
            "Eval_AverageEpLen : 138.66666666666666\n",
            "Train_AverageReturn : 174.27586364746094\n",
            "Train_StdReturn : 32.411041259765625\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 96.0\n",
            "Train_AverageEpLen : 174.27586206896552\n",
            "Train_EnvstepsSoFar : 126577\n",
            "TimeSinceStart : 160.31446886062622\n",
            "Training Loss : 395265.75\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 25 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 119.5\n",
            "Eval_StdReturn : 8.558621406555176\n",
            "Eval_MaxReturn : 130.0\n",
            "Eval_MinReturn : 107.0\n",
            "Eval_AverageEpLen : 119.5\n",
            "Train_AverageReturn : 154.18182373046875\n",
            "Train_StdReturn : 36.57242965698242\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 85.0\n",
            "Train_AverageEpLen : 154.1818181818182\n",
            "Train_EnvstepsSoFar : 131665\n",
            "TimeSinceStart : 165.88440465927124\n",
            "Training Loss : 354966.75\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 26 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 125.25\n",
            "Eval_StdReturn : 11.540688514709473\n",
            "Eval_MaxReturn : 140.0\n",
            "Eval_MinReturn : 113.0\n",
            "Eval_AverageEpLen : 125.25\n",
            "Train_AverageReturn : 141.13888549804688\n",
            "Train_StdReturn : 30.533363342285156\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 90.0\n",
            "Train_AverageEpLen : 141.13888888888889\n",
            "Train_EnvstepsSoFar : 136746\n",
            "TimeSinceStart : 171.53481435775757\n",
            "Training Loss : 327546.65625\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 27 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 120.75\n",
            "Eval_StdReturn : 9.756407737731934\n",
            "Eval_MaxReturn : 137.0\n",
            "Eval_MinReturn : 111.0\n",
            "Eval_AverageEpLen : 120.75\n",
            "Train_AverageReturn : 130.25640869140625\n",
            "Train_StdReturn : 26.31926155090332\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 95.0\n",
            "Train_AverageEpLen : 130.25641025641025\n",
            "Train_EnvstepsSoFar : 141826\n",
            "TimeSinceStart : 177.045814037323\n",
            "Training Loss : 291582.625\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 28 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 104.25\n",
            "Eval_StdReturn : 26.30945587158203\n",
            "Eval_MaxReturn : 132.0\n",
            "Eval_MinReturn : 65.0\n",
            "Eval_AverageEpLen : 104.25\n",
            "Train_AverageReturn : 121.23809814453125\n",
            "Train_StdReturn : 16.985721588134766\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 97.0\n",
            "Train_AverageEpLen : 121.23809523809524\n",
            "Train_EnvstepsSoFar : 146918\n",
            "TimeSinceStart : 182.58742904663086\n",
            "Training Loss : 269644.25\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 29 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 111.75\n",
            "Eval_StdReturn : 9.575359344482422\n",
            "Eval_MaxReturn : 126.0\n",
            "Eval_MinReturn : 103.0\n",
            "Eval_AverageEpLen : 111.75\n",
            "Train_AverageReturn : 119.26190185546875\n",
            "Train_StdReturn : 11.602666854858398\n",
            "Train_MaxReturn : 149.0\n",
            "Train_MinReturn : 97.0\n",
            "Train_AverageEpLen : 119.26190476190476\n",
            "Train_EnvstepsSoFar : 151927\n",
            "TimeSinceStart : 187.99977922439575\n",
            "Training Loss : 248315.3125\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 30 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 113.5\n",
            "Eval_StdReturn : 2.872281312942505\n",
            "Eval_MaxReturn : 118.0\n",
            "Eval_MinReturn : 110.0\n",
            "Eval_AverageEpLen : 113.5\n",
            "Train_AverageReturn : 113.95454406738281\n",
            "Train_StdReturn : 19.035797119140625\n",
            "Train_MaxReturn : 138.0\n",
            "Train_MinReturn : 36.0\n",
            "Train_AverageEpLen : 113.95454545454545\n",
            "Train_EnvstepsSoFar : 156941\n",
            "TimeSinceStart : 193.435711145401\n",
            "Training Loss : 247662.40625\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 31 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 127.5\n",
            "Eval_StdReturn : 1.658312439918518\n",
            "Eval_MaxReturn : 129.0\n",
            "Eval_MinReturn : 125.0\n",
            "Eval_AverageEpLen : 127.5\n",
            "Train_AverageReturn : 114.88636016845703\n",
            "Train_StdReturn : 12.3641996383667\n",
            "Train_MaxReturn : 148.0\n",
            "Train_MinReturn : 66.0\n",
            "Train_AverageEpLen : 114.88636363636364\n",
            "Train_EnvstepsSoFar : 161996\n",
            "TimeSinceStart : 198.98275923728943\n",
            "Training Loss : 245538.015625\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 32 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 120.0\n",
            "Eval_StdReturn : 6.363961219787598\n",
            "Eval_MaxReturn : 130.0\n",
            "Eval_MinReturn : 114.0\n",
            "Eval_AverageEpLen : 120.0\n",
            "Train_AverageReturn : 115.84091186523438\n",
            "Train_StdReturn : 11.387679100036621\n",
            "Train_MaxReturn : 143.0\n",
            "Train_MinReturn : 98.0\n",
            "Train_AverageEpLen : 115.8409090909091\n",
            "Train_EnvstepsSoFar : 167093\n",
            "TimeSinceStart : 204.52099895477295\n",
            "Training Loss : 249715.875\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 33 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 114.25\n",
            "Eval_StdReturn : 10.917303085327148\n",
            "Eval_MaxReturn : 130.0\n",
            "Eval_MinReturn : 101.0\n",
            "Eval_AverageEpLen : 114.25\n",
            "Train_AverageReturn : 111.4000015258789\n",
            "Train_StdReturn : 19.310791015625\n",
            "Train_MaxReturn : 134.0\n",
            "Train_MinReturn : 37.0\n",
            "Train_AverageEpLen : 111.4\n",
            "Train_EnvstepsSoFar : 172106\n",
            "TimeSinceStart : 210.2962188720703\n",
            "Training Loss : 233428.125\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 34 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 121.75\n",
            "Eval_StdReturn : 5.117372512817383\n",
            "Eval_MaxReturn : 130.0\n",
            "Eval_MinReturn : 116.0\n",
            "Eval_AverageEpLen : 121.75\n",
            "Train_AverageReturn : 108.86956787109375\n",
            "Train_StdReturn : 19.107940673828125\n",
            "Train_MaxReturn : 135.0\n",
            "Train_MinReturn : 54.0\n",
            "Train_AverageEpLen : 108.8695652173913\n",
            "Train_EnvstepsSoFar : 177114\n",
            "TimeSinceStart : 216.83194136619568\n",
            "Training Loss : 223074.875\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 35 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 119.5\n",
            "Eval_StdReturn : 1.5\n",
            "Eval_MaxReturn : 121.0\n",
            "Eval_MinReturn : 117.0\n",
            "Eval_AverageEpLen : 119.5\n",
            "Train_AverageReturn : 117.39534759521484\n",
            "Train_StdReturn : 14.719294548034668\n",
            "Train_MaxReturn : 145.0\n",
            "Train_MinReturn : 47.0\n",
            "Train_AverageEpLen : 117.3953488372093\n",
            "Train_EnvstepsSoFar : 182162\n",
            "TimeSinceStart : 222.3479118347168\n",
            "Training Loss : 240662.265625\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 36 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 140.6666717529297\n",
            "Eval_StdReturn : 4.027681827545166\n",
            "Eval_MaxReturn : 144.0\n",
            "Eval_MinReturn : 135.0\n",
            "Eval_AverageEpLen : 140.66666666666666\n",
            "Train_AverageReturn : 125.43902587890625\n",
            "Train_StdReturn : 11.382590293884277\n",
            "Train_MaxReturn : 146.0\n",
            "Train_MinReturn : 102.0\n",
            "Train_AverageEpLen : 125.4390243902439\n",
            "Train_EnvstepsSoFar : 187305\n",
            "TimeSinceStart : 227.99393916130066\n",
            "Training Loss : 249142.53125\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 37 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 140.3333282470703\n",
            "Eval_StdReturn : 7.363574028015137\n",
            "Eval_MaxReturn : 149.0\n",
            "Eval_MinReturn : 131.0\n",
            "Eval_AverageEpLen : 140.33333333333334\n",
            "Train_AverageReturn : 138.2432403564453\n",
            "Train_StdReturn : 15.078901290893555\n",
            "Train_MaxReturn : 170.0\n",
            "Train_MinReturn : 113.0\n",
            "Train_AverageEpLen : 138.24324324324326\n",
            "Train_EnvstepsSoFar : 192420\n",
            "TimeSinceStart : 233.37755250930786\n",
            "Training Loss : 282440.0\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 38 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 180.0\n",
            "Eval_StdReturn : 13.063945770263672\n",
            "Eval_MaxReturn : 196.0\n",
            "Eval_MinReturn : 164.0\n",
            "Eval_AverageEpLen : 180.0\n",
            "Train_AverageReturn : 156.71875\n",
            "Train_StdReturn : 21.916366577148438\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 125.0\n",
            "Train_AverageEpLen : 156.71875\n",
            "Train_EnvstepsSoFar : 197435\n",
            "TimeSinceStart : 238.89752531051636\n",
            "Training Loss : 313250.40625\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 39 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 185.0\n",
            "Eval_StdReturn : 21.21320343017578\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 155.0\n",
            "Eval_AverageEpLen : 185.0\n",
            "Train_AverageReturn : 177.86207580566406\n",
            "Train_StdReturn : 25.308748245239258\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 134.0\n",
            "Train_AverageEpLen : 177.86206896551724\n",
            "Train_EnvstepsSoFar : 202593\n",
            "TimeSinceStart : 244.550146818161\n",
            "Training Loss : 375871.6875\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 40 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 194.84616088867188\n",
            "Train_StdReturn : 13.363821029663086\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 146.0\n",
            "Train_AverageEpLen : 194.84615384615384\n",
            "Train_EnvstepsSoFar : 207659\n",
            "TimeSinceStart : 250.04895782470703\n",
            "Training Loss : 390603.4375\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 41 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 212659\n",
            "TimeSinceStart : 255.44427919387817\n",
            "Training Loss : 379442.71875\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 42 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 198.0\n",
            "Train_StdReturn : 10.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 148.0\n",
            "Train_AverageEpLen : 198.0\n",
            "Train_EnvstepsSoFar : 217807\n",
            "TimeSinceStart : 261.0561897754669\n",
            "Training Loss : 389023.75\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 43 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 222807\n",
            "TimeSinceStart : 266.3807225227356\n",
            "Training Loss : 377780.875\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 44 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 227807\n",
            "TimeSinceStart : 271.75551891326904\n",
            "Training Loss : 371898.78125\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 45 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 197.23077392578125\n",
            "Train_StdReturn : 13.846153259277344\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 128.0\n",
            "Train_AverageEpLen : 197.23076923076923\n",
            "Train_EnvstepsSoFar : 232935\n",
            "TimeSinceStart : 277.2248418331146\n",
            "Training Loss : 373889.9375\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 46 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 237935\n",
            "TimeSinceStart : 282.5143554210663\n",
            "Training Loss : 377685.5625\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 47 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 171.6666717529297\n",
            "Eval_StdReturn : 40.06938552856445\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 115.0\n",
            "Eval_AverageEpLen : 171.66666666666666\n",
            "Train_AverageReturn : 190.62962341308594\n",
            "Train_StdReturn : 26.512258529663086\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 96.0\n",
            "Train_AverageEpLen : 190.62962962962962\n",
            "Train_EnvstepsSoFar : 243082\n",
            "TimeSinceStart : 288.25617599487305\n",
            "Training Loss : 393394.0\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 48 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 188.25926208496094\n",
            "Train_StdReturn : 28.265399932861328\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 116.0\n",
            "Train_AverageEpLen : 188.25925925925927\n",
            "Train_EnvstepsSoFar : 248165\n",
            "TimeSinceStart : 294.6330029964447\n",
            "Training Loss : 387514.46875\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 49 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 180.17857360839844\n",
            "Train_StdReturn : 34.78511047363281\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 109.0\n",
            "Train_AverageEpLen : 180.17857142857142\n",
            "Train_EnvstepsSoFar : 253210\n",
            "TimeSinceStart : 300.06418633461\n",
            "Training Loss : 370622.28125\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 50 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 184.60714721679688\n",
            "Train_StdReturn : 32.240543365478516\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 107.0\n",
            "Train_AverageEpLen : 184.60714285714286\n",
            "Train_EnvstepsSoFar : 258379\n",
            "TimeSinceStart : 305.615754365921\n",
            "Training Loss : 388122.84375\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 51 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 167.6666717529297\n",
            "Eval_StdReturn : 45.72623825073242\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 103.0\n",
            "Eval_AverageEpLen : 167.66666666666666\n",
            "Train_AverageReturn : 181.60714721679688\n",
            "Train_StdReturn : 41.38351821899414\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 40.0\n",
            "Train_AverageEpLen : 181.60714285714286\n",
            "Train_EnvstepsSoFar : 263464\n",
            "TimeSinceStart : 311.1469647884369\n",
            "Training Loss : 396450.4375\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 52 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 184.42857360839844\n",
            "Train_StdReturn : 40.5713005065918\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 29.0\n",
            "Train_AverageEpLen : 184.42857142857142\n",
            "Train_EnvstepsSoFar : 268628\n",
            "TimeSinceStart : 316.78489351272583\n",
            "Training Loss : 410417.5625\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 53 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 197.6666717529297\n",
            "Eval_StdReturn : 3.2998316287994385\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 193.0\n",
            "Eval_AverageEpLen : 197.66666666666666\n",
            "Train_AverageReturn : 186.1481475830078\n",
            "Train_StdReturn : 39.43649673461914\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 32.0\n",
            "Train_AverageEpLen : 186.14814814814815\n",
            "Train_EnvstepsSoFar : 273654\n",
            "TimeSinceStart : 322.4410991668701\n",
            "Training Loss : 407322.46875\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 54 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 140.3333282470703\n",
            "Eval_StdReturn : 78.79227447509766\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 29.0\n",
            "Eval_AverageEpLen : 140.33333333333334\n",
            "Train_AverageReturn : 195.03846740722656\n",
            "Train_StdReturn : 19.28427505493164\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 100.0\n",
            "Train_AverageEpLen : 195.03846153846155\n",
            "Train_EnvstepsSoFar : 278725\n",
            "TimeSinceStart : 327.9428822994232\n",
            "Training Loss : 424819.4375\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 55 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 141.25\n",
            "Eval_StdReturn : 64.7586898803711\n",
            "Eval_MaxReturn : 191.0\n",
            "Eval_MinReturn : 30.0\n",
            "Eval_AverageEpLen : 141.25\n",
            "Train_AverageReturn : 179.42857360839844\n",
            "Train_StdReturn : 46.40460968017578\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 27.0\n",
            "Train_AverageEpLen : 179.42857142857142\n",
            "Train_EnvstepsSoFar : 283749\n",
            "TimeSinceStart : 333.6098082065582\n",
            "Training Loss : 414224.5\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 56 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 131.5\n",
            "Eval_StdReturn : 60.4710693359375\n",
            "Eval_MaxReturn : 178.0\n",
            "Eval_MinReturn : 28.0\n",
            "Eval_AverageEpLen : 131.5\n",
            "Train_AverageReturn : 156.8125\n",
            "Train_StdReturn : 50.42409896850586\n",
            "Train_MaxReturn : 195.0\n",
            "Train_MinReturn : 27.0\n",
            "Train_AverageEpLen : 156.8125\n",
            "Train_EnvstepsSoFar : 288767\n",
            "TimeSinceStart : 339.12510871887207\n",
            "Training Loss : 369590.40625\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 57 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 116.75\n",
            "Eval_StdReturn : 51.28535461425781\n",
            "Eval_MaxReturn : 153.0\n",
            "Eval_MinReturn : 29.0\n",
            "Eval_AverageEpLen : 116.75\n",
            "Train_AverageReturn : 131.35897827148438\n",
            "Train_StdReturn : 58.46782302856445\n",
            "Train_MaxReturn : 182.0\n",
            "Train_MinReturn : 21.0\n",
            "Train_AverageEpLen : 131.35897435897436\n",
            "Train_EnvstepsSoFar : 293890\n",
            "TimeSinceStart : 344.6672692298889\n",
            "Training Loss : 346385.03125\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 58 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 144.3333282470703\n",
            "Eval_StdReturn : 7.039570331573486\n",
            "Eval_MaxReturn : 152.0\n",
            "Eval_MinReturn : 135.0\n",
            "Eval_AverageEpLen : 144.33333333333334\n",
            "Train_AverageReturn : 94.81481170654297\n",
            "Train_StdReturn : 60.904014587402344\n",
            "Train_MaxReturn : 177.0\n",
            "Train_MinReturn : 21.0\n",
            "Train_AverageEpLen : 94.81481481481481\n",
            "Train_EnvstepsSoFar : 299010\n",
            "TimeSinceStart : 350.28950929641724\n",
            "Training Loss : 289724.4375\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 59 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 166.6666717529297\n",
            "Eval_StdReturn : 1.247219204902649\n",
            "Eval_MaxReturn : 168.0\n",
            "Eval_MinReturn : 165.0\n",
            "Eval_AverageEpLen : 166.66666666666666\n",
            "Train_AverageReturn : 131.73684692382812\n",
            "Train_StdReturn : 47.561973571777344\n",
            "Train_MaxReturn : 171.0\n",
            "Train_MinReturn : 19.0\n",
            "Train_AverageEpLen : 131.73684210526315\n",
            "Train_EnvstepsSoFar : 304016\n",
            "TimeSinceStart : 355.83886456489563\n",
            "Training Loss : 319468.125\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 60 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 185.3333282470703\n",
            "Eval_StdReturn : 6.182412147521973\n",
            "Eval_MaxReturn : 194.0\n",
            "Eval_MinReturn : 180.0\n",
            "Eval_AverageEpLen : 185.33333333333334\n",
            "Train_AverageReturn : 162.25807189941406\n",
            "Train_StdReturn : 25.233064651489258\n",
            "Train_MaxReturn : 179.0\n",
            "Train_MinReturn : 30.0\n",
            "Train_AverageEpLen : 162.25806451612902\n",
            "Train_EnvstepsSoFar : 309046\n",
            "TimeSinceStart : 361.48642468452454\n",
            "Training Loss : 350774.34375\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 61 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 172.96551513671875\n",
            "Train_StdReturn : 28.102622985839844\n",
            "Train_MaxReturn : 196.0\n",
            "Train_MinReturn : 31.0\n",
            "Train_AverageEpLen : 172.9655172413793\n",
            "Train_EnvstepsSoFar : 314062\n",
            "TimeSinceStart : 367.0217218399048\n",
            "Training Loss : 381044.84375\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 62 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 190.55555725097656\n",
            "Train_StdReturn : 32.297611236572266\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 28.0\n",
            "Train_AverageEpLen : 190.55555555555554\n",
            "Train_EnvstepsSoFar : 319207\n",
            "TimeSinceStart : 372.4770441055298\n",
            "Training Loss : 433986.9375\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 63 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 324207\n",
            "TimeSinceStart : 377.7648756504059\n",
            "Training Loss : 428559.4375\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 64 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 329207\n",
            "TimeSinceStart : 383.15286231040955\n",
            "Training Loss : 415596.375\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 65 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 334207\n",
            "TimeSinceStart : 388.57363867759705\n",
            "Training Loss : 418656.84375\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 66 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 339207\n",
            "TimeSinceStart : 393.9255542755127\n",
            "Training Loss : 421751.9375\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 67 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 344207\n",
            "TimeSinceStart : 399.2967097759247\n",
            "Training Loss : 411029.875\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 68 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 349207\n",
            "TimeSinceStart : 404.7032473087311\n",
            "Training Loss : 420298.5625\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 69 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 354207\n",
            "TimeSinceStart : 410.12287044525146\n",
            "Training Loss : 414711.15625\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 70 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 359207\n",
            "TimeSinceStart : 415.56434440612793\n",
            "Training Loss : 402592.25\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 71 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 364207\n",
            "TimeSinceStart : 420.94606280326843\n",
            "Training Loss : 419067.28125\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 72 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 369207\n",
            "TimeSinceStart : 426.6417233943939\n",
            "Training Loss : 406207.1875\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 73 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 374207\n",
            "TimeSinceStart : 432.1702878475189\n",
            "Training Loss : 401541.1875\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 74 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 379207\n",
            "TimeSinceStart : 437.587792634964\n",
            "Training Loss : 404763.6875\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 75 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 384207\n",
            "TimeSinceStart : 443.00639152526855\n",
            "Training Loss : 413892.96875\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 76 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 389207\n",
            "TimeSinceStart : 448.49598598480225\n",
            "Training Loss : 403418.625\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 77 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 394207\n",
            "TimeSinceStart : 453.96648693084717\n",
            "Training Loss : 394730.34375\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 78 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 399207\n",
            "TimeSinceStart : 459.42319345474243\n",
            "Training Loss : 411613.71875\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 79 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 404207\n",
            "TimeSinceStart : 464.8072500228882\n",
            "Training Loss : 408817.8125\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 80 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 409207\n",
            "TimeSinceStart : 470.30159735679626\n",
            "Training Loss : 409165.40625\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 81 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 414207\n",
            "TimeSinceStart : 475.8400287628174\n",
            "Training Loss : 415037.75\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 82 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 419207\n",
            "TimeSinceStart : 481.27052998542786\n",
            "Training Loss : 404705.1875\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 83 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 424207\n",
            "TimeSinceStart : 486.691960811615\n",
            "Training Loss : 425162.5\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 84 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 429207\n",
            "TimeSinceStart : 492.1284523010254\n",
            "Training Loss : 413736.0625\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 85 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 434207\n",
            "TimeSinceStart : 497.591744184494\n",
            "Training Loss : 416369.34375\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 86 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 439207\n",
            "TimeSinceStart : 503.11459708213806\n",
            "Training Loss : 412931.90625\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 87 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 444207\n",
            "TimeSinceStart : 508.46276116371155\n",
            "Training Loss : 426656.5\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 88 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 449207\n",
            "TimeSinceStart : 513.7622935771942\n",
            "Training Loss : 418070.0625\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 89 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 454207\n",
            "TimeSinceStart : 519.0367045402527\n",
            "Training Loss : 415278.8125\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 90 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 459207\n",
            "TimeSinceStart : 524.4409291744232\n",
            "Training Loss : 423176.75\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 91 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 464207\n",
            "TimeSinceStart : 529.7824699878693\n",
            "Training Loss : 432058.75\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 92 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 469207\n",
            "TimeSinceStart : 535.1155064105988\n",
            "Training Loss : 439134.0\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 93 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 474207\n",
            "TimeSinceStart : 540.6081211566925\n",
            "Training Loss : 436442.3125\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 94 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 479207\n",
            "TimeSinceStart : 546.142767906189\n",
            "Training Loss : 446864.0\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 95 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 484207\n",
            "TimeSinceStart : 551.5984888076782\n",
            "Training Loss : 444687.90625\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 96 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 489207\n",
            "TimeSinceStart : 556.9230661392212\n",
            "Training Loss : 452286.1875\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 97 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 494207\n",
            "TimeSinceStart : 562.4723362922668\n",
            "Training Loss : 444262.65625\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 98 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 499207\n",
            "TimeSinceStart : 567.9903430938721\n",
            "Training Loss : 444975.6875\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 99 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 504207\n",
            "TimeSinceStart : 573.5460793972015\n",
            "Training Loss : 449954.09375\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python cs285/scripts/run_hw2.py --env_name CartPole-v0 -n 100 -b 5000 \\\n",
        "-dsa --exp_name q1_lb_no_rtg_dsa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQJCEISsmnXx",
        "outputId": "00e0ff82-b3d5-46bc-f34a-a995057e2269"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "########################\n",
            "logging outputs to  /content/gdrive/My Drive/cs285_f2021/DRL_policy_grads/cs285/scripts/../../data/q2_pg_q1_lb_rtg_dsa_CartPole-v0_04-02-2022_16-55-37\n",
            "########################\n",
            "Using GPU id 0\n",
            "\n",
            "\n",
            "********** Iteration 0 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 33.33333206176758\n",
            "Eval_StdReturn : 20.159090042114258\n",
            "Eval_MaxReturn : 82.0\n",
            "Eval_MinReturn : 13.0\n",
            "Eval_AverageEpLen : 33.333333333333336\n",
            "Train_AverageReturn : 25.65816307067871\n",
            "Train_StdReturn : 14.328168869018555\n",
            "Train_MaxReturn : 132.0\n",
            "Train_MinReturn : 8.0\n",
            "Train_AverageEpLen : 25.658163265306122\n",
            "Train_EnvstepsSoFar : 5029\n",
            "TimeSinceStart : 5.6480793952941895\n",
            "Training Loss : 112792.4453125\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 1 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 39.83333206176758\n",
            "Eval_StdReturn : 23.39099884033203\n",
            "Eval_MaxReturn : 96.0\n",
            "Eval_MinReturn : 16.0\n",
            "Eval_AverageEpLen : 39.833333333333336\n",
            "Train_AverageReturn : 29.839284896850586\n",
            "Train_StdReturn : 16.807498931884766\n",
            "Train_MaxReturn : 85.0\n",
            "Train_MinReturn : 10.0\n",
            "Train_AverageEpLen : 29.839285714285715\n",
            "Train_EnvstepsSoFar : 10042\n",
            "TimeSinceStart : 11.372042655944824\n",
            "Training Loss : 128028.1640625\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 2 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 48.11111068725586\n",
            "Eval_StdReturn : 17.978038787841797\n",
            "Eval_MaxReturn : 81.0\n",
            "Eval_MinReturn : 24.0\n",
            "Eval_AverageEpLen : 48.111111111111114\n",
            "Train_AverageReturn : 40.90243911743164\n",
            "Train_StdReturn : 23.87106704711914\n",
            "Train_MaxReturn : 166.0\n",
            "Train_MinReturn : 12.0\n",
            "Train_AverageEpLen : 40.90243902439025\n",
            "Train_EnvstepsSoFar : 15073\n",
            "TimeSinceStart : 17.045406341552734\n",
            "Training Loss : 174920.265625\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 3 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 70.0\n",
            "Eval_StdReturn : 34.04898452758789\n",
            "Eval_MaxReturn : 134.0\n",
            "Eval_MinReturn : 39.0\n",
            "Eval_AverageEpLen : 70.0\n",
            "Train_AverageReturn : 52.19791793823242\n",
            "Train_StdReturn : 28.06377410888672\n",
            "Train_MaxReturn : 149.0\n",
            "Train_MinReturn : 15.0\n",
            "Train_AverageEpLen : 52.197916666666664\n",
            "Train_EnvstepsSoFar : 20084\n",
            "TimeSinceStart : 22.688806772232056\n",
            "Training Loss : 208941.6875\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 4 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 76.71428680419922\n",
            "Eval_StdReturn : 46.6406135559082\n",
            "Eval_MaxReturn : 186.0\n",
            "Eval_MinReturn : 38.0\n",
            "Eval_AverageEpLen : 76.71428571428571\n",
            "Train_AverageReturn : 57.8505744934082\n",
            "Train_StdReturn : 27.447978973388672\n",
            "Train_MaxReturn : 136.0\n",
            "Train_MinReturn : 18.0\n",
            "Train_AverageEpLen : 57.85057471264368\n",
            "Train_EnvstepsSoFar : 25117\n",
            "TimeSinceStart : 28.47703456878662\n",
            "Training Loss : 215942.15625\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 5 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 84.4000015258789\n",
            "Eval_StdReturn : 36.031097412109375\n",
            "Eval_MaxReturn : 149.0\n",
            "Eval_MinReturn : 51.0\n",
            "Eval_AverageEpLen : 84.4\n",
            "Train_AverageReturn : 63.658226013183594\n",
            "Train_StdReturn : 29.058597564697266\n",
            "Train_MaxReturn : 162.0\n",
            "Train_MinReturn : 15.0\n",
            "Train_AverageEpLen : 63.65822784810127\n",
            "Train_EnvstepsSoFar : 30146\n",
            "TimeSinceStart : 34.1542911529541\n",
            "Training Loss : 226563.65625\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 6 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 86.0\n",
            "Eval_StdReturn : 10.788883209228516\n",
            "Eval_MaxReturn : 100.0\n",
            "Eval_MinReturn : 71.0\n",
            "Eval_AverageEpLen : 86.0\n",
            "Train_AverageReturn : 74.57353210449219\n",
            "Train_StdReturn : 32.81916427612305\n",
            "Train_MaxReturn : 181.0\n",
            "Train_MinReturn : 24.0\n",
            "Train_AverageEpLen : 74.57352941176471\n",
            "Train_EnvstepsSoFar : 35217\n",
            "TimeSinceStart : 39.84207582473755\n",
            "Training Loss : 258801.46875\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 7 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 104.5999984741211\n",
            "Eval_StdReturn : 48.280845642089844\n",
            "Eval_MaxReturn : 167.0\n",
            "Eval_MinReturn : 44.0\n",
            "Eval_AverageEpLen : 104.6\n",
            "Train_AverageReturn : 82.42623138427734\n",
            "Train_StdReturn : 37.28246307373047\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 34.0\n",
            "Train_AverageEpLen : 82.42622950819673\n",
            "Train_EnvstepsSoFar : 40245\n",
            "TimeSinceStart : 45.65001726150513\n",
            "Training Loss : 278950.9375\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 8 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 114.25\n",
            "Eval_StdReturn : 52.17458724975586\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 59.0\n",
            "Eval_AverageEpLen : 114.25\n",
            "Train_AverageReturn : 104.1875\n",
            "Train_StdReturn : 46.60456466674805\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 36.0\n",
            "Train_AverageEpLen : 104.1875\n",
            "Train_EnvstepsSoFar : 45246\n",
            "TimeSinceStart : 51.34543204307556\n",
            "Training Loss : 345737.1875\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 9 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 160.6666717529297\n",
            "Eval_StdReturn : 31.84685516357422\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 122.0\n",
            "Eval_AverageEpLen : 160.66666666666666\n",
            "Train_AverageReturn : 118.86046600341797\n",
            "Train_StdReturn : 44.96747589111328\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 41.0\n",
            "Train_AverageEpLen : 118.86046511627907\n",
            "Train_EnvstepsSoFar : 50357\n",
            "TimeSinceStart : 57.224520683288574\n",
            "Training Loss : 377174.3125\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 10 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 146.3333282470703\n",
            "Eval_StdReturn : 13.274871826171875\n",
            "Eval_MaxReturn : 159.0\n",
            "Eval_MinReturn : 128.0\n",
            "Eval_AverageEpLen : 146.33333333333334\n",
            "Train_AverageReturn : 148.88235473632812\n",
            "Train_StdReturn : 31.768245697021484\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 65.0\n",
            "Train_AverageEpLen : 148.88235294117646\n",
            "Train_EnvstepsSoFar : 55419\n",
            "TimeSinceStart : 62.929423332214355\n",
            "Training Loss : 414556.25\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 11 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 143.6666717529297\n",
            "Eval_StdReturn : 21.51485252380371\n",
            "Eval_MaxReturn : 173.0\n",
            "Eval_MinReturn : 122.0\n",
            "Eval_AverageEpLen : 143.66666666666666\n",
            "Train_AverageReturn : 148.55882263183594\n",
            "Train_StdReturn : 28.618371963500977\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 99.0\n",
            "Train_AverageEpLen : 148.55882352941177\n",
            "Train_EnvstepsSoFar : 60470\n",
            "TimeSinceStart : 68.66142988204956\n",
            "Training Loss : 405207.125\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 12 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 152.3333282470703\n",
            "Eval_StdReturn : 62.52643966674805\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 64.0\n",
            "Eval_AverageEpLen : 152.33333333333334\n",
            "Train_AverageReturn : 159.75\n",
            "Train_StdReturn : 32.85859680175781\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 86.0\n",
            "Train_AverageEpLen : 159.75\n",
            "Train_EnvstepsSoFar : 65582\n",
            "TimeSinceStart : 74.43749284744263\n",
            "Training Loss : 436612.65625\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 13 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 191.0\n",
            "Eval_StdReturn : 12.727922439575195\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 173.0\n",
            "Eval_AverageEpLen : 191.0\n",
            "Train_AverageReturn : 151.35293579101562\n",
            "Train_StdReturn : 37.470680236816406\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 51.0\n",
            "Train_AverageEpLen : 151.35294117647058\n",
            "Train_EnvstepsSoFar : 70728\n",
            "TimeSinceStart : 80.40636205673218\n",
            "Training Loss : 413838.21875\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 14 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 166.0\n",
            "Eval_StdReturn : 24.711671829223633\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 142.0\n",
            "Eval_AverageEpLen : 166.0\n",
            "Train_AverageReturn : 161.3225860595703\n",
            "Train_StdReturn : 36.09788513183594\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 91.0\n",
            "Train_AverageEpLen : 161.32258064516128\n",
            "Train_EnvstepsSoFar : 75729\n",
            "TimeSinceStart : 86.1479332447052\n",
            "Training Loss : 425491.625\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 15 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 139.6666717529297\n",
            "Eval_StdReturn : 14.613540649414062\n",
            "Eval_MaxReturn : 155.0\n",
            "Eval_MinReturn : 120.0\n",
            "Eval_AverageEpLen : 139.66666666666666\n",
            "Train_AverageReturn : 155.36363220214844\n",
            "Train_StdReturn : 31.194229125976562\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 102.0\n",
            "Train_AverageEpLen : 155.36363636363637\n",
            "Train_EnvstepsSoFar : 80856\n",
            "TimeSinceStart : 91.85797882080078\n",
            "Training Loss : 406338.65625\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 16 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 148.0\n",
            "Eval_StdReturn : 14.966629981994629\n",
            "Eval_MaxReturn : 168.0\n",
            "Eval_MinReturn : 132.0\n",
            "Eval_AverageEpLen : 148.0\n",
            "Train_AverageReturn : 154.4242401123047\n",
            "Train_StdReturn : 31.542207717895508\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 99.0\n",
            "Train_AverageEpLen : 154.42424242424244\n",
            "Train_EnvstepsSoFar : 85952\n",
            "TimeSinceStart : 97.59909772872925\n",
            "Training Loss : 395371.40625\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 17 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 115.5\n",
            "Eval_StdReturn : 6.103277683258057\n",
            "Eval_MaxReturn : 120.0\n",
            "Eval_MinReturn : 105.0\n",
            "Eval_AverageEpLen : 115.5\n",
            "Train_AverageReturn : 136.45945739746094\n",
            "Train_StdReturn : 22.070642471313477\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 107.0\n",
            "Train_AverageEpLen : 136.45945945945945\n",
            "Train_EnvstepsSoFar : 91001\n",
            "TimeSinceStart : 103.2585940361023\n",
            "Training Loss : 341668.0625\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 18 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 121.5\n",
            "Eval_StdReturn : 11.346805572509766\n",
            "Eval_MaxReturn : 138.0\n",
            "Eval_MinReturn : 106.0\n",
            "Eval_AverageEpLen : 121.5\n",
            "Train_AverageReturn : 127.2249984741211\n",
            "Train_StdReturn : 16.757814407348633\n",
            "Train_MaxReturn : 168.0\n",
            "Train_MinReturn : 73.0\n",
            "Train_AverageEpLen : 127.225\n",
            "Train_EnvstepsSoFar : 96090\n",
            "TimeSinceStart : 109.06887102127075\n",
            "Training Loss : 315951.4375\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 19 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 139.3333282470703\n",
            "Eval_StdReturn : 24.72964859008789\n",
            "Eval_MaxReturn : 174.0\n",
            "Eval_MinReturn : 118.0\n",
            "Eval_AverageEpLen : 139.33333333333334\n",
            "Train_AverageReturn : 126.0\n",
            "Train_StdReturn : 21.907760620117188\n",
            "Train_MaxReturn : 166.0\n",
            "Train_MinReturn : 51.0\n",
            "Train_AverageEpLen : 126.0\n",
            "Train_EnvstepsSoFar : 101130\n",
            "TimeSinceStart : 114.74456191062927\n",
            "Training Loss : 312132.28125\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 20 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 107.75\n",
            "Eval_StdReturn : 38.19276809692383\n",
            "Eval_MaxReturn : 141.0\n",
            "Eval_MinReturn : 44.0\n",
            "Eval_AverageEpLen : 107.75\n",
            "Train_AverageReturn : 117.6744155883789\n",
            "Train_StdReturn : 27.333189010620117\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 43.0\n",
            "Train_AverageEpLen : 117.67441860465117\n",
            "Train_EnvstepsSoFar : 106190\n",
            "TimeSinceStart : 120.37649631500244\n",
            "Training Loss : 290906.625\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 21 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 127.0\n",
            "Eval_StdReturn : 10.747092247009277\n",
            "Eval_MaxReturn : 141.0\n",
            "Eval_MinReturn : 111.0\n",
            "Eval_AverageEpLen : 127.0\n",
            "Train_AverageReturn : 123.82926940917969\n",
            "Train_StdReturn : 18.803089141845703\n",
            "Train_MaxReturn : 153.0\n",
            "Train_MinReturn : 43.0\n",
            "Train_AverageEpLen : 123.82926829268293\n",
            "Train_EnvstepsSoFar : 111267\n",
            "TimeSinceStart : 126.11976957321167\n",
            "Training Loss : 301995.59375\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 22 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 131.75\n",
            "Eval_StdReturn : 17.9774169921875\n",
            "Eval_MaxReturn : 156.0\n",
            "Eval_MinReturn : 113.0\n",
            "Eval_AverageEpLen : 131.75\n",
            "Train_AverageReturn : 131.76315307617188\n",
            "Train_StdReturn : 20.348844528198242\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 96.0\n",
            "Train_AverageEpLen : 131.76315789473685\n",
            "Train_EnvstepsSoFar : 116274\n",
            "TimeSinceStart : 131.793123960495\n",
            "Training Loss : 310834.0\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 23 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 159.6666717529297\n",
            "Eval_StdReturn : 3.2998316287994385\n",
            "Eval_MaxReturn : 164.0\n",
            "Eval_MinReturn : 156.0\n",
            "Eval_AverageEpLen : 159.66666666666666\n",
            "Train_AverageReturn : 138.40541076660156\n",
            "Train_StdReturn : 22.3636531829834\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 100.0\n",
            "Train_AverageEpLen : 138.40540540540542\n",
            "Train_EnvstepsSoFar : 121395\n",
            "TimeSinceStart : 137.58761191368103\n",
            "Training Loss : 334652.625\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 24 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 166.3333282470703\n",
            "Eval_StdReturn : 28.193775177001953\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 131.0\n",
            "Eval_AverageEpLen : 166.33333333333334\n",
            "Train_AverageReturn : 159.1875\n",
            "Train_StdReturn : 25.223299026489258\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 119.0\n",
            "Train_AverageEpLen : 159.1875\n",
            "Train_EnvstepsSoFar : 126489\n",
            "TimeSinceStart : 143.3672206401825\n",
            "Training Loss : 376151.3125\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 25 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 175.0\n",
            "Eval_StdReturn : 26.695817947387695\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 138.0\n",
            "Eval_AverageEpLen : 175.0\n",
            "Train_AverageReturn : 163.51612854003906\n",
            "Train_StdReturn : 28.013673782348633\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 113.0\n",
            "Train_AverageEpLen : 163.51612903225808\n",
            "Train_EnvstepsSoFar : 131558\n",
            "TimeSinceStart : 149.14195680618286\n",
            "Training Loss : 381818.375\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 26 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 142.0\n",
            "Eval_StdReturn : 3.5590262413024902\n",
            "Eval_MaxReturn : 147.0\n",
            "Eval_MinReturn : 139.0\n",
            "Eval_AverageEpLen : 142.0\n",
            "Train_AverageReturn : 165.93548583984375\n",
            "Train_StdReturn : 23.862422943115234\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 126.0\n",
            "Train_AverageEpLen : 165.93548387096774\n",
            "Train_EnvstepsSoFar : 136702\n",
            "TimeSinceStart : 154.96738982200623\n",
            "Training Loss : 389400.40625\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 27 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 139.0\n",
            "Eval_StdReturn : 18.055469512939453\n",
            "Eval_MaxReturn : 164.0\n",
            "Eval_MinReturn : 122.0\n",
            "Eval_AverageEpLen : 139.0\n",
            "Train_AverageReturn : 161.48387145996094\n",
            "Train_StdReturn : 23.722686767578125\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 118.0\n",
            "Train_AverageEpLen : 161.48387096774192\n",
            "Train_EnvstepsSoFar : 141708\n",
            "TimeSinceStart : 160.57278776168823\n",
            "Training Loss : 362593.3125\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 28 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 159.3333282470703\n",
            "Eval_StdReturn : 29.318178176879883\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 132.0\n",
            "Eval_AverageEpLen : 159.33333333333334\n",
            "Train_AverageReturn : 167.06451416015625\n",
            "Train_StdReturn : 22.434040069580078\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 127.0\n",
            "Train_AverageEpLen : 167.06451612903226\n",
            "Train_EnvstepsSoFar : 146887\n",
            "TimeSinceStart : 166.5150842666626\n",
            "Training Loss : 381841.375\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 29 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 178.3333282470703\n",
            "Eval_StdReturn : 18.873849868774414\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 154.0\n",
            "Eval_AverageEpLen : 178.33333333333334\n",
            "Train_AverageReturn : 166.19354248046875\n",
            "Train_StdReturn : 25.2834529876709\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 115.0\n",
            "Train_AverageEpLen : 166.19354838709677\n",
            "Train_EnvstepsSoFar : 152039\n",
            "TimeSinceStart : 172.41221475601196\n",
            "Training Loss : 385141.15625\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 30 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 185.0\n",
            "Eval_StdReturn : 10.984837532043457\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 174.0\n",
            "Eval_AverageEpLen : 185.0\n",
            "Train_AverageReturn : 167.6774139404297\n",
            "Train_StdReturn : 22.804058074951172\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 118.0\n",
            "Train_AverageEpLen : 167.67741935483872\n",
            "Train_EnvstepsSoFar : 157237\n",
            "TimeSinceStart : 178.43793296813965\n",
            "Training Loss : 374073.4375\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 31 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 168.0\n",
            "Eval_StdReturn : 19.200695037841797\n",
            "Eval_MaxReturn : 195.0\n",
            "Eval_MinReturn : 152.0\n",
            "Eval_AverageEpLen : 168.0\n",
            "Train_AverageReturn : 182.82142639160156\n",
            "Train_StdReturn : 23.47347068786621\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 119.0\n",
            "Train_AverageEpLen : 182.82142857142858\n",
            "Train_EnvstepsSoFar : 162356\n",
            "TimeSinceStart : 184.33181476593018\n",
            "Training Loss : 412521.5\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 32 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 188.37037658691406\n",
            "Train_StdReturn : 17.401891708374023\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 130.0\n",
            "Train_AverageEpLen : 188.37037037037038\n",
            "Train_EnvstepsSoFar : 167442\n",
            "TimeSinceStart : 189.99545431137085\n",
            "Training Loss : 413505.5625\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 33 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 187.3333282470703\n",
            "Eval_StdReturn : 11.585432052612305\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 172.0\n",
            "Eval_AverageEpLen : 187.33333333333334\n",
            "Train_AverageReturn : 189.22222900390625\n",
            "Train_StdReturn : 15.788728713989258\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 151.0\n",
            "Train_AverageEpLen : 189.22222222222223\n",
            "Train_EnvstepsSoFar : 172551\n",
            "TimeSinceStart : 195.94099974632263\n",
            "Training Loss : 414704.28125\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 34 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 172.6666717529297\n",
            "Eval_StdReturn : 23.795425415039062\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 142.0\n",
            "Eval_AverageEpLen : 172.66666666666666\n",
            "Train_AverageReturn : 191.11111450195312\n",
            "Train_StdReturn : 14.561067581176758\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 150.0\n",
            "Train_AverageEpLen : 191.11111111111111\n",
            "Train_EnvstepsSoFar : 177711\n",
            "TimeSinceStart : 201.81557726860046\n",
            "Training Loss : 422280.0\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 35 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 145.0\n",
            "Eval_StdReturn : 8.602325439453125\n",
            "Eval_MaxReturn : 156.0\n",
            "Eval_MinReturn : 135.0\n",
            "Eval_AverageEpLen : 145.0\n",
            "Train_AverageReturn : 173.13792419433594\n",
            "Train_StdReturn : 22.868022918701172\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 130.0\n",
            "Train_AverageEpLen : 173.13793103448276\n",
            "Train_EnvstepsSoFar : 182732\n",
            "TimeSinceStart : 207.41799664497375\n",
            "Training Loss : 379647.9375\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 36 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 145.6666717529297\n",
            "Eval_StdReturn : 13.69509220123291\n",
            "Eval_MaxReturn : 165.0\n",
            "Eval_MinReturn : 135.0\n",
            "Eval_AverageEpLen : 145.66666666666666\n",
            "Train_AverageReturn : 151.3235321044922\n",
            "Train_StdReturn : 25.369874954223633\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 110.0\n",
            "Train_AverageEpLen : 151.3235294117647\n",
            "Train_EnvstepsSoFar : 187877\n",
            "TimeSinceStart : 213.25578594207764\n",
            "Training Loss : 337970.125\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 37 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 142.6666717529297\n",
            "Eval_StdReturn : 19.871810913085938\n",
            "Eval_MaxReturn : 169.0\n",
            "Eval_MinReturn : 121.0\n",
            "Eval_AverageEpLen : 142.66666666666666\n",
            "Train_AverageReturn : 134.7894744873047\n",
            "Train_StdReturn : 19.354257583618164\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 94.0\n",
            "Train_AverageEpLen : 134.78947368421052\n",
            "Train_EnvstepsSoFar : 192999\n",
            "TimeSinceStart : 219.09997534751892\n",
            "Training Loss : 295208.9375\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 38 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 137.5\n",
            "Eval_StdReturn : 21.289669036865234\n",
            "Eval_MaxReturn : 173.0\n",
            "Eval_MinReturn : 120.0\n",
            "Eval_AverageEpLen : 137.5\n",
            "Train_AverageReturn : 133.23684692382812\n",
            "Train_StdReturn : 18.744028091430664\n",
            "Train_MaxReturn : 186.0\n",
            "Train_MinReturn : 110.0\n",
            "Train_AverageEpLen : 133.23684210526315\n",
            "Train_EnvstepsSoFar : 198062\n",
            "TimeSinceStart : 224.87506937980652\n",
            "Training Loss : 289193.5625\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 39 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 116.0\n",
            "Eval_StdReturn : 7.280109882354736\n",
            "Eval_MaxReturn : 125.0\n",
            "Eval_MinReturn : 105.0\n",
            "Eval_AverageEpLen : 116.0\n",
            "Train_AverageReturn : 129.41026306152344\n",
            "Train_StdReturn : 14.35934066772461\n",
            "Train_MaxReturn : 179.0\n",
            "Train_MinReturn : 104.0\n",
            "Train_AverageEpLen : 129.4102564102564\n",
            "Train_EnvstepsSoFar : 203109\n",
            "TimeSinceStart : 230.7105050086975\n",
            "Training Loss : 278747.4375\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 40 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 139.3333282470703\n",
            "Eval_StdReturn : 7.586537837982178\n",
            "Eval_MaxReturn : 150.0\n",
            "Eval_MinReturn : 133.0\n",
            "Eval_AverageEpLen : 139.33333333333334\n",
            "Train_AverageReturn : 125.82499694824219\n",
            "Train_StdReturn : 13.850790023803711\n",
            "Train_MaxReturn : 160.0\n",
            "Train_MinReturn : 92.0\n",
            "Train_AverageEpLen : 125.825\n",
            "Train_EnvstepsSoFar : 208142\n",
            "TimeSinceStart : 236.51058340072632\n",
            "Training Loss : 270511.5625\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 41 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 116.0\n",
            "Eval_StdReturn : 14.781745910644531\n",
            "Eval_MaxReturn : 141.0\n",
            "Eval_MinReturn : 103.0\n",
            "Eval_AverageEpLen : 116.0\n",
            "Train_AverageReturn : 127.07499694824219\n",
            "Train_StdReturn : 16.57767677307129\n",
            "Train_MaxReturn : 163.0\n",
            "Train_MinReturn : 81.0\n",
            "Train_AverageEpLen : 127.075\n",
            "Train_EnvstepsSoFar : 213225\n",
            "TimeSinceStart : 242.33598589897156\n",
            "Training Loss : 278945.25\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 42 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 100.0\n",
            "Eval_StdReturn : 13.725887298583984\n",
            "Eval_MaxReturn : 118.0\n",
            "Eval_MinReturn : 80.0\n",
            "Eval_AverageEpLen : 100.0\n",
            "Train_AverageReturn : 116.15908813476562\n",
            "Train_StdReturn : 16.038227081298828\n",
            "Train_MaxReturn : 149.0\n",
            "Train_MinReturn : 76.0\n",
            "Train_AverageEpLen : 116.1590909090909\n",
            "Train_EnvstepsSoFar : 218336\n",
            "TimeSinceStart : 248.12183475494385\n",
            "Training Loss : 257893.09375\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 43 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 98.19999694824219\n",
            "Eval_StdReturn : 5.114684581756592\n",
            "Eval_MaxReturn : 105.0\n",
            "Eval_MinReturn : 90.0\n",
            "Eval_AverageEpLen : 98.2\n",
            "Train_AverageReturn : 112.4888916015625\n",
            "Train_StdReturn : 13.802773475646973\n",
            "Train_MaxReturn : 139.0\n",
            "Train_MinReturn : 77.0\n",
            "Train_AverageEpLen : 112.4888888888889\n",
            "Train_EnvstepsSoFar : 223398\n",
            "TimeSinceStart : 253.8227560520172\n",
            "Training Loss : 238750.078125\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 44 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 104.75\n",
            "Eval_StdReturn : 6.684871196746826\n",
            "Eval_MaxReturn : 114.0\n",
            "Eval_MinReturn : 97.0\n",
            "Eval_AverageEpLen : 104.75\n",
            "Train_AverageReturn : 105.97916412353516\n",
            "Train_StdReturn : 14.00965404510498\n",
            "Train_MaxReturn : 139.0\n",
            "Train_MinReturn : 74.0\n",
            "Train_AverageEpLen : 105.97916666666667\n",
            "Train_EnvstepsSoFar : 228485\n",
            "TimeSinceStart : 259.6305122375488\n",
            "Training Loss : 229184.9375\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 45 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 104.25\n",
            "Eval_StdReturn : 14.376630783081055\n",
            "Eval_MaxReturn : 125.0\n",
            "Eval_MinReturn : 85.0\n",
            "Eval_AverageEpLen : 104.25\n",
            "Train_AverageReturn : 101.87999725341797\n",
            "Train_StdReturn : 17.270366668701172\n",
            "Train_MaxReturn : 139.0\n",
            "Train_MinReturn : 59.0\n",
            "Train_AverageEpLen : 101.88\n",
            "Train_EnvstepsSoFar : 233579\n",
            "TimeSinceStart : 265.5639269351959\n",
            "Training Loss : 220727.359375\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 46 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 106.75\n",
            "Eval_StdReturn : 16.207637786865234\n",
            "Eval_MaxReturn : 134.0\n",
            "Eval_MinReturn : 94.0\n",
            "Eval_AverageEpLen : 106.75\n",
            "Train_AverageReturn : 102.12000274658203\n",
            "Train_StdReturn : 12.717924118041992\n",
            "Train_MaxReturn : 130.0\n",
            "Train_MinReturn : 66.0\n",
            "Train_AverageEpLen : 102.12\n",
            "Train_EnvstepsSoFar : 238685\n",
            "TimeSinceStart : 271.267062664032\n",
            "Training Loss : 212065.03125\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 47 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 83.5999984741211\n",
            "Eval_StdReturn : 13.836183547973633\n",
            "Eval_MaxReturn : 100.0\n",
            "Eval_MinReturn : 63.0\n",
            "Eval_AverageEpLen : 83.6\n",
            "Train_AverageReturn : 98.47058868408203\n",
            "Train_StdReturn : 15.464510917663574\n",
            "Train_MaxReturn : 131.0\n",
            "Train_MinReturn : 63.0\n",
            "Train_AverageEpLen : 98.47058823529412\n",
            "Train_EnvstepsSoFar : 243707\n",
            "TimeSinceStart : 276.9385437965393\n",
            "Training Loss : 207820.453125\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 48 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 100.75\n",
            "Eval_StdReturn : 12.96871280670166\n",
            "Eval_MaxReturn : 113.0\n",
            "Eval_MinReturn : 79.0\n",
            "Eval_AverageEpLen : 100.75\n",
            "Train_AverageReturn : 103.32653045654297\n",
            "Train_StdReturn : 15.444948196411133\n",
            "Train_MaxReturn : 142.0\n",
            "Train_MinReturn : 80.0\n",
            "Train_AverageEpLen : 103.3265306122449\n",
            "Train_EnvstepsSoFar : 248770\n",
            "TimeSinceStart : 282.70689630508423\n",
            "Training Loss : 220156.0\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 49 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 120.25\n",
            "Eval_StdReturn : 13.367403984069824\n",
            "Eval_MaxReturn : 137.0\n",
            "Eval_MinReturn : 101.0\n",
            "Eval_AverageEpLen : 120.25\n",
            "Train_AverageReturn : 108.59574127197266\n",
            "Train_StdReturn : 16.453235626220703\n",
            "Train_MaxReturn : 139.0\n",
            "Train_MinReturn : 50.0\n",
            "Train_AverageEpLen : 108.59574468085107\n",
            "Train_EnvstepsSoFar : 253874\n",
            "TimeSinceStart : 288.57934045791626\n",
            "Training Loss : 230127.90625\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 50 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 124.75\n",
            "Eval_StdReturn : 12.517487525939941\n",
            "Eval_MaxReturn : 138.0\n",
            "Eval_MinReturn : 109.0\n",
            "Eval_AverageEpLen : 124.75\n",
            "Train_AverageReturn : 107.85106658935547\n",
            "Train_StdReturn : 13.80869197845459\n",
            "Train_MaxReturn : 136.0\n",
            "Train_MinReturn : 82.0\n",
            "Train_AverageEpLen : 107.85106382978724\n",
            "Train_EnvstepsSoFar : 258943\n",
            "TimeSinceStart : 294.4232063293457\n",
            "Training Loss : 229449.171875\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 51 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 118.75\n",
            "Eval_StdReturn : 6.684871196746826\n",
            "Eval_MaxReturn : 128.0\n",
            "Eval_MinReturn : 111.0\n",
            "Eval_AverageEpLen : 118.75\n",
            "Train_AverageReturn : 109.65217590332031\n",
            "Train_StdReturn : 10.603972434997559\n",
            "Train_MaxReturn : 137.0\n",
            "Train_MinReturn : 84.0\n",
            "Train_AverageEpLen : 109.65217391304348\n",
            "Train_EnvstepsSoFar : 263987\n",
            "TimeSinceStart : 300.2130661010742\n",
            "Training Loss : 226569.65625\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 52 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 119.25\n",
            "Eval_StdReturn : 9.756407737731934\n",
            "Eval_MaxReturn : 129.0\n",
            "Eval_MinReturn : 103.0\n",
            "Eval_AverageEpLen : 119.25\n",
            "Train_AverageReturn : 114.5227279663086\n",
            "Train_StdReturn : 14.313834190368652\n",
            "Train_MaxReturn : 151.0\n",
            "Train_MinReturn : 87.0\n",
            "Train_AverageEpLen : 114.52272727272727\n",
            "Train_EnvstepsSoFar : 269026\n",
            "TimeSinceStart : 305.92770528793335\n",
            "Training Loss : 243719.203125\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 53 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 112.0\n",
            "Eval_StdReturn : 15.41103458404541\n",
            "Eval_MaxReturn : 131.0\n",
            "Eval_MinReturn : 88.0\n",
            "Eval_AverageEpLen : 112.0\n",
            "Train_AverageReturn : 112.80000305175781\n",
            "Train_StdReturn : 12.337117195129395\n",
            "Train_MaxReturn : 136.0\n",
            "Train_MinReturn : 87.0\n",
            "Train_AverageEpLen : 112.8\n",
            "Train_EnvstepsSoFar : 274102\n",
            "TimeSinceStart : 311.7221894264221\n",
            "Training Loss : 232411.3125\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 54 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 101.5999984741211\n",
            "Eval_StdReturn : 23.354656219482422\n",
            "Eval_MaxReturn : 119.0\n",
            "Eval_MinReturn : 57.0\n",
            "Eval_AverageEpLen : 101.6\n",
            "Train_AverageReturn : 103.51020050048828\n",
            "Train_StdReturn : 15.207573890686035\n",
            "Train_MaxReturn : 138.0\n",
            "Train_MinReturn : 58.0\n",
            "Train_AverageEpLen : 103.51020408163265\n",
            "Train_EnvstepsSoFar : 279174\n",
            "TimeSinceStart : 317.52294731140137\n",
            "Training Loss : 218370.78125\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 55 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 105.5\n",
            "Eval_StdReturn : 7.632168769836426\n",
            "Eval_MaxReturn : 115.0\n",
            "Eval_MinReturn : 95.0\n",
            "Eval_AverageEpLen : 105.5\n",
            "Train_AverageReturn : 105.83333587646484\n",
            "Train_StdReturn : 12.315866470336914\n",
            "Train_MaxReturn : 129.0\n",
            "Train_MinReturn : 68.0\n",
            "Train_AverageEpLen : 105.83333333333333\n",
            "Train_EnvstepsSoFar : 284254\n",
            "TimeSinceStart : 323.23088574409485\n",
            "Training Loss : 224940.328125\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 56 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 110.25\n",
            "Eval_StdReturn : 11.734031677246094\n",
            "Eval_MaxReturn : 124.0\n",
            "Eval_MinReturn : 95.0\n",
            "Eval_AverageEpLen : 110.25\n",
            "Train_AverageReturn : 101.4800033569336\n",
            "Train_StdReturn : 15.590047836303711\n",
            "Train_MaxReturn : 131.0\n",
            "Train_MinReturn : 54.0\n",
            "Train_AverageEpLen : 101.48\n",
            "Train_EnvstepsSoFar : 289328\n",
            "TimeSinceStart : 328.98166131973267\n",
            "Training Loss : 211756.0\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 57 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 102.75\n",
            "Eval_StdReturn : 10.80219841003418\n",
            "Eval_MaxReturn : 119.0\n",
            "Eval_MinReturn : 92.0\n",
            "Eval_AverageEpLen : 102.75\n",
            "Train_AverageReturn : 106.7872314453125\n",
            "Train_StdReturn : 14.926679611206055\n",
            "Train_MaxReturn : 142.0\n",
            "Train_MinReturn : 74.0\n",
            "Train_AverageEpLen : 106.7872340425532\n",
            "Train_EnvstepsSoFar : 294347\n",
            "TimeSinceStart : 334.56231236457825\n",
            "Training Loss : 223823.328125\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 58 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 120.5\n",
            "Eval_StdReturn : 17.909494400024414\n",
            "Eval_MaxReturn : 141.0\n",
            "Eval_MinReturn : 95.0\n",
            "Eval_AverageEpLen : 120.5\n",
            "Train_AverageReturn : 111.3043441772461\n",
            "Train_StdReturn : 11.24213695526123\n",
            "Train_MaxReturn : 135.0\n",
            "Train_MinReturn : 89.0\n",
            "Train_AverageEpLen : 111.30434782608695\n",
            "Train_EnvstepsSoFar : 299467\n",
            "TimeSinceStart : 340.3971383571625\n",
            "Training Loss : 231163.25\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 59 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 123.0\n",
            "Eval_StdReturn : 12.267844200134277\n",
            "Eval_MaxReturn : 134.0\n",
            "Eval_MinReturn : 103.0\n",
            "Eval_AverageEpLen : 123.0\n",
            "Train_AverageReturn : 116.15908813476562\n",
            "Train_StdReturn : 14.414234161376953\n",
            "Train_MaxReturn : 168.0\n",
            "Train_MinReturn : 92.0\n",
            "Train_AverageEpLen : 116.1590909090909\n",
            "Train_EnvstepsSoFar : 304578\n",
            "TimeSinceStart : 346.2129371166229\n",
            "Training Loss : 243898.046875\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 60 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 136.0\n",
            "Eval_StdReturn : 7.874007701873779\n",
            "Eval_MaxReturn : 143.0\n",
            "Eval_MinReturn : 125.0\n",
            "Eval_AverageEpLen : 136.0\n",
            "Train_AverageReturn : 133.5\n",
            "Train_StdReturn : 17.103015899658203\n",
            "Train_MaxReturn : 183.0\n",
            "Train_MinReturn : 108.0\n",
            "Train_AverageEpLen : 133.5\n",
            "Train_EnvstepsSoFar : 309651\n",
            "TimeSinceStart : 351.93991565704346\n",
            "Training Loss : 280247.03125\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 61 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 180.0\n",
            "Eval_StdReturn : 24.041629791259766\n",
            "Eval_MaxReturn : 197.0\n",
            "Eval_MinReturn : 146.0\n",
            "Eval_AverageEpLen : 180.0\n",
            "Train_AverageReturn : 145.8000030517578\n",
            "Train_StdReturn : 19.04100799560547\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 120.0\n",
            "Train_AverageEpLen : 145.8\n",
            "Train_EnvstepsSoFar : 314754\n",
            "TimeSinceStart : 357.76950335502625\n",
            "Training Loss : 309466.5\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 62 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 179.6666717529297\n",
            "Eval_StdReturn : 11.440669059753418\n",
            "Eval_MaxReturn : 194.0\n",
            "Eval_MinReturn : 166.0\n",
            "Eval_AverageEpLen : 179.66666666666666\n",
            "Train_AverageReturn : 162.4193572998047\n",
            "Train_StdReturn : 20.963523864746094\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 126.0\n",
            "Train_AverageEpLen : 162.41935483870967\n",
            "Train_EnvstepsSoFar : 319789\n",
            "TimeSinceStart : 363.5308666229248\n",
            "Training Loss : 339506.65625\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 63 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 185.1851806640625\n",
            "Train_StdReturn : 17.699207305908203\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 149.0\n",
            "Train_AverageEpLen : 185.1851851851852\n",
            "Train_EnvstepsSoFar : 324789\n",
            "TimeSinceStart : 369.23532700538635\n",
            "Training Loss : 378466.5625\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 64 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 198.23077392578125\n",
            "Train_StdReturn : 6.283725738525391\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 172.0\n",
            "Train_AverageEpLen : 198.23076923076923\n",
            "Train_EnvstepsSoFar : 329943\n",
            "TimeSinceStart : 375.0240080356598\n",
            "Training Loss : 409723.9375\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 65 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 199.8076934814453\n",
            "Train_StdReturn : 0.9615384340286255\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 195.0\n",
            "Train_AverageEpLen : 199.80769230769232\n",
            "Train_EnvstepsSoFar : 335138\n",
            "TimeSinceStart : 380.9189531803131\n",
            "Training Loss : 425880.75\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 66 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 191.0\n",
            "Eval_StdReturn : 6.68331241607666\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 184.0\n",
            "Eval_AverageEpLen : 191.0\n",
            "Train_AverageReturn : 196.07691955566406\n",
            "Train_StdReturn : 8.74828815460205\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 164.0\n",
            "Train_AverageEpLen : 196.07692307692307\n",
            "Train_EnvstepsSoFar : 340236\n",
            "TimeSinceStart : 386.94339966773987\n",
            "Training Loss : 404376.5625\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 67 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 195.3076934814453\n",
            "Train_StdReturn : 8.137137413024902\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 175.0\n",
            "Train_AverageEpLen : 195.30769230769232\n",
            "Train_EnvstepsSoFar : 345314\n",
            "TimeSinceStart : 392.6163384914398\n",
            "Training Loss : 414743.75\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 68 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 199.38461303710938\n",
            "Train_StdReturn : 2.2027416229248047\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 190.0\n",
            "Train_AverageEpLen : 199.3846153846154\n",
            "Train_EnvstepsSoFar : 350498\n",
            "TimeSinceStart : 398.44240140914917\n",
            "Training Loss : 432121.40625\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 69 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 355498\n",
            "TimeSinceStart : 404.1352162361145\n",
            "Training Loss : 425028.5625\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 70 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 360498\n",
            "TimeSinceStart : 409.88750100135803\n",
            "Training Loss : 411156.1875\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 71 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 365498\n",
            "TimeSinceStart : 415.5501732826233\n",
            "Training Loss : 426145.09375\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 72 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 370498\n",
            "TimeSinceStart : 421.2365918159485\n",
            "Training Loss : 413436.625\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 73 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 375498\n",
            "TimeSinceStart : 426.95928025245667\n",
            "Training Loss : 421310.125\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 74 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 380498\n",
            "TimeSinceStart : 432.67796325683594\n",
            "Training Loss : 414823.5\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 75 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 385498\n",
            "TimeSinceStart : 438.3265678882599\n",
            "Training Loss : 417724.59375\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 76 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 390498\n",
            "TimeSinceStart : 443.932053565979\n",
            "Training Loss : 410912.0\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 77 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 395498\n",
            "TimeSinceStart : 449.6547932624817\n",
            "Training Loss : 419509.84375\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 78 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 196.3076934814453\n",
            "Train_StdReturn : 18.461536407470703\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 104.0\n",
            "Train_AverageEpLen : 196.30769230769232\n",
            "Train_EnvstepsSoFar : 400602\n",
            "TimeSinceStart : 455.45656657218933\n",
            "Training Loss : 435003.6875\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 79 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 405602\n",
            "TimeSinceStart : 461.1580219268799\n",
            "Training Loss : 426989.375\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 80 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 410602\n",
            "TimeSinceStart : 466.8514084815979\n",
            "Training Loss : 434927.0625\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 81 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 195.1923065185547\n",
            "Train_StdReturn : 24.038461685180664\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 75.0\n",
            "Train_AverageEpLen : 195.19230769230768\n",
            "Train_EnvstepsSoFar : 415677\n",
            "TimeSinceStart : 472.6300218105316\n",
            "Training Loss : 438797.25\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 82 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 182.82142639160156\n",
            "Train_StdReturn : 42.09687042236328\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 75.0\n",
            "Train_AverageEpLen : 182.82142857142858\n",
            "Train_EnvstepsSoFar : 420796\n",
            "TimeSinceStart : 478.4417164325714\n",
            "Training Loss : 430376.5\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 83 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 190.29629516601562\n",
            "Train_StdReturn : 31.95345687866211\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 75.0\n",
            "Train_AverageEpLen : 190.2962962962963\n",
            "Train_EnvstepsSoFar : 425934\n",
            "TimeSinceStart : 484.2978072166443\n",
            "Training Loss : 438016.9375\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 84 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 158.3333282470703\n",
            "Eval_StdReturn : 58.92556381225586\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 75.0\n",
            "Eval_AverageEpLen : 158.33333333333334\n",
            "Train_AverageReturn : 199.38461303710938\n",
            "Train_StdReturn : 3.076923370361328\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 184.0\n",
            "Train_AverageEpLen : 199.3846153846154\n",
            "Train_EnvstepsSoFar : 431118\n",
            "TimeSinceStart : 490.3033425807953\n",
            "Training Loss : 430846.4375\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 85 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 177.0\n",
            "Eval_StdReturn : 32.526912689208984\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 131.0\n",
            "Eval_AverageEpLen : 177.0\n",
            "Train_AverageReturn : 188.9629669189453\n",
            "Train_StdReturn : 31.31971549987793\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 63.0\n",
            "Train_AverageEpLen : 188.96296296296296\n",
            "Train_EnvstepsSoFar : 436220\n",
            "TimeSinceStart : 496.2632782459259\n",
            "Training Loss : 420344.25\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 86 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 190.59259033203125\n",
            "Train_StdReturn : 28.178346633911133\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 76.0\n",
            "Train_AverageEpLen : 190.59259259259258\n",
            "Train_EnvstepsSoFar : 441366\n",
            "TimeSinceStart : 502.0864243507385\n",
            "Training Loss : 414711.59375\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 87 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 446366\n",
            "TimeSinceStart : 507.84220480918884\n",
            "Training Loss : 401856.75\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 88 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 451366\n",
            "TimeSinceStart : 513.5669424533844\n",
            "Training Loss : 393646.75\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 89 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 181.3333282470703\n",
            "Eval_StdReturn : 26.398653030395508\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 144.0\n",
            "Eval_AverageEpLen : 181.33333333333334\n",
            "Train_AverageReturn : 199.8076934814453\n",
            "Train_StdReturn : 0.9615384340286255\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 195.0\n",
            "Train_AverageEpLen : 199.80769230769232\n",
            "Train_EnvstepsSoFar : 456561\n",
            "TimeSinceStart : 519.6572217941284\n",
            "Training Loss : 399340.65625\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 90 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 199.11538696289062\n",
            "Train_StdReturn : 2.4857583045959473\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 191.0\n",
            "Train_AverageEpLen : 199.1153846153846\n",
            "Train_EnvstepsSoFar : 461738\n",
            "TimeSinceStart : 525.5146071910858\n",
            "Training Loss : 383732.8125\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 91 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 466738\n",
            "TimeSinceStart : 531.1562459468842\n",
            "Training Loss : 366620.125\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 92 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 471738\n",
            "TimeSinceStart : 536.8611261844635\n",
            "Training Loss : 351437.0625\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 93 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 193.57691955566406\n",
            "Train_StdReturn : 24.00668716430664\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 84.0\n",
            "Train_AverageEpLen : 193.57692307692307\n",
            "Train_EnvstepsSoFar : 476771\n",
            "TimeSinceStart : 542.6671636104584\n",
            "Training Loss : 349870.25\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 94 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 199.5\n",
            "Train_StdReturn : 2.5\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 187.0\n",
            "Train_AverageEpLen : 199.5\n",
            "Train_EnvstepsSoFar : 481958\n",
            "TimeSinceStart : 548.5152900218964\n",
            "Training Loss : 358380.25\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 95 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 199.92308044433594\n",
            "Train_StdReturn : 0.38461536169052124\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 198.0\n",
            "Train_AverageEpLen : 199.92307692307693\n",
            "Train_EnvstepsSoFar : 487156\n",
            "TimeSinceStart : 554.2691974639893\n",
            "Training Loss : 354337.875\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 96 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 199.88461303710938\n",
            "Train_StdReturn : 0.5769230723381042\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 197.0\n",
            "Train_AverageEpLen : 199.8846153846154\n",
            "Train_EnvstepsSoFar : 492353\n",
            "TimeSinceStart : 560.1853170394897\n",
            "Training Loss : 350363.375\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 97 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 497353\n",
            "TimeSinceStart : 565.9419820308685\n",
            "Training Loss : 338669.3125\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 98 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 502353\n",
            "TimeSinceStart : 571.6348440647125\n",
            "Training Loss : 348763.96875\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 99 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 507353\n",
            "TimeSinceStart : 577.2592279911041\n",
            "Training Loss : 342645.875\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python cs285/scripts/run_hw2.py --env_name CartPole-v0 -n 100 -b 5000 \\\n",
        "-rtg -dsa --exp_name q1_lb_rtg_dsa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_AK5O9kmq3m",
        "outputId": "3c407466-290b-40eb-94a7-de3c2d04b23c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "########################\n",
            "logging outputs to  /content/gdrive/My Drive/cs285_f2021/DRL_policy_grads/cs285/scripts/../../data/q2_pg_q1_lb_rtg_na_CartPole-v0_04-02-2022_17-06-28\n",
            "########################\n",
            "Using GPU id 0\n",
            "\n",
            "\n",
            "********** Iteration 0 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 29.85714340209961\n",
            "Eval_StdReturn : 15.458964347839355\n",
            "Eval_MaxReturn : 67.0\n",
            "Eval_MinReturn : 13.0\n",
            "Eval_AverageEpLen : 29.857142857142858\n",
            "Train_AverageReturn : 25.65816307067871\n",
            "Train_StdReturn : 14.328168869018555\n",
            "Train_MaxReturn : 132.0\n",
            "Train_MinReturn : 8.0\n",
            "Train_AverageEpLen : 25.658163265306122\n",
            "Train_EnvstepsSoFar : 5029\n",
            "TimeSinceStart : 5.46908974647522\n",
            "Training Loss : -14.951866149902344\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 1 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 37.58333206176758\n",
            "Eval_StdReturn : 18.508819580078125\n",
            "Eval_MaxReturn : 76.0\n",
            "Eval_MinReturn : 19.0\n",
            "Eval_AverageEpLen : 37.583333333333336\n",
            "Train_AverageReturn : 29.61403465270996\n",
            "Train_StdReturn : 16.134037017822266\n",
            "Train_MaxReturn : 124.0\n",
            "Train_MinReturn : 11.0\n",
            "Train_AverageEpLen : 29.614035087719298\n",
            "Train_EnvstepsSoFar : 10093\n",
            "TimeSinceStart : 10.953059673309326\n",
            "Training Loss : -51.18506622314453\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 2 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 50.5\n",
            "Eval_StdReturn : 15.272523880004883\n",
            "Eval_MaxReturn : 68.0\n",
            "Eval_MinReturn : 23.0\n",
            "Eval_AverageEpLen : 50.5\n",
            "Train_AverageReturn : 40.879032135009766\n",
            "Train_StdReturn : 22.385042190551758\n",
            "Train_MaxReturn : 108.0\n",
            "Train_MinReturn : 12.0\n",
            "Train_AverageEpLen : 40.87903225806452\n",
            "Train_EnvstepsSoFar : 15162\n",
            "TimeSinceStart : 16.427634716033936\n",
            "Training Loss : -60.88793182373047\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 3 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 47.0\n",
            "Eval_StdReturn : 20.06987762451172\n",
            "Eval_MaxReturn : 84.0\n",
            "Eval_MinReturn : 18.0\n",
            "Eval_AverageEpLen : 47.0\n",
            "Train_AverageReturn : 48.07692337036133\n",
            "Train_StdReturn : 21.701068878173828\n",
            "Train_MaxReturn : 134.0\n",
            "Train_MinReturn : 11.0\n",
            "Train_AverageEpLen : 48.07692307692308\n",
            "Train_EnvstepsSoFar : 20162\n",
            "TimeSinceStart : 21.8602397441864\n",
            "Training Loss : -59.744422912597656\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 4 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 74.5\n",
            "Eval_StdReturn : 18.30072784423828\n",
            "Eval_MaxReturn : 100.0\n",
            "Eval_MinReturn : 54.0\n",
            "Eval_AverageEpLen : 74.5\n",
            "Train_AverageReturn : 54.10752868652344\n",
            "Train_StdReturn : 26.35835075378418\n",
            "Train_MaxReturn : 157.0\n",
            "Train_MinReturn : 18.0\n",
            "Train_AverageEpLen : 54.10752688172043\n",
            "Train_EnvstepsSoFar : 25194\n",
            "TimeSinceStart : 27.374410152435303\n",
            "Training Loss : -23.494461059570312\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 5 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 72.83333587646484\n",
            "Eval_StdReturn : 46.741905212402344\n",
            "Eval_MaxReturn : 171.0\n",
            "Eval_MinReturn : 37.0\n",
            "Eval_AverageEpLen : 72.83333333333333\n",
            "Train_AverageReturn : 65.90908813476562\n",
            "Train_StdReturn : 30.157670974731445\n",
            "Train_MaxReturn : 170.0\n",
            "Train_MinReturn : 21.0\n",
            "Train_AverageEpLen : 65.9090909090909\n",
            "Train_EnvstepsSoFar : 30269\n",
            "TimeSinceStart : 32.98580718040466\n",
            "Training Loss : -28.711397171020508\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 6 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 60.28571319580078\n",
            "Eval_StdReturn : 10.989790916442871\n",
            "Eval_MaxReturn : 82.0\n",
            "Eval_MinReturn : 48.0\n",
            "Eval_AverageEpLen : 60.285714285714285\n",
            "Train_AverageReturn : 70.8591537475586\n",
            "Train_StdReturn : 27.646303176879883\n",
            "Train_MaxReturn : 182.0\n",
            "Train_MinReturn : 32.0\n",
            "Train_AverageEpLen : 70.85915492957747\n",
            "Train_EnvstepsSoFar : 35300\n",
            "TimeSinceStart : 38.3994300365448\n",
            "Training Loss : -35.71420669555664\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 7 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 90.19999694824219\n",
            "Eval_StdReturn : 17.611360549926758\n",
            "Eval_MaxReturn : 111.0\n",
            "Eval_MinReturn : 59.0\n",
            "Eval_AverageEpLen : 90.2\n",
            "Train_AverageReturn : 77.64615631103516\n",
            "Train_StdReturn : 35.258358001708984\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 25.0\n",
            "Train_AverageEpLen : 77.64615384615385\n",
            "Train_EnvstepsSoFar : 40347\n",
            "TimeSinceStart : 43.92927956581116\n",
            "Training Loss : 16.14666748046875\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 8 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 108.0\n",
            "Eval_StdReturn : 40.255435943603516\n",
            "Eval_MaxReturn : 154.0\n",
            "Eval_MinReturn : 53.0\n",
            "Eval_AverageEpLen : 108.0\n",
            "Train_AverageReturn : 81.54838562011719\n",
            "Train_StdReturn : 33.63642120361328\n",
            "Train_MaxReturn : 170.0\n",
            "Train_MinReturn : 32.0\n",
            "Train_AverageEpLen : 81.54838709677419\n",
            "Train_EnvstepsSoFar : 45403\n",
            "TimeSinceStart : 49.98302888870239\n",
            "Training Loss : 12.401607513427734\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 9 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 94.0\n",
            "Eval_StdReturn : 24.81128692626953\n",
            "Eval_MaxReturn : 140.0\n",
            "Eval_MinReturn : 67.0\n",
            "Eval_AverageEpLen : 94.0\n",
            "Train_AverageReturn : 77.73846435546875\n",
            "Train_StdReturn : 31.21798324584961\n",
            "Train_MaxReturn : 194.0\n",
            "Train_MinReturn : 37.0\n",
            "Train_AverageEpLen : 77.73846153846154\n",
            "Train_EnvstepsSoFar : 50456\n",
            "TimeSinceStart : 55.62457013130188\n",
            "Training Loss : 3.7004241943359375\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 10 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 112.5\n",
            "Eval_StdReturn : 50.727210998535156\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 77.0\n",
            "Eval_AverageEpLen : 112.5\n",
            "Train_AverageReturn : 100.16000366210938\n",
            "Train_StdReturn : 38.058040618896484\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 42.0\n",
            "Train_AverageEpLen : 100.16\n",
            "Train_EnvstepsSoFar : 55464\n",
            "TimeSinceStart : 61.08631086349487\n",
            "Training Loss : -24.131423950195312\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 11 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 148.3333282470703\n",
            "Eval_StdReturn : 2.357022762298584\n",
            "Eval_MaxReturn : 150.0\n",
            "Eval_MinReturn : 145.0\n",
            "Eval_AverageEpLen : 148.33333333333334\n",
            "Train_AverageReturn : 121.26190185546875\n",
            "Train_StdReturn : 43.17906188964844\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 46.0\n",
            "Train_AverageEpLen : 121.26190476190476\n",
            "Train_EnvstepsSoFar : 60557\n",
            "TimeSinceStart : 66.62901878356934\n",
            "Training Loss : 6.629051208496094\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 12 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 155.6666717529297\n",
            "Eval_StdReturn : 37.187217712402344\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 109.0\n",
            "Eval_AverageEpLen : 155.66666666666666\n",
            "Train_AverageReturn : 143.22857666015625\n",
            "Train_StdReturn : 44.53190612792969\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 54.0\n",
            "Train_AverageEpLen : 143.22857142857143\n",
            "Train_EnvstepsSoFar : 65570\n",
            "TimeSinceStart : 72.15342307090759\n",
            "Training Loss : 0.7922592163085938\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 13 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 161.6666717529297\n",
            "Eval_StdReturn : 33.02860641479492\n",
            "Eval_MaxReturn : 193.0\n",
            "Eval_MinReturn : 116.0\n",
            "Eval_AverageEpLen : 161.66666666666666\n",
            "Train_AverageReturn : 162.125\n",
            "Train_StdReturn : 41.2187385559082\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 75.0\n",
            "Train_AverageEpLen : 162.125\n",
            "Train_EnvstepsSoFar : 70758\n",
            "TimeSinceStart : 77.85395169258118\n",
            "Training Loss : -19.573444366455078\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 14 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 172.3333282470703\n",
            "Eval_StdReturn : 26.836956024169922\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 136.0\n",
            "Eval_AverageEpLen : 172.33333333333334\n",
            "Train_AverageReturn : 171.53334045410156\n",
            "Train_StdReturn : 24.15054702758789\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 113.0\n",
            "Train_AverageEpLen : 171.53333333333333\n",
            "Train_EnvstepsSoFar : 75904\n",
            "TimeSinceStart : 83.52775192260742\n",
            "Training Loss : -34.19506072998047\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 15 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 137.25\n",
            "Eval_StdReturn : 21.92458724975586\n",
            "Eval_MaxReturn : 174.0\n",
            "Eval_MinReturn : 120.0\n",
            "Eval_AverageEpLen : 137.25\n",
            "Train_AverageReturn : 185.37037658691406\n",
            "Train_StdReturn : 23.579883575439453\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 121.0\n",
            "Train_AverageEpLen : 185.37037037037038\n",
            "Train_EnvstepsSoFar : 80909\n",
            "TimeSinceStart : 89.03923845291138\n",
            "Training Loss : -20.96901512145996\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 16 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 172.93333435058594\n",
            "Train_StdReturn : 26.991275787353516\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 119.0\n",
            "Train_AverageEpLen : 172.93333333333334\n",
            "Train_EnvstepsSoFar : 86097\n",
            "TimeSinceStart : 94.56283330917358\n",
            "Training Loss : -34.40095138549805\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 17 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 177.6666717529297\n",
            "Eval_StdReturn : 31.584104537963867\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 133.0\n",
            "Eval_AverageEpLen : 177.66666666666666\n",
            "Train_AverageReturn : 170.8000030517578\n",
            "Train_StdReturn : 27.10030746459961\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 118.0\n",
            "Train_AverageEpLen : 170.8\n",
            "Train_EnvstepsSoFar : 91221\n",
            "TimeSinceStart : 100.14763903617859\n",
            "Training Loss : -30.017578125\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 18 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 182.2142791748047\n",
            "Train_StdReturn : 24.742034912109375\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 131.0\n",
            "Train_AverageEpLen : 182.21428571428572\n",
            "Train_EnvstepsSoFar : 96323\n",
            "TimeSinceStart : 105.76645922660828\n",
            "Training Loss : -50.36277770996094\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 19 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 193.1923065185547\n",
            "Train_StdReturn : 16.155540466308594\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 131.0\n",
            "Train_AverageEpLen : 193.19230769230768\n",
            "Train_EnvstepsSoFar : 101346\n",
            "TimeSinceStart : 111.16203331947327\n",
            "Training Loss : -6.338771820068359\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 20 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 199.73077392578125\n",
            "Train_StdReturn : 1.3461538553237915\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 193.0\n",
            "Train_AverageEpLen : 199.73076923076923\n",
            "Train_EnvstepsSoFar : 106539\n",
            "TimeSinceStart : 116.72649431228638\n",
            "Training Loss : 4.18438720703125\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 21 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 111539\n",
            "TimeSinceStart : 122.12566018104553\n",
            "Training Loss : 84.88375854492188\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 22 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 116539\n",
            "TimeSinceStart : 127.60103297233582\n",
            "Training Loss : 88.40724182128906\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 23 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 121539\n",
            "TimeSinceStart : 132.9599642753601\n",
            "Training Loss : 93.07659149169922\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 24 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 126539\n",
            "TimeSinceStart : 138.35073709487915\n",
            "Training Loss : 71.71144104003906\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 25 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 131539\n",
            "TimeSinceStart : 143.81486988067627\n",
            "Training Loss : 58.14474868774414\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 26 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 136539\n",
            "TimeSinceStart : 149.2099883556366\n",
            "Training Loss : 83.42762756347656\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 27 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 141539\n",
            "TimeSinceStart : 154.73924565315247\n",
            "Training Loss : 80.88597869873047\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 28 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 146539\n",
            "TimeSinceStart : 160.12431812286377\n",
            "Training Loss : 83.86727905273438\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 29 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 151539\n",
            "TimeSinceStart : 165.48895835876465\n",
            "Training Loss : 77.91504669189453\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 30 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 156539\n",
            "TimeSinceStart : 170.86881756782532\n",
            "Training Loss : 111.4225845336914\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 31 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 161539\n",
            "TimeSinceStart : 176.29410886764526\n",
            "Training Loss : 65.5816421508789\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 32 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 166539\n",
            "TimeSinceStart : 181.62098503112793\n",
            "Training Loss : 89.54704284667969\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 33 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 171539\n",
            "TimeSinceStart : 187.03304076194763\n",
            "Training Loss : 105.29299926757812\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 34 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 176539\n",
            "TimeSinceStart : 192.42587065696716\n",
            "Training Loss : 69.64445495605469\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 35 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 181539\n",
            "TimeSinceStart : 197.74528217315674\n",
            "Training Loss : 83.30875396728516\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 36 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 186539\n",
            "TimeSinceStart : 203.09725689888\n",
            "Training Loss : 67.78364562988281\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 37 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 191539\n",
            "TimeSinceStart : 208.45903372764587\n",
            "Training Loss : 88.2174072265625\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 38 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 196539\n",
            "TimeSinceStart : 213.80493140220642\n",
            "Training Loss : 101.18619537353516\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 39 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 201539\n",
            "TimeSinceStart : 219.29569101333618\n",
            "Training Loss : 125.2761001586914\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 40 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 206539\n",
            "TimeSinceStart : 224.6604082584381\n",
            "Training Loss : 81.4107437133789\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 41 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 211539\n",
            "TimeSinceStart : 230.00337982177734\n",
            "Training Loss : 71.56184387207031\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 42 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 216539\n",
            "TimeSinceStart : 235.31712937355042\n",
            "Training Loss : 68.91944885253906\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 43 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 221539\n",
            "TimeSinceStart : 240.66070771217346\n",
            "Training Loss : 79.56194305419922\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 44 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 226539\n",
            "TimeSinceStart : 245.94515657424927\n",
            "Training Loss : 92.4443359375\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 45 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 231539\n",
            "TimeSinceStart : 251.3004322052002\n",
            "Training Loss : 82.57289123535156\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 46 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 236539\n",
            "TimeSinceStart : 256.6262423992157\n",
            "Training Loss : 113.08785247802734\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 47 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 241539\n",
            "TimeSinceStart : 261.91614174842834\n",
            "Training Loss : 53.462852478027344\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 48 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 246539\n",
            "TimeSinceStart : 267.2850253582001\n",
            "Training Loss : 75.41378784179688\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 49 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 251539\n",
            "TimeSinceStart : 272.5920078754425\n",
            "Training Loss : 45.98012924194336\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 50 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 256539\n",
            "TimeSinceStart : 277.86459255218506\n",
            "Training Loss : 59.8517951965332\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 51 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 261539\n",
            "TimeSinceStart : 283.2401192188263\n",
            "Training Loss : 85.79449462890625\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 52 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 266539\n",
            "TimeSinceStart : 288.6438992023468\n",
            "Training Loss : 76.09854125976562\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 53 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 271539\n",
            "TimeSinceStart : 293.9539668560028\n",
            "Training Loss : 110.63101196289062\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 54 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 276539\n",
            "TimeSinceStart : 299.2934567928314\n",
            "Training Loss : 88.24662780761719\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 55 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 281539\n",
            "TimeSinceStart : 304.6849534511566\n",
            "Training Loss : 79.0805892944336\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 56 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 286539\n",
            "TimeSinceStart : 309.9893653392792\n",
            "Training Loss : 70.47989654541016\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 57 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 196.3333282470703\n",
            "Eval_StdReturn : 5.185449600219727\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 189.0\n",
            "Eval_AverageEpLen : 196.33333333333334\n",
            "Train_AverageReturn : 199.73077392578125\n",
            "Train_StdReturn : 1.3461538553237915\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 193.0\n",
            "Train_AverageEpLen : 199.73076923076923\n",
            "Train_EnvstepsSoFar : 291732\n",
            "TimeSinceStart : 315.6633970737457\n",
            "Training Loss : -16.344247817993164\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 58 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 198.88461303710938\n",
            "Train_StdReturn : 3.456620454788208\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 183.0\n",
            "Train_AverageEpLen : 198.8846153846154\n",
            "Train_EnvstepsSoFar : 296903\n",
            "TimeSinceStart : 321.17608189582825\n",
            "Training Loss : -8.454654693603516\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 59 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 199.5\n",
            "Train_StdReturn : 2.5\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 187.0\n",
            "Train_AverageEpLen : 199.5\n",
            "Train_EnvstepsSoFar : 302090\n",
            "TimeSinceStart : 326.6148066520691\n",
            "Training Loss : -31.187313079833984\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 60 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 307090\n",
            "TimeSinceStart : 332.03838658332825\n",
            "Training Loss : 50.569034576416016\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 61 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 312090\n",
            "TimeSinceStart : 337.3884425163269\n",
            "Training Loss : 88.63755798339844\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 62 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 317090\n",
            "TimeSinceStart : 342.8784601688385\n",
            "Training Loss : 6.187535762786865\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 63 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 322090\n",
            "TimeSinceStart : 348.13404846191406\n",
            "Training Loss : 38.35913848876953\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 64 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 327090\n",
            "TimeSinceStart : 353.534259557724\n",
            "Training Loss : 76.71174621582031\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 65 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 332090\n",
            "TimeSinceStart : 358.93510842323303\n",
            "Training Loss : 95.58694458007812\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 66 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 337090\n",
            "TimeSinceStart : 364.2942147254944\n",
            "Training Loss : 8.264545440673828\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 67 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 342090\n",
            "TimeSinceStart : 369.5724575519562\n",
            "Training Loss : 50.72811508178711\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 68 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 347090\n",
            "TimeSinceStart : 374.96034932136536\n",
            "Training Loss : 12.745805740356445\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 69 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 352090\n",
            "TimeSinceStart : 380.3579478263855\n",
            "Training Loss : 11.308767318725586\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 70 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 357090\n",
            "TimeSinceStart : 385.7170321941376\n",
            "Training Loss : -31.44483757019043\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 71 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 362090\n",
            "TimeSinceStart : 391.18378043174744\n",
            "Training Loss : -10.66861343383789\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 72 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 367090\n",
            "TimeSinceStart : 396.59934735298157\n",
            "Training Loss : -30.258068084716797\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 73 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 372090\n",
            "TimeSinceStart : 402.08894777297974\n",
            "Training Loss : -113.46687316894531\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 74 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 377090\n",
            "TimeSinceStart : 407.5940194129944\n",
            "Training Loss : -3.134505271911621\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 75 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 196.57691955566406\n",
            "Train_StdReturn : 17.11538314819336\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 111.0\n",
            "Train_AverageEpLen : 196.57692307692307\n",
            "Train_EnvstepsSoFar : 382201\n",
            "TimeSinceStart : 413.2504994869232\n",
            "Training Loss : -7.558603286743164\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 76 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 387201\n",
            "TimeSinceStart : 418.6848261356354\n",
            "Training Loss : -97.63068389892578\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 77 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 392201\n",
            "TimeSinceStart : 424.05610179901123\n",
            "Training Loss : -46.346405029296875\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 78 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 397201\n",
            "TimeSinceStart : 429.4473707675934\n",
            "Training Loss : -35.83935546875\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 79 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 402201\n",
            "TimeSinceStart : 434.8232231140137\n",
            "Training Loss : -146.14633178710938\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 80 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 407201\n",
            "TimeSinceStart : 440.26888632774353\n",
            "Training Loss : -145.96615600585938\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 81 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 159.3333282470703\n",
            "Eval_StdReturn : 57.5113525390625\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 78.0\n",
            "Eval_AverageEpLen : 159.33333333333334\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 412201\n",
            "TimeSinceStart : 445.73501420021057\n",
            "Training Loss : -147.23492431640625\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 82 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 417201\n",
            "TimeSinceStart : 451.1880955696106\n",
            "Training Loss : -150.4266357421875\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 83 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 422201\n",
            "TimeSinceStart : 456.5962471961975\n",
            "Training Loss : -147.68875122070312\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 84 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 195.11538696289062\n",
            "Train_StdReturn : 24.423076629638672\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 73.0\n",
            "Train_AverageEpLen : 195.1153846153846\n",
            "Train_EnvstepsSoFar : 427274\n",
            "TimeSinceStart : 462.07252526283264\n",
            "Training Loss : -50.390846252441406\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 85 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 195.26922607421875\n",
            "Train_StdReturn : 23.653844833374023\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 77.0\n",
            "Train_AverageEpLen : 195.26923076923077\n",
            "Train_EnvstepsSoFar : 432351\n",
            "TimeSinceStart : 467.65238308906555\n",
            "Training Loss : -42.51190185546875\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 86 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 437351\n",
            "TimeSinceStart : 473.0892279148102\n",
            "Training Loss : -150.28482055664062\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 87 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 442351\n",
            "TimeSinceStart : 478.5286588668823\n",
            "Training Loss : -147.77516174316406\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 88 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 447351\n",
            "TimeSinceStart : 483.93540024757385\n",
            "Training Loss : -82.59574890136719\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 89 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 452351\n",
            "TimeSinceStart : 489.27967643737793\n",
            "Training Loss : -91.76374816894531\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 90 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 457351\n",
            "TimeSinceStart : 494.7113404273987\n",
            "Training Loss : -95.92726135253906\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 91 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 462351\n",
            "TimeSinceStart : 500.0469856262207\n",
            "Training Loss : -138.46942138671875\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 92 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 467351\n",
            "TimeSinceStart : 505.5139660835266\n",
            "Training Loss : -135.07301330566406\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 93 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 472351\n",
            "TimeSinceStart : 510.8987271785736\n",
            "Training Loss : -133.8439483642578\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 94 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 477351\n",
            "TimeSinceStart : 516.3011445999146\n",
            "Training Loss : -134.78106689453125\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 95 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 482351\n",
            "TimeSinceStart : 521.7630593776703\n",
            "Training Loss : -75.20435333251953\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 96 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 487351\n",
            "TimeSinceStart : 527.1605072021484\n",
            "Training Loss : -132.0423583984375\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 97 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 200.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 200.0\n",
            "Train_AverageEpLen : 200.0\n",
            "Train_EnvstepsSoFar : 492351\n",
            "TimeSinceStart : 532.4813299179077\n",
            "Training Loss : -131.2044677734375\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 98 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 199.88461303710938\n",
            "Train_StdReturn : 0.5769230723381042\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 197.0\n",
            "Train_AverageEpLen : 199.8846153846154\n",
            "Train_EnvstepsSoFar : 497548\n",
            "TimeSinceStart : 538.0454337596893\n",
            "Training Loss : -126.42959594726562\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 99 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 199.03846740722656\n",
            "Train_StdReturn : 2.4726314544677734\n",
            "Train_MaxReturn : 200.0\n",
            "Train_MinReturn : 191.0\n",
            "Train_AverageEpLen : 199.03846153846155\n",
            "Train_EnvstepsSoFar : 502723\n",
            "TimeSinceStart : 543.6402552127838\n",
            "Training Loss : 14.53679084777832\n",
            "Initial_DataCollection_AverageReturn : 25.65816307067871\n",
            "Done logging...\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python cs285/scripts/run_hw2.py --env_name CartPole-v0 -n 100 -b 5000 \\\n",
        "-rtg --exp_name q1_lb_rtg_na"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0eIOrQ_oD1s"
      },
      "source": [
        "## Plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "PJdos2b-okYm"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import glob\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "figsize=(6, 3)\n",
        "export_dir = os.path.join('solution', 'plots')\n",
        "\n",
        "\n",
        "plt.style.use(\"seaborn-whitegrid\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "86ZDGxqZolz7"
      },
      "outputs": [],
      "source": [
        "def get_section_results(file):\n",
        "    \"\"\"\n",
        "        requires tensorflow==1.12.0\n",
        "    \"\"\"\n",
        "    X = [v.simple_value for e in tf.compat.v1.train.summary_iterator(file) for v in e.summary.value if v.tag == 'Train_EnvstepsSoFar']\n",
        "    Y = [v.simple_value for e in tf.compat.v1.train.summary_iterator(file) for v in e.summary.value if v.tag == 'Eval_AverageReturn']\n",
        "    return X, Y"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def read_data(opt, env_name, version):\n",
        "    full_data = pd.DataFrame()\n",
        "    if opt:\n",
        "      ok = True\n",
        "    for folder in os.listdir('data'):\n",
        "        split = folder.split('_')\n",
        "        if opt:\n",
        "          if f\"q{version}\" in split and opt in split:\n",
        "            config_list = split[split.index(opt):split.index(env_name)]\n",
        "            # print('_'.join(config))\n",
        "            config = '_'.join(config_list)\n",
        "\n",
        "            logdir = os.path.join('data', folder, 'events*')\n",
        "            eventfile = glob.glob(logdir)[0]\n",
        "\n",
        "            X, Y = get_section_results(eventfile)\n",
        "            data = pd.DataFrame({'Iteration': range(len(X)), \n",
        "                                 'Config': np.repeat(config, len(X)), \n",
        "                                 'Train_EnvstepsSoFar': X, \n",
        "                                 'Eval_AverageReturn': Y})\n",
        "            data['Eval_AverageReturn_Smooth'] = data['Eval_AverageReturn'].ewm(alpha=0.6).mean()\n",
        "            full_data = pd.concat([full_data, data], axis=0, ignore_index=True)\n",
        "        else:\n",
        "          if f\"q{version}\" in split:\n",
        "            config_list = split[split.index(f\"q{version}\")+1:split.index(env_name)]\n",
        "            # print('_'.join(config))\n",
        "            config = '_'.join(config_list)\n",
        "\n",
        "            logdir = os.path.join('data', folder, 'events*')\n",
        "            eventfile = glob.glob(logdir)[0]\n",
        "\n",
        "            X, Y = get_section_results(eventfile)\n",
        "            data = pd.DataFrame({'Iteration': range(len(X)), \n",
        "                                 'Config': np.repeat(config, len(X)), \n",
        "                                 'Train_EnvstepsSoFar': X, \n",
        "                                 'Eval_AverageReturn': Y})\n",
        "            data['Eval_AverageReturn_Smooth'] = data['Eval_AverageReturn'].ewm(alpha=0.6).mean()\n",
        "            full_data = pd.concat([full_data, data], axis=0, ignore_index=True)\n",
        "        \n",
        "    return full_data"
      ],
      "metadata": {
        "id": "_OtKlK7MtI3x"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_lb = read_data('lb','CartPole-v0',1)\n",
        "data_lb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "R8WF8-AZwPK6",
        "outputId": "14c40f84-a9f2-4ad8-9920-8c029208438c"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-4363b987-f260-4368-8fc1-9bf156f9afd5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Iteration</th>\n",
              "      <th>Config</th>\n",
              "      <th>Train_EnvstepsSoFar</th>\n",
              "      <th>Eval_AverageReturn</th>\n",
              "      <th>Eval_AverageReturn_Smooth</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>lb_no_rtg_dsa</td>\n",
              "      <td>5029.0</td>\n",
              "      <td>33.333332</td>\n",
              "      <td>33.333332</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>lb_no_rtg_dsa</td>\n",
              "      <td>10049.0</td>\n",
              "      <td>31.538462</td>\n",
              "      <td>32.051282</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>lb_no_rtg_dsa</td>\n",
              "      <td>15058.0</td>\n",
              "      <td>52.500000</td>\n",
              "      <td>45.159434</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>lb_no_rtg_dsa</td>\n",
              "      <td>20062.0</td>\n",
              "      <td>60.857143</td>\n",
              "      <td>54.825511</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>lb_no_rtg_dsa</td>\n",
              "      <td>25080.0</td>\n",
              "      <td>68.833336</td>\n",
              "      <td>63.317161</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>295</th>\n",
              "      <td>95</td>\n",
              "      <td>lb_rtg_na</td>\n",
              "      <td>482351.0</td>\n",
              "      <td>200.000000</td>\n",
              "      <td>199.999935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>296</th>\n",
              "      <td>96</td>\n",
              "      <td>lb_rtg_na</td>\n",
              "      <td>487351.0</td>\n",
              "      <td>200.000000</td>\n",
              "      <td>199.999974</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>297</th>\n",
              "      <td>97</td>\n",
              "      <td>lb_rtg_na</td>\n",
              "      <td>492351.0</td>\n",
              "      <td>200.000000</td>\n",
              "      <td>199.999990</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>298</th>\n",
              "      <td>98</td>\n",
              "      <td>lb_rtg_na</td>\n",
              "      <td>497548.0</td>\n",
              "      <td>200.000000</td>\n",
              "      <td>199.999996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>299</th>\n",
              "      <td>99</td>\n",
              "      <td>lb_rtg_na</td>\n",
              "      <td>502723.0</td>\n",
              "      <td>200.000000</td>\n",
              "      <td>199.999998</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>300 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4363b987-f260-4368-8fc1-9bf156f9afd5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4363b987-f260-4368-8fc1-9bf156f9afd5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4363b987-f260-4368-8fc1-9bf156f9afd5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     Iteration         Config  ...  Eval_AverageReturn  Eval_AverageReturn_Smooth\n",
              "0            0  lb_no_rtg_dsa  ...           33.333332                  33.333332\n",
              "1            1  lb_no_rtg_dsa  ...           31.538462                  32.051282\n",
              "2            2  lb_no_rtg_dsa  ...           52.500000                  45.159434\n",
              "3            3  lb_no_rtg_dsa  ...           60.857143                  54.825511\n",
              "4            4  lb_no_rtg_dsa  ...           68.833336                  63.317161\n",
              "..         ...            ...  ...                 ...                        ...\n",
              "295         95      lb_rtg_na  ...          200.000000                 199.999935\n",
              "296         96      lb_rtg_na  ...          200.000000                 199.999974\n",
              "297         97      lb_rtg_na  ...          200.000000                 199.999990\n",
              "298         98      lb_rtg_na  ...          200.000000                 199.999996\n",
              "299         99      lb_rtg_na  ...          200.000000                 199.999998\n",
              "\n",
              "[300 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "ivmNj4Xevv30",
        "outputId": "b3288b46-6352-4b2e-8f94-6f770f7f0432"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fa4a1ea5dd0>"
            ]
          },
          "metadata": {},
          "execution_count": 65
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAADNCAYAAABQMXCtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydeXxU5dX4v3f2ycxknewrJAQStrAIAgqIC4hSUbTWrS68rbvVat1wq9Za259Vq6/oW0W01qUudbdKRWSTLRAgZCOBkIXsmSXL7HN/fwwEQibJJJlAEu738wkf5rnPc+957sycOfc85zlHEEVRREJCQkLitEJ2qgWQkJCQkDj5SMpfQkJC4jREUv4SEhISpyGS8peQkJA4DZGUv4SEhMRpiOJUCxAIubm5p1oECQkJiWHJtGnT/LYPC+UP3U8gEAoLC8nKygqiNEOf03HOcHrO+3ScM5ye8+7rnHsynCW3j4SEhMRpiKT8JSQkJE5DJOUvISEhcRoiKX8JCQmJ05CAFnxLS0tZvXo1tbW1eL3eTsdWrVrV49ja2loeffRRtFotbrebJ554gsceewyVSkVUVBSPP/44paWlPPPMM2g0GiZMmMCtt97a/xlJSEhISPRKQMr/nnvuYcaMGSxatAi5XN6nCxQVFXH77beTk5PDH/7wB2699VZ+85vfMHfuXFasWEFeXh6rVq3i4YcfJj09neXLl1NXV0dsbGy/JiRxjLZWF7WHbTQ12LG1u2lvc2O3uXG7RNxuL263iCiKeL0gekVEQBRFOC7V33BL++cVRTatKfR/UBSPzE8ExGOTEzv+OYZMhiA/NcFwaekGZs2LRadXdrTZ2t001Nkwm5xYTE7aWl04nV6cDg9tbSI7N+3H6xHxeH1z9E3z2Ht57H0U8b3h4pFpH70X3cvj6yH4/i8IR7oKPQwR+jv1gPEg8pWrDuvnFd1LIcLtpf/m7MY9HW0uuZam8HG06hKwqyOwq8JxKvV45Go8MhVemRKvTI4oyBEFGb55CiAcP1//8/MKMl+fIN8jhaaBX982P+D+AZ83kE5Op5NHH320XxeYP38+AHa7nbKyMkJDQztClbKzsyksLKS8vJz09HQAMjMzKS4u7qL8Cwu7+UIHgN1uH9D44YTXI1JVDjWVIuvt+1GpQR8KKrXvzxABcjnI5CCT+f6OfLaPfRyP+1wKJ7we6jgdTlRq1XENTpS5G5EfKEYwNSEaQvFGxSDqDIg6A2i0iAolKJWIcgXI5MjrqpAX7cV+/Z29Xk+oO4xy12ZkdTXYr70d5APzpHo8UFFm5b03rYzK9L1nddXQ3AByBWhDQKsDtQY0OtCHQbjXhVoNguzI+yjge0+PymhrQ5G3Ffmh/ciaGxDDI/CGReLWh1MaEkeGxo2gVB25BzIQFIgyGZUuBdtbVBS2K5ALYFR5iVaKGBQiGpmIViaiFETkMpDj+zv6ORKOXPyIKB3/Dxam5lh+GeZFH+rsts9njWr2zbqEqXGLqDaHU2c10GLXoJB7MajtqBVutEo3oXIPMsGLXOZFJtgRBJEDNhktHphqcHe6l8cQ8QL5rQoK2uQctMlRChCl8BKuFAlX+O6P6sifQvDdH5ng87Uf/V4Fcn9S0yM79FcwdVlAyv+ss84aUExtXV0dTz/9NA888AB/+ctfOD6LtCB0nbK/toHE854u8cCHDrSweV0tXq9I8mg302dmEBqm9Hs/RyrHv9f2XVtofv2PCEoVhqVXoZ48A0V8Uq/3w1V9iNpfryJhfDzysAi/fdy11TS/8CSOfbvQzl6ArWo7cSlalKnpA57D7LNEiveZ2bKhHlEUSc8M4+wFYcTEaf3K3tPn275rK02vPoYiOpaQhRehnT4HRXwSDa0OHv48n7xqCzdNSOXWs4/J3dzm5J5PdlPS0Mq5Y2N4MieRSYlhyIbQ5+irTw4hVypYtCS72z41Gw9QWtlCYUsoLa1OJk2PIilVR1S0ptvPgKndyXNr97Omog65TOC6qxdg0Ci79LPYXKz4Ip/i1lYWZsVybWY0OYnhyGWDe4+CGeffo/K/8cYbEQQBURS59tprSU9PR6/Xd+rTm8+/ubmZJ598kieffJKoqKgOaz8mJob8/HyuvfZaMjIyKC0tJSMjg5KSEpYvXx7w5CR8bNtUz57cJiZPjyLnDCOlpcWEhat6HzgCEUUR86t/pvWbTwi9/HpCf7EcQaUOeLwiPhlBZ8BZsg/tGWd1Oe5psdDw+F0o4pKI/79PUMQncXj5JTjLioOi/AVBYNyECDLGhfnkUfT9aUL0uLG88xotH79N6JU3+e7BETfWjgoTK77IJyNaz7M/m8CKL/eREa3n/HGxWGwubv/XLsK0Sr68ZQ5RuqH5GQoLV9HQ0NZjn4g2GaNqFRjGKll0STJabc+27s5KE/d/lk9KuJZ/Xj+D33y0m3WljSyZEN+p3/76Vu77dA9ROhXv3jCDaH3gn62hRI9342c/+5nf//eFN954o2PRF+Diiy/mvffe48MPPyQlJYXx48dzxx138PTTT6NUKjn77LMxGo39utbpSk11O7t3NHLRslQSknSnWpxTjm3zWtrWfE7sc6tRjen7E58gk6Eak+VX+YsuJ01P/w6ZzkDUw88iU2sAUI3OxHWgBBYs9ntOR3E+zX99nOgnXkQRnxSQHP1R+kdp+fgd2r77jOinX0Ez8dju+H01Vu74MI8bZqbyq9mjkMsEfmdz8ftvConUqXhxXSlalZy/XjaJENXQTQAQFq6iorz746YmB+bCdjZ6rfx6URYKWc/30u7y8PtvClmUFcs954xBLhM4b2wM3xXWdVL+++tbuendHSzKiuN352aiGsB7dKrp8d299NJLAVi9ejU33HBDl+PPPvtsrxf43e9+16Vt8eLOX5DRo0fzxhtv9Houia64nF7WfVvNhCmRkuIHsNswv/Ycob/4n34p/qOoMsfjLCno1CaKIs1/+wPu+jpi//pmh+IHUI4ei2PvTv8i5e+k8Ym7EW3tuMpLA1b+/cVjMWP98E0ibn+ok+IHeGVDGYuyYrnlrNEdbZflJLK/oZVb3t/FuFgDf7s8Z0grfoCwCBW2dv/HRFFk4w81JI3Ws7+4llqrg6RwbY/ne+OncmSCwJ3z0jtcNxdkxbL8n7mY2p1EhPiegF7bdICzRhtZsXBcMKdzSujxHS4pKaGoqIhVq1ZhNBo7+eqtVivvv/8+DzzwwKALKdE9WzbWIZMLnDE75lSLMiRQffcJQogOw6XXDuw8Y7Jp+/ZTRFHs8A+3r/sPtq3riX1uNfLwyM79R2fS+vl7nfoD2HJ/ounp+zAs+yW2bRtxNzUMSK5AsH7wBor4ZELmXtCpPbfCxM5KMx8tP7PLmHsXjCExXMvF4+PQq4e24gef5e92gd3uQaPpHIFYVmKlvtbGldenoy8vp9LU3qPyL2ts5Z3tFTx/2STUimPnyo4zEBuq5oeSBi7LSaS4roUNZY28e8OMQZvXyaTHd9lut5Obm4vVauWDDz7odEypVPq16iVOHlWHWinaa+KSK0cNyEUwUnCWFaPcuIaIZ1YiKLsu0vUFVeZ4vBYTnoZaFDG+x/72tV+hu+ASlMlpXfor08fitVrwNNWjMPoi1TzmZhqfupewa28m9PLrcR0owdNUPyC5esNdU0XrVx8S/eRLCMe5OkRR5JUNB7hkUgKJfhShQi7j2jNSBlW2YKIPVYEAFpMDTXxIR7vT4eGnH+uYfmY0eoOK5HAtlSYbs0b5P49XFHl2TTELMqM5c1RUp2OCIHDBuFi+K6rjspxEXv+pnAWZMaQb9f5PNszoUflPmjSJSZMmkZWVxS9+8YuTJZNEgOzd1UzWxAhi4np+pD1dMK18FvfU2WgmTB3wuRTGGGSRRpwl+1DExOMxN2PP207sL2/z218eFYMsNAxXWXGH8rdv34Q8PBLDsl929Bls5W95+xU0k2egmXxGp/bNB5sorm/hT5dMGNTrnyzkcgGNFixmJ7HHKf/crQ2o1XImTPEp8qQILVVmW7fn+U9BHSX1rfxxif/7csG4WN7aeohNB5pYX9rAP68fGVY/BJje4ZJLLuHVV1/luuuuY/HixVx33XWsWrUKp7P7GFuJwcXj9nK4so20dMOpFiUgWuwuypvbOrkOg4m7oRZn4R6c5y8N2jlVY7JxluwDoH3j9yhi41Fm+F9HEAQB5aixOA+UdLTZtm9AO+PsDjeQ3BiDp3Hw3D7O/YW0b/wvYTd23p/gFUVWbjjA5TmJwzYyxR/aELCYjukgURQpyjczfXY0crnvnieHa6k0d7M4AKwprmPppASM3dyXjGgdqZEhrPginwWZMWREjwyrHwKM83/yySexWq3ccMMNhIWFYTab+eijj6isrOTxxx8fbBkl/FBXY0MUIS4xpPfOQ4D/XX+Aj3dXE6VTMT0lgmU5iUxJCg/a+R17dyKPjkOMCt7ahyozG0fedgDa139LyLyFPe4R8EX8FAMgulzYd24l6sE/dhyXR0UPquVv++kHNDkzUI0a06l9V6WZ8uZ2XroiZ9CufSrQ6nyW/1GaGx04HV4Sk48FPiRFhLC2xP8PrscrkldlYdnkxG6vcdT183+bD7J8VlrQZB8KBKT8d+/ezVdffdXpgz9//vx+h39KDJyqijbiEjTQcBhvWDiCVtfr5iWv3YazYDeaqV0X/AabPYct3DxnFCmRIawpqmfFF/l8cfOcoG2KceTvRD1x4O6e41FnTqDlo3/grq/BuS+PyNsf6rG/cnQm7T/94JNn3y7wetBMmt5xfLDdPo6ifNQTpnRp33PYQnacoSNiZaSgDQFL0zHlX1PdTlS0GvVxC8DJ4VqqLTY8XrHLZ620oZV2p5ucXoyQK6clkW7UjSirHwJ0+4ii2MXF43a7B0UgicCoOtRKVPV2av5nKdVXzKdq6Sxq77yaln+/g8fU5HeMbdP3NP7x/kFzvXSHzenhQGMbs0dHccG4WJ5YnEWrw8OWcv9y9gfH3p2og+DrPx7lmCxEWxvWd/+OMi2j1w1cytGZeGqr8ba1Ytu2AXXOjE6by+TGGERbO9721qDKCSB6PDhL9qEeN7HLsYLaFrLiQoN+zVONNgSsZmfH57mmqr3Lk3BSuBaXR6S+xd5lfG6licwYQ6/RTaEaJQvGjrxouoAs/wsuuICrrrqKSy+9lNDQUMxmM59//jmLFi0abPkk/GC3uWmoszP+8FbCrr8d7Zxz8VpMOPbtovXbzzCvegnVgoshq3M+JtfBUkRbO2J7G4Lu5FkxxfUtyGQw5ojlpFMpOG9sDJ/tqWHO6IFv6PM0N+I+XIF64jSwBE+xyg1hKOKTaPvvF4Rd13umWWVSGihVOA+WYN+2AcPl13c+3xGXlKexAVlKcO+/q/Igoq0NVeb4LscKaq2cPwKVl1YHTqcXu82DRiuntrqd2efEdeoTpVMRopRTabYRH9Y5MGJnpZmpQXQ9DjcCsvzvvvtuli9fzt69e/niiy8oLCzkV7/6FXfddddgyyfhh+qKNrQhckLKtqAaOxFlYgrq7MmEXnEDcSv/RcRt96PYuq7LOGf5fsC3OHoy2VdjZWyMAeVxSc8umRjP+rJGTO0DDxpw7M1FHhUzKJunVJnjQRS7xMz7Q1AoUKZlYFu/BndNFZrpczodl2lDEEJ0eJrqgi6nszgfRfIoZPrOAQCNrQ7qWxxkxw2PwIC+oNH4EhNaTE6sZift7W7iT7D8BUEgKcIX7nk8XlEkr8rM1JTTV/kHZPkLgsBFF13E5MmTaW5uJioqisTE7hdJJAaXqoo2EqIFcDhQpnV2RQiCgGbqLGQvP4OnqQF5VHTHMVd5KQCexnpIyzhp8u6rtTI+vrPbYVJiGEnhWr7eV8s1A4wvtx/x9w9GAjv1pOl4mhsC/mFRjc6k9bvPUKaPQ2Hsam3LjbGDEvHjLNqLelzXcMV9tVbCNAq/sf3DHUEmEBqmxGJ2YjaJhIWrCNF1VWm+WP/OET9lDW1Y7e6gBh0MNwKy/PPz81m4cCHLli3jt7/9LUuXLmXJkiWUlpYOtnwSJyCKIlWHWolTNCMLj/KbdVIeE4+o1eEsK+po81hMeE1NPsuzMfiWZ0/sq7GSfYLPWRAEfjYhns/21gx4DWIw/P1H0S+6lOhnXgu4v3J0JricaGec7ff4YEX8OIr3ohrbvb9/pGZ2DQ1XYTE7qalqJz7Jf+RbUkRIl1j/nVUmMqL1hPrJ2Hm6EJDyf+qpp7j33nvZunUr//3vf9m+fTs333wzTzzxxCCLJwEcKc7hU5AWk5PWFjdGa/cZJAVBwJOUhrP0mPJ3lZciqDWosyb7LP+ThKndyWGLvYvlD7B4fBwVze3sq7H2+/weUxPuyoNBj/Q5nr4oTtXoTAA0M7pmAwWf398dbOVva8ddcRCVv8XeGivZfu79SCEsQoXF5KSmur2Ly+covlj/E5R/pZmpyaev1Q8BKv+WlhYuuKCzz/Piiy+mubl5UISS6MyaL6t4d1UpG9fWsGdnE5FGNYqqoi4un+PxJqbhLD1W9MF1cD/KtAzkMXF4GgfP5+/2ejtZ8gW1VgxqBckRXd0ORr2as9Kj+GxvTb+v58jfhSw8CkViar/PEUxUYycQcdcjqLrZDKYwxgT9x1deeQBBrUGZMrpTuyiKFNZaR6S//yhh4Spqq9tpsbq63fOSFKGl2mzDe+RzKYqipPwJUPlrNBry8vI6te3evRuNRtPNCIlg0tToICEphPY2N6VFVlJHG3CVl/YYeuhNSsNVVtzx2lV+RPkbY3APouV//6f5PP/DMXegz+Vj6LYQyILMGLYd6r8R4cjPHTR/f38Q5Ar0C5d2yqtzPD63T3B9/rKKUlSZ4xFOKLFabbFjsbsZPwLDPI8SFq6ivd2NTq/AEOrfhZMcHoLD7aWh1QHAgaY2zDbXaR3pAwEu+D7wwAPceuutxMfHExoaislkoqmpiRdeeGGw5TvtEUWRthYX48bHE5+kw+sVwe2k+k8VKHtYtPUkjcLTWIfH3Iw8PBJneRm6BYuRhehpbxgcn399i4ONZY3IBIGfTYwnI1pPQW2LX5fPUTJj9By22GlzutH1I42wY+9OdIsvH4jYJ5XB2OglP1SGamLXzV0FtVZiDOpuUxeMBMIifBvX4pNCujUAjHoVaoWMKpONWIOGHRUm0o06wkfYpre+EtC3bebMmXz//ffs3r0bk8lEVFQUkyZNQqvtPYJAFEXeeustVq5cyZo1a/jiiy/YtGkTAOXl5dxxxx2UlZWxfv16oqN9kSkvv/wysl6KL5wu2G0ePB4RvcFn1chkAs7qCvB6ujzmH48YGY0QosNZWoRmykzch8p8PxZeL57Gui6ph4PBmqI60qJ0pBt1vPDDfl66Iod9NVYunZzQ7ZjUyBDkMoEDjW1MTAjr0/U8FhOuQ2VoBtHfH2zkxhi85mZEl2vAmUfB9/2SHypFvaxrCusCPwvtIw29QYlcLhCf0H2aE5kgkBSu5V+7qnht0wHyqiz8anY3aT5PIwJS/l6vlz179tDQ0IDX66WmpoaaGp+fdunSnhNpWSwWMjMzycz0LYRdc801XHPNNdjtdu677z4uuOACVq5cyc0338x5553X7XlGagH3oiYHo8JVqOX+FXGLxeenrKgqRXbY10excxOqqBiKyw91e16704k2LpnqLRtwt9vROR0cdHoR2lvR2W0U7cr17ZIJIp/uamB6nJZZiSIPrjPx0je5mG0uVC11FBY2djsuTidnw55SFJa+5SlS5G1BZQijtM0Bg1DgejAQWizogOJtWxAjB77BTWisQ9feyiGZGvGEee840MSkGPWQvh8DwW63U1RUxNhJIh6hlsLC7p9oU0JE9lU3MzNByxVzjSSFDu3PSXec9ALuN998MyUlJaSmpiI/zq8oCEKvyj88PJzZs2ezcuXKTu2rV6/mmmuuQaHwifDxxx/z5Zdfkpqayj333NPlPCOxgLvD7eGGr37k4gnxPLrIv3wHS62E6GoZPz6zo8289XtcGeNI7WFOhYWFhE2ehqe+hhCZF3NUNFnTZ+C126kG0iPDUQUx1r+8qY1ySw0v/HwCieFarm0v4+1tFcQa1Mya0nMa4fGlHtqVKrKyMnvsdyLNaz5GnD6b1OxjRbyH6nt9FNHrpUqhYFSEAXUQ5Gxbe5DGCCPjZs7q1O7xilR8u547z00nKy2ym9HDm473OoDb+Oeh+5HoEyetgPtRysrKWLNmDSpVcHxkLpeLbdu2ccsttwCwbNkyrr76aqKiolixYgU//fQTs2bN6uUsw5/DFjteEb4pqOXMtEjOHxfbpU9ri6vD5XMUV3lpR0hhT6jSx2HZ/APKlHSUab5MjzKNBpkhzBfrH0Tl/21hHZMSwjo2E10/M5XP99b06O8/Ska0vl+Lvva8bYRd/es+jzuVCDLZEb9/cBZ9nfsL8CR3df8dbGrD5vKM6EgfiYERkGN9ypQp1NYGLzxw69atTJ16zE+7e/dulEf8nzqdDpfLFbRrDWUqTTYiQpTcPX8Mf/yumMOWrkUnWlvc6A2df6Ndh8p6TTIGoMrIwlN3GMfe3E5hofIghxuKosh/CutYmHXsx0unUvDsJRO58cy0XsePNuooa2zr0zXdNVV46g6jzjmj985DDHlUdNDuv6usGG9SWpf2vCozo6JCMJzGm5gkeiYgy/+KK67g8ssvJyUlhZCQzn7Zt99+u8exBQUFvPzyy5SUlHDfffexZMkSmpqaSE5O7ugTFhbGb37zG3Q6HQaDgbPO8r9BZqRRZW4nKUzLFVMS2VLezKNfFvDaVVNQHLfY3XaC5e9tb8VTX9NjpM9RFAnJCBotjvyd6BYec8/JjbF4ghjxU1DbQo3FznknJA+bnBjYAm6GUY+p3UVTm5MoXWBPl/a8bSiS0jqqZg0ngrXRS/R6cR4owTu761rZxgNNzD6hLKGExPEEpPwfeughli1bxtixY/schZOdnc0rr7zSY5/Zs2cze/bsPp13JFBltpEUoUUQBB5bNI7L39jC+v2NndLHtra4iIk/FlXlOnQAFAoUCb3nwxHkcpSjM3EW7EZ5XIEPuTGm2+RiXlHkPwW1LMyKCzjX/n8Ka5mZFklkgIr7ROLDNGiVcsoaW4nSBeaftudtQzMMrX44ev8HrvzdtdWItja8CZ03uNldHnZUmLhuGNXklTj5BKT89Xo9DzzwwGDLctpRabIx6Uh4Y3iIislJ4eyrtXZR/sdb/q7yUpSJqQGHCaoysnAW5/vSDR9BYYzFvtf/QtCuSjOPf11IYpiWyQFugtlY1sSNZ/Z/h61MEEg36ihtaGNGau/KX/R6cezeTsRvHu2171BEERXdUR5yILjKipFHxSAaOj9hba8woZTLAn7ykjg9CciM/+Uvf8nf//53Dh48SF1dXac/if5z1PI/yrhYA4W1LR2vvV6R9jZ3Z+V/NF4/QNSTpqPOntzpx8KXWdK/5fl1gW9tZ2+A+XYaWx1UmW0D3i2ZbtRxoDGwXPyuAyV421rQTJw2oGueKuRRwVlzcR4oRpk+tkv7xrJGzkyLRCGX9spIdE9Alv+jj/osrOeee65TuyAIwzJWdijg9nipsdpJOhIdI4oimlI3jWZbxwas9jY3okgn5e8o2I3unMCL6ITMmk/IrPmd2uTRsX43etldHr4vric1MoS9hy0BnT+v2kKUTjXglMHp0Xq+7SFO+3jseVtRjcnukrt+uOBz+zQMeKOdq7SoS/EWURTZeKCJ28/ufgOghAQEqPyLiop67yTRJ2qtdjxekeQjSrOuxkZ7k4twj5zDFjuJ4VpaW1zIZKAN8e2t8DQ34iorQnPfUwO6ttwYg2i3Iba1IhynQDceaEIhl3HTmWm8vL40IOWUV2VmSlL4gHcL+yz/Nryi2G0eoKP4/P0zBnS9U4k8KgbcLrxWs9+U3IEgiiLOA8XoLrysU/v+hlYaWhzMkhZ7JXqh1+fC3bt3d8rS+K9//Ys//OEPfPfdd4Mq2Ein0mxDr1YQpvVZ9WXFPjdLolJNUZ3P9dPa4kKnV3YoVlvuZuSxCSiS0wZ0bXmUL0LGfUJe/28Kajl/bAxTk8NpaHVS1+Lo9Vx5Veag+JYzjHpsLg+HLV1rrR6P6HTg3JeHevIwVv6RvjQmA6mr4G1uxGtuRnWC22djWRMTEkJHXLF2ieDTo/L/8MMPueWWW2hq8hXafuWVV3jxxRdRKpW8/PLLfPDBBydFyJFIldlGUrgv0sfrFTlQYmVUhgEjSgprfT8ErS0u9MdlKrTv2Ix2+pwBW9kdG72OK+dobney6UATF2bHEWtQE61XsacX10+rw83+hlZygpAdMVKnIiJESVkvfn9X1SFEpwPV2K61aocLglKJPCoad3VFv8/hLCtGpg9FHhPfqX1jWSNnBaEussTIp0fl//bbb/P+++9jNBoRRZF3332XRx99lAceeIBVq1bxzjvvnCw5RxxVJluHv/9wVRsOh4cz5sSg8AqUVfss/7YWN3q9T/mLHjf2XVvQTA9OSOyJi75riuuJM6iZmOCr+jQxIaxXv3/+YQsahZyM6ODkCEo36ilr6Hmzl7umClmkEZlmeJclVE+cjn3X1n6Pdx4oQpk+tpMhYGp3kl9j5ax0yeUj0Ts9Kn+Xy0Vqqi+Er6ioCIvFwvz58wEwGo04nQMvvn26Umm2dRQ4KSu2khwvQ7nlC+QqgeYGB6Io+tw+R3b3Ogv3IjqdqCdND8r1fbt8j7kdvimo5cLsuA5l4lP+PUf87Kq2MCkxrNOmtIGQbtRR2ovl766tGpRC7ScbzbQzse/c0u8Slq6yYlSjO7t8tpY3E61XMyZaHwwRJUY4AX9rN2zYwJQpU6QCLkHiqNvH9OHblO0+TORXz2P6v78SKZjQuWXUWO2dYvxtOzahmTg1aBavPDq2o6hLtdnG3sNWFmXHdRyfmBBGcV0LDren23PsDpK//ygZ0XqK61p6VIjumioUcSNA+U85E09jHe7Kg/0a7yzrGuZZabKRHq0bMoVtJIY2PSr/CRMm8Nxzz7FmzRpWr17NkiVLOo59+umnHU8FEn3DK4pUm23EtTdR9uV6RIWaiX98nLBrfk1U7W4S5GqKals6KX/7jk1oplhR2rsAACAASURBVM8JmgyKqJiOFA8/ljaSYdSRGnksdce4WJ/1WHTcvoPjcXm85NdYg+LvP8pZo6OosdrZUWHqto+7ZmRY/vKIKJSjM7Hn/tTnsd4WK566w10We2tb7MQZJONMIjB6VP4rVqygurqaF198kaVLl3LFFVcAsG7dOp599lnuu+++kyLkSKO+xYHT4yVy11rqsy5m9LhINAnxhJx1HoaD24hEQWGNFbvNg96gxN1Yj+vg/qAqf3l0bEeKh/WlDcwdE93puFohZ1ysodvNXkV1Lbi9IhOCWBzcqFezeHwc/9je/UKou6Z6RCh/AM202dh39l35Ow+UIKjVXeoW11ntxIaO3KpdEsGlR+UfERHBX//6V7788kvuv//+jvYZM2awdu3ajgItAJ999tngSTnCqDbbUCtkKDb8hxptBunjfK4TRXwSRqMSuShQXeFb+NQblNhzN6OIT0KZGLxcLXJjHJ6GWsytNvKqLMxN7xohMiEhtNtF37wqC1mxBjRKud/j/eXa6SlsOdjM/vquvn/R7cbTUDtylP/UM3Hk78Lr6Dm89URcB4pQjsrsUrO3tsUhWf4SAdOvlbqQkJAuJRxfe+21oAh0OlBptpGg9FAXPhmlRklSyrFomfA5c5C7rYjNHhRKAZVahm3TWjTTgpv4TjV2PAgyfly3nUidkiw/ed+PRvz488HnVQfX33+UtCgdZ2cYeceP9e+urwGvZ8Qof3XWZJDLceTv6tM4Z2kxyhMWe0VRpNZqJy5UUv4SgRG05B/9jVo4Hak0tRNnreFw5mLGZIUjOy57ZshZ5xHWvJ84rwqNToFtwxoce3PRL/l5UGWQabRoZ83nx8Jqzk43+t1VOykhjIZWJzXWzpZpu9PNjkMmzkjt3+7U3rjujBS+Laqj9oTrumuqEHR6ZIaRkbBMUCpRT5reZ9ePs6wIVca4Tm0WmwuH20uspPwlAiRoyl+KMAicyjoTcY3V1HuNjM3urMgUcYnEK8xoBBmtbidNrzxL2PW3d8rKGSwU8y5kuyecs1P858iJNfjCBr/K71zIZ01RPTq1nJmDVB5wcmIY2XEG3s+t7NR+NNJnJH3WNFNnYd+5JeD+Xls77qpyVBmdS/nVtTgQgBi95POXCIxBT/sniiKrV69m5syZWK1WPvnkE5YsWcJtt93GbbfdRkNDA/X19dxyyy3cdddd/P73vx9skU45lYcbiYkYjTFGQ6Sxq6UWNy4BgDJrGw9NuoWKGYsHRY59kb7soOOrdvs9LggCv5iWxEd51Tjd3o72T/ccZsnEhKDF9/u77i9npPLJ7sNUmto72kdKjP/xaKfNwl1xAHdDYJXyXAdLQK5AmdI5cVut1U6kToVKIWXylAiMgBK7DQSLxUJmZmanxeFly5Zxww03dLx+9tlnufrqq5k7dy4rVqwgLy+PnJycTucZSPbQYFa8Hyii10uVXQDDaMKi/MvlTTJCnZf51Rv5fvIUbnp3J7dPDeeM+MBj/AOZ82d7LUySWTB//R21iaP89kkVRFxuN2//sIs5SSFUWl3sq7FyY5Z6UO9pjCgyPkrJfR/m8sicKBQyAU1JId7YBBp6uO5Qeq8DJcQYy8EvPsY9a0GvfZUb16GIS6KotLSjzW63k1dziDClOOzmPhCG43s9UII556Ap/+58/uHh4cyePZuVK1d2tK1du5a9e/cSGhrKQw89RElJCTfddBPgq/xVWFjYRfn3pWL9ifS14v1g8tWOUoyCCi9a5szLRKv18xZkZVG4Yx2j5k7juaXzeOLrAipdMn6ZNa5r327obc6iKJK/bjM3TxuD4oW/khkXgzzCf1qAy01q1h9sZvl54/hq7X5mpkUyd9rEgGXpL38a5eLqt7axrlHFnfMyqGk1Yzh3Mfoe5jWU3utAMc+7ANfBQqJvur3Xvk3ffIAwIYe04+ZYWFgIIUpGxaiH3dwHwnB8rwdKX+ecm+u/aBME0e1z6aWXBtRv3rx5PPvsszz33HNER0fz+eefA51/PEaST/d4GlodPLexkkVtzaSO0vlX/Ee4/N75ZC2dB8CYaH2vCc/6Skl9K41tDs6eNRFFfBLt67vP0np5ThIlDa3sqDDx9b5alk5KCKos3RGmVfLURdn8c0clW8ub8NRWj4jdvSeinb0A++7teFt6L6DjKi3sstgLUNdilxZ7JfpEQMp/x44dLF++nAsvvJCFCxd2+jvKr3/964AuWFxcjMfjSxmg0+lwuVwd1j5Afn4+EycOvlV5shFFkT9+W8SYEAGFYRRjJwS+WHo0130wI6oK61pIjdQREaIi5JzFtK/7ptu+MQY152ZG88iXBSjkAnMzTl7WyKnJEdwwM5UnvtyHxSsfcT5/AFXmeOThUdi2ru+xn9dux1V5sMtiL/h8/rFSjL9EHwjI7fPggw9y1VVXkZ2djVzet009BQUFvPzyy5SUlHDfffcxadIkXn/9dfR6PaIo8qc//QmbzcYjjzzChx9+SEpKCuPHD990vd3x5b5adlaaeS7Rxc5WFUmpgWfCTI/W0+b0UGu1Ex8WnNw+JfUtZMb4UjiEzD0f6zuv4m6sR2GM8dv/F9OS+a6onuvOSEF5kssD/s/sNH4qqOTVsVfwYlR07wOGGYJMhnb2ObRvXovuvIu77ecq3w+CgDI1vcuxOquDOGl3r0QfCEj5q1Qqli9f3q8LZGdn88orr/TYR6fT8eqrr/br/EOVarON53/Yj9XuxunxUtbYyj3zx+DKzSfCXYdCEfjTjVGnIkyjoLSxLYjKv5V5GT5FqkhIQRYRhbNwD4qzz/Pbf0J8KHfNy+DC7NigXL8vKGQyHk5oYbkpk68L67l4Qnzvg4YZ2jkLaHj0TrztbchC/BsGztIilKnpCKrOSt7tFWlodUgbvCT6REAm3HnnnccPP/ww2LKMGNqcbu799x5sLg9zM4wszo7j9xdmc+nkBOpb1UTLu09c5g9BEBhtDJ7f3yuK7K9v7bD8BUFAnT0ZR6H/kM+jfa6bkYLxFMWRx5kq+bWrgP/3fQnVZtspkWEwUWfnIAvRYd+xqds+rtJCVOld/f1muwcRpNQOEn0iIMt/27ZtrF69Gr1ej8HQeUPQt99+OyiCDVe8osjjXxUgEwT+snQiIapjt9jrFWn0hJOpr+rzeTOidb0WOgmUKrONdpenQ/kDqLMm9bjoe6px11RxsTGCXTHhPPF1Aa9dNbXXWr/DCUEuR3vmfNo3rSVk7gV++zjLitAt7BpY0WTzopLLiAhR+hklIeGfgJT/b3/728GWY8Tw6sYD7K628NZ10zspfoCmBjtuFMQY++4zTzfq+TivOigyltS3EqNXd6rzqsqajPnNl/Da7ciGYM0Gd00VIeMmsmLBOC56dRP761sZG+t/Z/JwRTtnAU1/vB+vw45M3fk9EJ0OXIfK/Eb6NNk8xBrUIzZKTmJwCEj5r1+/XkrfHACFtVbe3lbByiunkODHN19b3U6YvQZNVN/TIqQbdZQ3t+H2eFEMcMH1+MXeo6jSx4FMjnP/PjQTpw3o/IOBu9aX2sGgV5MRrSev2jzilL9m0nSQy7Hv3ELIrPmdjrkOlYEookwb02Vck90jhXlK9JmAtEh+fj6VlZW9dzzNOdjURlK4lindFDipqW4norkIeWTfQyXTjTpcHpEK08D93SXH+fuPIiiVqDKzcRZ07/c/VXjbWvFaLR1hnlOSwsmr6rm+8HBEUCrRTpuNPXdzl2PO0kKUyaP8PpU12TxSpI9EnwnI8jcYDFxyySWkpaURHt5Zsa1atWpQBBuO1LU4uk2sJYoiNVVtZDXtQx6xxG+fnjBolMQY1JQ1tjLaOLCC6SX1LfzMT8SMOmsyjsI9Azr3YNC+eS2CWoMizre5bHJiGM+t3Y8oiiPO1aGeMpOWf73Zpd1ZUoDSj8sHfMp/dIJk+Uv0jYCU/4IFC1iwoPe8I6c79S0OYgz+lb/Z5MRu9xJpKu6X5Q+QYdRT2tjG+QOQsbnNSUOrs4vlD75F37b//BvR60UYpKRtfcVVXYH51b8Q/ut7EZS+NYqcpHCa2pxUm20kRYT0cobhhSZnJqYXn8JdW40iLhHw5YOybd9I+P/c43dMs01y+0j0nYCUf6CpG0536lsdZHRjlddWtxMa4kUjcyJ0E8fdG+lGHQcaBhbuWVLfgk4lJyG865qEKmsy3lYr7qpDKFP8J3o7mYguF03PPoxm+hx0C5d2tEfr1SSGadhVbemk/NeXNhLmGd51JRQxcSgSUrDnbUO/yPe9c5bsw2s1o+2mjGeTzUNcN0aHhER3BGTejR8/ngkTJvj9kziGz/L3b4HVVLUTE9KOLMLYb1dFulFHaaP/cM93d1Ty/Nr9vZ6jpL6VMdF6v2GS8rBwFIkpPcb7n0wsb/0v3hYLkXeu6HLPcpLC2V1l7nhd1tjKvf/ew0/Vw38PgGbKTOx52zpe2zb/gHrSdGT6rgvcrQ437W5R2uAl0WcCsvy/+65z/LfFYuGzzz477TLq9UZ9i71bt0/N4XYmqpq6zZwZCBnReqrNNmxOD1rVsTQbbq+Xfx4pe3j3ORk9/riUNLSSGdN9lIw6ezLOwt1wnKV9KnDuL6Tl8/eI+dP/+VV6OUnh/GPbsVKP7+dWIQDba+zcchLlHAzUOTMwvfQHRK8XBAHbT+vQX3KV3751Lb5qZ1JeH4m+EpDln5iY2OkvOzubhx56iHfeeWew5Rs2ON1emttdfhd821pdtFpdRDoq++3vB0iNDEEQ4GBzZ+t/84FmzDYX9a2OLqUPT8RfmOfxqLIm4xgCET+2LT+injAVdfZkv8dzksKoMLXT1ObE3O7km4JafjVnFPsaHVjtrpMsbXDRTJqOt7UF14ES3JXluA9XoD1znt++tVYHeqXQyRiQkAiEfq/qlZSUUFdXF0xZhjUNrQ7AV/rwRCwmJwqFgMZShTyi/8pfo5STHBFC6Ql+/0/3HOai8XHEGNTsOdx9CKTd5eFQc3uPyl+dNRl3dQWOfXn9ljMY2HduRjNtVrfHUyNCiAhRsrvazCe7D5MYruWmM9MIVcnYUNp4EiUNPjK9AdWYbOx5W7FtWYcqc3y3CffqrHYitZLil+g7/fL5Z2dnc9lll3HttdcOtnzDhvpWByq5jDBt1y32FrMTQ5gKr6lpQJY/QHacgW8K6vB4fQubdS12Nh1o5NLJCUxKCGN3dffKv7i+9UieoO4XnBXJaRguv576h2+h5fP3g5pGOlA8FjPO/YVops3uto8gCExODGdHhYkPd1Vx1bRk5DKB6fEa1u5vOInSDg6anBnY87Zh+2kd2hM2fB1PXrWZ5FAprYNE3+mXz18ulxMREYFKpepmxOnHUX+/P3+71eIkNEyJt7kR2QB8/gB3zM3gure38X+bD3LrWaP5fG8NY6L1ZMWFMjkxjC/ya/yOc3u9vPRjKXPTjagV3VuKgiAQfuOdqDLH0/z873EU7iby7se7pBsYTOy7tiCPNPpNXXw8U5LCeOnHMvRqBYuyfNlGz4jX8P+2NdPqcKNXD3qV0kFDnTMD68f/ALeLyHue8NvH5vSwbn8jt08JPbnCSYwIArL8H3jggU4+/7i4ONRqNXPnzu117IkF3Gtra/nVr37FXXfdxW233YbD4eCll17iiiuu6Cjq7vV6ez3vUKOnGH+r2UVouAqPqXHAln+MQc0fl0zgra2H+LG0gc/3HubSyb548MmJYZQ2tNLmdHcZ9/bWCipNNh66YGxA1wmZs4DYF9/GVVZM0zMPIrq7nnOwsO/8Cc3UM3uNipqcGI7bK3JZTiIape8HLTNShV4tZ9OB4e36UWdNQpDLUSSmoEhO89vnx9IGtEoZ441SmKdE3+nRNPr000/57LPP2LdvX0eN3aO0trYiC2Aj0IkF3IuKirj99tvJycnhD3/4Azt37gTg5ptv5rzz/OeSHw7UtTj8+vvBZ/nHx6vxWi0D8vkfZVpKBLefnc6Dn+WjkAssPGL1jonRo1LIyD9s5XhbcF+Nlf/bfJDnLp3YKZlbbygTU4l++hXqf7ec5uefIPLeJwd985fo9WLP3ULEzff22ndsrJ6Lxsfx8ynHqnvJBIFzxsSwtqSBhVlxgynqoCIoVWimzkKZ1n301jcFdZw/Lha5zHOSpZMYCfSo/BcvXkxaWhp33HEHS5Z0TkmgUCiYNq33BGAnFnCfP38+4KtCX1ZWxh133MGOHTv4+OOP+fLLL0lNTeWee7ruZBxIxfpgVrzvjtLDzcTrFF2uI4oipmaw1jcQBhxoMiE6By7LNL3IzAQNBpWMygPH4vtHhSr4fncpF6YoKSwsxOH28siGRs5J1hLpaKCwsO/+cOGme9G+/BTmZx7GeekvYRBTKsiqD6G1NHMoJBwCeM+uHCVQX1FG/ZHXdrudDK3A83ubydu7D7ViaOxU7hdLrwdB4LCf+2B1eNhS3sT5CVHY7d5B/3wPRU7G93qoEdQ5iwHQ2NgoiqIo1tTUiPv27QtkSBeuvfZa0WKxiKIoirW1teKdd94pFhYWiqIoitXV1R3XePjhh8XNmzd3Grtjx45+XfMoBQUFAxofCL98e5v4QW5ll3Zbu0t89a/7xPrcvWLFxWeIXrd7UOV4ZUOZeMe/dnXM+c9risVlr/8k2pwDu66jtFCsvOwssX3r+mCI2S2WD94Ua++5vt/jCwoKRJfHI577tx/FtcX1wRNsiPF+boV42d83i16v96R8vocip+O8+zrnnnRnQGaRzWZj2bJlLFmypKNQ+/3339+v6l7Nzc08+eSTPP7444wb50tUtXv3bpRKX8TC0aLuw436btw+FrMTQYAQWyOy8EiEPtZA7iuTE8PYe9iCVxTZVWXm47xqHr8wq8Mn3l9U6ePQnjkf2+a1AY9p37AG09//im3HZryOnvcfHMW+86ceQzwDQSGTMT0lgh0VfauYNpz4T0Edi7LiRlxiO4mTR0DhEPfddx/Lly9n8eLFXHjhhQDceeed3HnnnZxzzjk9jj2xgHt5eTkGg4FHH30UgKuuuoqwsDB+85vfoNPpMBgMnHXWWQOc1snF7fHS1Ob0u+BrtbjQG5SIlsag+Pt7Y2J8KO1ODwfNLt7cXMiVU5OYmBAWlHNrz5yHaeWziB5Prz9ioseN+e9/RRYeRdu3nyK63egXLyP8V7/torC8dhuCSo1ot+EoyCPs+tsHLOu0lAg+ClLxm6FGhamd/BorT16UfapFkRjGBKT8m5ubWbx4MUDHFzc5OTkgCz2QAu4As2d3H9M91GlscyKC37w+VrPzSKTPwGP8A8GgUTLaqGPlLjMqlYpbzx4dtHNrps3C29aKs2gv6vE5Pfa1b9+Et72duNc+RlAose/ZQfOfVyCo1ITfcAcAXocd0wtPHisfqVQhC9Gjyhy4UpueEsGf/1tCc5uTSN3ghiSb2p3874YydCoFRp2KMK0Sh9uLzelBJhO4/LhopGDw792HmRAfSvIIy2gqcXIJSPmHhoby008/MWvWscfxPXv2EBIiffjAF+mjkAl+a6j6YvxVeA43DiivT1+YnBjGJ7vbeHXJuKAqHVmIDs3kM7D9tK5X5d/6zSeEnLMImdb3GdFOm4Xx8edpeOQ2ZKHh6OYvovGp3+JtbyPmL28gKFV47e3IwyIQ5AOPz0+LDCFKpyK30sT542IHfL6e+NfOKrYfMjE+PpSiuhYsNhdqhYwQlZyKZhtFdS08dVF2UFw0BbVW3sut5PnLJgVBconTmYC+ZQ899BC33XYbcXFx1NTUcPnll9PQ0MDf/va3wZZvWHB0g5e/TJlWs5O0dAOe5kZUozNPijzLchIJ9bYyLSUi6OfWnjmXln//k7Dlv+lWmbnra7Hnbib2xc65n9TZk4l6+M80PnUvLR+uRjk6k9gnX0ZmCP4mJUEQmJYcTm6leVCVv9Pt5ZPd1dw5L4OL/RTIKW9u48Z3clm99RA3npk2oGs53B6e+LqASybGM2vUyTEkJEYuASn/adOmsXbtWnbs2EFLSwsxMTFMnjwZtVraXAJHNnh1U8HLanF1uH1kJ8HnD5AZY8CTOrBqX92hnTkP0//+CXflQZQp/l1Kbd9+impMFqr0rhvKtNPnEHX/0zhLiwi75mYExeDtwp2WEsF7Owa3/OiaojpE4Pxx/nPvpEXqeGbJeO7+ZA+jjTrmZUT3+1qvbTyIw+3lrvkZ/T6HhMRReo32aW1tJT8/H0EQmDdvHhdffDEzZsxArVazbt26kyDi0Ke73b0ul5f2NjehQcrrMxSQR0WjyszGtuVHv8dFj5u2NZ+hW3RZt+cImXMu4dffPqiKH3x+//LmdhqPJN0LNqIo8v7OKi6bnNhjyowzR0Vx17wMHvuygGpz/+oN7K4y8+6OSh67MAudavimrZAYOvSo/H/88UfmzZvHLbfcwoIFCygoKAB8G66uv/56HnnkkZMi5FCnvtV/ERerxQmAwaDwpXY4ST7/wUY7c163yt++bSPe9nZC5l5wkqXqSnK4lhi9mtzKwQn53FNtYX9DK8tyEnvte9W0JMbGGngvt39PIis3HmDppASmJQfflSdxetKjCfHiiy/yxhtvkJOTw7fffsszzzxDQkIC69at46abbuLVV189WXIOaepa7ExK7BpOaTU70YbIkdut4PGMCMsfQHPmPCz/WImjaC/ysAiQyXCWFGDbsQn7tvXozl3csdB7KhEEgWkp4eyoMA9Kqof3d1Zx3tgYortx+Z0oyzVnJPPolwXcPGcUBk3gmTirzDZyK808cH5geZkkJAKhR+Xf1tZGTo4vqmPhwoWsWLGCqVOnsmbNGkJDpUyCR6lvcRDrRwFYLS5Cw1Q4i/Yi04ciNw5u1MnJQpmajjItg/p7b+xok4VFoJk+m4hbH+i28MipYHpKBKu3HAr6eeta7PxQ0sDrV08NeMzZ6UaMOhWf7qnhuhkpAY/7Mr+GifGhjIoanHUcidOTHpW//ISNPNHR0X7z7pzOeLwija3dbPAyOwkLV2HfuQV1zoxB3917shAEgdi//RPR6QC3G9HrQWYIG/Skb/1hWnIET/2niLoWe1BLHf64v5GUyBAm9GEDnUwQ+MW0ZN7edoirpiehCOB+ebwiX+bXsHxW2gCklZDoSp++rdJW8q40tzvxiGK3Pv/QcFVHiuKRhCCXI9OGIDOE+mLzh6DiB0gI0xAfqmFTWVNQz7ujwsSM1L7735dMiMfm8rC2xH+CvfKmNlodx9Jnbz/kK9E52HsVJE4/erT8GxoaOtIw+HsN8NRTTw2OZMOE+hYHckEgys8uUqvZSXq8F3dN1YhT/sMFQRC4Ykoib24t5+IJ8aiCkOXTK4rkVpp4bFFWn8dqVXKWTkrg3R2VnD82psOgcnu9vLnlEG9sLme0UccrP88hPETFF/k1nJsZM6wL00gMTXr8Jlx//fXExsZ2/J34OjZWskaqLTai9Crkss5PRR6PSIvVhaa6AEXyKBTRwze3/HDniilJeLwiH+8OTq6f/fWttDrcTE0O79f4n09Noqiuhfs/3ct7uZVsP9TMze/t4uO8ap752QT0ajm3frCL8uY21u1v5GcTu24ek5AYKD2aE3fcccfJkmPYsvlAE9P8KIHWFheiCMrCzZLVf4rRKOX8avYoXtlwgJ9NjO8xTv5Qczvv5VaSFK7l2jP8L8purzAxNtbQp4id44k1aPjfn+ewbn8DX++rpaS+hbPSjfy/I8V2ZqZFcPfHe/jl2zsw6lVM6eePjIRETwT0LOl0OnnhhRf47rvv8Hg8/PDDD7z++uuce+65jBo1arBlHLK4PV7WlzbyqJ/H/6pDrb66vZs2onnwj6dAOonjWTIxnne2V/Lu9kp+Ncf3ma212jnU3E6rw02Lw82GskY2lDaSHBHChtJGrpme7Heda0eFiTMGmDpjWnJER8y+y+NFKT/2EB6iUvDissms+HIfs0ZF+k0bIiExUALO7WMwGHjppZe4++67AUhLS+Oxxx7jH//4x6AKOJTZUWHC5fUya1Rkl2MHSqykRtjA5UQ9ofeKZxKDi0Im49azR/PUN4WEaZX8t7ieXVVm9GoFBrUCvVrB2Fg971x/BlE6NYte2Uh5c3uX8Eq3x8uuSjNXTk3q5kp953jFfxStSs5fpeRtEoNIQMo/Ly+P77//HjgW/nneeefx/PPPD55kw4Af9jcwe1RUl8yZ7W1uDle1MzFsF+rxU5BpghdiKNF/FmRG88/tFfxj+yEWZcXx4PljGW30Hzs/JlrPtkPNXZR/QW0LDo+XnETJFSMxvAlI+atUKhobGzEaj+1QbW5uDij0UxRF3nrrLVauXMmaNWtQKBQ8+OCDCIKAXC7n2WefxWQy8dhjj6FSqYiKiuLxxx/v/4xOEh6vyLr9Dfx2wZguxw7stxIWoUKd9z2as4dvUfqRhkwQ+PvVU5EJQq+ulDNSI9h2yMSVU5M7te+oMDExPhStamTs2ZA4fQko7u2GG25g6dKlPP3005hMJv785z9z5ZVXcsMNN/Q61mKxkJmZSWamL53xv//9b2bNmsWLL75IRkYG3333HW+++SZXX301f/vb33A6neTl5Q1oUieDPYcttDjczBndNWVDWYmVUckK3KWFaKYOrCShRHBRyGQB+dBnpEaSW2HC7fV2at9eYWL6IKTKlpA42QRk+V955ZWkp6fzww8/cP755xMSEsKLL75IdnbvFZfCw8OZPXs2K1euBKC4uJjLLvNlfMzOzmbHjh2UlJRw0003dbQVFhZ2pJU4ykAq1ge14v0RPtpnITtKReWB/Z3aHXaR2mqRUdtX4UlJp8zmgiBfOxAGY87DgWDNW+f2Ynd5+HrLXsZE+PZwOD0iu6tMXJAoDKl7K73Xpw/BnHNAyv/w4cMkJCRwzTXXdGqvqanBYDCg1+v7dFFRFDv+f9R15K/teLKy+r6h5iiFhYUDGn8ioiiy+8fN/HrOKLKyEjod27uziVChjKi6AuJedZPNkAAAIABJREFU+McpS+YW7DkPF4I578n7HNQTys+yfNFBW8ubkcnquejMSUHZLBYspPf69KGvc87Nze32WEDKf8mSJdjtdrzHPQILgoBMJsPj8ZCens6f/vQnJkyY0Ou5srOzKSgoYMqUKeTn5zNx4kTAN6mYmBjy8/O59tprAxHrlFFQ20Jjq5O56UZqqtvZuLaGrAkRjB0fzv7th4g9+D3GFX8ZMVk8T1dmpEawtbyZ/5k9Cofbwws/7GdRVuyQUvwSEv0lIOX/wAMPUF5eznXXXUdMTAwNDQ289957jB49mgsuuICvvvqKJ554go8++qjL2IKCAl5++WVKSkq47777WLJkCf/973/ZsmULer2e2267jalTp/LII4/w4YcfkpKSwvjx44M+0WCyoayRnKQwwkNUFO804XZ52Z3bxPYNh3F6NMy8YCrqsb3/EEoMbWakRvL3zeW0O928tvEg7S4Pd5/TdYFfQmI4EpDyf+utt/jqq686XsfFxXHPPfdw6aWXcskll3D55Zfz+uuv+x2bnZ3NK6+80qltyZIlnV4bjcZhVRtgy4FG5hpliC4nDXV2MtK1pO34OweKzLjmXEriRQtPtYgSQSArzoBGIeO1jQf5YFcVr/1iqpRjR2LEENDza1tbGxs3buzUtn37diwWCwBff/31aVPP12p3UVjXQvpbT1J5+VzqDzai+Oh5PAf3M2XFnZx1w/xTLaJEkFDIZExPieDd3EpunJnKZD8FeyQkhisBmTFPPfUUDz74IC6Xi9DQUNra2vB4PB3x+KtWrRoWsfnBYMchEwbBTdbETIRFf8C1QUHSvDMwXnIZgrJrZk+J4c2F2XF4vCLLZ6edalEkJIJKQMr/7LPPZv369Rw8eBCr1Yperyc1NZW6ujoAv77+kcqW8mameBpQJaTQoEtFH1pP9OW/ONViSQwS546N4dyxMadaDAmJoBNw2EJDQwMmkwm3243ZbOann37i6quvHkzZhhyiKPqUv6UMeUwc9XU2YmKl1A0SEhLDj4As/9WrV/Pcc88RHR1NQ0MDERER2O12rrzyysGWb0hRabZRY7UzsXoPiuhzaDhoIy3dcKrFkpCQkOgzAVn+77zzDl9//TVr164lKSmJ9evX89BDDxEff3oVmdhysJn0qBDCGw8hRMXS1GAnOk57qsWSkJCQ6DMBKX+lUklysi/B1dGNXpdeeikffPDB4Ek2BNl6qJkzon2Lui1KI263SHSM5PaRkBgulJaWcuONN/Lzn/+cyy67jDfffLNP47du3crChQvZuHEjd9111yBJeXIISPknJiby5JNP4vF4iI+P54MPPmDv3r2YTKbBlm/I4PZ42XHIxP9v787joizXBo7/ZhgWGfZhj4ME4oKS21HTRE1Qs7Qy81VBS+v1k2Vl4oah6IfAXA6VRKmdE1ketXJBzFOmmFsLalgGCoZihiD7JsuwzvsHr3NCAYdhn7m/fw3PPMt9zQzXPHM/z33df++hRNJDTl6JBCsbI4yMRXVHQegOampqWLJkCYGBgXz55Zfs2bOHkydPcvLkSY33cf78eebPn8/o0aOJjIxsv8Z2AI36/Ddu3MjWrVsxMDAgMDCQ5cuXU1hYyOLFi9u7fV1G4q0SaupU9K/No9regdxsJXYOostHELqLM2fOMGDAAHVJGWNjYz744AOMjIxYunQpOTk5qFQqwsLCkMlkBAcHY2trS2pqKhMmTGDy5MkcOHAAQ0NDnJ2dWb16NadPnyYmJobo6GhcXFyQSqU899xzjBgxopOjvT+Nkn96ejqrV68G4KGHHuLbb79t10Z1NSqVit0/pzPU1QrD/N9R2TmSm62kj5eY0EMQuosbN27Qp0+fBsvMzMzYt28fDg4ORERE8MMPP/D++++zZMkSkpKSiIuLw9TUFF9fX1577TWmTZuGo6MjY8aMAeq7wd9//31iYmJQqVRMnDiR5557rjPCazGNun2Cg4Pbux1dWnT8H1xIL2SFb29qc26BrTMFeUrsHEV/vyB0FxKJpEFxyjtSUlIYMmQIAMOGDVOXTPbw8MDa2hpjY2Ok0sZTZWFhIVZWVlhaWmJlZcXgwYPbL4A2ptGZv5+fHwsWLGDs2LFYWjYc4n53nR5dc+pqLv/88Q+2TB+Ii7UpOTnZlHo9CvmgsBPJXxC6C3d3dw4ePNhgWXZ2NtXV1eoy8jU1NerHd6asbY5KpWrwxaDJ7IZdhUbJ/8KFCwD3dPdIJBKdTv7X88tY+5/LvD7WgxFu9ZO01+ZmUWjkhI2tCTJR2lcQuo1Ro0axadMmzp49y4gRI1Aqlbz55puMHz+en3/+GV9fXy5cuKDRJFV3WFlZkZ+fT3l5OdXV1d1iFsI7NEr+O3fubO92dEmRJ6/ysJsNs4fW3+aqUqmoyc0iv8YSeydxsVcQuhMDAwO2b99OcHAwmzdvRiaTMXPmTJ544glWrVrFc889h0QiISwsTON9ymQyXnjhBWbNmoWbmxve3t4a/WLoCjRK/iqVit27d3Ps2DEqKyvZs2cPBw8exMfHB4VC0d5t7BQZRRX8kJbPzueGqX/K1RUXQnUVuaWGDBPJXxC6HWdn50bv7Y+IiLhn2Z49e9SPT58+DcBrr712zzJbW1t2796NXC5n+vTpuLi4tHWz24VGyf/tt9/mzz//ZM6cOWzevBmAyspKgoODtarDv2vXLn744QcA/vjjDwDkcjl2dnYAREVFNXmBpaMcuJiBt7MlfRz+W76hJucWShNrSsvqcHAy7cTWCYLQVZSWljJnzhyMjY0ZP348jo6Ond0kjWiU/OPi4oiLi0Mqlaq/IWfOnMmnn36q1UEDAgIICAhAqVSybNkyPDw88Pb2xs/PT6v9tbWqmjoOJd5iyV2zNtXmZlHiMgSTHgZYWBp2UusEQehKZsyYwYwZMzq7GS2mUfI3MjKioqICuVyu7gJRKpUNJl3Xxo4dOwgICODnn39m//79HD58mJ49e7JkyZJ71m3NjPUtnfH+x5sV1NbW8oCqgOTk/45iNky6SJ5lb+TmtaSkpGjdno7Q0ph1hT7GrY8xg37G3ZYxa5T8p0yZwqxZs5g+fTqlpaXs2rWLQ4cO8dRTT2l94Orqas6dO8fChQvp2bMn/v7+KBQKgoOD+emnnxg5cmSD9VsyY/3dWjrjfcQvCUwb5IK3mwOqmmoMrOrv9Ck88zW/Wnrg4WlPv35de3L2lsasK/Qxbn2MGfQz7pbGnJCQ0ORzGiX/V199FRcXF06ePImnpydJSUksWLCgVd00Z8+eVQ+suHjxIo888ghQ3/dfXV2t9X5bKzWnlN8yiln3uBf5EW9SV1SAw7v13VvVuTkUmipwcBYXewVB6N40Sv7vvPMOkydP5umnn26zA1+9elVdKdTS0pLFixcjl8sxNzdn9OjRbXacltp/MYORDypwrCzk1vnvQSKhMiUR477e5BepUJlKRU0fQRC6PY2Sv1KpZNGiRRgaGjJ58mQmT558T42Mlpo3b5768ahRoxg1alSr9tcWqmvriEvJZtXEvpR+8yU3hr5AtbktprF7MO7rTV6NBdbyWgwNxeAuQeguDhw4QElJCdAw73RVTz31FLGxse1+HI2S/5tvvsmbb77JpUuXOH78OMuXL6empobJkyc3uO+1u4v/o4CaOhWjXM35Y9M5Lg9YCRKwSDqKRWY6hUbO2DuISdoFoa3Uld5GVanUaltJcSG1+bn1j41NkJp1nVn1Fi9ezJYtWzq7Gc3SKPnf0b9/fzw9PRk4cCBffvkl27dv16nk/21yNuM87aiNP0Viz//Bo7c5ljYmJFX/L06ffkSh5QT69rTu7GYKgk5Q1daQOX8KqvIyrbaXA5n//1hiKueBz48jMWg6pf3444+kpaVx48YNIiIisLW996aNoKAg9fL09HS2bNnCxYsX2bZtG+bm5jg6OhIYGNjo/gMCAnB1dWXatGnEx8fzz3/+k1GjRrFx40Y8PDz4888/WbZsWaMXbPfu3cuJEydwdXWlqqqKuro6li9fjomJCfn5+YSEhFBZWUlYWBgODg5YW1uzZs2aFr9mf6VR8i8sLOTkyZMcP36cc+fO4e3tzaRJk3jrrbdadfCupLyqhlNXc9n8lDeXdhyl1OpRpoxzxtjEgLSLGcSn90Npa4ujm0j+gtAWJAYynD85rPWZf2pqKp6e9WNxJMYmzSZ+AEdHR0JDQ9W3lTfVBTRs2DDGjh3Liy++SF5eHpGRkWzatAmFQsHChQvJyspqdCBXdnY2H3zwAVZWVjg6OrJgwQKCgoIICgrCy8ur2Tpoe/bsYd++fSiVSr766itu375NVlYW0dHRlJaWIpFIyMnJ4fnnn2fixIn4+/ujVCoxMdG+uKRGyX/cuHE8/PDDTJw4kfDw8Hsqe+qCU1fzMDWU4VmRR6x8FMP/bo6pvP7lGf9ULw7sNsC4phRzMbhLENqM1MwctOyuUeXkYaCw03h9V1dXoP5LIC0trcn17O3tgfrJXpRKJQUFBeoyNo6Ojk0mf1NTU6ysGs7xkZOTo163V69eTcfy/9VBTU1NsbS0xNLSkoCAABYtWoRcLickJAQjIyNiY2M5f/482dnZVFVVtX/y//777zE3/+8bVFhYyOHDh4mNjWXfvn1aH7wr+TY5mwl97fn12BXMJXL6jx6mfs7WyZwhiluUFpYjkQzvxFYKgqCtW7duAfVn6HcSvCYUCgW5ubnY2dmRkZGBk5NTo+v9tZzznXkDrK2tycvLw8bGhmvXrjV5jDtzDZSXl1NUVERRURG9evXiX//6F1999RWHDh3i/PnzTJs2DT8/P+Lj41s9yFaj5G9ubk5NTQ0nTpwgJiaG3377DR8fHxYuXNiqg3cVheVVxF8v4KNn+pH0kzFe3ub31OX++7xJndQ6QRDaQlZWFmFhYaSlpalrlGni9ddfZ926dZiZmTF48GAcHBzuu03Pnj0JDQ3F39+f9evX8+CDD2JhYdFkvf9nn32WhQsX4urqiq2tLTKZjC1btmBiYkJlZSWBgYFIpVKio6OJj49n8ODB7Nixo1VT6UpU9/n6uHjxIjExMZw+fZrhw4dz9OhRzp8/36FlSxMSEhg6dKjW299vVNy+X27y7/N/Em1/k71pXkyb9SD2znKtj9cV6OPoR9DPuPUxZugecV+/fh0jIyMeeOABXnjhBTZs2NCiXx1302aEb1O5s9kz/6effhonJyemTp1KUFAQJiYmHD9+vNvUq9bUidRcJvS1JzNmH1JXLxQOomKnIOiya9eu3VOY0s7OTqO7F48fP86pU6caLBs2bFijF3QrKytZt24ddnZ29OnTh/T0dKKiohqs4+npydy5c7WIonWaTf4mJibU1tZSWVmp7sPqTtOUaaKmro6kzBJm2VZSUGWGwtYYAwPdilEQhIY8PDwIDQ3ValtfX198fX01Wrdv3773fMm0phejLTWb/D///HNSU1OJiYlh69ateHt7U1NTQ21trc6c/V/LLaOiuhbX+ENc8hiNnbNZZzdJEASh3d23ToGnpycrVqzgyJEjPPnkk4wZM4YxY8awdOlSvv76645oY7tKzCzG3doE6U/HKTbriZ2jqNsjCILu07hIjVQqZezYsbz33nt88803DB06lM8++0z9/PXr19ulge3tt8xi+lZmg8cASsok2Dtof9+sIAhCd6FVhTILCwv8/f35/PPP1csWLVrUZo3qSImZxfT6/ScqR89AJpNgZWPc2U0SBKENHThwgB07drBjx44OO2ZQUFCXn2imzcpTtnbAQWcoKKviZpESz+xkShy9sbU3QSoVF3sFQYBt27Z1+QTeGi0q7Nac7ngXUGJmMRZU4z6wP78U1on+fkHoYLeV1Shr6rTatlBZS25pJQAmMinmJs2XXtG0sJuRkREuLi7ExMRw+fJlwsPDWbJkCS4uLpSXl+Pl5dVoXaBLly6xadMmPD091eUjtm/fztWrVykvL2fmzJmMGDGCFStW0KNHDwoKCnjvvfcwNe2cW8vbLPm3xIEDB/jkk0/Uk7msW7dOXbtCoVCwdu3aDmnHb38W0LswDbOnHic3UYm7p0WHHFcQhPrbrKdu/5GyqlrtdxKXA4DcyIC413yQSZvuzNC0sNuYMWPw8/MjLS2N559/nmPHjjF69GjmzZvXbDHLnTt3smrVKvr27cvs2bMBOHnyJJGRkVhaWpKRkUFRURHPPvssPj4+vPvuuyQkJODj46N9/K3QKckfYPr06eoXf+PGjfj7+zNmzBiCg4P59ddfGTRoUIP122MC93NJ1xlSlsHvhqMpvV1NSWkGycmZjeyh+9HHya1BP+PuzjH/41Fbqmq16zKurKzE2Lj+Gp2RgYTUK1caXS8zM5OysjJMTExITk6mqqqKlJSURl+zoqIiKisrSU5OpqioiLS0NJKSknjggQdITk7GzMyM7OzsRrdNS0ujuLiY5ORk5HI5aWlp+Pv7s3LlSkpLSwkICMDJyYl9+/Zx8OBB0tLSsLKyavQXSFM6fAL39vDdd9+RmJiIhYUFV69e5YUXXgDAy8uL5OTke5J/W0/gXlNbR9pXN3nR8wGsrNwwMs5g8NA+3bL7qjHdYeh7e9DHuPUxZtA87uTkZEpKSkhPT6dfv37q7Rrb1srKCnd3d/r164e1tTVubm6UlZVRVVVFv3792L9/Py4uLo1u6+bmhrW1Nb1796akpIQHH3yQ8vJyoqOjyc7OZu3atTz88MM8/PDDzJ49m9DQ0Cb31dqY72j1BO6acHd313jdsWPHMnLkSJycnPjwww/Zu3dvgwvGHZGAk69lUAMM9vUhNVuJnUMPnUn8giDcq6WF3fr06cPbb79NZGQky5Yt4+rVqxQVFam7q+8WEBBAaGgo7u7uGBkZIZFI+Pbbb9m5cycA06ZNw87Ojs2bN3PlyhVsbW357LPPmDBhQpvGqalmk78mM8Xc6QO7u15Fc65cuaKurS2Xy+nRowfJycnY29uTlJTEnDlzNN6XthJ+SGBQtZTELAVXUwoYMEhM0iIIuuiZZ54BNJu/d8OGDerH8+bNY968eRQVFbFkyRK8vb3Ztm2burb/3QYOHMi///3vBsuCg4PvWW/Pnj3qx6+++qomIbSLZpO/JqVLtWFjY0NISAhmZmaoVCoOHjzIW2+9xd69e3F1daV///7tcty/ys+zY7CpJaUl1Ywa54CHuNgrCHqjJYXdDA0NiYqKwtLSkvLycqZOnUpISMg967R2WsWO1mzyv9+30saNG7U6aN++fYmOjm6wbNu2bVrtSxtXf7+FmcwaN+9qJvm5dthxBUHoGlpS2E0ul7N9+/YGy7QtCteVaNTnf+vWLT788EPS09PV1T3Ly8vJyspi5cqV7drA9hB7/E/qaiRMeLRrVNcTBEHoaBqN8F2xYgW1tbU8+eSTXL9+nalTp2JhYcGHH37Y3u1rc2l5pdRV9KC35DpSHalMKgiC0FIaJf+cnBzWr1/PM888g5mZGTNmzCAiIoItW7a0d/va3MfH0jBDik9/UbpZEAT9pVG3j4GBATk5Odjb2yOVSikuLsba2pqbN2+2d/va1MWbRZRnVmFVeA2LYY92dnMEQegABw4coKSkBNDsjh99odGZ//z585kwYQI1NTU8+uijBAQE8NJLL2Fpadne7WszNbV1vHfiKr2lxvRRJiGz1X4eTUEQdJ8o7AbMmDEDX19fZDIZgYGB9OnTh4KCAqZMmdLe7WszW79Pw6C4DiNVDa69xD39gtAVVCprqdGysFulUkVZaTUAMpkUY5Pmr+G1d2G3999/n9zcXGxsbLh06RJRUVFkZmayYcMG5HI51tbWXep2UI2S/8yZM3n88cd57LHHcHBwaHSi4q7sQpaSXReyWPKAKxa/HEM+fVhnN0kQ9F5dnYrdH6dSVaVd8gc4ezIVACMjKc+/3KfZkuztXdgN6m9j9/f3JyQkhJSUFFQqFStWrMDDwwN/f3+USiUmJl1jwiiNkv+CBQuIi4tj69atuLu7M3nyZB577DHs7Ozau32tlllcwUcXi1j4kBvFl8oZ8GccxgPmdnazBEHvSaUS/F/01PrMPzU1FU9PT6D+zP9+c3HcqSrg6OioLrncGGdn5wZ/5+Tk4ObmBkCvXr2orKxsclt7+/ruZGNjY5RKJebm5kRHR2Nqakp2djZVVVXdK/n7+fnh5+dHbW0t58+fJy4uDn9/fxwdHdV1K7qqdZ8co39tNcY3nHDrkYnt36yQmso7u1mCIADGJgYYo90t18YmEuRmzdfw/6tbt24BkJ2drU7SjblT40sikVBXV4eNjQ15eXlA/chgFxcXjY8ZFRXF0qVLcXd3Jz4+vktNetWimbykUimGhoYYGRlhZmamvoLelc1yM+KJwgKqs7NwO/Y2JoNGdHaTBEHoBHcKux0+fFij65V3Crv5+fnx3XffsW7dOvLy8lpUAHLEiBFs2LCBsLAwBg8e3KFTSd6PRKXBV9GxY8c4fvw4p06dwsnJiccee4yJEyeqfwq1t4SEBIYO1W40bn6ukv270pj4iCE2105j6jcFmW371CzqSkSZX/2hjzFDx8VdVFREenq6urCbi4tLp93sok1J56Zyp0bdPh999BGTJk1i0aJFTZYz7ap+PJWFvRO4DfOEYZ6d3RxBELoAUdjtPsk/MTERb29v9u7d2+jzu3btIiAgoF0a1la8Byu4XVbe2c0QBKELEYXd7tPnf3fRtrvr7O/atavtW9TG3DzMkRmKSVoEQRD+qtnkf/flgPz8/GafFwRBELqHZrt97r6qfb+/NZWVlcWaNWvo0aMHNTU1uLu7c/bsWfW4gaioKKTSFt2IJAiCILRAp0zgnpKSwqJFixg0aBBhYWH88ssvvPTSS/j5+TW5TWtqbLTljPfdhT7GDPoZtz7GDPoZd1vG3Gzyr62tJScnR92909jf2hg3bhxQH8i1a9fo16+fesh1z549WbJkyT3btOaWLn28FU4fYwb9jFsfYwb9jFubWz2b0mzyv3HjBmPHjm3Qtz9mzBj1Y227faB+lF14eDgrV67EwsICY2NjFAoFwcHB/PTTT4wcOVLrfQuCIAjN02iQV1srKChgzZo1hIaGolAo+Oabb3jkkUewsLBg/fr1jB49usGXTHPfXoIgCELTmhrk1SnJf/PmzcTHx+PgUD/Sdvbs2URHRyOXyzE3Nyc8PFxc8BUEQWhHnZL8BUEQhM4lTq8FQRD0kEj+giAIekgkf0EQBD3UKYO8Okp5eTlBQUFIJBIMDAzYuHEjhoaaT/7Qndw9anrdunWEhIRgZGSEQqFg7dq1nd3EdvPFF19w+PBhIiIi9CbmjRs3kp6eTkVFBevXryc8PFynP+fXrl3jH//4BwqFgpKSElauXMlbb72lk++1SqXi008/ZevWrRw7dgyZTHZPHissLGz1Z12nz/xjYmIYOXIkW7ZsoVevXhw9erSzm9Ru7oyajoyMxNnZmZdffhl/f38iIyOpqqri119/7ewmtousrCySkpIA+OSTT/Qi5oSEBMrKyoiKimLVqlXs3btX5z/nZ86cwdfXl7CwMFxdXQkKCtLZ97q4uJjevXvTu3dvoPE81hafdZ1O/leuXFGPhvPy8tLpoeDjxo1j0KBB6lHTFhYWehH7u+++yxtvvAHA77//rhcxJyYmAhASEkJ0dDQZGRk6H/fTTz/Nzp07ef3117l06RIymUxnY7aysmLUqFHqvxvLY23xWdfp5A8NK4+2ZkRyd5Cdnc2KFStYuXIlUqlU52M/dOgQI0eORKFQqJfpeswA1dXVODs7ExoayoABA4iNjdX5uHfv3s3LL79MZGQkI0eO5Ny5czof8181Fmtr49fp5O/l5cXly5cBSEpKwtvbu5Nb1H4KCgoIDQ1l7dq19O3bt8HZgK7GfubMGeLj4wkKCiItLY3r16/rfMwAvXv3pq6uDgALCwteeeUVnf+cl5SUYGVlBYClpSWmpqZ68V5D43msLf6/dXqQV0VFBUFBQdTV1WFmZqbTI4fvHjU9ZcoUDh06hEwmw9XVlRUrVnRyC9vX3Llzeffdd1m9erXOx1xXV0dISAjl5eWUlZUREhLCpk2bdPpznp6ezoYNG7CysuL27duEhITo7Ht9+fJloqKiSEhIYODAgUydOpW4uLgG729BQUGr49fp5C8IgiA0TrdODwRBEASNiOQvCIKgh0TyFwRB0EMi+QuCIOghkfwFQRD0kEj+gl4ZP348P//8MxcvXiQlJaVN933mzBkyMzMBiIiIYM+ePW26f0FoSyL5C3pp//79XLlypU33uWPHDnXyX7p0KbNnz27T/QtCW9Lpqp6C0Jhz584RGxvLd999R0FBAfPmzeODDz7gq6++oqqqCl9fX1atWoWBgQFz585lyJAhHD16lPDwcFxdXVm5ciUZGRlUVVUxd+5c5s+fz3vvvUd8fDxpaWksX76c06dP4+rqyiuvvEJKSgrr1q2jqKgIY2Njli1bho+PD2fPnuWdd95h+PDhxMXFUVlZyYYNGxg+fHhnv0SCHhBn/oLeGT58OA899BDLly9n/vz5xMbGcuTIEfbt28exY8dIT09v0GWTlJTEf/7zH4YMGcLWrVtxcXHhyJEjfPrpp0RERHDr1i3eeOMNHBwc2Lx5M48//rh627q6OgIDA5kzZw5HjhwhLCyMpUuXUlpaCtSP5hw4cCDffPMN/v7+bN26tcNfD0E/ieQv6L0TJ04wffp0zM3NkclkzJgxo0FZ5LFjx6rLJaxevZo1a9YA8Le//Q07Oztu3rzZ5L5v3rxJXl4eTzzxBADe3t44OzurK3PK5XL8/PwA6N+/v7rbSBDam+j2EfTe7du3+fjjj/niiy8AqK2txcbGRv28paWl+nFiYqL6bF8qlZKbm6sustaYgoICzM3NG1RdtLCwoKCgAFtbW8zNzdXLpVJps/sShLYkkr+g9+zt7Rk/fjxz5sy577rLly/n+edT9XSeAAABIUlEQVSfZ/bs2UgkEnx8fJpdX6FQUFxcjEqlUn8BFBUVNShDLQidQXT7CHpJJpNx+/ZtAHx9fYmNjaWiogKAzz//nJiYmEa3y8/PZ8CAAUgkEmJiYqioqKC8vPyefd7h4uKCo6MjX3/9NQAXLlwgLy+Phx56qL1CEwSNiDN/QS/5+fmxefNm0tPTCQoKIjU1lWnTpgHg6upKeHh4o9stXryYRYsWYWVlxaxZs5g5cyZr1qxh9+7dTJo0icDAQF5//XX1+hKJhHfeeYe1a9cSFRVFjx492LJlC6amph0SpyA0RZR0FgRB0EOi20cQBEEPieQvCIKgh0TyFwRB0EMi+QuCIOghkfwFQRD0kEj+giAIekgkf0EQBD0kkr8gCIIe+j9kPSGmFjRjDwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x216 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.figure(figsize=figsize)\n",
        "sns.lineplot(data=data_lb, x='Iteration', y='Eval_AverageReturn_Smooth', hue='Config')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "wANZ-Jo-wPdX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "f4012011-c15e-4e01-8bd6-f376b1acc831"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-d8b457a2-f8c6-44f3-ad7d-faa794af3eaa\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Iteration</th>\n",
              "      <th>Config</th>\n",
              "      <th>Train_EnvstepsSoFar</th>\n",
              "      <th>Eval_AverageReturn</th>\n",
              "      <th>Eval_AverageReturn_Smooth</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>sb_rtg_dsa</td>\n",
              "      <td>1023.0</td>\n",
              "      <td>28.857143</td>\n",
              "      <td>28.857143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>sb_rtg_dsa</td>\n",
              "      <td>2024.0</td>\n",
              "      <td>35.750000</td>\n",
              "      <td>33.780612</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>sb_rtg_dsa</td>\n",
              "      <td>3049.0</td>\n",
              "      <td>45.777779</td>\n",
              "      <td>41.471104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>sb_rtg_dsa</td>\n",
              "      <td>4070.0</td>\n",
              "      <td>50.375000</td>\n",
              "      <td>46.953798</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>sb_rtg_dsa</td>\n",
              "      <td>5087.0</td>\n",
              "      <td>72.714287</td>\n",
              "      <td>62.570001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>295</th>\n",
              "      <td>95</td>\n",
              "      <td>sb_rtg_na</td>\n",
              "      <td>98292.0</td>\n",
              "      <td>200.000000</td>\n",
              "      <td>199.992627</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>296</th>\n",
              "      <td>96</td>\n",
              "      <td>sb_rtg_na</td>\n",
              "      <td>99292.0</td>\n",
              "      <td>200.000000</td>\n",
              "      <td>199.997051</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>297</th>\n",
              "      <td>97</td>\n",
              "      <td>sb_rtg_na</td>\n",
              "      <td>100292.0</td>\n",
              "      <td>200.000000</td>\n",
              "      <td>199.998820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>298</th>\n",
              "      <td>98</td>\n",
              "      <td>sb_rtg_na</td>\n",
              "      <td>101292.0</td>\n",
              "      <td>200.000000</td>\n",
              "      <td>199.999528</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>299</th>\n",
              "      <td>99</td>\n",
              "      <td>sb_rtg_na</td>\n",
              "      <td>102292.0</td>\n",
              "      <td>200.000000</td>\n",
              "      <td>199.999811</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>300 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d8b457a2-f8c6-44f3-ad7d-faa794af3eaa')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d8b457a2-f8c6-44f3-ad7d-faa794af3eaa button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d8b457a2-f8c6-44f3-ad7d-faa794af3eaa');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     Iteration      Config  ...  Eval_AverageReturn  Eval_AverageReturn_Smooth\n",
              "0            0  sb_rtg_dsa  ...           28.857143                  28.857143\n",
              "1            1  sb_rtg_dsa  ...           35.750000                  33.780612\n",
              "2            2  sb_rtg_dsa  ...           45.777779                  41.471104\n",
              "3            3  sb_rtg_dsa  ...           50.375000                  46.953798\n",
              "4            4  sb_rtg_dsa  ...           72.714287                  62.570001\n",
              "..         ...         ...  ...                 ...                        ...\n",
              "295         95   sb_rtg_na  ...          200.000000                 199.992627\n",
              "296         96   sb_rtg_na  ...          200.000000                 199.997051\n",
              "297         97   sb_rtg_na  ...          200.000000                 199.998820\n",
              "298         98   sb_rtg_na  ...          200.000000                 199.999528\n",
              "299         99   sb_rtg_na  ...          200.000000                 199.999811\n",
              "\n",
              "[300 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "data_sb = read_data('sb','CartPole-v0',1)\n",
        "data_sb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=figsize)\n",
        "sns.lineplot(data=data_sb, x='Iteration', y='Eval_AverageReturn_Smooth', hue='Config')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "HEepYyU6zODy",
        "outputId": "3baa2c7c-de17-4c13-b5fc-2baf02d82a1e"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fa4a1ea7bd0>"
            ]
          },
          "metadata": {},
          "execution_count": 67
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x216 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIj1PMd1nMb5"
      },
      "source": [
        "#Experiment 2 (InvertedPendulum-v2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-lI_uS3x8w7",
        "outputId": "16cd043e-b497-4b1a-ec21-ab1ce60df728"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "########################\n",
            "logging outputs to  /content/gdrive/My Drive/cs285_f2021/DRL_policy_grads/cs285/scripts/../../data/q2_b100_r05_InvertedPendulum-v2_06-02-2022_17-29-11\n",
            "########################\n",
            "Using GPU id 0\n",
            "Sequential(\n",
            "  (0): Linear(in_features=4, out_features=64, bias=True)\n",
            "  (1): Tanh()\n",
            "  (2): Linear(in_features=64, out_features=64, bias=True)\n",
            "  (3): Tanh()\n",
            "  (4): Linear(in_features=64, out_features=1, bias=True)\n",
            "  (5): Identity()\n",
            ")\n",
            "\n",
            "\n",
            "********** Iteration 0 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([104])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 15.178571701049805\n",
            "Eval_StdReturn : 7.516902923583984\n",
            "Eval_MaxReturn : 34.0\n",
            "Eval_MinReturn : 7.0\n",
            "Eval_AverageEpLen : 15.178571428571429\n",
            "Train_AverageReturn : 7.4285712242126465\n",
            "Train_StdReturn : 3.0169589519500732\n",
            "Train_MaxReturn : 14.0\n",
            "Train_MinReturn : 4.0\n",
            "Train_AverageEpLen : 7.428571428571429\n",
            "Train_EnvstepsSoFar : 104\n",
            "TimeSinceStart : 0.3319675922393799\n",
            "Training Loss : -0.09512589126825333\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 1 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([102])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 9.204545021057129\n",
            "Eval_StdReturn : 2.8570451736450195\n",
            "Eval_MaxReturn : 18.0\n",
            "Eval_MinReturn : 4.0\n",
            "Eval_AverageEpLen : 9.204545454545455\n",
            "Train_AverageReturn : 14.571428298950195\n",
            "Train_StdReturn : 5.851913928985596\n",
            "Train_MaxReturn : 26.0\n",
            "Train_MinReturn : 8.0\n",
            "Train_AverageEpLen : 14.571428571428571\n",
            "Train_EnvstepsSoFar : 206\n",
            "TimeSinceStart : 0.661036491394043\n",
            "Training Loss : 0.042272549122571945\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 2 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([104])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 43.0\n",
            "Eval_StdReturn : 24.915857315063477\n",
            "Eval_MaxReturn : 87.0\n",
            "Eval_MinReturn : 17.0\n",
            "Eval_AverageEpLen : 43.0\n",
            "Train_AverageReturn : 11.55555534362793\n",
            "Train_StdReturn : 4.374448776245117\n",
            "Train_MaxReturn : 21.0\n",
            "Train_MinReturn : 6.0\n",
            "Train_AverageEpLen : 11.555555555555555\n",
            "Train_EnvstepsSoFar : 310\n",
            "TimeSinceStart : 0.9827718734741211\n",
            "Training Loss : 0.057771969586610794\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 3 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([109])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 9.159090995788574\n",
            "Eval_StdReturn : 3.7534420490264893\n",
            "Eval_MaxReturn : 23.0\n",
            "Eval_MinReturn : 3.0\n",
            "Eval_AverageEpLen : 9.159090909090908\n",
            "Train_AverageReturn : 36.33333206176758\n",
            "Train_StdReturn : 12.498888969421387\n",
            "Train_MaxReturn : 54.0\n",
            "Train_MinReturn : 27.0\n",
            "Train_AverageEpLen : 36.333333333333336\n",
            "Train_EnvstepsSoFar : 419\n",
            "TimeSinceStart : 1.3316454887390137\n",
            "Training Loss : 0.07182174921035767\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 4 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([103])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 13.333333015441895\n",
            "Eval_StdReturn : 7.006346225738525\n",
            "Eval_MaxReturn : 38.0\n",
            "Eval_MinReturn : 3.0\n",
            "Eval_AverageEpLen : 13.333333333333334\n",
            "Train_AverageReturn : 6.866666793823242\n",
            "Train_StdReturn : 2.1868293285369873\n",
            "Train_MaxReturn : 11.0\n",
            "Train_MinReturn : 4.0\n",
            "Train_AverageEpLen : 6.866666666666666\n",
            "Train_EnvstepsSoFar : 522\n",
            "TimeSinceStart : 1.6821067333221436\n",
            "Training Loss : -0.12999597191810608\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 5 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([105])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 29.214284896850586\n",
            "Eval_StdReturn : 17.113813400268555\n",
            "Eval_MaxReturn : 74.0\n",
            "Eval_MinReturn : 8.0\n",
            "Eval_AverageEpLen : 29.214285714285715\n",
            "Train_AverageReturn : 15.0\n",
            "Train_StdReturn : 5.855400562286377\n",
            "Train_MaxReturn : 26.0\n",
            "Train_MinReturn : 7.0\n",
            "Train_AverageEpLen : 15.0\n",
            "Train_EnvstepsSoFar : 627\n",
            "TimeSinceStart : 2.0617849826812744\n",
            "Training Loss : 0.058433424681425095\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 6 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([102])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 25.27777862548828\n",
            "Eval_StdReturn : 17.255613327026367\n",
            "Eval_MaxReturn : 58.0\n",
            "Eval_MinReturn : 6.0\n",
            "Eval_AverageEpLen : 25.27777777777778\n",
            "Train_AverageReturn : 28.75\n",
            "Train_StdReturn : 25.469345092773438\n",
            "Train_MaxReturn : 72.0\n",
            "Train_MinReturn : 8.0\n",
            "Train_AverageEpLen : 28.75\n",
            "Train_EnvstepsSoFar : 742\n",
            "TimeSinceStart : 2.4891765117645264\n",
            "Training Loss : -0.05095653235912323\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 7 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([102])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 16.83333396911621\n",
            "Eval_StdReturn : 10.9531831741333\n",
            "Eval_MaxReturn : 57.0\n",
            "Eval_MinReturn : 4.0\n",
            "Eval_AverageEpLen : 16.833333333333332\n",
            "Train_AverageReturn : 22.0\n",
            "Train_StdReturn : 13.608820915222168\n",
            "Train_MaxReturn : 48.0\n",
            "Train_MinReturn : 8.0\n",
            "Train_AverageEpLen : 22.0\n",
            "Train_EnvstepsSoFar : 852\n",
            "TimeSinceStart : 2.8790652751922607\n",
            "Training Loss : -0.0439518541097641\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 8 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([107])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 14.655172348022461\n",
            "Eval_StdReturn : 9.90742015838623\n",
            "Eval_MaxReturn : 37.0\n",
            "Eval_MinReturn : 4.0\n",
            "Eval_AverageEpLen : 14.655172413793103\n",
            "Train_AverageReturn : 21.399999618530273\n",
            "Train_StdReturn : 11.199999809265137\n",
            "Train_MaxReturn : 35.0\n",
            "Train_MinReturn : 9.0\n",
            "Train_AverageEpLen : 21.4\n",
            "Train_EnvstepsSoFar : 959\n",
            "TimeSinceStart : 3.294675588607788\n",
            "Training Loss : 0.0847502201795578\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 9 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([108])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 13.129032135009766\n",
            "Eval_StdReturn : 12.81063461303711\n",
            "Eval_MaxReturn : 42.0\n",
            "Eval_MinReturn : 2.0\n",
            "Eval_AverageEpLen : 13.129032258064516\n",
            "Train_AverageReturn : 8.307692527770996\n",
            "Train_StdReturn : 4.374482154846191\n",
            "Train_MaxReturn : 17.0\n",
            "Train_MinReturn : 4.0\n",
            "Train_AverageEpLen : 8.307692307692308\n",
            "Train_EnvstepsSoFar : 1067\n",
            "TimeSinceStart : 3.690986156463623\n",
            "Training Loss : -0.021517988294363022\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 10 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 12.21212100982666\n",
            "Eval_StdReturn : 10.825777053833008\n",
            "Eval_MaxReturn : 41.0\n",
            "Eval_MinReturn : 2.0\n",
            "Eval_AverageEpLen : 12.212121212121213\n",
            "Train_AverageReturn : 11.11111068725586\n",
            "Train_StdReturn : 11.327885627746582\n",
            "Train_MaxReturn : 40.0\n",
            "Train_MinReturn : 2.0\n",
            "Train_AverageEpLen : 11.11111111111111\n",
            "Train_EnvstepsSoFar : 1167\n",
            "TimeSinceStart : 4.086575746536255\n",
            "Training Loss : 0.0025833570398390293\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 11 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([106])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 13.933333396911621\n",
            "Eval_StdReturn : 13.236145973205566\n",
            "Eval_MaxReturn : 56.0\n",
            "Eval_MinReturn : 3.0\n",
            "Eval_AverageEpLen : 13.933333333333334\n",
            "Train_AverageReturn : 15.714285850524902\n",
            "Train_StdReturn : 13.551112174987793\n",
            "Train_MaxReturn : 45.0\n",
            "Train_MinReturn : 3.0\n",
            "Train_AverageEpLen : 15.714285714285714\n",
            "Train_EnvstepsSoFar : 1277\n",
            "TimeSinceStart : 4.452817916870117\n",
            "Training Loss : -0.04611596465110779\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 12 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([103])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 40.20000076293945\n",
            "Eval_StdReturn : 31.233957290649414\n",
            "Eval_MaxReturn : 96.0\n",
            "Eval_MinReturn : 5.0\n",
            "Eval_AverageEpLen : 40.2\n",
            "Train_AverageReturn : 17.66666603088379\n",
            "Train_StdReturn : 13.682917594909668\n",
            "Train_MaxReturn : 42.0\n",
            "Train_MinReturn : 3.0\n",
            "Train_AverageEpLen : 17.666666666666668\n",
            "Train_EnvstepsSoFar : 1383\n",
            "TimeSinceStart : 4.7758142948150635\n",
            "Training Loss : -0.08649756759405136\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 13 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([126])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 51.625\n",
            "Eval_StdReturn : 31.527517318725586\n",
            "Eval_MaxReturn : 107.0\n",
            "Eval_MinReturn : 13.0\n",
            "Eval_AverageEpLen : 51.625\n",
            "Train_AverageReturn : 42.0\n",
            "Train_StdReturn : 4.242640495300293\n",
            "Train_MaxReturn : 48.0\n",
            "Train_MinReturn : 39.0\n",
            "Train_AverageEpLen : 42.0\n",
            "Train_EnvstepsSoFar : 1509\n",
            "TimeSinceStart : 5.095900774002075\n",
            "Training Loss : -0.16223342716693878\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 14 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([130])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 50.125\n",
            "Eval_StdReturn : 16.736469268798828\n",
            "Eval_MaxReturn : 66.0\n",
            "Eval_MinReturn : 11.0\n",
            "Eval_AverageEpLen : 50.125\n",
            "Train_AverageReturn : 65.0\n",
            "Train_StdReturn : 18.0\n",
            "Train_MaxReturn : 83.0\n",
            "Train_MinReturn : 47.0\n",
            "Train_AverageEpLen : 65.0\n",
            "Train_EnvstepsSoFar : 1639\n",
            "TimeSinceStart : 5.412125825881958\n",
            "Training Loss : -0.04049573466181755\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 15 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([105])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 59.0\n",
            "Eval_StdReturn : 19.659603118896484\n",
            "Eval_MaxReturn : 88.0\n",
            "Eval_MinReturn : 16.0\n",
            "Eval_AverageEpLen : 59.0\n",
            "Train_AverageReturn : 51.0\n",
            "Train_StdReturn : 2.943920373916626\n",
            "Train_MaxReturn : 55.0\n",
            "Train_MinReturn : 48.0\n",
            "Train_AverageEpLen : 51.0\n",
            "Train_EnvstepsSoFar : 1792\n",
            "TimeSinceStart : 5.822126626968384\n",
            "Training Loss : -0.05140738934278488\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 16 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([140])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 61.0\n",
            "Eval_StdReturn : 4.407785415649414\n",
            "Eval_MaxReturn : 66.0\n",
            "Eval_MinReturn : 52.0\n",
            "Eval_AverageEpLen : 61.0\n",
            "Train_AverageReturn : 70.0\n",
            "Train_StdReturn : 1.0\n",
            "Train_MaxReturn : 71.0\n",
            "Train_MinReturn : 69.0\n",
            "Train_AverageEpLen : 70.0\n",
            "Train_EnvstepsSoFar : 1932\n",
            "TimeSinceStart : 6.153310060501099\n",
            "Training Loss : -0.050927020609378815\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 17 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([101])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 78.5\n",
            "Eval_StdReturn : 9.10585880279541\n",
            "Eval_MaxReturn : 94.0\n",
            "Eval_MinReturn : 63.0\n",
            "Eval_AverageEpLen : 78.5\n",
            "Train_AverageReturn : 50.5\n",
            "Train_StdReturn : 2.5\n",
            "Train_MaxReturn : 53.0\n",
            "Train_MinReturn : 48.0\n",
            "Train_AverageEpLen : 50.5\n",
            "Train_EnvstepsSoFar : 2033\n",
            "TimeSinceStart : 6.486337423324585\n",
            "Training Loss : -0.02962021715939045\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 18 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([102])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 82.83333587646484\n",
            "Eval_StdReturn : 12.863600730895996\n",
            "Eval_MaxReturn : 101.0\n",
            "Eval_MinReturn : 58.0\n",
            "Eval_AverageEpLen : 82.83333333333333\n",
            "Train_AverageReturn : 102.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 102.0\n",
            "Train_MinReturn : 102.0\n",
            "Train_AverageEpLen : 102.0\n",
            "Train_EnvstepsSoFar : 2135\n",
            "TimeSinceStart : 6.854913234710693\n",
            "Training Loss : -0.04046843200922012\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 19 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 83.5\n",
            "Eval_StdReturn : 51.20140075683594\n",
            "Eval_MaxReturn : 148.0\n",
            "Eval_MinReturn : 8.0\n",
            "Eval_AverageEpLen : 83.5\n",
            "Train_AverageReturn : 57.5\n",
            "Train_StdReturn : 42.5\n",
            "Train_MaxReturn : 100.0\n",
            "Train_MinReturn : 15.0\n",
            "Train_AverageEpLen : 57.5\n",
            "Train_EnvstepsSoFar : 2250\n",
            "TimeSinceStart : 7.23913311958313\n",
            "Training Loss : -0.04188079759478569\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 20 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([124])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 66.42857360839844\n",
            "Eval_StdReturn : 24.470722198486328\n",
            "Eval_MaxReturn : 82.0\n",
            "Eval_MinReturn : 7.0\n",
            "Eval_AverageEpLen : 66.42857142857143\n",
            "Train_AverageReturn : 124.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 124.0\n",
            "Train_MinReturn : 124.0\n",
            "Train_AverageEpLen : 124.0\n",
            "Train_EnvstepsSoFar : 2374\n",
            "TimeSinceStart : 7.612927198410034\n",
            "Training Loss : -0.005362664349377155\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 21 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([165])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 65.42857360839844\n",
            "Eval_StdReturn : 5.010193347930908\n",
            "Eval_MaxReturn : 71.0\n",
            "Eval_MinReturn : 57.0\n",
            "Eval_AverageEpLen : 65.42857142857143\n",
            "Train_AverageReturn : 57.66666793823242\n",
            "Train_StdReturn : 35.31131362915039\n",
            "Train_MaxReturn : 87.0\n",
            "Train_MinReturn : 8.0\n",
            "Train_AverageEpLen : 57.666666666666664\n",
            "Train_EnvstepsSoFar : 2547\n",
            "TimeSinceStart : 8.017596960067749\n",
            "Training Loss : -0.01303229108452797\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 22 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([129])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 55.5\n",
            "Eval_StdReturn : 3.872983455657959\n",
            "Eval_MaxReturn : 63.0\n",
            "Eval_MinReturn : 50.0\n",
            "Eval_AverageEpLen : 55.5\n",
            "Train_AverageReturn : 64.5\n",
            "Train_StdReturn : 2.5\n",
            "Train_MaxReturn : 67.0\n",
            "Train_MinReturn : 62.0\n",
            "Train_AverageEpLen : 64.5\n",
            "Train_EnvstepsSoFar : 2676\n",
            "TimeSinceStart : 8.353230714797974\n",
            "Training Loss : -0.16131694614887238\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 23 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([114])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 65.14286041259766\n",
            "Eval_StdReturn : 19.65726661682129\n",
            "Eval_MaxReturn : 94.0\n",
            "Eval_MinReturn : 31.0\n",
            "Eval_AverageEpLen : 65.14285714285714\n",
            "Train_AverageReturn : 57.0\n",
            "Train_StdReturn : 1.0\n",
            "Train_MaxReturn : 58.0\n",
            "Train_MinReturn : 56.0\n",
            "Train_AverageEpLen : 57.0\n",
            "Train_EnvstepsSoFar : 2790\n",
            "TimeSinceStart : 8.691590070724487\n",
            "Training Loss : 0.07007401436567307\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 24 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([161])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 49.22222137451172\n",
            "Eval_StdReturn : 22.37447738647461\n",
            "Eval_MaxReturn : 93.0\n",
            "Eval_MinReturn : 6.0\n",
            "Eval_AverageEpLen : 49.22222222222222\n",
            "Train_AverageReturn : 80.5\n",
            "Train_StdReturn : 1.5\n",
            "Train_MaxReturn : 82.0\n",
            "Train_MinReturn : 79.0\n",
            "Train_AverageEpLen : 80.5\n",
            "Train_EnvstepsSoFar : 2951\n",
            "TimeSinceStart : 9.052824974060059\n",
            "Training Loss : 0.0001781416212907061\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 25 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([123])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 34.75\n",
            "Eval_StdReturn : 16.114822387695312\n",
            "Eval_MaxReturn : 63.0\n",
            "Eval_MinReturn : 6.0\n",
            "Eval_AverageEpLen : 34.75\n",
            "Train_AverageReturn : 46.33333206176758\n",
            "Train_StdReturn : 24.115463256835938\n",
            "Train_MaxReturn : 75.0\n",
            "Train_MinReturn : 16.0\n",
            "Train_AverageEpLen : 46.333333333333336\n",
            "Train_EnvstepsSoFar : 3090\n",
            "TimeSinceStart : 9.377734422683716\n",
            "Training Loss : -0.008208396844565868\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 26 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([101])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 19.619047164916992\n",
            "Eval_StdReturn : 15.49032211303711\n",
            "Eval_MaxReturn : 52.0\n",
            "Eval_MinReturn : 4.0\n",
            "Eval_AverageEpLen : 19.61904761904762\n",
            "Train_AverageReturn : 33.66666793823242\n",
            "Train_StdReturn : 9.030811309814453\n",
            "Train_MaxReturn : 44.0\n",
            "Train_MinReturn : 22.0\n",
            "Train_AverageEpLen : 33.666666666666664\n",
            "Train_EnvstepsSoFar : 3191\n",
            "TimeSinceStart : 9.708708047866821\n",
            "Training Loss : -0.13909511268138885\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 27 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([111])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 31.30769157409668\n",
            "Eval_StdReturn : 12.028074264526367\n",
            "Eval_MaxReturn : 54.0\n",
            "Eval_MinReturn : 12.0\n",
            "Eval_AverageEpLen : 31.307692307692307\n",
            "Train_AverageReturn : 37.0\n",
            "Train_StdReturn : 10.614455223083496\n",
            "Train_MaxReturn : 45.0\n",
            "Train_MinReturn : 22.0\n",
            "Train_AverageEpLen : 37.0\n",
            "Train_EnvstepsSoFar : 3302\n",
            "TimeSinceStart : 10.086970329284668\n",
            "Training Loss : -0.08899889886379242\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 28 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([133])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 27.66666603088379\n",
            "Eval_StdReturn : 19.223827362060547\n",
            "Eval_MaxReturn : 57.0\n",
            "Eval_MinReturn : 3.0\n",
            "Eval_AverageEpLen : 27.666666666666668\n",
            "Train_AverageReturn : 27.799999237060547\n",
            "Train_StdReturn : 19.19791603088379\n",
            "Train_MaxReturn : 53.0\n",
            "Train_MinReturn : 5.0\n",
            "Train_AverageEpLen : 27.8\n",
            "Train_EnvstepsSoFar : 3441\n",
            "TimeSinceStart : 10.491316795349121\n",
            "Training Loss : 0.09447444975376129\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 29 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([106])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 40.3636360168457\n",
            "Eval_StdReturn : 21.785202026367188\n",
            "Eval_MaxReturn : 78.0\n",
            "Eval_MinReturn : 5.0\n",
            "Eval_AverageEpLen : 40.36363636363637\n",
            "Train_AverageReturn : 21.200000762939453\n",
            "Train_StdReturn : 8.61161994934082\n",
            "Train_MaxReturn : 36.0\n",
            "Train_MinReturn : 11.0\n",
            "Train_AverageEpLen : 21.2\n",
            "Train_EnvstepsSoFar : 3547\n",
            "TimeSinceStart : 10.838945388793945\n",
            "Training Loss : 0.0053013768047094345\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 30 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([103])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 81.16666412353516\n",
            "Eval_StdReturn : 40.43684768676758\n",
            "Eval_MaxReturn : 142.0\n",
            "Eval_MinReturn : 19.0\n",
            "Eval_AverageEpLen : 81.16666666666667\n",
            "Train_AverageReturn : 37.5\n",
            "Train_StdReturn : 19.032865524291992\n",
            "Train_MaxReturn : 62.0\n",
            "Train_MinReturn : 11.0\n",
            "Train_AverageEpLen : 37.5\n",
            "Train_EnvstepsSoFar : 3697\n",
            "TimeSinceStart : 11.222529649734497\n",
            "Training Loss : -0.08200660347938538\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 31 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([130])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 71.66666412353516\n",
            "Eval_StdReturn : 39.21592712402344\n",
            "Eval_MaxReturn : 119.0\n",
            "Eval_MinReturn : 10.0\n",
            "Eval_AverageEpLen : 71.66666666666667\n",
            "Train_AverageReturn : 65.0\n",
            "Train_StdReturn : 33.0\n",
            "Train_MaxReturn : 98.0\n",
            "Train_MinReturn : 32.0\n",
            "Train_AverageEpLen : 65.0\n",
            "Train_EnvstepsSoFar : 3827\n",
            "TimeSinceStart : 11.550469160079956\n",
            "Training Loss : -0.03662396967411041\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 32 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 42.29999923706055\n",
            "Eval_StdReturn : 31.660858154296875\n",
            "Eval_MaxReturn : 96.0\n",
            "Eval_MinReturn : 8.0\n",
            "Eval_AverageEpLen : 42.3\n",
            "Train_AverageReturn : 67.5\n",
            "Train_StdReturn : 32.5\n",
            "Train_MaxReturn : 100.0\n",
            "Train_MinReturn : 35.0\n",
            "Train_AverageEpLen : 67.5\n",
            "Train_EnvstepsSoFar : 3962\n",
            "TimeSinceStart : 11.930742025375366\n",
            "Training Loss : -0.1776353418827057\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 33 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([117])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 11.13888931274414\n",
            "Eval_StdReturn : 13.664944648742676\n",
            "Eval_MaxReturn : 58.0\n",
            "Eval_MinReturn : 3.0\n",
            "Eval_AverageEpLen : 11.13888888888889\n",
            "Train_AverageReturn : 36.400001525878906\n",
            "Train_StdReturn : 40.4998779296875\n",
            "Train_MaxReturn : 117.0\n",
            "Train_MinReturn : 9.0\n",
            "Train_AverageEpLen : 36.4\n",
            "Train_EnvstepsSoFar : 4144\n",
            "TimeSinceStart : 12.362683773040771\n",
            "Training Loss : -0.0451577827334404\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 34 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([101])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 14.034482955932617\n",
            "Eval_StdReturn : 13.946901321411133\n",
            "Eval_MaxReturn : 47.0\n",
            "Eval_MinReturn : 3.0\n",
            "Eval_AverageEpLen : 14.03448275862069\n",
            "Train_AverageReturn : 16.83333396911621\n",
            "Train_StdReturn : 18.667409896850586\n",
            "Train_MaxReturn : 57.0\n",
            "Train_MinReturn : 3.0\n",
            "Train_AverageEpLen : 16.833333333333332\n",
            "Train_EnvstepsSoFar : 4245\n",
            "TimeSinceStart : 12.715852975845337\n",
            "Training Loss : -0.028402134776115417\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 35 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([102])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 20.700000762939453\n",
            "Eval_StdReturn : 12.841729164123535\n",
            "Eval_MaxReturn : 50.0\n",
            "Eval_MinReturn : 4.0\n",
            "Eval_AverageEpLen : 20.7\n",
            "Train_AverageReturn : 17.0\n",
            "Train_StdReturn : 15.470401763916016\n",
            "Train_MaxReturn : 44.0\n",
            "Train_MinReturn : 4.0\n",
            "Train_AverageEpLen : 17.0\n",
            "Train_EnvstepsSoFar : 4347\n",
            "TimeSinceStart : 13.106195449829102\n",
            "Training Loss : 0.07042121142148972\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 36 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([109])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 3.612612724304199\n",
            "Eval_StdReturn : 6.387165069580078\n",
            "Eval_MaxReturn : 49.0\n",
            "Eval_MinReturn : 2.0\n",
            "Eval_AverageEpLen : 3.6126126126126126\n",
            "Train_AverageReturn : 18.83333396911621\n",
            "Train_StdReturn : 9.702520370483398\n",
            "Train_MaxReturn : 30.0\n",
            "Train_MinReturn : 4.0\n",
            "Train_AverageEpLen : 18.833333333333332\n",
            "Train_EnvstepsSoFar : 4460\n",
            "TimeSinceStart : 13.471338748931885\n",
            "Training Loss : -0.17557378113269806\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 37 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([101])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 12.470588684082031\n",
            "Eval_StdReturn : 10.018321990966797\n",
            "Eval_MaxReturn : 43.0\n",
            "Eval_MinReturn : 2.0\n",
            "Eval_AverageEpLen : 12.470588235294118\n",
            "Train_AverageReturn : 3.5833332538604736\n",
            "Train_StdReturn : 6.170607089996338\n",
            "Train_MaxReturn : 36.0\n",
            "Train_MinReturn : 2.0\n",
            "Train_AverageEpLen : 3.5833333333333335\n",
            "Train_EnvstepsSoFar : 4589\n",
            "TimeSinceStart : 13.814276218414307\n",
            "Training Loss : 0.05295133963227272\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 38 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([102])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 14.193548202514648\n",
            "Eval_StdReturn : 14.21135139465332\n",
            "Eval_MaxReturn : 48.0\n",
            "Eval_MinReturn : 4.0\n",
            "Eval_AverageEpLen : 14.193548387096774\n",
            "Train_AverageReturn : 12.777777671813965\n",
            "Train_StdReturn : 7.020252704620361\n",
            "Train_MaxReturn : 23.0\n",
            "Train_MinReturn : 2.0\n",
            "Train_AverageEpLen : 12.777777777777779\n",
            "Train_EnvstepsSoFar : 4704\n",
            "TimeSinceStart : 14.161148309707642\n",
            "Training Loss : 0.021849730983376503\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 39 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([101])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 9.714285850524902\n",
            "Eval_StdReturn : 9.189242362976074\n",
            "Eval_MaxReturn : 35.0\n",
            "Eval_MinReturn : 4.0\n",
            "Eval_AverageEpLen : 9.714285714285714\n",
            "Train_AverageReturn : 8.416666984558105\n",
            "Train_StdReturn : 7.825794219970703\n",
            "Train_MaxReturn : 31.0\n",
            "Train_MinReturn : 4.0\n",
            "Train_AverageEpLen : 8.416666666666666\n",
            "Train_EnvstepsSoFar : 4805\n",
            "TimeSinceStart : 14.473551988601685\n",
            "Training Loss : -0.00012140226317569613\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 40 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([114])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 19.31818199157715\n",
            "Eval_StdReturn : 12.16696834564209\n",
            "Eval_MaxReturn : 45.0\n",
            "Eval_MinReturn : 2.0\n",
            "Eval_AverageEpLen : 19.318181818181817\n",
            "Train_AverageReturn : 6.6315789222717285\n",
            "Train_StdReturn : 6.123384952545166\n",
            "Train_MaxReturn : 29.0\n",
            "Train_MinReturn : 4.0\n",
            "Train_AverageEpLen : 6.631578947368421\n",
            "Train_EnvstepsSoFar : 4931\n",
            "TimeSinceStart : 14.833520412445068\n",
            "Training Loss : 0.04612354189157486\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 41 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([101])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 2.0459184646606445\n",
            "Eval_StdReturn : 0.20930807292461395\n",
            "Eval_MaxReturn : 3.0\n",
            "Eval_MinReturn : 2.0\n",
            "Eval_AverageEpLen : 2.045918367346939\n",
            "Train_AverageReturn : 20.200000762939453\n",
            "Train_StdReturn : 13.120975494384766\n",
            "Train_MaxReturn : 46.0\n",
            "Train_MinReturn : 11.0\n",
            "Train_AverageEpLen : 20.2\n",
            "Train_EnvstepsSoFar : 5032\n",
            "TimeSinceStart : 15.190178394317627\n",
            "Training Loss : -0.013062949292361736\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 42 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 2.005000114440918\n",
            "Eval_StdReturn : 0.07053367048501968\n",
            "Eval_MaxReturn : 3.0\n",
            "Eval_MinReturn : 2.0\n",
            "Eval_AverageEpLen : 2.005\n",
            "Train_AverageReturn : 2.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 2.0\n",
            "Train_MinReturn : 2.0\n",
            "Train_AverageEpLen : 2.0\n",
            "Train_EnvstepsSoFar : 5132\n",
            "TimeSinceStart : 15.559104919433594\n",
            "Training Loss : -0.04555520415306091\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 43 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 2.0202019214630127\n",
            "Eval_StdReturn : 0.14069078862667084\n",
            "Eval_MaxReturn : 3.0\n",
            "Eval_MinReturn : 2.0\n",
            "Eval_AverageEpLen : 2.0202020202020203\n",
            "Train_AverageReturn : 2.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 2.0\n",
            "Train_MinReturn : 2.0\n",
            "Train_AverageEpLen : 2.0\n",
            "Train_EnvstepsSoFar : 5232\n",
            "TimeSinceStart : 15.941154718399048\n",
            "Training Loss : -0.06118655204772949\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 44 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([101])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 2.7094595432281494\n",
            "Eval_StdReturn : 0.4686579406261444\n",
            "Eval_MaxReturn : 4.0\n",
            "Eval_MinReturn : 2.0\n",
            "Eval_AverageEpLen : 2.7094594594594597\n",
            "Train_AverageReturn : 2.0199999809265137\n",
            "Train_StdReturn : 0.14000000059604645\n",
            "Train_MaxReturn : 3.0\n",
            "Train_MinReturn : 2.0\n",
            "Train_AverageEpLen : 2.02\n",
            "Train_EnvstepsSoFar : 5333\n",
            "TimeSinceStart : 16.356756687164307\n",
            "Training Loss : 0.05825304239988327\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 45 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([101])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 12.363636016845703\n",
            "Eval_StdReturn : 11.538651466369629\n",
            "Eval_MaxReturn : 38.0\n",
            "Eval_MinReturn : 3.0\n",
            "Eval_AverageEpLen : 12.363636363636363\n",
            "Train_AverageReturn : 2.5897436141967773\n",
            "Train_StdReturn : 0.4918801486492157\n",
            "Train_MaxReturn : 3.0\n",
            "Train_MinReturn : 2.0\n",
            "Train_AverageEpLen : 2.58974358974359\n",
            "Train_EnvstepsSoFar : 5434\n",
            "TimeSinceStart : 16.72076940536499\n",
            "Training Loss : 0.0392279252409935\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 46 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([126])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 27.200000762939453\n",
            "Eval_StdReturn : 10.734368324279785\n",
            "Eval_MaxReturn : 41.0\n",
            "Eval_MinReturn : 8.0\n",
            "Eval_AverageEpLen : 27.2\n",
            "Train_AverageReturn : 21.0\n",
            "Train_StdReturn : 10.832051277160645\n",
            "Train_MaxReturn : 38.0\n",
            "Train_MinReturn : 11.0\n",
            "Train_AverageEpLen : 21.0\n",
            "Train_EnvstepsSoFar : 5560\n",
            "TimeSinceStart : 17.074243307113647\n",
            "Training Loss : 0.09633030742406845\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 47 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([120])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 21.473684310913086\n",
            "Eval_StdReturn : 16.19411277770996\n",
            "Eval_MaxReturn : 45.0\n",
            "Eval_MinReturn : 4.0\n",
            "Eval_AverageEpLen : 21.473684210526315\n",
            "Train_AverageReturn : 30.0\n",
            "Train_StdReturn : 8.154753684997559\n",
            "Train_MaxReturn : 38.0\n",
            "Train_MinReturn : 18.0\n",
            "Train_AverageEpLen : 30.0\n",
            "Train_EnvstepsSoFar : 5680\n",
            "TimeSinceStart : 17.475266695022583\n",
            "Training Loss : -0.006474737543612719\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 48 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([130])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 37.54545593261719\n",
            "Eval_StdReturn : 15.732789039611816\n",
            "Eval_MaxReturn : 55.0\n",
            "Eval_MinReturn : 5.0\n",
            "Eval_AverageEpLen : 37.54545454545455\n",
            "Train_AverageReturn : 32.5\n",
            "Train_StdReturn : 15.628499984741211\n",
            "Train_MaxReturn : 46.0\n",
            "Train_MinReturn : 6.0\n",
            "Train_AverageEpLen : 32.5\n",
            "Train_EnvstepsSoFar : 5810\n",
            "TimeSinceStart : 17.871235132217407\n",
            "Training Loss : -0.04755564033985138\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 49 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([139])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 27.866666793823242\n",
            "Eval_StdReturn : 12.365903854370117\n",
            "Eval_MaxReturn : 44.0\n",
            "Eval_MinReturn : 6.0\n",
            "Eval_AverageEpLen : 27.866666666666667\n",
            "Train_AverageReturn : 46.33333206176758\n",
            "Train_StdReturn : 3.2998316287994385\n",
            "Train_MaxReturn : 50.0\n",
            "Train_MinReturn : 42.0\n",
            "Train_AverageEpLen : 46.333333333333336\n",
            "Train_EnvstepsSoFar : 5949\n",
            "TimeSinceStart : 18.281569719314575\n",
            "Training Loss : -0.1931818723678589\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 50 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([107])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 14.88888931274414\n",
            "Eval_StdReturn : 12.440475463867188\n",
            "Eval_MaxReturn : 49.0\n",
            "Eval_MinReturn : 4.0\n",
            "Eval_AverageEpLen : 14.88888888888889\n",
            "Train_AverageReturn : 21.399999618530273\n",
            "Train_StdReturn : 11.306634902954102\n",
            "Train_MaxReturn : 36.0\n",
            "Train_MinReturn : 10.0\n",
            "Train_AverageEpLen : 21.4\n",
            "Train_EnvstepsSoFar : 6056\n",
            "TimeSinceStart : 18.592042922973633\n",
            "Training Loss : 0.0013520115753635764\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 51 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([105])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 10.945945739746094\n",
            "Eval_StdReturn : 8.529585838317871\n",
            "Eval_MaxReturn : 44.0\n",
            "Eval_MinReturn : 4.0\n",
            "Eval_AverageEpLen : 10.945945945945946\n",
            "Train_AverageReturn : 15.0\n",
            "Train_StdReturn : 11.338933944702148\n",
            "Train_MaxReturn : 42.0\n",
            "Train_MinReturn : 6.0\n",
            "Train_AverageEpLen : 15.0\n",
            "Train_EnvstepsSoFar : 6161\n",
            "TimeSinceStart : 18.947670221328735\n",
            "Training Loss : -0.15378758311271667\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 52 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 11.941176414489746\n",
            "Eval_StdReturn : 8.804882049560547\n",
            "Eval_MaxReturn : 37.0\n",
            "Eval_MinReturn : 4.0\n",
            "Eval_AverageEpLen : 11.941176470588236\n",
            "Train_AverageReturn : 6.5625\n",
            "Train_StdReturn : 2.621277093887329\n",
            "Train_MaxReturn : 14.0\n",
            "Train_MinReturn : 4.0\n",
            "Train_AverageEpLen : 6.5625\n",
            "Train_EnvstepsSoFar : 6266\n",
            "TimeSinceStart : 19.26907753944397\n",
            "Training Loss : 0.11846727132797241\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 53 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([103])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 42.70000076293945\n",
            "Eval_StdReturn : 13.379462242126465\n",
            "Eval_MaxReturn : 57.0\n",
            "Eval_MinReturn : 8.0\n",
            "Eval_AverageEpLen : 42.7\n",
            "Train_AverageReturn : 9.363636016845703\n",
            "Train_StdReturn : 4.02882194519043\n",
            "Train_MaxReturn : 16.0\n",
            "Train_MinReturn : 5.0\n",
            "Train_AverageEpLen : 9.363636363636363\n",
            "Train_EnvstepsSoFar : 6369\n",
            "TimeSinceStart : 19.591936349868774\n",
            "Training Loss : -0.029864061623811722\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 54 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([140])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 67.0\n",
            "Eval_StdReturn : 7.505553245544434\n",
            "Eval_MaxReturn : 76.0\n",
            "Eval_MinReturn : 54.0\n",
            "Eval_AverageEpLen : 67.0\n",
            "Train_AverageReturn : 46.66666793823242\n",
            "Train_StdReturn : 2.054804801940918\n",
            "Train_MaxReturn : 49.0\n",
            "Train_MinReturn : 44.0\n",
            "Train_AverageEpLen : 46.666666666666664\n",
            "Train_EnvstepsSoFar : 6509\n",
            "TimeSinceStart : 19.98306155204773\n",
            "Training Loss : 0.01449836976826191\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 55 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([137])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 68.66666412353516\n",
            "Eval_StdReturn : 4.422166347503662\n",
            "Eval_MaxReturn : 78.0\n",
            "Eval_MinReturn : 66.0\n",
            "Eval_AverageEpLen : 68.66666666666667\n",
            "Train_AverageReturn : 68.5\n",
            "Train_StdReturn : 3.5\n",
            "Train_MaxReturn : 72.0\n",
            "Train_MinReturn : 65.0\n",
            "Train_AverageEpLen : 68.5\n",
            "Train_EnvstepsSoFar : 6646\n",
            "TimeSinceStart : 20.38991379737854\n",
            "Training Loss : -0.057496245950460434\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 56 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([135])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 99.4000015258789\n",
            "Eval_StdReturn : 18.006664276123047\n",
            "Eval_MaxReturn : 132.0\n",
            "Eval_MinReturn : 79.0\n",
            "Eval_AverageEpLen : 99.4\n",
            "Train_AverageReturn : 67.5\n",
            "Train_StdReturn : 12.5\n",
            "Train_MaxReturn : 80.0\n",
            "Train_MinReturn : 55.0\n",
            "Train_AverageEpLen : 67.5\n",
            "Train_EnvstepsSoFar : 6781\n",
            "TimeSinceStart : 20.82362723350525\n",
            "Training Loss : 0.03710108995437622\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 57 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([141])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 90.5999984741211\n",
            "Eval_StdReturn : 16.316864013671875\n",
            "Eval_MaxReturn : 122.0\n",
            "Eval_MinReturn : 78.0\n",
            "Eval_AverageEpLen : 90.6\n",
            "Train_AverageReturn : 70.5\n",
            "Train_StdReturn : 25.5\n",
            "Train_MaxReturn : 96.0\n",
            "Train_MinReturn : 45.0\n",
            "Train_AverageEpLen : 70.5\n",
            "Train_EnvstepsSoFar : 6922\n",
            "TimeSinceStart : 21.181304931640625\n",
            "Training Loss : 0.015047705732285976\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 58 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([107])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 64.0\n",
            "Eval_StdReturn : 6.480740547180176\n",
            "Eval_MaxReturn : 76.0\n",
            "Eval_MinReturn : 56.0\n",
            "Eval_AverageEpLen : 64.0\n",
            "Train_AverageReturn : 107.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 107.0\n",
            "Train_MinReturn : 107.0\n",
            "Train_AverageEpLen : 107.0\n",
            "Train_EnvstepsSoFar : 7029\n",
            "TimeSinceStart : 21.507283687591553\n",
            "Training Loss : -0.12027929723262787\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 59 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([117])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 5.840579509735107\n",
            "Eval_StdReturn : 1.9899981021881104\n",
            "Eval_MaxReturn : 13.0\n",
            "Eval_MinReturn : 4.0\n",
            "Eval_AverageEpLen : 5.840579710144928\n",
            "Train_AverageReturn : 51.66666793823242\n",
            "Train_StdReturn : 10.338708877563477\n",
            "Train_MaxReturn : 63.0\n",
            "Train_MinReturn : 38.0\n",
            "Train_AverageEpLen : 51.666666666666664\n",
            "Train_EnvstepsSoFar : 7184\n",
            "TimeSinceStart : 21.906201362609863\n",
            "Training Loss : -0.05203244835138321\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 60 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([102])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 10.605262756347656\n",
            "Eval_StdReturn : 4.568423748016357\n",
            "Eval_MaxReturn : 22.0\n",
            "Eval_MinReturn : 5.0\n",
            "Eval_AverageEpLen : 10.605263157894736\n",
            "Train_AverageReturn : 6.0\n",
            "Train_StdReturn : 2.400980234146118\n",
            "Train_MaxReturn : 13.0\n",
            "Train_MinReturn : 4.0\n",
            "Train_AverageEpLen : 6.0\n",
            "Train_EnvstepsSoFar : 7286\n",
            "TimeSinceStart : 22.312580108642578\n",
            "Training Loss : -0.013408600352704525\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 61 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([104])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 45.77777862548828\n",
            "Eval_StdReturn : 30.176435470581055\n",
            "Eval_MaxReturn : 91.0\n",
            "Eval_MinReturn : 8.0\n",
            "Eval_AverageEpLen : 45.77777777777778\n",
            "Train_AverageReturn : 11.55555534362793\n",
            "Train_StdReturn : 3.685138702392578\n",
            "Train_MaxReturn : 18.0\n",
            "Train_MinReturn : 6.0\n",
            "Train_AverageEpLen : 11.555555555555555\n",
            "Train_EnvstepsSoFar : 7390\n",
            "TimeSinceStart : 22.682639360427856\n",
            "Training Loss : -0.14808185398578644\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 62 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 68.5\n",
            "Eval_StdReturn : 2.0615527629852295\n",
            "Eval_MaxReturn : 72.0\n",
            "Eval_MinReturn : 66.0\n",
            "Eval_AverageEpLen : 68.5\n",
            "Train_AverageReturn : 100.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 100.0\n",
            "Train_MinReturn : 100.0\n",
            "Train_AverageEpLen : 100.0\n",
            "Train_EnvstepsSoFar : 7490\n",
            "TimeSinceStart : 23.008942127227783\n",
            "Training Loss : 0.040604542940855026\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 63 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([129])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 55.25\n",
            "Eval_StdReturn : 2.817356824874878\n",
            "Eval_MaxReturn : 58.0\n",
            "Eval_MinReturn : 50.0\n",
            "Eval_AverageEpLen : 55.25\n",
            "Train_AverageReturn : 64.5\n",
            "Train_StdReturn : 6.5\n",
            "Train_MaxReturn : 71.0\n",
            "Train_MinReturn : 58.0\n",
            "Train_AverageEpLen : 64.5\n",
            "Train_EnvstepsSoFar : 7619\n",
            "TimeSinceStart : 23.357537269592285\n",
            "Training Loss : 0.01877599209547043\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 64 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([110])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 44.55555725097656\n",
            "Eval_StdReturn : 6.41372013092041\n",
            "Eval_MaxReturn : 50.0\n",
            "Eval_MinReturn : 33.0\n",
            "Eval_AverageEpLen : 44.55555555555556\n",
            "Train_AverageReturn : 55.0\n",
            "Train_StdReturn : 2.0\n",
            "Train_MaxReturn : 57.0\n",
            "Train_MinReturn : 53.0\n",
            "Train_AverageEpLen : 55.0\n",
            "Train_EnvstepsSoFar : 7729\n",
            "TimeSinceStart : 23.686190128326416\n",
            "Training Loss : 0.029829133301973343\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 65 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 42.29999923706055\n",
            "Eval_StdReturn : 5.040833473205566\n",
            "Eval_MaxReturn : 47.0\n",
            "Eval_MinReturn : 33.0\n",
            "Eval_AverageEpLen : 42.3\n",
            "Train_AverageReturn : 50.0\n",
            "Train_StdReturn : 3.0\n",
            "Train_MaxReturn : 53.0\n",
            "Train_MinReturn : 47.0\n",
            "Train_AverageEpLen : 50.0\n",
            "Train_EnvstepsSoFar : 7829\n",
            "TimeSinceStart : 24.05397319793701\n",
            "Training Loss : 0.03822822868824005\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 66 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([119])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 47.44444274902344\n",
            "Eval_StdReturn : 8.111872673034668\n",
            "Eval_MaxReturn : 57.0\n",
            "Eval_MinReturn : 31.0\n",
            "Eval_AverageEpLen : 47.44444444444444\n",
            "Train_AverageReturn : 39.66666793823242\n",
            "Train_StdReturn : 7.586537837982178\n",
            "Train_MaxReturn : 50.0\n",
            "Train_MinReturn : 32.0\n",
            "Train_AverageEpLen : 39.666666666666664\n",
            "Train_EnvstepsSoFar : 7948\n",
            "TimeSinceStart : 24.478424072265625\n",
            "Training Loss : 0.05967605859041214\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 67 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([102])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 51.375\n",
            "Eval_StdReturn : 5.633327007293701\n",
            "Eval_MaxReturn : 62.0\n",
            "Eval_MinReturn : 44.0\n",
            "Eval_AverageEpLen : 51.375\n",
            "Train_AverageReturn : 51.0\n",
            "Train_StdReturn : 1.0\n",
            "Train_MaxReturn : 52.0\n",
            "Train_MinReturn : 50.0\n",
            "Train_AverageEpLen : 51.0\n",
            "Train_EnvstepsSoFar : 8050\n",
            "TimeSinceStart : 24.8291974067688\n",
            "Training Loss : -0.05032375827431679\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 68 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([116])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 60.57143020629883\n",
            "Eval_StdReturn : 7.247800350189209\n",
            "Eval_MaxReturn : 74.0\n",
            "Eval_MinReturn : 54.0\n",
            "Eval_AverageEpLen : 60.57142857142857\n",
            "Train_AverageReturn : 58.0\n",
            "Train_StdReturn : 1.0\n",
            "Train_MaxReturn : 59.0\n",
            "Train_MinReturn : 57.0\n",
            "Train_AverageEpLen : 58.0\n",
            "Train_EnvstepsSoFar : 8166\n",
            "TimeSinceStart : 25.154459714889526\n",
            "Training Loss : 0.006169592496007681\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 69 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([119])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 55.875\n",
            "Eval_StdReturn : 4.754931449890137\n",
            "Eval_MaxReturn : 63.0\n",
            "Eval_MinReturn : 49.0\n",
            "Eval_AverageEpLen : 55.875\n",
            "Train_AverageReturn : 59.5\n",
            "Train_StdReturn : 0.5\n",
            "Train_MaxReturn : 60.0\n",
            "Train_MinReturn : 59.0\n",
            "Train_AverageEpLen : 59.5\n",
            "Train_EnvstepsSoFar : 8285\n",
            "TimeSinceStart : 25.499729871749878\n",
            "Training Loss : 0.029886098578572273\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 70 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([105])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 50.5\n",
            "Eval_StdReturn : 2.1794495582580566\n",
            "Eval_MaxReturn : 54.0\n",
            "Eval_MinReturn : 47.0\n",
            "Eval_AverageEpLen : 50.5\n",
            "Train_AverageReturn : 52.5\n",
            "Train_StdReturn : 3.5\n",
            "Train_MaxReturn : 56.0\n",
            "Train_MinReturn : 49.0\n",
            "Train_AverageEpLen : 52.5\n",
            "Train_EnvstepsSoFar : 8390\n",
            "TimeSinceStart : 25.854023218154907\n",
            "Training Loss : -0.019259013235569\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 71 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([111])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 75.0\n",
            "Eval_StdReturn : 7.187952995300293\n",
            "Eval_MaxReturn : 82.0\n",
            "Eval_MinReturn : 61.0\n",
            "Eval_AverageEpLen : 75.0\n",
            "Train_AverageReturn : 55.5\n",
            "Train_StdReturn : 3.5\n",
            "Train_MaxReturn : 59.0\n",
            "Train_MinReturn : 52.0\n",
            "Train_AverageEpLen : 55.5\n",
            "Train_EnvstepsSoFar : 8501\n",
            "TimeSinceStart : 26.205705404281616\n",
            "Training Loss : -0.09910668432712555\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 72 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([145])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 92.4000015258789\n",
            "Eval_StdReturn : 47.5083122253418\n",
            "Eval_MaxReturn : 166.0\n",
            "Eval_MinReturn : 26.0\n",
            "Eval_AverageEpLen : 92.4\n",
            "Train_AverageReturn : 72.5\n",
            "Train_StdReturn : 0.5\n",
            "Train_MaxReturn : 73.0\n",
            "Train_MinReturn : 72.0\n",
            "Train_AverageEpLen : 72.5\n",
            "Train_EnvstepsSoFar : 8646\n",
            "TimeSinceStart : 26.579802989959717\n",
            "Training Loss : 0.0582345649600029\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 73 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([162])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 73.5\n",
            "Eval_StdReturn : 11.557825088500977\n",
            "Eval_MaxReturn : 91.0\n",
            "Eval_MinReturn : 54.0\n",
            "Eval_AverageEpLen : 73.5\n",
            "Train_AverageReturn : 81.0\n",
            "Train_StdReturn : 2.0\n",
            "Train_MaxReturn : 83.0\n",
            "Train_MinReturn : 79.0\n",
            "Train_AverageEpLen : 81.0\n",
            "Train_EnvstepsSoFar : 8808\n",
            "TimeSinceStart : 26.999953508377075\n",
            "Training Loss : 0.03675198182463646\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 74 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([170])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 60.0\n",
            "Eval_StdReturn : 36.488746643066406\n",
            "Eval_MaxReturn : 93.0\n",
            "Eval_MinReturn : 3.0\n",
            "Eval_AverageEpLen : 60.0\n",
            "Train_AverageReturn : 85.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 85.0\n",
            "Train_MinReturn : 85.0\n",
            "Train_AverageEpLen : 85.0\n",
            "Train_EnvstepsSoFar : 8978\n",
            "TimeSinceStart : 27.411426782608032\n",
            "Training Loss : 0.018966281786561012\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 75 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([145])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 36.58333206176758\n",
            "Eval_StdReturn : 32.05583190917969\n",
            "Eval_MaxReturn : 76.0\n",
            "Eval_MinReturn : 3.0\n",
            "Eval_AverageEpLen : 36.583333333333336\n",
            "Train_AverageReturn : 72.5\n",
            "Train_StdReturn : 1.5\n",
            "Train_MaxReturn : 74.0\n",
            "Train_MinReturn : 71.0\n",
            "Train_AverageEpLen : 72.5\n",
            "Train_EnvstepsSoFar : 9123\n",
            "TimeSinceStart : 27.81605052947998\n",
            "Training Loss : 0.09747175872325897\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 76 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([137])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 68.85713958740234\n",
            "Eval_StdReturn : 58.57700729370117\n",
            "Eval_MaxReturn : 162.0\n",
            "Eval_MinReturn : 4.0\n",
            "Eval_AverageEpLen : 68.85714285714286\n",
            "Train_AverageReturn : 14.699999809265137\n",
            "Train_StdReturn : 22.004772186279297\n",
            "Train_MaxReturn : 68.0\n",
            "Train_MinReturn : 3.0\n",
            "Train_AverageEpLen : 14.7\n",
            "Train_EnvstepsSoFar : 9270\n",
            "TimeSinceStart : 28.24235701560974\n",
            "Training Loss : -0.010009897872805595\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 77 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([111])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 75.0\n",
            "Eval_StdReturn : 37.59432601928711\n",
            "Eval_MaxReturn : 131.0\n",
            "Eval_MinReturn : 32.0\n",
            "Eval_AverageEpLen : 75.0\n",
            "Train_AverageReturn : 111.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 111.0\n",
            "Train_MinReturn : 111.0\n",
            "Train_AverageEpLen : 111.0\n",
            "Train_EnvstepsSoFar : 9381\n",
            "TimeSinceStart : 28.570115566253662\n",
            "Training Loss : -0.023789290338754654\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 78 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([136])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 107.0\n",
            "Eval_StdReturn : 41.29890823364258\n",
            "Eval_MaxReturn : 158.0\n",
            "Eval_MinReturn : 50.0\n",
            "Eval_AverageEpLen : 107.0\n",
            "Train_AverageReturn : 136.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 136.0\n",
            "Train_MinReturn : 136.0\n",
            "Train_AverageEpLen : 136.0\n",
            "Train_EnvstepsSoFar : 9517\n",
            "TimeSinceStart : 28.961124897003174\n",
            "Training Loss : -0.051879558712244034\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 79 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([171])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 135.5\n",
            "Eval_StdReturn : 60.027076721191406\n",
            "Eval_MaxReturn : 186.0\n",
            "Eval_MinReturn : 33.0\n",
            "Eval_AverageEpLen : 135.5\n",
            "Train_AverageReturn : 171.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 171.0\n",
            "Train_MinReturn : 171.0\n",
            "Train_AverageEpLen : 171.0\n",
            "Train_EnvstepsSoFar : 9688\n",
            "TimeSinceStart : 29.384331464767456\n",
            "Training Loss : 0.06370019167661667\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 80 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([113])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 105.5\n",
            "Eval_StdReturn : 3.640054941177368\n",
            "Eval_MaxReturn : 111.0\n",
            "Eval_MinReturn : 101.0\n",
            "Eval_AverageEpLen : 105.5\n",
            "Train_AverageReturn : 37.66666793823242\n",
            "Train_StdReturn : 25.31578254699707\n",
            "Train_MaxReturn : 73.0\n",
            "Train_MinReturn : 15.0\n",
            "Train_AverageEpLen : 37.666666666666664\n",
            "Train_EnvstepsSoFar : 9801\n",
            "TimeSinceStart : 29.738057851791382\n",
            "Training Loss : -0.05338108912110329\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 81 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([106])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 41.818180084228516\n",
            "Eval_StdReturn : 30.16565704345703\n",
            "Eval_MaxReturn : 70.0\n",
            "Eval_MinReturn : 2.0\n",
            "Eval_AverageEpLen : 41.81818181818182\n",
            "Train_AverageReturn : 106.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 106.0\n",
            "Train_MinReturn : 106.0\n",
            "Train_AverageEpLen : 106.0\n",
            "Train_EnvstepsSoFar : 9907\n",
            "TimeSinceStart : 30.151248931884766\n",
            "Training Loss : -0.02306307666003704\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 82 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([130])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 8.416666984558105\n",
            "Eval_StdReturn : 15.255918502807617\n",
            "Eval_MaxReturn : 48.0\n",
            "Eval_MinReturn : 2.0\n",
            "Eval_AverageEpLen : 8.416666666666666\n",
            "Train_AverageReturn : 33.5\n",
            "Train_StdReturn : 31.53173065185547\n",
            "Train_MaxReturn : 67.0\n",
            "Train_MinReturn : 2.0\n",
            "Train_AverageEpLen : 33.5\n",
            "Train_EnvstepsSoFar : 10041\n",
            "TimeSinceStart : 30.484379053115845\n",
            "Training Loss : 0.08876112848520279\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 83 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([108])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 52.875\n",
            "Eval_StdReturn : 3.9191038608551025\n",
            "Eval_MaxReturn : 59.0\n",
            "Eval_MinReturn : 47.0\n",
            "Eval_AverageEpLen : 52.875\n",
            "Train_AverageReturn : 9.076923370361328\n",
            "Train_StdReturn : 16.76287841796875\n",
            "Train_MaxReturn : 54.0\n",
            "Train_MinReturn : 2.0\n",
            "Train_AverageEpLen : 9.076923076923077\n",
            "Train_EnvstepsSoFar : 10159\n",
            "TimeSinceStart : 30.804704904556274\n",
            "Training Loss : -0.13064223527908325\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 84 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([102])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 53.625\n",
            "Eval_StdReturn : 1.8666480779647827\n",
            "Eval_MaxReturn : 57.0\n",
            "Eval_MinReturn : 51.0\n",
            "Eval_AverageEpLen : 53.625\n",
            "Train_AverageReturn : 49.66666793823242\n",
            "Train_StdReturn : 1.885617971420288\n",
            "Train_MaxReturn : 51.0\n",
            "Train_MinReturn : 47.0\n",
            "Train_AverageEpLen : 49.666666666666664\n",
            "Train_EnvstepsSoFar : 10308\n",
            "TimeSinceStart : 31.155044078826904\n",
            "Training Loss : -0.0494028739631176\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 85 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([123])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 266.25\n",
            "Eval_StdReturn : 312.9851379394531\n",
            "Eval_MaxReturn : 808.0\n",
            "Eval_MinReturn : 69.0\n",
            "Eval_AverageEpLen : 266.25\n",
            "Train_AverageReturn : 61.5\n",
            "Train_StdReturn : 4.5\n",
            "Train_MaxReturn : 66.0\n",
            "Train_MinReturn : 57.0\n",
            "Train_AverageEpLen : 61.5\n",
            "Train_EnvstepsSoFar : 10431\n",
            "TimeSinceStart : 31.865582942962646\n",
            "Training Loss : 0.006305361166596413\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 86 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 549.5\n",
            "Eval_StdReturn : 450.5\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 99.0\n",
            "Eval_AverageEpLen : 549.5\n",
            "Train_AverageReturn : 549.0\n",
            "Train_StdReturn : 451.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 98.0\n",
            "Train_AverageEpLen : 549.0\n",
            "Train_EnvstepsSoFar : 11529\n",
            "TimeSinceStart : 33.208765506744385\n",
            "Training Loss : -0.0075930445455014706\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 87 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 12529\n",
            "TimeSinceStart : 34.46000814437866\n",
            "Training Loss : -0.013895412907004356\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 88 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 420.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 420.0\n",
            "Eval_MinReturn : 420.0\n",
            "Eval_AverageEpLen : 420.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 13529\n",
            "TimeSinceStart : 35.29154181480408\n",
            "Training Loss : 0.004860969725996256\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 89 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([701])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 481.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 481.0\n",
            "Eval_MinReturn : 481.0\n",
            "Eval_AverageEpLen : 481.0\n",
            "Train_AverageReturn : 701.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 701.0\n",
            "Train_MinReturn : 701.0\n",
            "Train_AverageEpLen : 701.0\n",
            "Train_EnvstepsSoFar : 14230\n",
            "TimeSinceStart : 36.07673358917236\n",
            "Training Loss : -0.05038381367921829\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 90 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([830])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 222.0\n",
            "Eval_StdReturn : 9.0\n",
            "Eval_MaxReturn : 231.0\n",
            "Eval_MinReturn : 213.0\n",
            "Eval_AverageEpLen : 222.0\n",
            "Train_AverageReturn : 830.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 830.0\n",
            "Train_MinReturn : 830.0\n",
            "Train_AverageEpLen : 830.0\n",
            "Train_EnvstepsSoFar : 15060\n",
            "TimeSinceStart : 36.9055073261261\n",
            "Training Loss : 0.04442765936255455\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 91 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([304])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 172.0\n",
            "Eval_StdReturn : 50.405025482177734\n",
            "Eval_MaxReturn : 243.0\n",
            "Eval_MinReturn : 131.0\n",
            "Eval_AverageEpLen : 172.0\n",
            "Train_AverageReturn : 304.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 304.0\n",
            "Train_MinReturn : 304.0\n",
            "Train_AverageEpLen : 304.0\n",
            "Train_EnvstepsSoFar : 15364\n",
            "TimeSinceStart : 37.466431617736816\n",
            "Training Loss : 0.03833000734448433\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 92 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([174])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 653.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 653.0\n",
            "Eval_MinReturn : 653.0\n",
            "Eval_AverageEpLen : 653.0\n",
            "Train_AverageReturn : 174.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 174.0\n",
            "Train_MinReturn : 174.0\n",
            "Train_AverageEpLen : 174.0\n",
            "Train_EnvstepsSoFar : 15538\n",
            "TimeSinceStart : 38.0172393321991\n",
            "Training Loss : -0.09461922198534012\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 93 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([547])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 472.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 472.0\n",
            "Eval_MinReturn : 472.0\n",
            "Eval_AverageEpLen : 472.0\n",
            "Train_AverageReturn : 547.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 547.0\n",
            "Train_MinReturn : 547.0\n",
            "Train_AverageEpLen : 547.0\n",
            "Train_EnvstepsSoFar : 16085\n",
            "TimeSinceStart : 38.66190552711487\n",
            "Training Loss : 0.004462496843189001\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 94 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([617])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 379.5\n",
            "Eval_StdReturn : 108.5\n",
            "Eval_MaxReturn : 488.0\n",
            "Eval_MinReturn : 271.0\n",
            "Eval_AverageEpLen : 379.5\n",
            "Train_AverageReturn : 617.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 617.0\n",
            "Train_MinReturn : 617.0\n",
            "Train_AverageEpLen : 617.0\n",
            "Train_EnvstepsSoFar : 16702\n",
            "TimeSinceStart : 39.58483290672302\n",
            "Training Loss : 0.00334872561506927\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 95 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([403])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 257.5\n",
            "Eval_StdReturn : 9.5\n",
            "Eval_MaxReturn : 267.0\n",
            "Eval_MinReturn : 248.0\n",
            "Eval_AverageEpLen : 257.5\n",
            "Train_AverageReturn : 403.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 403.0\n",
            "Train_MinReturn : 403.0\n",
            "Train_AverageEpLen : 403.0\n",
            "Train_EnvstepsSoFar : 17105\n",
            "TimeSinceStart : 40.12674403190613\n",
            "Training Loss : -0.02697041817009449\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 96 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([261])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 346.0\n",
            "Eval_StdReturn : 27.0\n",
            "Eval_MaxReturn : 373.0\n",
            "Eval_MinReturn : 319.0\n",
            "Eval_AverageEpLen : 346.0\n",
            "Train_AverageReturn : 261.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 261.0\n",
            "Train_MinReturn : 261.0\n",
            "Train_AverageEpLen : 261.0\n",
            "Train_EnvstepsSoFar : 17366\n",
            "TimeSinceStart : 40.697344064712524\n",
            "Training Loss : 0.0174399521201849\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 97 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([309])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 443.0\n",
            "Eval_StdReturn : 84.0\n",
            "Eval_MaxReturn : 527.0\n",
            "Eval_MinReturn : 359.0\n",
            "Eval_AverageEpLen : 443.0\n",
            "Train_AverageReturn : 309.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 309.0\n",
            "Train_MinReturn : 309.0\n",
            "Train_AverageEpLen : 309.0\n",
            "Train_EnvstepsSoFar : 17675\n",
            "TimeSinceStart : 41.53006458282471\n",
            "Training Loss : 0.017182033509016037\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 98 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([356])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 485.0\n",
            "Eval_StdReturn : 478.0\n",
            "Eval_MaxReturn : 963.0\n",
            "Eval_MinReturn : 7.0\n",
            "Eval_AverageEpLen : 485.0\n",
            "Train_AverageReturn : 356.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 356.0\n",
            "Train_MinReturn : 356.0\n",
            "Train_AverageEpLen : 356.0\n",
            "Train_EnvstepsSoFar : 18031\n",
            "TimeSinceStart : 42.431365728378296\n",
            "Training Loss : -0.017157310619950294\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 99 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([387])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 132.25\n",
            "Eval_StdReturn : 125.66100311279297\n",
            "Eval_MaxReturn : 300.0\n",
            "Eval_MinReturn : 7.0\n",
            "Eval_AverageEpLen : 132.25\n",
            "Train_AverageReturn : 387.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 387.0\n",
            "Train_MinReturn : 387.0\n",
            "Train_AverageEpLen : 387.0\n",
            "Train_EnvstepsSoFar : 18418\n",
            "TimeSinceStart : 42.9990394115448\n",
            "Training Loss : -0.036828286945819855\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python cs285/scripts/run_hw2.py --env_name InvertedPendulum-v2 \\\n",
        "--ep_len 1000 --discount 0.9 -n 100 -l 2 -s 64 -b 100 -lr 0.05 -rtg \\\n",
        "--exp_name q2_b100_r05"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmD9V_WyyGbv",
        "outputId": "600ca585-8b68-4577-c307-65961b3f0bb8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "########################\n",
            "logging outputs to  /content/gdrive/My Drive/cs285_f2021/DRL_policy_grads/cs285/scripts/../../data/q2_b120_r05_InvertedPendulum-v2_06-02-2022_17-29-59\n",
            "########################\n",
            "Using GPU id 0\n",
            "Sequential(\n",
            "  (0): Linear(in_features=4, out_features=64, bias=True)\n",
            "  (1): Tanh()\n",
            "  (2): Linear(in_features=64, out_features=64, bias=True)\n",
            "  (3): Tanh()\n",
            "  (4): Linear(in_features=64, out_features=1, bias=True)\n",
            "  (5): Identity()\n",
            ")\n",
            "\n",
            "\n",
            "********** Iteration 0 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([121])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 16.479999542236328\n",
            "Eval_StdReturn : 7.990594387054443\n",
            "Eval_MaxReturn : 40.0\n",
            "Eval_MinReturn : 7.0\n",
            "Eval_AverageEpLen : 16.48\n",
            "Train_AverageReturn : 7.875\n",
            "Train_StdReturn : 3.2379584312438965\n",
            "Train_MaxReturn : 14.0\n",
            "Train_MinReturn : 4.0\n",
            "Train_AverageEpLen : 7.875\n",
            "Train_EnvstepsSoFar : 126\n",
            "TimeSinceStart : 0.3438127040863037\n",
            "Training Loss : -0.05899066478013992\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 1 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([131])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 8.36734676361084\n",
            "Eval_StdReturn : 4.355123043060303\n",
            "Eval_MaxReturn : 22.0\n",
            "Eval_MinReturn : 3.0\n",
            "Eval_AverageEpLen : 8.36734693877551\n",
            "Train_AverageReturn : 18.714284896850586\n",
            "Train_StdReturn : 6.942915916442871\n",
            "Train_MaxReturn : 34.0\n",
            "Train_MinReturn : 13.0\n",
            "Train_AverageEpLen : 18.714285714285715\n",
            "Train_EnvstepsSoFar : 257\n",
            "TimeSinceStart : 0.6954030990600586\n",
            "Training Loss : 0.0015909653156995773\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 2 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([123])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 6.215384483337402\n",
            "Eval_StdReturn : 2.703230619430542\n",
            "Eval_MaxReturn : 14.0\n",
            "Eval_MinReturn : 3.0\n",
            "Eval_AverageEpLen : 6.2153846153846155\n",
            "Train_AverageReturn : 9.84615421295166\n",
            "Train_StdReturn : 9.662346839904785\n",
            "Train_MaxReturn : 42.0\n",
            "Train_MinReturn : 4.0\n",
            "Train_AverageEpLen : 9.846153846153847\n",
            "Train_EnvstepsSoFar : 385\n",
            "TimeSinceStart : 1.027707815170288\n",
            "Training Loss : 0.014298919588327408\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 3 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([127])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 12.151515007019043\n",
            "Eval_StdReturn : 5.18810510635376\n",
            "Eval_MaxReturn : 28.0\n",
            "Eval_MinReturn : 5.0\n",
            "Eval_AverageEpLen : 12.151515151515152\n",
            "Train_AverageReturn : 5.291666507720947\n",
            "Train_StdReturn : 2.244978904724121\n",
            "Train_MaxReturn : 10.0\n",
            "Train_MinReturn : 3.0\n",
            "Train_AverageEpLen : 5.291666666666667\n",
            "Train_EnvstepsSoFar : 512\n",
            "TimeSinceStart : 1.3669955730438232\n",
            "Training Loss : -0.10266105085611343\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 4 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([133])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 30.928571701049805\n",
            "Eval_StdReturn : 14.70405387878418\n",
            "Eval_MaxReturn : 57.0\n",
            "Eval_MinReturn : 12.0\n",
            "Eval_AverageEpLen : 30.928571428571427\n",
            "Train_AverageReturn : 19.0\n",
            "Train_StdReturn : 16.587430953979492\n",
            "Train_MaxReturn : 53.0\n",
            "Train_MinReturn : 4.0\n",
            "Train_AverageEpLen : 19.0\n",
            "Train_EnvstepsSoFar : 645\n",
            "TimeSinceStart : 1.7664706707000732\n",
            "Training Loss : -0.11665321886539459\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 5 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([120])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 13.09375\n",
            "Eval_StdReturn : 7.658163070678711\n",
            "Eval_MaxReturn : 39.0\n",
            "Eval_MinReturn : 5.0\n",
            "Eval_AverageEpLen : 13.09375\n",
            "Train_AverageReturn : 20.0\n",
            "Train_StdReturn : 7.852812767028809\n",
            "Train_MaxReturn : 29.0\n",
            "Train_MinReturn : 10.0\n",
            "Train_AverageEpLen : 20.0\n",
            "Train_EnvstepsSoFar : 765\n",
            "TimeSinceStart : 2.1827456951141357\n",
            "Training Loss : -0.12010366469621658\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 6 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([120])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 11.911765098571777\n",
            "Eval_StdReturn : 7.134702682495117\n",
            "Eval_MaxReturn : 28.0\n",
            "Eval_MinReturn : 4.0\n",
            "Eval_AverageEpLen : 11.911764705882353\n",
            "Train_AverageReturn : 15.625\n",
            "Train_StdReturn : 12.766533851623535\n",
            "Train_MaxReturn : 46.0\n",
            "Train_MinReturn : 5.0\n",
            "Train_AverageEpLen : 15.625\n",
            "Train_EnvstepsSoFar : 890\n",
            "TimeSinceStart : 2.5396502017974854\n",
            "Training Loss : -0.10409876704216003\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 7 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([121])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 9.571428298950195\n",
            "Eval_StdReturn : 4.232205390930176\n",
            "Eval_MaxReturn : 24.0\n",
            "Eval_MinReturn : 4.0\n",
            "Eval_AverageEpLen : 9.571428571428571\n",
            "Train_AverageReturn : 11.15384578704834\n",
            "Train_StdReturn : 7.6846113204956055\n",
            "Train_MaxReturn : 37.0\n",
            "Train_MinReturn : 5.0\n",
            "Train_AverageEpLen : 11.153846153846153\n",
            "Train_EnvstepsSoFar : 1035\n",
            "TimeSinceStart : 2.8719770908355713\n",
            "Training Loss : 0.01566799357533455\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 8 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([134])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 8.88888931274414\n",
            "Eval_StdReturn : 3.928370952606201\n",
            "Eval_MaxReturn : 19.0\n",
            "Eval_MinReturn : 4.0\n",
            "Eval_AverageEpLen : 8.88888888888889\n",
            "Train_AverageReturn : 12.181818008422852\n",
            "Train_StdReturn : 6.534080982208252\n",
            "Train_MaxReturn : 25.0\n",
            "Train_MinReturn : 5.0\n",
            "Train_AverageEpLen : 12.181818181818182\n",
            "Train_EnvstepsSoFar : 1169\n",
            "TimeSinceStart : 3.2017743587493896\n",
            "Training Loss : 0.04533606767654419\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 9 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([122])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 8.039999961853027\n",
            "Eval_StdReturn : 4.454031944274902\n",
            "Eval_MaxReturn : 24.0\n",
            "Eval_MinReturn : 3.0\n",
            "Eval_AverageEpLen : 8.04\n",
            "Train_AverageReturn : 8.133333206176758\n",
            "Train_StdReturn : 3.9810662269592285\n",
            "Train_MaxReturn : 18.0\n",
            "Train_MinReturn : 4.0\n",
            "Train_AverageEpLen : 8.133333333333333\n",
            "Train_EnvstepsSoFar : 1291\n",
            "TimeSinceStart : 3.533874273300171\n",
            "Training Loss : -0.0019312059739604592\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 10 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([128])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 11.45714282989502\n",
            "Eval_StdReturn : 6.011146068572998\n",
            "Eval_MaxReturn : 31.0\n",
            "Eval_MinReturn : 4.0\n",
            "Eval_AverageEpLen : 11.457142857142857\n",
            "Train_AverageReturn : 8.533333778381348\n",
            "Train_StdReturn : 5.264556407928467\n",
            "Train_MaxReturn : 21.0\n",
            "Train_MinReturn : 3.0\n",
            "Train_AverageEpLen : 8.533333333333333\n",
            "Train_EnvstepsSoFar : 1419\n",
            "TimeSinceStart : 3.856947660446167\n",
            "Training Loss : -0.05345289409160614\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 11 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([123])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 10.350000381469727\n",
            "Eval_StdReturn : 5.8075385093688965\n",
            "Eval_MaxReturn : 26.0\n",
            "Eval_MinReturn : 4.0\n",
            "Eval_AverageEpLen : 10.35\n",
            "Train_AverageReturn : 10.25\n",
            "Train_StdReturn : 4.621057033538818\n",
            "Train_MaxReturn : 18.0\n",
            "Train_MinReturn : 5.0\n",
            "Train_AverageEpLen : 10.25\n",
            "Train_EnvstepsSoFar : 1542\n",
            "TimeSinceStart : 4.196440696716309\n",
            "Training Loss : -0.05423156917095184\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 12 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([121])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 12.903225898742676\n",
            "Eval_StdReturn : 7.887740135192871\n",
            "Eval_MaxReturn : 45.0\n",
            "Eval_MinReturn : 4.0\n",
            "Eval_AverageEpLen : 12.903225806451612\n",
            "Train_AverageReturn : 11.0\n",
            "Train_StdReturn : 6.605782508850098\n",
            "Train_MaxReturn : 27.0\n",
            "Train_MinReturn : 4.0\n",
            "Train_AverageEpLen : 11.0\n",
            "Train_EnvstepsSoFar : 1663\n",
            "TimeSinceStart : 4.550398588180542\n",
            "Training Loss : 0.0321272537112236\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 13 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([129])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 9.92682933807373\n",
            "Eval_StdReturn : 4.865960597991943\n",
            "Eval_MaxReturn : 23.0\n",
            "Eval_MinReturn : 4.0\n",
            "Eval_AverageEpLen : 9.926829268292684\n",
            "Train_AverageReturn : 14.333333015441895\n",
            "Train_StdReturn : 8.956686019897461\n",
            "Train_MaxReturn : 30.0\n",
            "Train_MinReturn : 3.0\n",
            "Train_AverageEpLen : 14.333333333333334\n",
            "Train_EnvstepsSoFar : 1792\n",
            "TimeSinceStart : 4.882979869842529\n",
            "Training Loss : -0.07277339696884155\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 14 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([130])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 7.730769157409668\n",
            "Eval_StdReturn : 2.935953378677368\n",
            "Eval_MaxReturn : 18.0\n",
            "Eval_MinReturn : 4.0\n",
            "Eval_AverageEpLen : 7.730769230769231\n",
            "Train_AverageReturn : 17.875\n",
            "Train_StdReturn : 13.778946876525879\n",
            "Train_MaxReturn : 43.0\n",
            "Train_MinReturn : 5.0\n",
            "Train_AverageEpLen : 17.875\n",
            "Train_EnvstepsSoFar : 1935\n",
            "TimeSinceStart : 5.21281361579895\n",
            "Training Loss : -0.012046821415424347\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 15 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([121])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 3.93137264251709\n",
            "Eval_StdReturn : 0.717564046382904\n",
            "Eval_MaxReturn : 6.0\n",
            "Eval_MinReturn : 3.0\n",
            "Eval_AverageEpLen : 3.9313725490196076\n",
            "Train_AverageReturn : 10.133333206176758\n",
            "Train_StdReturn : 8.040453910827637\n",
            "Train_MaxReturn : 38.0\n",
            "Train_MinReturn : 4.0\n",
            "Train_AverageEpLen : 10.133333333333333\n",
            "Train_EnvstepsSoFar : 2087\n",
            "TimeSinceStart : 5.571484088897705\n",
            "Training Loss : 0.08460099995136261\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 16 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([120])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 5.050000190734863\n",
            "Eval_StdReturn : 1.1926860809326172\n",
            "Eval_MaxReturn : 9.0\n",
            "Eval_MinReturn : 3.0\n",
            "Eval_AverageEpLen : 5.05\n",
            "Train_AverageReturn : 4.137930870056152\n",
            "Train_StdReturn : 0.8599976301193237\n",
            "Train_MaxReturn : 7.0\n",
            "Train_MinReturn : 3.0\n",
            "Train_AverageEpLen : 4.137931034482759\n",
            "Train_EnvstepsSoFar : 2207\n",
            "TimeSinceStart : 5.900780200958252\n",
            "Training Loss : 0.025413203984498978\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 17 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([122])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 37.16666793823242\n",
            "Eval_StdReturn : 23.469247817993164\n",
            "Eval_MaxReturn : 84.0\n",
            "Eval_MinReturn : 6.0\n",
            "Eval_AverageEpLen : 37.166666666666664\n",
            "Train_AverageReturn : 5.083333492279053\n",
            "Train_StdReturn : 1.2555432319641113\n",
            "Train_MaxReturn : 7.0\n",
            "Train_MinReturn : 3.0\n",
            "Train_AverageEpLen : 5.083333333333333\n",
            "Train_EnvstepsSoFar : 2329\n",
            "TimeSinceStart : 6.240887641906738\n",
            "Training Loss : -0.007217918988317251\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 18 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([137])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 50.5\n",
            "Eval_StdReturn : 16.5\n",
            "Eval_MaxReturn : 81.0\n",
            "Eval_MinReturn : 26.0\n",
            "Eval_AverageEpLen : 50.5\n",
            "Train_AverageReturn : 30.83333396911621\n",
            "Train_StdReturn : 24.244699478149414\n",
            "Train_MaxReturn : 80.0\n",
            "Train_MinReturn : 5.0\n",
            "Train_AverageEpLen : 30.833333333333332\n",
            "Train_EnvstepsSoFar : 2514\n",
            "TimeSinceStart : 6.603594779968262\n",
            "Training Loss : -0.13329848647117615\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 19 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([154])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 23.882352828979492\n",
            "Eval_StdReturn : 19.94369125366211\n",
            "Eval_MaxReturn : 70.0\n",
            "Eval_MinReturn : 6.0\n",
            "Eval_AverageEpLen : 23.88235294117647\n",
            "Train_AverageReturn : 51.33333206176758\n",
            "Train_StdReturn : 31.647363662719727\n",
            "Train_MaxReturn : 95.0\n",
            "Train_MinReturn : 21.0\n",
            "Train_AverageEpLen : 51.333333333333336\n",
            "Train_EnvstepsSoFar : 2668\n",
            "TimeSinceStart : 6.9362499713897705\n",
            "Training Loss : 0.028272293508052826\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 20 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([149])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 40.90909194946289\n",
            "Eval_StdReturn : 19.709041595458984\n",
            "Eval_MaxReturn : 69.0\n",
            "Eval_MinReturn : 12.0\n",
            "Eval_AverageEpLen : 40.90909090909091\n",
            "Train_AverageReturn : 24.83333396911621\n",
            "Train_StdReturn : 14.322670936584473\n",
            "Train_MaxReturn : 41.0\n",
            "Train_MinReturn : 8.0\n",
            "Train_AverageEpLen : 24.833333333333332\n",
            "Train_EnvstepsSoFar : 2817\n",
            "TimeSinceStart : 7.292127847671509\n",
            "Training Loss : 0.007884223945438862\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 21 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([120])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 25.0\n",
            "Eval_StdReturn : 21.14533042907715\n",
            "Eval_MaxReturn : 82.0\n",
            "Eval_MinReturn : 4.0\n",
            "Eval_AverageEpLen : 25.0\n",
            "Train_AverageReturn : 17.375\n",
            "Train_StdReturn : 20.118011474609375\n",
            "Train_MaxReturn : 68.0\n",
            "Train_MinReturn : 5.0\n",
            "Train_AverageEpLen : 17.375\n",
            "Train_EnvstepsSoFar : 2956\n",
            "TimeSinceStart : 7.676597356796265\n",
            "Training Loss : 0.0009785493602976203\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 22 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([134])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 22.38888931274414\n",
            "Eval_StdReturn : 16.190322875976562\n",
            "Eval_MaxReturn : 62.0\n",
            "Eval_MinReturn : 4.0\n",
            "Eval_AverageEpLen : 22.38888888888889\n",
            "Train_AverageReturn : 47.5\n",
            "Train_StdReturn : 26.63174819946289\n",
            "Train_MaxReturn : 81.0\n",
            "Train_MinReturn : 7.0\n",
            "Train_AverageEpLen : 47.5\n",
            "Train_EnvstepsSoFar : 3146\n",
            "TimeSinceStart : 8.104475259780884\n",
            "Training Loss : -0.03578504920005798\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 23 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([128])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 21.210525512695312\n",
            "Eval_StdReturn : 12.314214706420898\n",
            "Eval_MaxReturn : 50.0\n",
            "Eval_MinReturn : 5.0\n",
            "Eval_AverageEpLen : 21.210526315789473\n",
            "Train_AverageReturn : 14.090909004211426\n",
            "Train_StdReturn : 10.448615074157715\n",
            "Train_MaxReturn : 42.0\n",
            "Train_MinReturn : 6.0\n",
            "Train_AverageEpLen : 14.090909090909092\n",
            "Train_EnvstepsSoFar : 3301\n",
            "TimeSinceStart : 8.522865295410156\n",
            "Training Loss : 0.09645207971334457\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 24 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([128])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 18.454545974731445\n",
            "Eval_StdReturn : 10.739592552185059\n",
            "Eval_MaxReturn : 40.0\n",
            "Eval_MinReturn : 5.0\n",
            "Eval_AverageEpLen : 18.454545454545453\n",
            "Train_AverageReturn : 14.222222328186035\n",
            "Train_StdReturn : 4.565030574798584\n",
            "Train_MaxReturn : 25.0\n",
            "Train_MinReturn : 9.0\n",
            "Train_AverageEpLen : 14.222222222222221\n",
            "Train_EnvstepsSoFar : 3429\n",
            "TimeSinceStart : 8.932914733886719\n",
            "Training Loss : 0.047053009271621704\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 25 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([120])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 19.285715103149414\n",
            "Eval_StdReturn : 10.915881156921387\n",
            "Eval_MaxReturn : 51.0\n",
            "Eval_MinReturn : 5.0\n",
            "Eval_AverageEpLen : 19.285714285714285\n",
            "Train_AverageReturn : 13.5\n",
            "Train_StdReturn : 4.341658592224121\n",
            "Train_MaxReturn : 21.0\n",
            "Train_MinReturn : 6.0\n",
            "Train_AverageEpLen : 13.5\n",
            "Train_EnvstepsSoFar : 3564\n",
            "TimeSinceStart : 9.319760084152222\n",
            "Training Loss : -0.005929403007030487\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 26 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([131])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 22.33333396911621\n",
            "Eval_StdReturn : 11.348029136657715\n",
            "Eval_MaxReturn : 44.0\n",
            "Eval_MinReturn : 5.0\n",
            "Eval_AverageEpLen : 22.333333333333332\n",
            "Train_AverageReturn : 18.714284896850586\n",
            "Train_StdReturn : 9.967293739318848\n",
            "Train_MaxReturn : 40.0\n",
            "Train_MinReturn : 11.0\n",
            "Train_AverageEpLen : 18.714285714285715\n",
            "Train_EnvstepsSoFar : 3695\n",
            "TimeSinceStart : 9.646031379699707\n",
            "Training Loss : 0.05027449131011963\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 27 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([129])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 25.625\n",
            "Eval_StdReturn : 15.519644737243652\n",
            "Eval_MaxReturn : 62.0\n",
            "Eval_MinReturn : 10.0\n",
            "Eval_AverageEpLen : 25.625\n",
            "Train_AverageReturn : 18.428571701049805\n",
            "Train_StdReturn : 12.361889839172363\n",
            "Train_MaxReturn : 47.0\n",
            "Train_MinReturn : 8.0\n",
            "Train_AverageEpLen : 18.428571428571427\n",
            "Train_EnvstepsSoFar : 3824\n",
            "TimeSinceStart : 9.964568138122559\n",
            "Training Loss : -0.008034521713852882\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 28 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([125])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 40.09090805053711\n",
            "Eval_StdReturn : 20.407014846801758\n",
            "Eval_MaxReturn : 78.0\n",
            "Eval_MinReturn : 7.0\n",
            "Eval_AverageEpLen : 40.09090909090909\n",
            "Train_AverageReturn : 31.25\n",
            "Train_StdReturn : 14.289419174194336\n",
            "Train_MaxReturn : 47.0\n",
            "Train_MinReturn : 17.0\n",
            "Train_AverageEpLen : 31.25\n",
            "Train_EnvstepsSoFar : 3949\n",
            "TimeSinceStart : 10.342912912368774\n",
            "Training Loss : -0.0403672493994236\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 29 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([139])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 48.22222137451172\n",
            "Eval_StdReturn : 13.306453704833984\n",
            "Eval_MaxReturn : 68.0\n",
            "Eval_MinReturn : 28.0\n",
            "Eval_AverageEpLen : 48.22222222222222\n",
            "Train_AverageReturn : 27.799999237060547\n",
            "Train_StdReturn : 12.122706413269043\n",
            "Train_MaxReturn : 44.0\n",
            "Train_MinReturn : 9.0\n",
            "Train_AverageEpLen : 27.8\n",
            "Train_EnvstepsSoFar : 4088\n",
            "TimeSinceStart : 10.733291149139404\n",
            "Training Loss : 0.04316888377070427\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 30 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([128])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 67.0\n",
            "Eval_StdReturn : 18.6636905670166\n",
            "Eval_MaxReturn : 94.0\n",
            "Eval_MinReturn : 39.0\n",
            "Eval_AverageEpLen : 67.0\n",
            "Train_AverageReturn : 32.0\n",
            "Train_StdReturn : 9.110433578491211\n",
            "Train_MaxReturn : 43.0\n",
            "Train_MinReturn : 23.0\n",
            "Train_AverageEpLen : 32.0\n",
            "Train_EnvstepsSoFar : 4216\n",
            "TimeSinceStart : 11.049614429473877\n",
            "Training Loss : -0.12968243658542633\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 31 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([120])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 62.14285659790039\n",
            "Eval_StdReturn : 21.918214797973633\n",
            "Eval_MaxReturn : 97.0\n",
            "Eval_MinReturn : 30.0\n",
            "Eval_AverageEpLen : 62.142857142857146\n",
            "Train_AverageReturn : 56.0\n",
            "Train_StdReturn : 11.313708305358887\n",
            "Train_MaxReturn : 72.0\n",
            "Train_MinReturn : 48.0\n",
            "Train_AverageEpLen : 56.0\n",
            "Train_EnvstepsSoFar : 4384\n",
            "TimeSinceStart : 11.410942554473877\n",
            "Training Loss : 0.06908297538757324\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 32 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([126])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 56.75\n",
            "Eval_StdReturn : 13.188536643981934\n",
            "Eval_MaxReturn : 72.0\n",
            "Eval_MinReturn : 27.0\n",
            "Eval_AverageEpLen : 56.75\n",
            "Train_AverageReturn : 42.0\n",
            "Train_StdReturn : 13.880441665649414\n",
            "Train_MaxReturn : 59.0\n",
            "Train_MinReturn : 25.0\n",
            "Train_AverageEpLen : 42.0\n",
            "Train_EnvstepsSoFar : 4510\n",
            "TimeSinceStart : 11.825528621673584\n",
            "Training Loss : -0.008236488327383995\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 33 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([133])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 57.85714340209961\n",
            "Eval_StdReturn : 15.606121063232422\n",
            "Eval_MaxReturn : 94.0\n",
            "Eval_MinReturn : 47.0\n",
            "Eval_AverageEpLen : 57.857142857142854\n",
            "Train_AverageReturn : 52.0\n",
            "Train_StdReturn : 20.832666397094727\n",
            "Train_MaxReturn : 71.0\n",
            "Train_MinReturn : 23.0\n",
            "Train_AverageEpLen : 52.0\n",
            "Train_EnvstepsSoFar : 4666\n",
            "TimeSinceStart : 12.172491788864136\n",
            "Training Loss : 0.01590779796242714\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 34 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([136])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 47.33333206176758\n",
            "Eval_StdReturn : 24.819347381591797\n",
            "Eval_MaxReturn : 101.0\n",
            "Eval_MinReturn : 11.0\n",
            "Eval_AverageEpLen : 47.333333333333336\n",
            "Train_AverageReturn : 45.33333206176758\n",
            "Train_StdReturn : 11.671427726745605\n",
            "Train_MaxReturn : 61.0\n",
            "Train_MinReturn : 33.0\n",
            "Train_AverageEpLen : 45.333333333333336\n",
            "Train_EnvstepsSoFar : 4802\n",
            "TimeSinceStart : 12.527292728424072\n",
            "Training Loss : -0.025169407948851585\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 35 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([158])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 50.5\n",
            "Eval_StdReturn : 21.908903121948242\n",
            "Eval_MaxReturn : 80.0\n",
            "Eval_MinReturn : 10.0\n",
            "Eval_AverageEpLen : 50.5\n",
            "Train_AverageReturn : 52.66666793823242\n",
            "Train_StdReturn : 2.494438409805298\n",
            "Train_MaxReturn : 56.0\n",
            "Train_MinReturn : 50.0\n",
            "Train_AverageEpLen : 52.666666666666664\n",
            "Train_EnvstepsSoFar : 4960\n",
            "TimeSinceStart : 12.852988481521606\n",
            "Training Loss : -0.08247432857751846\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 36 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([122])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 35.0\n",
            "Eval_StdReturn : 18.524757385253906\n",
            "Eval_MaxReturn : 87.0\n",
            "Eval_MinReturn : 16.0\n",
            "Eval_AverageEpLen : 35.0\n",
            "Train_AverageReturn : 61.0\n",
            "Train_StdReturn : 13.0\n",
            "Train_MaxReturn : 74.0\n",
            "Train_MinReturn : 48.0\n",
            "Train_AverageEpLen : 61.0\n",
            "Train_EnvstepsSoFar : 5082\n",
            "TimeSinceStart : 13.169403314590454\n",
            "Training Loss : -0.03227459266781807\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 37 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([149])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 13.399999618530273\n",
            "Eval_StdReturn : 6.916646480560303\n",
            "Eval_MaxReturn : 37.0\n",
            "Eval_MinReturn : 5.0\n",
            "Eval_AverageEpLen : 13.4\n",
            "Train_AverageReturn : 60.33333206176758\n",
            "Train_StdReturn : 20.531818389892578\n",
            "Train_MaxReturn : 80.0\n",
            "Train_MinReturn : 32.0\n",
            "Train_AverageEpLen : 60.333333333333336\n",
            "Train_EnvstepsSoFar : 5263\n",
            "TimeSinceStart : 13.533966779708862\n",
            "Training Loss : -0.042165204882621765\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 38 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([121])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 19.636363983154297\n",
            "Eval_StdReturn : 17.473474502563477\n",
            "Eval_MaxReturn : 79.0\n",
            "Eval_MinReturn : 5.0\n",
            "Eval_AverageEpLen : 19.636363636363637\n",
            "Train_AverageReturn : 20.0\n",
            "Train_StdReturn : 10.636863708496094\n",
            "Train_MaxReturn : 43.0\n",
            "Train_MinReturn : 9.0\n",
            "Train_AverageEpLen : 20.0\n",
            "Train_EnvstepsSoFar : 5403\n",
            "TimeSinceStart : 13.99159049987793\n",
            "Training Loss : 0.05170455574989319\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 39 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([140])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 92.19999694824219\n",
            "Eval_StdReturn : 24.44913101196289\n",
            "Eval_MaxReturn : 120.0\n",
            "Eval_MinReturn : 50.0\n",
            "Eval_AverageEpLen : 92.2\n",
            "Train_AverageReturn : 20.0\n",
            "Train_StdReturn : 9.856107711791992\n",
            "Train_MaxReturn : 38.0\n",
            "Train_MinReturn : 9.0\n",
            "Train_AverageEpLen : 20.0\n",
            "Train_EnvstepsSoFar : 5543\n",
            "TimeSinceStart : 14.438759565353394\n",
            "Training Loss : -0.06190495565533638\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 40 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([145])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 95.5999984741211\n",
            "Eval_StdReturn : 30.598037719726562\n",
            "Eval_MaxReturn : 129.0\n",
            "Eval_MinReturn : 48.0\n",
            "Eval_AverageEpLen : 95.6\n",
            "Train_AverageReturn : 72.5\n",
            "Train_StdReturn : 2.5\n",
            "Train_MaxReturn : 75.0\n",
            "Train_MinReturn : 70.0\n",
            "Train_AverageEpLen : 72.5\n",
            "Train_EnvstepsSoFar : 5688\n",
            "TimeSinceStart : 14.816606521606445\n",
            "Training Loss : 0.08024948090314865\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 41 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([127])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 58.28571319580078\n",
            "Eval_StdReturn : 19.454814910888672\n",
            "Eval_MaxReturn : 86.0\n",
            "Eval_MinReturn : 24.0\n",
            "Eval_AverageEpLen : 58.285714285714285\n",
            "Train_AverageReturn : 61.33333206176758\n",
            "Train_StdReturn : 9.877021789550781\n",
            "Train_MaxReturn : 75.0\n",
            "Train_MinReturn : 52.0\n",
            "Train_AverageEpLen : 61.333333333333336\n",
            "Train_EnvstepsSoFar : 5872\n",
            "TimeSinceStart : 15.162472248077393\n",
            "Training Loss : 0.02269238792359829\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 42 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([124])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 50.375\n",
            "Eval_StdReturn : 16.178207397460938\n",
            "Eval_MaxReturn : 73.0\n",
            "Eval_MinReturn : 19.0\n",
            "Eval_AverageEpLen : 50.375\n",
            "Train_AverageReturn : 55.33333206176758\n",
            "Train_StdReturn : 13.597384452819824\n",
            "Train_MaxReturn : 74.0\n",
            "Train_MinReturn : 42.0\n",
            "Train_AverageEpLen : 55.333333333333336\n",
            "Train_EnvstepsSoFar : 6038\n",
            "TimeSinceStart : 15.491567850112915\n",
            "Training Loss : -0.005086548626422882\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 43 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([141])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 57.71428680419922\n",
            "Eval_StdReturn : 13.55111312866211\n",
            "Eval_MaxReturn : 78.0\n",
            "Eval_MinReturn : 38.0\n",
            "Eval_AverageEpLen : 57.714285714285715\n",
            "Train_AverageReturn : 70.5\n",
            "Train_StdReturn : 23.5\n",
            "Train_MaxReturn : 94.0\n",
            "Train_MinReturn : 47.0\n",
            "Train_AverageEpLen : 70.5\n",
            "Train_EnvstepsSoFar : 6179\n",
            "TimeSinceStart : 15.83140778541565\n",
            "Training Loss : -0.052352577447891235\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 44 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([157])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 52.22222137451172\n",
            "Eval_StdReturn : 21.84174346923828\n",
            "Eval_MaxReturn : 80.0\n",
            "Eval_MinReturn : 12.0\n",
            "Eval_AverageEpLen : 52.22222222222222\n",
            "Train_AverageReturn : 52.33333206176758\n",
            "Train_StdReturn : 36.527008056640625\n",
            "Train_MaxReturn : 101.0\n",
            "Train_MinReturn : 13.0\n",
            "Train_AverageEpLen : 52.333333333333336\n",
            "Train_EnvstepsSoFar : 6336\n",
            "TimeSinceStart : 16.206178903579712\n",
            "Training Loss : -0.027845699340105057\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 45 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([124])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 89.5999984741211\n",
            "Eval_StdReturn : 40.361366271972656\n",
            "Eval_MaxReturn : 155.0\n",
            "Eval_MinReturn : 38.0\n",
            "Eval_AverageEpLen : 89.6\n",
            "Train_AverageReturn : 62.0\n",
            "Train_StdReturn : 12.0\n",
            "Train_MaxReturn : 74.0\n",
            "Train_MinReturn : 50.0\n",
            "Train_AverageEpLen : 62.0\n",
            "Train_EnvstepsSoFar : 6460\n",
            "TimeSinceStart : 16.64019536972046\n",
            "Training Loss : 0.028150057420134544\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 46 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([124])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 46.77777862548828\n",
            "Eval_StdReturn : 40.22652053833008\n",
            "Eval_MaxReturn : 158.0\n",
            "Eval_MinReturn : 19.0\n",
            "Eval_AverageEpLen : 46.77777777777778\n",
            "Train_AverageReturn : 54.33333206176758\n",
            "Train_StdReturn : 23.113248825073242\n",
            "Train_MaxReturn : 87.0\n",
            "Train_MinReturn : 37.0\n",
            "Train_AverageEpLen : 54.333333333333336\n",
            "Train_EnvstepsSoFar : 6623\n",
            "TimeSinceStart : 17.10231304168701\n",
            "Training Loss : 0.0784287229180336\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 47 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([157])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 40.0\n",
            "Eval_StdReturn : 21.45184898376465\n",
            "Eval_MaxReturn : 91.0\n",
            "Eval_MinReturn : 20.0\n",
            "Eval_AverageEpLen : 40.0\n",
            "Train_AverageReturn : 52.33333206176758\n",
            "Train_StdReturn : 7.930251121520996\n",
            "Train_MaxReturn : 63.0\n",
            "Train_MinReturn : 44.0\n",
            "Train_AverageEpLen : 52.333333333333336\n",
            "Train_EnvstepsSoFar : 6780\n",
            "TimeSinceStart : 17.491040468215942\n",
            "Training Loss : -0.0017108188476413488\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 48 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([138])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 37.181819915771484\n",
            "Eval_StdReturn : 19.044532775878906\n",
            "Eval_MaxReturn : 72.0\n",
            "Eval_MinReturn : 5.0\n",
            "Eval_AverageEpLen : 37.18181818181818\n",
            "Train_AverageReturn : 34.5\n",
            "Train_StdReturn : 13.444329261779785\n",
            "Train_MaxReturn : 55.0\n",
            "Train_MinReturn : 19.0\n",
            "Train_AverageEpLen : 34.5\n",
            "Train_EnvstepsSoFar : 6918\n",
            "TimeSinceStart : 17.82188582420349\n",
            "Training Loss : -0.0660087987780571\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 49 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([146])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 27.5625\n",
            "Eval_StdReturn : 15.272396087646484\n",
            "Eval_MaxReturn : 56.0\n",
            "Eval_MinReturn : 4.0\n",
            "Eval_AverageEpLen : 27.5625\n",
            "Train_AverageReturn : 36.5\n",
            "Train_StdReturn : 13.369742393493652\n",
            "Train_MaxReturn : 58.0\n",
            "Train_MinReturn : 22.0\n",
            "Train_AverageEpLen : 36.5\n",
            "Train_EnvstepsSoFar : 7064\n",
            "TimeSinceStart : 18.180089473724365\n",
            "Training Loss : -0.009422661736607552\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 50 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([136])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 37.90909194946289\n",
            "Eval_StdReturn : 29.258888244628906\n",
            "Eval_MaxReturn : 101.0\n",
            "Eval_MinReturn : 4.0\n",
            "Eval_AverageEpLen : 37.90909090909091\n",
            "Train_AverageReturn : 49.25\n",
            "Train_StdReturn : 39.37876892089844\n",
            "Train_MaxReturn : 108.0\n",
            "Train_MinReturn : 6.0\n",
            "Train_AverageEpLen : 49.25\n",
            "Train_EnvstepsSoFar : 7261\n",
            "TimeSinceStart : 18.573179244995117\n",
            "Training Loss : -0.00359176192432642\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 51 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([144])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 57.85714340209961\n",
            "Eval_StdReturn : 47.3691520690918\n",
            "Eval_MaxReturn : 113.0\n",
            "Eval_MinReturn : 2.0\n",
            "Eval_AverageEpLen : 57.857142857142854\n",
            "Train_AverageReturn : 41.0\n",
            "Train_StdReturn : 52.49761962890625\n",
            "Train_MaxReturn : 144.0\n",
            "Train_MinReturn : 4.0\n",
            "Train_AverageEpLen : 41.0\n",
            "Train_EnvstepsSoFar : 7466\n",
            "TimeSinceStart : 18.94292640686035\n",
            "Training Loss : 0.019736971706151962\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 52 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([216])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 58.875\n",
            "Eval_StdReturn : 43.964298248291016\n",
            "Eval_MaxReturn : 102.0\n",
            "Eval_MinReturn : 2.0\n",
            "Eval_AverageEpLen : 58.875\n",
            "Train_AverageReturn : 108.0\n",
            "Train_StdReturn : 10.0\n",
            "Train_MaxReturn : 118.0\n",
            "Train_MinReturn : 98.0\n",
            "Train_AverageEpLen : 108.0\n",
            "Train_EnvstepsSoFar : 7682\n",
            "TimeSinceStart : 19.369532823562622\n",
            "Training Loss : -0.027546795085072517\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 53 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([200])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 41.5\n",
            "Eval_StdReturn : 48.454620361328125\n",
            "Eval_MaxReturn : 105.0\n",
            "Eval_MinReturn : 2.0\n",
            "Eval_AverageEpLen : 41.5\n",
            "Train_AverageReturn : 100.0\n",
            "Train_StdReturn : 1.0\n",
            "Train_MaxReturn : 101.0\n",
            "Train_MinReturn : 99.0\n",
            "Train_AverageEpLen : 100.0\n",
            "Train_EnvstepsSoFar : 7882\n",
            "TimeSinceStart : 19.810198068618774\n",
            "Training Loss : -0.027395954355597496\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 54 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([191])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 16.576923370361328\n",
            "Eval_StdReturn : 34.208831787109375\n",
            "Eval_MaxReturn : 103.0\n",
            "Eval_MinReturn : 2.0\n",
            "Eval_AverageEpLen : 16.576923076923077\n",
            "Train_AverageReturn : 63.66666793823242\n",
            "Train_StdReturn : 43.60683059692383\n",
            "Train_MaxReturn : 95.0\n",
            "Train_MinReturn : 2.0\n",
            "Train_AverageEpLen : 63.666666666666664\n",
            "Train_EnvstepsSoFar : 8073\n",
            "TimeSinceStart : 20.269644498825073\n",
            "Training Loss : -0.09256020188331604\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 55 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([190])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 4.761904716491699\n",
            "Eval_StdReturn : 14.769353866577148\n",
            "Eval_MaxReturn : 93.0\n",
            "Eval_MinReturn : 2.0\n",
            "Eval_AverageEpLen : 4.761904761904762\n",
            "Train_AverageReturn : 32.33333206176758\n",
            "Train_StdReturn : 42.901695251464844\n",
            "Train_MaxReturn : 94.0\n",
            "Train_MinReturn : 2.0\n",
            "Train_AverageEpLen : 32.333333333333336\n",
            "Train_EnvstepsSoFar : 8267\n",
            "TimeSinceStart : 20.72739887237549\n",
            "Training Loss : 0.007747620344161987\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 56 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([121])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 2.7094595432281494\n",
            "Eval_StdReturn : 8.437570571899414\n",
            "Eval_MaxReturn : 105.0\n",
            "Eval_MinReturn : 2.0\n",
            "Eval_AverageEpLen : 2.7094594594594597\n",
            "Train_AverageReturn : 2.0166666507720947\n",
            "Train_StdReturn : 0.1280190795660019\n",
            "Train_MaxReturn : 3.0\n",
            "Train_MinReturn : 2.0\n",
            "Train_AverageEpLen : 2.0166666666666666\n",
            "Train_EnvstepsSoFar : 8388\n",
            "TimeSinceStart : 21.116241455078125\n",
            "Training Loss : 0.0012312013423070312\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 57 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([124])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 4.081632614135742\n",
            "Eval_StdReturn : 14.447425842285156\n",
            "Eval_MaxReturn : 110.0\n",
            "Eval_MinReturn : 2.0\n",
            "Eval_AverageEpLen : 4.081632653061225\n",
            "Train_AverageReturn : 15.55555534362793\n",
            "Train_StdReturn : 38.34090042114258\n",
            "Train_MaxReturn : 124.0\n",
            "Train_MinReturn : 2.0\n",
            "Train_AverageEpLen : 15.555555555555555\n",
            "Train_EnvstepsSoFar : 8528\n",
            "TimeSinceStart : 21.498013973236084\n",
            "Training Loss : 0.04461631923913956\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 58 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([120])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 2.919708013534546\n",
            "Eval_StdReturn : 10.64013671875\n",
            "Eval_MaxReturn : 127.0\n",
            "Eval_MinReturn : 2.0\n",
            "Eval_AverageEpLen : 2.9197080291970803\n",
            "Train_AverageReturn : 10.0\n",
            "Train_StdReturn : 26.53299903869629\n",
            "Train_MaxReturn : 98.0\n",
            "Train_MinReturn : 2.0\n",
            "Train_AverageEpLen : 10.0\n",
            "Train_EnvstepsSoFar : 8648\n",
            "TimeSinceStart : 21.88832449913025\n",
            "Training Loss : -0.07621140778064728\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 59 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([121])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 10.268292427062988\n",
            "Eval_StdReturn : 28.727502822875977\n",
            "Eval_MaxReturn : 148.0\n",
            "Eval_MinReturn : 2.0\n",
            "Eval_AverageEpLen : 10.268292682926829\n",
            "Train_AverageReturn : 2.8809523582458496\n",
            "Train_StdReturn : 5.640847682952881\n",
            "Train_MaxReturn : 39.0\n",
            "Train_MinReturn : 2.0\n",
            "Train_AverageEpLen : 2.880952380952381\n",
            "Train_EnvstepsSoFar : 8769\n",
            "TimeSinceStart : 22.290056943893433\n",
            "Training Loss : 0.21247060596942902\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 60 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([204])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 59.0\n",
            "Eval_StdReturn : 70.62982177734375\n",
            "Eval_MaxReturn : 217.0\n",
            "Eval_MinReturn : 2.0\n",
            "Eval_AverageEpLen : 59.0\n",
            "Train_AverageReturn : 52.5\n",
            "Train_StdReturn : 87.46856689453125\n",
            "Train_MaxReturn : 204.0\n",
            "Train_MinReturn : 2.0\n",
            "Train_AverageEpLen : 52.5\n",
            "Train_EnvstepsSoFar : 8979\n",
            "TimeSinceStart : 22.74716067314148\n",
            "Training Loss : -0.02421930804848671\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 61 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([130])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 16.75\n",
            "Eval_StdReturn : 29.127338409423828\n",
            "Eval_MaxReturn : 129.0\n",
            "Eval_MinReturn : 2.0\n",
            "Eval_AverageEpLen : 16.75\n",
            "Train_AverageReturn : 20.571428298950195\n",
            "Train_StdReturn : 33.906837463378906\n",
            "Train_MaxReturn : 101.0\n",
            "Train_MinReturn : 2.0\n",
            "Train_AverageEpLen : 20.571428571428573\n",
            "Train_EnvstepsSoFar : 9123\n",
            "TimeSinceStart : 23.137272596359253\n",
            "Training Loss : 0.11456632614135742\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 62 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([134])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 59.85714340209961\n",
            "Eval_StdReturn : 34.30713653564453\n",
            "Eval_MaxReturn : 95.0\n",
            "Eval_MinReturn : 2.0\n",
            "Eval_AverageEpLen : 59.857142857142854\n",
            "Train_AverageReturn : 15.55555534362793\n",
            "Train_StdReturn : 18.451805114746094\n",
            "Train_MaxReturn : 59.0\n",
            "Train_MinReturn : 2.0\n",
            "Train_AverageEpLen : 15.555555555555555\n",
            "Train_EnvstepsSoFar : 9263\n",
            "TimeSinceStart : 23.480724334716797\n",
            "Training Loss : -0.009312786161899567\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 63 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([130])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 62.25\n",
            "Eval_StdReturn : 49.37547302246094\n",
            "Eval_MaxReturn : 176.0\n",
            "Eval_MinReturn : 5.0\n",
            "Eval_AverageEpLen : 62.25\n",
            "Train_AverageReturn : 130.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 130.0\n",
            "Train_MinReturn : 130.0\n",
            "Train_AverageEpLen : 130.0\n",
            "Train_EnvstepsSoFar : 9393\n",
            "TimeSinceStart : 23.858024835586548\n",
            "Training Loss : -0.01917368732392788\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 64 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([126])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 65.14286041259766\n",
            "Eval_StdReturn : 38.371971130371094\n",
            "Eval_MaxReturn : 142.0\n",
            "Eval_MinReturn : 15.0\n",
            "Eval_AverageEpLen : 65.14285714285714\n",
            "Train_AverageReturn : 31.5\n",
            "Train_StdReturn : 20.303939819335938\n",
            "Train_MaxReturn : 51.0\n",
            "Train_MinReturn : 4.0\n",
            "Train_AverageEpLen : 31.5\n",
            "Train_EnvstepsSoFar : 9519\n",
            "TimeSinceStart : 24.213645696640015\n",
            "Training Loss : -0.0794772207736969\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 65 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([145])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 60.0\n",
            "Eval_StdReturn : 58.8848762512207\n",
            "Eval_MaxReturn : 153.0\n",
            "Eval_MinReturn : 4.0\n",
            "Eval_AverageEpLen : 60.0\n",
            "Train_AverageReturn : 44.0\n",
            "Train_StdReturn : 34.438350677490234\n",
            "Train_MaxReturn : 108.0\n",
            "Train_MinReturn : 4.0\n",
            "Train_AverageEpLen : 44.0\n",
            "Train_EnvstepsSoFar : 9739\n",
            "TimeSinceStart : 24.654069423675537\n",
            "Training Loss : 0.004536885302513838\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 66 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([158])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 136.0\n",
            "Eval_StdReturn : 107.79981231689453\n",
            "Eval_MaxReturn : 315.0\n",
            "Eval_MinReturn : 6.0\n",
            "Eval_AverageEpLen : 136.0\n",
            "Train_AverageReturn : 42.5\n",
            "Train_StdReturn : 41.52408981323242\n",
            "Train_MaxReturn : 107.0\n",
            "Train_MinReturn : 6.0\n",
            "Train_AverageEpLen : 42.5\n",
            "Train_EnvstepsSoFar : 9909\n",
            "TimeSinceStart : 25.164355754852295\n",
            "Training Loss : -0.13065126538276672\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 67 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([459])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 452.0\n",
            "Eval_StdReturn : 425.0\n",
            "Eval_MaxReturn : 877.0\n",
            "Eval_MinReturn : 27.0\n",
            "Eval_AverageEpLen : 452.0\n",
            "Train_AverageReturn : 231.5\n",
            "Train_StdReturn : 227.5\n",
            "Train_MaxReturn : 459.0\n",
            "Train_MinReturn : 4.0\n",
            "Train_AverageEpLen : 231.5\n",
            "Train_EnvstepsSoFar : 10372\n",
            "TimeSinceStart : 25.991408824920654\n",
            "Training Loss : 0.03131227195262909\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 68 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([161])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 818.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 818.0\n",
            "Eval_MinReturn : 818.0\n",
            "Eval_AverageEpLen : 818.0\n",
            "Train_AverageReturn : 80.5\n",
            "Train_StdReturn : 32.5\n",
            "Train_MaxReturn : 113.0\n",
            "Train_MinReturn : 48.0\n",
            "Train_AverageEpLen : 80.5\n",
            "Train_EnvstepsSoFar : 10533\n",
            "TimeSinceStart : 26.620842695236206\n",
            "Training Loss : 0.044767290353775024\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 69 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 443.6666564941406\n",
            "Eval_StdReturn : 411.8902282714844\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 16.0\n",
            "Eval_AverageEpLen : 443.6666666666667\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 11533\n",
            "TimeSinceStart : 28.001709461212158\n",
            "Training Loss : 0.002184906043112278\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 70 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 676.0\n",
            "Eval_StdReturn : 324.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 352.0\n",
            "Eval_AverageEpLen : 676.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 12533\n",
            "TimeSinceStart : 29.43536353111267\n",
            "Training Loss : -0.01135554164648056\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 71 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 13533\n",
            "TimeSinceStart : 30.758591890335083\n",
            "Training Loss : 0.00856960378587246\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 72 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 782.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 782.0\n",
            "Eval_MinReturn : 782.0\n",
            "Eval_AverageEpLen : 782.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 14533\n",
            "TimeSinceStart : 31.83371591567993\n",
            "Training Loss : -0.027405159547924995\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 73 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 234.0\n",
            "Eval_StdReturn : 11.0\n",
            "Eval_MaxReturn : 245.0\n",
            "Eval_MinReturn : 223.0\n",
            "Eval_AverageEpLen : 234.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 15533\n",
            "TimeSinceStart : 32.72525715827942\n",
            "Training Loss : 0.015449730679392815\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 74 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([476])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 726.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 726.0\n",
            "Eval_MinReturn : 726.0\n",
            "Eval_AverageEpLen : 726.0\n",
            "Train_AverageReturn : 476.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 476.0\n",
            "Train_MinReturn : 476.0\n",
            "Train_AverageEpLen : 476.0\n",
            "Train_EnvstepsSoFar : 16009\n",
            "TimeSinceStart : 33.509063482284546\n",
            "Training Loss : -0.05151856318116188\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 75 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([197])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 476.5\n",
            "Eval_StdReturn : 419.5\n",
            "Eval_MaxReturn : 896.0\n",
            "Eval_MinReturn : 57.0\n",
            "Eval_AverageEpLen : 476.5\n",
            "Train_AverageReturn : 135.5\n",
            "Train_StdReturn : 61.5\n",
            "Train_MaxReturn : 197.0\n",
            "Train_MinReturn : 74.0\n",
            "Train_AverageEpLen : 135.5\n",
            "Train_EnvstepsSoFar : 16280\n",
            "TimeSinceStart : 34.286212682724\n",
            "Training Loss : -0.05279963091015816\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 76 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([239])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 100.80000305175781\n",
            "Eval_StdReturn : 51.02313232421875\n",
            "Eval_MaxReturn : 189.0\n",
            "Eval_MinReturn : 52.0\n",
            "Eval_AverageEpLen : 100.8\n",
            "Train_AverageReturn : 239.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 239.0\n",
            "Train_MinReturn : 239.0\n",
            "Train_AverageEpLen : 239.0\n",
            "Train_EnvstepsSoFar : 16519\n",
            "TimeSinceStart : 34.72582006454468\n",
            "Training Loss : 0.04012142866849899\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 77 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([412])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 147.6666717529297\n",
            "Eval_StdReturn : 29.510826110839844\n",
            "Eval_MaxReturn : 189.0\n",
            "Eval_MinReturn : 122.0\n",
            "Eval_AverageEpLen : 147.66666666666666\n",
            "Train_AverageReturn : 243.5\n",
            "Train_StdReturn : 168.5\n",
            "Train_MaxReturn : 412.0\n",
            "Train_MinReturn : 75.0\n",
            "Train_AverageEpLen : 243.5\n",
            "Train_EnvstepsSoFar : 17006\n",
            "TimeSinceStart : 35.352272510528564\n",
            "Training Loss : -0.039476145058870316\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 78 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([186])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 67.83333587646484\n",
            "Eval_StdReturn : 45.55369186401367\n",
            "Eval_MaxReturn : 152.0\n",
            "Eval_MinReturn : 24.0\n",
            "Eval_AverageEpLen : 67.83333333333333\n",
            "Train_AverageReturn : 130.0\n",
            "Train_StdReturn : 56.0\n",
            "Train_MaxReturn : 186.0\n",
            "Train_MinReturn : 74.0\n",
            "Train_AverageEpLen : 130.0\n",
            "Train_EnvstepsSoFar : 17266\n",
            "TimeSinceStart : 35.82343816757202\n",
            "Training Loss : -0.029270777478814125\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 79 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([134])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 26.1875\n",
            "Eval_StdReturn : 16.66290283203125\n",
            "Eval_MaxReturn : 74.0\n",
            "Eval_MinReturn : 4.0\n",
            "Eval_AverageEpLen : 26.1875\n",
            "Train_AverageReturn : 64.66666412353516\n",
            "Train_StdReturn : 23.907228469848633\n",
            "Train_MaxReturn : 96.0\n",
            "Train_MinReturn : 38.0\n",
            "Train_AverageEpLen : 64.66666666666667\n",
            "Train_EnvstepsSoFar : 17460\n",
            "TimeSinceStart : 36.28254795074463\n",
            "Training Loss : -0.02768740989267826\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 80 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([126])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 7.811320781707764\n",
            "Eval_StdReturn : 7.1217360496521\n",
            "Eval_MaxReturn : 33.0\n",
            "Eval_MinReturn : 2.0\n",
            "Eval_AverageEpLen : 7.811320754716981\n",
            "Train_AverageReturn : 54.33333206176758\n",
            "Train_StdReturn : 30.34615135192871\n",
            "Train_MaxReturn : 97.0\n",
            "Train_MinReturn : 29.0\n",
            "Train_AverageEpLen : 54.333333333333336\n",
            "Train_EnvstepsSoFar : 17623\n",
            "TimeSinceStart : 36.715707540512085\n",
            "Training Loss : 0.018377577885985374\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 81 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([121])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 3.5087718963623047\n",
            "Eval_StdReturn : 2.1974692344665527\n",
            "Eval_MaxReturn : 12.0\n",
            "Eval_MinReturn : 2.0\n",
            "Eval_AverageEpLen : 3.508771929824561\n",
            "Train_AverageReturn : 6.722222328186035\n",
            "Train_StdReturn : 4.770342826843262\n",
            "Train_MaxReturn : 16.0\n",
            "Train_MinReturn : 3.0\n",
            "Train_AverageEpLen : 6.722222222222222\n",
            "Train_EnvstepsSoFar : 17744\n",
            "TimeSinceStart : 37.11860156059265\n",
            "Training Loss : 0.03007606416940689\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 82 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([121])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 8.531914710998535\n",
            "Eval_StdReturn : 3.002488613128662\n",
            "Eval_MaxReturn : 14.0\n",
            "Eval_MinReturn : 3.0\n",
            "Eval_AverageEpLen : 8.53191489361702\n",
            "Train_AverageReturn : 4.481481552124023\n",
            "Train_StdReturn : 4.1398725509643555\n",
            "Train_MaxReturn : 18.0\n",
            "Train_MinReturn : 2.0\n",
            "Train_AverageEpLen : 4.481481481481482\n",
            "Train_EnvstepsSoFar : 17865\n",
            "TimeSinceStart : 37.45018529891968\n",
            "Training Loss : 0.003193279728293419\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 83 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([124])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 8.306122779846191\n",
            "Eval_StdReturn : 2.5491421222686768\n",
            "Eval_MaxReturn : 14.0\n",
            "Eval_MinReturn : 4.0\n",
            "Eval_AverageEpLen : 8.306122448979592\n",
            "Train_AverageReturn : 8.266666412353516\n",
            "Train_StdReturn : 2.862788200378418\n",
            "Train_MaxReturn : 13.0\n",
            "Train_MinReturn : 3.0\n",
            "Train_AverageEpLen : 8.266666666666667\n",
            "Train_EnvstepsSoFar : 17989\n",
            "TimeSinceStart : 37.86640906333923\n",
            "Training Loss : -0.027320286259055138\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 84 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([121])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 3.97029709815979\n",
            "Eval_StdReturn : 2.787722110748291\n",
            "Eval_MaxReturn : 15.0\n",
            "Eval_MinReturn : 2.0\n",
            "Eval_AverageEpLen : 3.9702970297029703\n",
            "Train_AverageReturn : 7.333333492279053\n",
            "Train_StdReturn : 2.624669313430786\n",
            "Train_MaxReturn : 13.0\n",
            "Train_MinReturn : 3.0\n",
            "Train_AverageEpLen : 7.333333333333333\n",
            "Train_EnvstepsSoFar : 18121\n",
            "TimeSinceStart : 38.27590465545654\n",
            "Training Loss : -0.038733985275030136\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 85 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([120])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 8.020000457763672\n",
            "Eval_StdReturn : 2.7238943576812744\n",
            "Eval_MaxReturn : 13.0\n",
            "Eval_MinReturn : 3.0\n",
            "Eval_AverageEpLen : 8.02\n",
            "Train_AverageReturn : 4.800000190734863\n",
            "Train_StdReturn : 3.6110939979553223\n",
            "Train_MaxReturn : 14.0\n",
            "Train_MinReturn : 2.0\n",
            "Train_AverageEpLen : 4.8\n",
            "Train_EnvstepsSoFar : 18241\n",
            "TimeSinceStart : 38.66398620605469\n",
            "Training Loss : 0.09009025990962982\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 86 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([122])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 4.962963104248047\n",
            "Eval_StdReturn : 1.7173367738723755\n",
            "Eval_MaxReturn : 13.0\n",
            "Eval_MinReturn : 3.0\n",
            "Eval_AverageEpLen : 4.962962962962963\n",
            "Train_AverageReturn : 8.714285850524902\n",
            "Train_StdReturn : 2.7367491722106934\n",
            "Train_MaxReturn : 12.0\n",
            "Train_MinReturn : 2.0\n",
            "Train_AverageEpLen : 8.714285714285714\n",
            "Train_EnvstepsSoFar : 18363\n",
            "TimeSinceStart : 39.047712564468384\n",
            "Training Loss : -0.05717961862683296\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 87 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([124])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 7.363636493682861\n",
            "Eval_StdReturn : 3.8910791873931885\n",
            "Eval_MaxReturn : 20.0\n",
            "Eval_MinReturn : 3.0\n",
            "Eval_AverageEpLen : 7.363636363636363\n",
            "Train_AverageReturn : 4.769230842590332\n",
            "Train_StdReturn : 2.0438969135284424\n",
            "Train_MaxReturn : 14.0\n",
            "Train_MinReturn : 3.0\n",
            "Train_AverageEpLen : 4.769230769230769\n",
            "Train_EnvstepsSoFar : 18487\n",
            "TimeSinceStart : 39.3932409286499\n",
            "Training Loss : 0.17728641629219055\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 88 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([121])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 3.045454502105713\n",
            "Eval_StdReturn : 1.1068905591964722\n",
            "Eval_MaxReturn : 10.0\n",
            "Eval_MinReturn : 2.0\n",
            "Eval_AverageEpLen : 3.0454545454545454\n",
            "Train_AverageReturn : 6.5789475440979\n",
            "Train_StdReturn : 3.150869369506836\n",
            "Train_MaxReturn : 15.0\n",
            "Train_MinReturn : 3.0\n",
            "Train_AverageEpLen : 6.578947368421052\n",
            "Train_EnvstepsSoFar : 18612\n",
            "TimeSinceStart : 39.82499122619629\n",
            "Training Loss : 0.005491611082106829\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 89 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([120])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 2.7397260665893555\n",
            "Eval_StdReturn : 1.1939046382904053\n",
            "Eval_MaxReturn : 8.0\n",
            "Eval_MinReturn : 2.0\n",
            "Eval_AverageEpLen : 2.73972602739726\n",
            "Train_AverageReturn : 2.9268293380737305\n",
            "Train_StdReturn : 0.6768018007278442\n",
            "Train_MaxReturn : 5.0\n",
            "Train_MinReturn : 2.0\n",
            "Train_AverageEpLen : 2.926829268292683\n",
            "Train_EnvstepsSoFar : 18732\n",
            "TimeSinceStart : 40.28822994232178\n",
            "Training Loss : 0.062165625393390656\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 90 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([120])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 4.545454502105713\n",
            "Eval_StdReturn : 1.5660394430160522\n",
            "Eval_MaxReturn : 9.0\n",
            "Eval_MinReturn : 2.0\n",
            "Eval_AverageEpLen : 4.545454545454546\n",
            "Train_AverageReturn : 2.857142925262451\n",
            "Train_StdReturn : 1.520830512046814\n",
            "Train_MaxReturn : 8.0\n",
            "Train_MinReturn : 2.0\n",
            "Train_AverageEpLen : 2.857142857142857\n",
            "Train_EnvstepsSoFar : 18852\n",
            "TimeSinceStart : 40.67718839645386\n",
            "Training Loss : 0.012069432996213436\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 91 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([120])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 5.386666774749756\n",
            "Eval_StdReturn : 1.7579786777496338\n",
            "Eval_MaxReturn : 14.0\n",
            "Eval_MinReturn : 4.0\n",
            "Eval_AverageEpLen : 5.386666666666667\n",
            "Train_AverageReturn : 4.392857074737549\n",
            "Train_StdReturn : 1.5198516845703125\n",
            "Train_MaxReturn : 8.0\n",
            "Train_MinReturn : 2.0\n",
            "Train_AverageEpLen : 4.392857142857143\n",
            "Train_EnvstepsSoFar : 18975\n",
            "TimeSinceStart : 41.04776048660278\n",
            "Training Loss : 0.06431487202644348\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 92 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([120])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 6.7166666984558105\n",
            "Eval_StdReturn : 1.8893707990646362\n",
            "Eval_MaxReturn : 13.0\n",
            "Eval_MinReturn : 4.0\n",
            "Eval_AverageEpLen : 6.716666666666667\n",
            "Train_AverageReturn : 5.714285850524902\n",
            "Train_StdReturn : 1.4521857500076294\n",
            "Train_MaxReturn : 8.0\n",
            "Train_MinReturn : 4.0\n",
            "Train_AverageEpLen : 5.714285714285714\n",
            "Train_EnvstepsSoFar : 19095\n",
            "TimeSinceStart : 41.444138526916504\n",
            "Training Loss : -0.006135391537100077\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 93 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([124])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 9.0\n",
            "Eval_StdReturn : 2.6749870777130127\n",
            "Eval_MaxReturn : 19.0\n",
            "Eval_MinReturn : 4.0\n",
            "Eval_AverageEpLen : 9.0\n",
            "Train_AverageReturn : 8.266666412353516\n",
            "Train_StdReturn : 2.322833776473999\n",
            "Train_MaxReturn : 13.0\n",
            "Train_MinReturn : 4.0\n",
            "Train_AverageEpLen : 8.266666666666667\n",
            "Train_EnvstepsSoFar : 19219\n",
            "TimeSinceStart : 41.847596168518066\n",
            "Training Loss : 0.05443853139877319\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 94 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([123])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 11.428571701049805\n",
            "Eval_StdReturn : 3.7438385486602783\n",
            "Eval_MaxReturn : 24.0\n",
            "Eval_MinReturn : 6.0\n",
            "Eval_AverageEpLen : 11.428571428571429\n",
            "Train_AverageReturn : 9.461538314819336\n",
            "Train_StdReturn : 1.737167477607727\n",
            "Train_MaxReturn : 12.0\n",
            "Train_MinReturn : 7.0\n",
            "Train_AverageEpLen : 9.461538461538462\n",
            "Train_EnvstepsSoFar : 19342\n",
            "TimeSinceStart : 42.215118408203125\n",
            "Training Loss : -0.09557028859853745\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 95 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([122])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 8.88888931274414\n",
            "Eval_StdReturn : 2.359116792678833\n",
            "Eval_MaxReturn : 16.0\n",
            "Eval_MinReturn : 4.0\n",
            "Eval_AverageEpLen : 8.88888888888889\n",
            "Train_AverageReturn : 11.818181991577148\n",
            "Train_StdReturn : 3.562894105911255\n",
            "Train_MaxReturn : 17.0\n",
            "Train_MinReturn : 7.0\n",
            "Train_AverageEpLen : 11.818181818181818\n",
            "Train_EnvstepsSoFar : 19472\n",
            "TimeSinceStart : 42.60852336883545\n",
            "Training Loss : -0.03670545667409897\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 96 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([129])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 8.739130020141602\n",
            "Eval_StdReturn : 3.2666614055633545\n",
            "Eval_MaxReturn : 23.0\n",
            "Eval_MinReturn : 5.0\n",
            "Eval_AverageEpLen : 8.73913043478261\n",
            "Train_AverageReturn : 9.923076629638672\n",
            "Train_StdReturn : 2.2000536918640137\n",
            "Train_MaxReturn : 13.0\n",
            "Train_MinReturn : 6.0\n",
            "Train_AverageEpLen : 9.923076923076923\n",
            "Train_EnvstepsSoFar : 19601\n",
            "TimeSinceStart : 42.981865644454956\n",
            "Training Loss : -0.011288691312074661\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 97 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([124])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 10.149999618530273\n",
            "Eval_StdReturn : 3.908644199371338\n",
            "Eval_MaxReturn : 20.0\n",
            "Eval_MinReturn : 3.0\n",
            "Eval_AverageEpLen : 10.15\n",
            "Train_AverageReturn : 9.538461685180664\n",
            "Train_StdReturn : 4.430929660797119\n",
            "Train_MaxReturn : 19.0\n",
            "Train_MinReturn : 5.0\n",
            "Train_AverageEpLen : 9.538461538461538\n",
            "Train_EnvstepsSoFar : 19725\n",
            "TimeSinceStart : 43.32052683830261\n",
            "Training Loss : -0.03718525171279907\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 98 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([127])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 5.0\n",
            "Eval_StdReturn : 3.2546262741088867\n",
            "Eval_MaxReturn : 16.0\n",
            "Eval_MinReturn : 2.0\n",
            "Eval_AverageEpLen : 5.0\n",
            "Train_AverageReturn : 9.357142448425293\n",
            "Train_StdReturn : 3.7149722576141357\n",
            "Train_MaxReturn : 17.0\n",
            "Train_MinReturn : 4.0\n",
            "Train_AverageEpLen : 9.357142857142858\n",
            "Train_EnvstepsSoFar : 19856\n",
            "TimeSinceStart : 43.66366267204285\n",
            "Training Loss : 0.03705501928925514\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 99 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([122])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 6.779661178588867\n",
            "Eval_StdReturn : 5.349062442779541\n",
            "Eval_MaxReturn : 30.0\n",
            "Eval_MinReturn : 3.0\n",
            "Eval_AverageEpLen : 6.779661016949152\n",
            "Train_AverageReturn : 4.206896781921387\n",
            "Train_StdReturn : 1.471084713935852\n",
            "Train_MaxReturn : 9.0\n",
            "Train_MinReturn : 3.0\n",
            "Train_AverageEpLen : 4.206896551724138\n",
            "Train_EnvstepsSoFar : 19978\n",
            "TimeSinceStart : 44.000367641448975\n",
            "Training Loss : -0.01628207229077816\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python cs285/scripts/run_hw2.py --env_name InvertedPendulum-v2 \\\n",
        "--ep_len 1000 --discount 0.9 -n 100 -l 2 -s 64 -b 120 -lr 0.05 -rtg \\\n",
        "--exp_name q2_b120_r05"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "syIQuF02yKpb",
        "outputId": "85688bb0-f44b-49cb-b349-6ffdd12e8e13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "########################\n",
            "logging outputs to  /content/gdrive/My Drive/cs285_f2021/DRL_policy_grads/cs285/scripts/../../data/q2_b100_r05_InvertedPendulum-v2_06-02-2022_17-30-47\n",
            "########################\n",
            "Using GPU id 0\n",
            "Sequential(\n",
            "  (0): Linear(in_features=4, out_features=64, bias=True)\n",
            "  (1): Tanh()\n",
            "  (2): Linear(in_features=64, out_features=64, bias=True)\n",
            "  (3): Tanh()\n",
            "  (4): Linear(in_features=64, out_features=1, bias=True)\n",
            "  (5): Identity()\n",
            ")\n",
            "\n",
            "\n",
            "********** Iteration 0 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([104])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 15.178571701049805\n",
            "Eval_StdReturn : 7.516902923583984\n",
            "Eval_MaxReturn : 34.0\n",
            "Eval_MinReturn : 7.0\n",
            "Eval_AverageEpLen : 15.178571428571429\n",
            "Train_AverageReturn : 7.4285712242126465\n",
            "Train_StdReturn : 3.0169589519500732\n",
            "Train_MaxReturn : 14.0\n",
            "Train_MinReturn : 4.0\n",
            "Train_AverageEpLen : 7.428571428571429\n",
            "Train_EnvstepsSoFar : 104\n",
            "TimeSinceStart : 0.3343329429626465\n",
            "Training Loss : -0.09512589126825333\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 1 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([102])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 9.204545021057129\n",
            "Eval_StdReturn : 2.8570451736450195\n",
            "Eval_MaxReturn : 18.0\n",
            "Eval_MinReturn : 4.0\n",
            "Eval_AverageEpLen : 9.204545454545455\n",
            "Train_AverageReturn : 14.571428298950195\n",
            "Train_StdReturn : 5.851913928985596\n",
            "Train_MaxReturn : 26.0\n",
            "Train_MinReturn : 8.0\n",
            "Train_AverageEpLen : 14.571428571428571\n",
            "Train_EnvstepsSoFar : 206\n",
            "TimeSinceStart : 0.6517293453216553\n",
            "Training Loss : 0.042272549122571945\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 2 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([104])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 43.0\n",
            "Eval_StdReturn : 24.915857315063477\n",
            "Eval_MaxReturn : 87.0\n",
            "Eval_MinReturn : 17.0\n",
            "Eval_AverageEpLen : 43.0\n",
            "Train_AverageReturn : 11.55555534362793\n",
            "Train_StdReturn : 4.374448776245117\n",
            "Train_MaxReturn : 21.0\n",
            "Train_MinReturn : 6.0\n",
            "Train_AverageEpLen : 11.555555555555555\n",
            "Train_EnvstepsSoFar : 310\n",
            "TimeSinceStart : 0.9686720371246338\n",
            "Training Loss : 0.057771969586610794\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 3 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([109])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 9.159090995788574\n",
            "Eval_StdReturn : 3.7534420490264893\n",
            "Eval_MaxReturn : 23.0\n",
            "Eval_MinReturn : 3.0\n",
            "Eval_AverageEpLen : 9.159090909090908\n",
            "Train_AverageReturn : 36.33333206176758\n",
            "Train_StdReturn : 12.498888969421387\n",
            "Train_MaxReturn : 54.0\n",
            "Train_MinReturn : 27.0\n",
            "Train_AverageEpLen : 36.333333333333336\n",
            "Train_EnvstepsSoFar : 419\n",
            "TimeSinceStart : 1.2811827659606934\n",
            "Training Loss : 0.07182174921035767\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 4 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([103])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 13.333333015441895\n",
            "Eval_StdReturn : 7.006346225738525\n",
            "Eval_MaxReturn : 38.0\n",
            "Eval_MinReturn : 3.0\n",
            "Eval_AverageEpLen : 13.333333333333334\n",
            "Train_AverageReturn : 6.866666793823242\n",
            "Train_StdReturn : 2.1868293285369873\n",
            "Train_MaxReturn : 11.0\n",
            "Train_MinReturn : 4.0\n",
            "Train_AverageEpLen : 6.866666666666666\n",
            "Train_EnvstepsSoFar : 522\n",
            "TimeSinceStart : 1.5886955261230469\n",
            "Training Loss : -0.12999597191810608\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 5 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([105])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 29.214284896850586\n",
            "Eval_StdReturn : 17.113813400268555\n",
            "Eval_MaxReturn : 74.0\n",
            "Eval_MinReturn : 8.0\n",
            "Eval_AverageEpLen : 29.214285714285715\n",
            "Train_AverageReturn : 15.0\n",
            "Train_StdReturn : 5.855400562286377\n",
            "Train_MaxReturn : 26.0\n",
            "Train_MinReturn : 7.0\n",
            "Train_AverageEpLen : 15.0\n",
            "Train_EnvstepsSoFar : 627\n",
            "TimeSinceStart : 1.9062883853912354\n",
            "Training Loss : 0.058433424681425095\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 6 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([102])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 25.27777862548828\n",
            "Eval_StdReturn : 17.255613327026367\n",
            "Eval_MaxReturn : 58.0\n",
            "Eval_MinReturn : 6.0\n",
            "Eval_AverageEpLen : 25.27777777777778\n",
            "Train_AverageReturn : 28.75\n",
            "Train_StdReturn : 25.469345092773438\n",
            "Train_MaxReturn : 72.0\n",
            "Train_MinReturn : 8.0\n",
            "Train_AverageEpLen : 28.75\n",
            "Train_EnvstepsSoFar : 742\n",
            "TimeSinceStart : 2.3230223655700684\n",
            "Training Loss : -0.05095653235912323\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 7 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([102])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 16.83333396911621\n",
            "Eval_StdReturn : 10.9531831741333\n",
            "Eval_MaxReturn : 57.0\n",
            "Eval_MinReturn : 4.0\n",
            "Eval_AverageEpLen : 16.833333333333332\n",
            "Train_AverageReturn : 22.0\n",
            "Train_StdReturn : 13.608820915222168\n",
            "Train_MaxReturn : 48.0\n",
            "Train_MinReturn : 8.0\n",
            "Train_AverageEpLen : 22.0\n",
            "Train_EnvstepsSoFar : 852\n",
            "TimeSinceStart : 2.7107434272766113\n",
            "Training Loss : -0.0439518541097641\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 8 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([107])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 14.655172348022461\n",
            "Eval_StdReturn : 9.90742015838623\n",
            "Eval_MaxReturn : 37.0\n",
            "Eval_MinReturn : 4.0\n",
            "Eval_AverageEpLen : 14.655172413793103\n",
            "Train_AverageReturn : 21.399999618530273\n",
            "Train_StdReturn : 11.199999809265137\n",
            "Train_MaxReturn : 35.0\n",
            "Train_MinReturn : 9.0\n",
            "Train_AverageEpLen : 21.4\n",
            "Train_EnvstepsSoFar : 959\n",
            "TimeSinceStart : 3.1110751628875732\n",
            "Training Loss : 0.0847502201795578\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 9 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([108])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 13.129032135009766\n",
            "Eval_StdReturn : 12.81063461303711\n",
            "Eval_MaxReturn : 42.0\n",
            "Eval_MinReturn : 2.0\n",
            "Eval_AverageEpLen : 13.129032258064516\n",
            "Train_AverageReturn : 8.307692527770996\n",
            "Train_StdReturn : 4.374482154846191\n",
            "Train_MaxReturn : 17.0\n",
            "Train_MinReturn : 4.0\n",
            "Train_AverageEpLen : 8.307692307692308\n",
            "Train_EnvstepsSoFar : 1067\n",
            "TimeSinceStart : 3.4987895488739014\n",
            "Training Loss : -0.021517988294363022\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 10 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 12.21212100982666\n",
            "Eval_StdReturn : 10.825777053833008\n",
            "Eval_MaxReturn : 41.0\n",
            "Eval_MinReturn : 2.0\n",
            "Eval_AverageEpLen : 12.212121212121213\n",
            "Train_AverageReturn : 11.11111068725586\n",
            "Train_StdReturn : 11.327885627746582\n",
            "Train_MaxReturn : 40.0\n",
            "Train_MinReturn : 2.0\n",
            "Train_AverageEpLen : 11.11111111111111\n",
            "Train_EnvstepsSoFar : 1167\n",
            "TimeSinceStart : 3.886411190032959\n",
            "Training Loss : 0.0025833570398390293\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 11 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([106])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 13.933333396911621\n",
            "Eval_StdReturn : 13.236145973205566\n",
            "Eval_MaxReturn : 56.0\n",
            "Eval_MinReturn : 3.0\n",
            "Eval_AverageEpLen : 13.933333333333334\n",
            "Train_AverageReturn : 15.714285850524902\n",
            "Train_StdReturn : 13.551112174987793\n",
            "Train_MaxReturn : 45.0\n",
            "Train_MinReturn : 3.0\n",
            "Train_AverageEpLen : 15.714285714285714\n",
            "Train_EnvstepsSoFar : 1277\n",
            "TimeSinceStart : 4.274616956710815\n",
            "Training Loss : -0.04611596465110779\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 12 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([103])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 40.20000076293945\n",
            "Eval_StdReturn : 31.233957290649414\n",
            "Eval_MaxReturn : 96.0\n",
            "Eval_MinReturn : 5.0\n",
            "Eval_AverageEpLen : 40.2\n",
            "Train_AverageReturn : 17.66666603088379\n",
            "Train_StdReturn : 13.682917594909668\n",
            "Train_MaxReturn : 42.0\n",
            "Train_MinReturn : 3.0\n",
            "Train_AverageEpLen : 17.666666666666668\n",
            "Train_EnvstepsSoFar : 1383\n",
            "TimeSinceStart : 4.612648010253906\n",
            "Training Loss : -0.08649756759405136\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 13 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([126])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 51.625\n",
            "Eval_StdReturn : 31.527517318725586\n",
            "Eval_MaxReturn : 107.0\n",
            "Eval_MinReturn : 13.0\n",
            "Eval_AverageEpLen : 51.625\n",
            "Train_AverageReturn : 42.0\n",
            "Train_StdReturn : 4.242640495300293\n",
            "Train_MaxReturn : 48.0\n",
            "Train_MinReturn : 39.0\n",
            "Train_AverageEpLen : 42.0\n",
            "Train_EnvstepsSoFar : 1509\n",
            "TimeSinceStart : 4.945388317108154\n",
            "Training Loss : -0.16223342716693878\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 14 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([130])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 50.125\n",
            "Eval_StdReturn : 16.736469268798828\n",
            "Eval_MaxReturn : 66.0\n",
            "Eval_MinReturn : 11.0\n",
            "Eval_AverageEpLen : 50.125\n",
            "Train_AverageReturn : 65.0\n",
            "Train_StdReturn : 18.0\n",
            "Train_MaxReturn : 83.0\n",
            "Train_MinReturn : 47.0\n",
            "Train_AverageEpLen : 65.0\n",
            "Train_EnvstepsSoFar : 1639\n",
            "TimeSinceStart : 5.271734237670898\n",
            "Training Loss : -0.04049573466181755\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 15 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([105])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 59.0\n",
            "Eval_StdReturn : 19.659603118896484\n",
            "Eval_MaxReturn : 88.0\n",
            "Eval_MinReturn : 16.0\n",
            "Eval_AverageEpLen : 59.0\n",
            "Train_AverageReturn : 51.0\n",
            "Train_StdReturn : 2.943920373916626\n",
            "Train_MaxReturn : 55.0\n",
            "Train_MinReturn : 48.0\n",
            "Train_AverageEpLen : 51.0\n",
            "Train_EnvstepsSoFar : 1792\n",
            "TimeSinceStart : 5.636390209197998\n",
            "Training Loss : -0.05140738934278488\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 16 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([140])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 61.0\n",
            "Eval_StdReturn : 4.407785415649414\n",
            "Eval_MaxReturn : 66.0\n",
            "Eval_MinReturn : 52.0\n",
            "Eval_AverageEpLen : 61.0\n",
            "Train_AverageReturn : 70.0\n",
            "Train_StdReturn : 1.0\n",
            "Train_MaxReturn : 71.0\n",
            "Train_MinReturn : 69.0\n",
            "Train_AverageEpLen : 70.0\n",
            "Train_EnvstepsSoFar : 1932\n",
            "TimeSinceStart : 5.989428520202637\n",
            "Training Loss : -0.050927020609378815\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 17 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([101])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 78.5\n",
            "Eval_StdReturn : 9.10585880279541\n",
            "Eval_MaxReturn : 94.0\n",
            "Eval_MinReturn : 63.0\n",
            "Eval_AverageEpLen : 78.5\n",
            "Train_AverageReturn : 50.5\n",
            "Train_StdReturn : 2.5\n",
            "Train_MaxReturn : 53.0\n",
            "Train_MinReturn : 48.0\n",
            "Train_AverageEpLen : 50.5\n",
            "Train_EnvstepsSoFar : 2033\n",
            "TimeSinceStart : 6.425209045410156\n",
            "Training Loss : -0.02962021715939045\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 18 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([102])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 82.83333587646484\n",
            "Eval_StdReturn : 12.863600730895996\n",
            "Eval_MaxReturn : 101.0\n",
            "Eval_MinReturn : 58.0\n",
            "Eval_AverageEpLen : 82.83333333333333\n",
            "Train_AverageReturn : 102.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 102.0\n",
            "Train_MinReturn : 102.0\n",
            "Train_AverageEpLen : 102.0\n",
            "Train_EnvstepsSoFar : 2135\n",
            "TimeSinceStart : 6.8653528690338135\n",
            "Training Loss : -0.04046843200922012\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 19 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 83.5\n",
            "Eval_StdReturn : 51.20140075683594\n",
            "Eval_MaxReturn : 148.0\n",
            "Eval_MinReturn : 8.0\n",
            "Eval_AverageEpLen : 83.5\n",
            "Train_AverageReturn : 57.5\n",
            "Train_StdReturn : 42.5\n",
            "Train_MaxReturn : 100.0\n",
            "Train_MinReturn : 15.0\n",
            "Train_AverageEpLen : 57.5\n",
            "Train_EnvstepsSoFar : 2250\n",
            "TimeSinceStart : 7.2522735595703125\n",
            "Training Loss : -0.04188079759478569\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 20 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([124])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 66.42857360839844\n",
            "Eval_StdReturn : 24.470722198486328\n",
            "Eval_MaxReturn : 82.0\n",
            "Eval_MinReturn : 7.0\n",
            "Eval_AverageEpLen : 66.42857142857143\n",
            "Train_AverageReturn : 124.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 124.0\n",
            "Train_MinReturn : 124.0\n",
            "Train_AverageEpLen : 124.0\n",
            "Train_EnvstepsSoFar : 2374\n",
            "TimeSinceStart : 7.6026451587677\n",
            "Training Loss : -0.005362664349377155\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 21 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([165])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 65.42857360839844\n",
            "Eval_StdReturn : 5.010193347930908\n",
            "Eval_MaxReturn : 71.0\n",
            "Eval_MinReturn : 57.0\n",
            "Eval_AverageEpLen : 65.42857142857143\n",
            "Train_AverageReturn : 57.66666793823242\n",
            "Train_StdReturn : 35.31131362915039\n",
            "Train_MaxReturn : 87.0\n",
            "Train_MinReturn : 8.0\n",
            "Train_AverageEpLen : 57.666666666666664\n",
            "Train_EnvstepsSoFar : 2547\n",
            "TimeSinceStart : 8.043554782867432\n",
            "Training Loss : -0.01303229108452797\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 22 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([129])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 55.5\n",
            "Eval_StdReturn : 3.872983455657959\n",
            "Eval_MaxReturn : 63.0\n",
            "Eval_MinReturn : 50.0\n",
            "Eval_AverageEpLen : 55.5\n",
            "Train_AverageReturn : 64.5\n",
            "Train_StdReturn : 2.5\n",
            "Train_MaxReturn : 67.0\n",
            "Train_MinReturn : 62.0\n",
            "Train_AverageEpLen : 64.5\n",
            "Train_EnvstepsSoFar : 2676\n",
            "TimeSinceStart : 8.41700267791748\n",
            "Training Loss : -0.16131694614887238\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 23 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([114])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 65.14286041259766\n",
            "Eval_StdReturn : 19.65726661682129\n",
            "Eval_MaxReturn : 94.0\n",
            "Eval_MinReturn : 31.0\n",
            "Eval_AverageEpLen : 65.14285714285714\n",
            "Train_AverageReturn : 57.0\n",
            "Train_StdReturn : 1.0\n",
            "Train_MaxReturn : 58.0\n",
            "Train_MinReturn : 56.0\n",
            "Train_AverageEpLen : 57.0\n",
            "Train_EnvstepsSoFar : 2790\n",
            "TimeSinceStart : 8.75907564163208\n",
            "Training Loss : 0.07007401436567307\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 24 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([161])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 49.22222137451172\n",
            "Eval_StdReturn : 22.37447738647461\n",
            "Eval_MaxReturn : 93.0\n",
            "Eval_MinReturn : 6.0\n",
            "Eval_AverageEpLen : 49.22222222222222\n",
            "Train_AverageReturn : 80.5\n",
            "Train_StdReturn : 1.5\n",
            "Train_MaxReturn : 82.0\n",
            "Train_MinReturn : 79.0\n",
            "Train_AverageEpLen : 80.5\n",
            "Train_EnvstepsSoFar : 2951\n",
            "TimeSinceStart : 9.143565654754639\n",
            "Training Loss : 0.0001781416212907061\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 25 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([123])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 34.75\n",
            "Eval_StdReturn : 16.114822387695312\n",
            "Eval_MaxReturn : 63.0\n",
            "Eval_MinReturn : 6.0\n",
            "Eval_AverageEpLen : 34.75\n",
            "Train_AverageReturn : 46.33333206176758\n",
            "Train_StdReturn : 24.115463256835938\n",
            "Train_MaxReturn : 75.0\n",
            "Train_MinReturn : 16.0\n",
            "Train_AverageEpLen : 46.333333333333336\n",
            "Train_EnvstepsSoFar : 3090\n",
            "TimeSinceStart : 9.4686119556427\n",
            "Training Loss : -0.008208396844565868\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 26 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([101])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 19.619047164916992\n",
            "Eval_StdReturn : 15.49032211303711\n",
            "Eval_MaxReturn : 52.0\n",
            "Eval_MinReturn : 4.0\n",
            "Eval_AverageEpLen : 19.61904761904762\n",
            "Train_AverageReturn : 33.66666793823242\n",
            "Train_StdReturn : 9.030811309814453\n",
            "Train_MaxReturn : 44.0\n",
            "Train_MinReturn : 22.0\n",
            "Train_AverageEpLen : 33.666666666666664\n",
            "Train_EnvstepsSoFar : 3191\n",
            "TimeSinceStart : 9.773279666900635\n",
            "Training Loss : -0.13909511268138885\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 27 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([111])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 31.30769157409668\n",
            "Eval_StdReturn : 12.028074264526367\n",
            "Eval_MaxReturn : 54.0\n",
            "Eval_MinReturn : 12.0\n",
            "Eval_AverageEpLen : 31.307692307692307\n",
            "Train_AverageReturn : 37.0\n",
            "Train_StdReturn : 10.614455223083496\n",
            "Train_MaxReturn : 45.0\n",
            "Train_MinReturn : 22.0\n",
            "Train_AverageEpLen : 37.0\n",
            "Train_EnvstepsSoFar : 3302\n",
            "TimeSinceStart : 10.15822958946228\n",
            "Training Loss : -0.08899889886379242\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 28 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([133])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 27.66666603088379\n",
            "Eval_StdReturn : 19.223827362060547\n",
            "Eval_MaxReturn : 57.0\n",
            "Eval_MinReturn : 3.0\n",
            "Eval_AverageEpLen : 27.666666666666668\n",
            "Train_AverageReturn : 27.799999237060547\n",
            "Train_StdReturn : 19.19791603088379\n",
            "Train_MaxReturn : 53.0\n",
            "Train_MinReturn : 5.0\n",
            "Train_AverageEpLen : 27.8\n",
            "Train_EnvstepsSoFar : 3441\n",
            "TimeSinceStart : 10.554343461990356\n",
            "Training Loss : 0.09447444975376129\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 29 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([106])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 40.3636360168457\n",
            "Eval_StdReturn : 21.785202026367188\n",
            "Eval_MaxReturn : 78.0\n",
            "Eval_MinReturn : 5.0\n",
            "Eval_AverageEpLen : 40.36363636363637\n",
            "Train_AverageReturn : 21.200000762939453\n",
            "Train_StdReturn : 8.61161994934082\n",
            "Train_MaxReturn : 36.0\n",
            "Train_MinReturn : 11.0\n",
            "Train_AverageEpLen : 21.2\n",
            "Train_EnvstepsSoFar : 3547\n",
            "TimeSinceStart : 10.95769715309143\n",
            "Training Loss : 0.0053013768047094345\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 30 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([103])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 81.16666412353516\n",
            "Eval_StdReturn : 40.43684768676758\n",
            "Eval_MaxReturn : 142.0\n",
            "Eval_MinReturn : 19.0\n",
            "Eval_AverageEpLen : 81.16666666666667\n",
            "Train_AverageReturn : 37.5\n",
            "Train_StdReturn : 19.032865524291992\n",
            "Train_MaxReturn : 62.0\n",
            "Train_MinReturn : 11.0\n",
            "Train_AverageEpLen : 37.5\n",
            "Train_EnvstepsSoFar : 3697\n",
            "TimeSinceStart : 11.336215019226074\n",
            "Training Loss : -0.08200660347938538\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 31 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([130])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 71.66666412353516\n",
            "Eval_StdReturn : 39.21592712402344\n",
            "Eval_MaxReturn : 119.0\n",
            "Eval_MinReturn : 10.0\n",
            "Eval_AverageEpLen : 71.66666666666667\n",
            "Train_AverageReturn : 65.0\n",
            "Train_StdReturn : 33.0\n",
            "Train_MaxReturn : 98.0\n",
            "Train_MinReturn : 32.0\n",
            "Train_AverageEpLen : 65.0\n",
            "Train_EnvstepsSoFar : 3827\n",
            "TimeSinceStart : 11.66119384765625\n",
            "Training Loss : -0.03662396967411041\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 32 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 42.29999923706055\n",
            "Eval_StdReturn : 31.660858154296875\n",
            "Eval_MaxReturn : 96.0\n",
            "Eval_MinReturn : 8.0\n",
            "Eval_AverageEpLen : 42.3\n",
            "Train_AverageReturn : 67.5\n",
            "Train_StdReturn : 32.5\n",
            "Train_MaxReturn : 100.0\n",
            "Train_MinReturn : 35.0\n",
            "Train_AverageEpLen : 67.5\n",
            "Train_EnvstepsSoFar : 3962\n",
            "TimeSinceStart : 12.0461905002594\n",
            "Training Loss : -0.1776353418827057\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 33 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([117])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 11.13888931274414\n",
            "Eval_StdReturn : 13.664944648742676\n",
            "Eval_MaxReturn : 58.0\n",
            "Eval_MinReturn : 3.0\n",
            "Eval_AverageEpLen : 11.13888888888889\n",
            "Train_AverageReturn : 36.400001525878906\n",
            "Train_StdReturn : 40.4998779296875\n",
            "Train_MaxReturn : 117.0\n",
            "Train_MinReturn : 9.0\n",
            "Train_AverageEpLen : 36.4\n",
            "Train_EnvstepsSoFar : 4144\n",
            "TimeSinceStart : 12.480546474456787\n",
            "Training Loss : -0.0451577827334404\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 34 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([101])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 14.034482955932617\n",
            "Eval_StdReturn : 13.946901321411133\n",
            "Eval_MaxReturn : 47.0\n",
            "Eval_MinReturn : 3.0\n",
            "Eval_AverageEpLen : 14.03448275862069\n",
            "Train_AverageReturn : 16.83333396911621\n",
            "Train_StdReturn : 18.667409896850586\n",
            "Train_MaxReturn : 57.0\n",
            "Train_MinReturn : 3.0\n",
            "Train_AverageEpLen : 16.833333333333332\n",
            "Train_EnvstepsSoFar : 4245\n",
            "TimeSinceStart : 12.87546443939209\n",
            "Training Loss : -0.028402134776115417\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 35 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([102])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 20.700000762939453\n",
            "Eval_StdReturn : 12.841729164123535\n",
            "Eval_MaxReturn : 50.0\n",
            "Eval_MinReturn : 4.0\n",
            "Eval_AverageEpLen : 20.7\n",
            "Train_AverageReturn : 17.0\n",
            "Train_StdReturn : 15.470401763916016\n",
            "Train_MaxReturn : 44.0\n",
            "Train_MinReturn : 4.0\n",
            "Train_AverageEpLen : 17.0\n",
            "Train_EnvstepsSoFar : 4347\n",
            "TimeSinceStart : 13.230138063430786\n",
            "Training Loss : 0.07042121142148972\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 36 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([109])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 3.612612724304199\n",
            "Eval_StdReturn : 6.387165069580078\n",
            "Eval_MaxReturn : 49.0\n",
            "Eval_MinReturn : 2.0\n",
            "Eval_AverageEpLen : 3.6126126126126126\n",
            "Train_AverageReturn : 18.83333396911621\n",
            "Train_StdReturn : 9.702520370483398\n",
            "Train_MaxReturn : 30.0\n",
            "Train_MinReturn : 4.0\n",
            "Train_AverageEpLen : 18.833333333333332\n",
            "Train_EnvstepsSoFar : 4460\n",
            "TimeSinceStart : 13.61104702949524\n",
            "Training Loss : -0.17557378113269806\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 37 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([101])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 12.470588684082031\n",
            "Eval_StdReturn : 10.018321990966797\n",
            "Eval_MaxReturn : 43.0\n",
            "Eval_MinReturn : 2.0\n",
            "Eval_AverageEpLen : 12.470588235294118\n",
            "Train_AverageReturn : 3.5833332538604736\n",
            "Train_StdReturn : 6.170607089996338\n",
            "Train_MaxReturn : 36.0\n",
            "Train_MinReturn : 2.0\n",
            "Train_AverageEpLen : 3.5833333333333335\n",
            "Train_EnvstepsSoFar : 4589\n",
            "TimeSinceStart : 14.009917259216309\n",
            "Training Loss : 0.05295133963227272\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 38 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([102])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 14.193548202514648\n",
            "Eval_StdReturn : 14.21135139465332\n",
            "Eval_MaxReturn : 48.0\n",
            "Eval_MinReturn : 4.0\n",
            "Eval_AverageEpLen : 14.193548387096774\n",
            "Train_AverageReturn : 12.777777671813965\n",
            "Train_StdReturn : 7.020252704620361\n",
            "Train_MaxReturn : 23.0\n",
            "Train_MinReturn : 2.0\n",
            "Train_AverageEpLen : 12.777777777777779\n",
            "Train_EnvstepsSoFar : 4704\n",
            "TimeSinceStart : 14.372894048690796\n",
            "Training Loss : 0.021849730983376503\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 39 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([101])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 9.714285850524902\n",
            "Eval_StdReturn : 9.189242362976074\n",
            "Eval_MaxReturn : 35.0\n",
            "Eval_MinReturn : 4.0\n",
            "Eval_AverageEpLen : 9.714285714285714\n",
            "Train_AverageReturn : 8.416666984558105\n",
            "Train_StdReturn : 7.825794219970703\n",
            "Train_MaxReturn : 31.0\n",
            "Train_MinReturn : 4.0\n",
            "Train_AverageEpLen : 8.416666666666666\n",
            "Train_EnvstepsSoFar : 4805\n",
            "TimeSinceStart : 14.679104566574097\n",
            "Training Loss : -0.00012140226317569613\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 40 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([114])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 19.31818199157715\n",
            "Eval_StdReturn : 12.16696834564209\n",
            "Eval_MaxReturn : 45.0\n",
            "Eval_MinReturn : 2.0\n",
            "Eval_AverageEpLen : 19.318181818181817\n",
            "Train_AverageReturn : 6.6315789222717285\n",
            "Train_StdReturn : 6.123384952545166\n",
            "Train_MaxReturn : 29.0\n",
            "Train_MinReturn : 4.0\n",
            "Train_AverageEpLen : 6.631578947368421\n",
            "Train_EnvstepsSoFar : 4931\n",
            "TimeSinceStart : 15.014360666275024\n",
            "Training Loss : 0.04612354189157486\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 41 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([101])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 2.0459184646606445\n",
            "Eval_StdReturn : 0.20930807292461395\n",
            "Eval_MaxReturn : 3.0\n",
            "Eval_MinReturn : 2.0\n",
            "Eval_AverageEpLen : 2.045918367346939\n",
            "Train_AverageReturn : 20.200000762939453\n",
            "Train_StdReturn : 13.120975494384766\n",
            "Train_MaxReturn : 46.0\n",
            "Train_MinReturn : 11.0\n",
            "Train_AverageEpLen : 20.2\n",
            "Train_EnvstepsSoFar : 5032\n",
            "TimeSinceStart : 15.366811513900757\n",
            "Training Loss : -0.013062949292361736\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 42 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 2.005000114440918\n",
            "Eval_StdReturn : 0.07053367048501968\n",
            "Eval_MaxReturn : 3.0\n",
            "Eval_MinReturn : 2.0\n",
            "Eval_AverageEpLen : 2.005\n",
            "Train_AverageReturn : 2.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 2.0\n",
            "Train_MinReturn : 2.0\n",
            "Train_AverageEpLen : 2.0\n",
            "Train_EnvstepsSoFar : 5132\n",
            "TimeSinceStart : 15.730973482131958\n",
            "Training Loss : -0.04555520415306091\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 43 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 2.0202019214630127\n",
            "Eval_StdReturn : 0.14069078862667084\n",
            "Eval_MaxReturn : 3.0\n",
            "Eval_MinReturn : 2.0\n",
            "Eval_AverageEpLen : 2.0202020202020203\n",
            "Train_AverageReturn : 2.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 2.0\n",
            "Train_MinReturn : 2.0\n",
            "Train_AverageEpLen : 2.0\n",
            "Train_EnvstepsSoFar : 5232\n",
            "TimeSinceStart : 16.120299100875854\n",
            "Training Loss : -0.06118655204772949\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 44 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([101])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 2.7094595432281494\n",
            "Eval_StdReturn : 0.4686579406261444\n",
            "Eval_MaxReturn : 4.0\n",
            "Eval_MinReturn : 2.0\n",
            "Eval_AverageEpLen : 2.7094594594594597\n",
            "Train_AverageReturn : 2.0199999809265137\n",
            "Train_StdReturn : 0.14000000059604645\n",
            "Train_MaxReturn : 3.0\n",
            "Train_MinReturn : 2.0\n",
            "Train_AverageEpLen : 2.02\n",
            "Train_EnvstepsSoFar : 5333\n",
            "TimeSinceStart : 16.476187467575073\n",
            "Training Loss : 0.05825304239988327\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 45 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([101])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 12.363636016845703\n",
            "Eval_StdReturn : 11.538651466369629\n",
            "Eval_MaxReturn : 38.0\n",
            "Eval_MinReturn : 3.0\n",
            "Eval_AverageEpLen : 12.363636363636363\n",
            "Train_AverageReturn : 2.5897436141967773\n",
            "Train_StdReturn : 0.4918801486492157\n",
            "Train_MaxReturn : 3.0\n",
            "Train_MinReturn : 2.0\n",
            "Train_AverageEpLen : 2.58974358974359\n",
            "Train_EnvstepsSoFar : 5434\n",
            "TimeSinceStart : 16.801554679870605\n",
            "Training Loss : 0.0392279252409935\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 46 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([126])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 27.200000762939453\n",
            "Eval_StdReturn : 10.734368324279785\n",
            "Eval_MaxReturn : 41.0\n",
            "Eval_MinReturn : 8.0\n",
            "Eval_AverageEpLen : 27.2\n",
            "Train_AverageReturn : 21.0\n",
            "Train_StdReturn : 10.832051277160645\n",
            "Train_MaxReturn : 38.0\n",
            "Train_MinReturn : 11.0\n",
            "Train_AverageEpLen : 21.0\n",
            "Train_EnvstepsSoFar : 5560\n",
            "TimeSinceStart : 17.132941246032715\n",
            "Training Loss : 0.09633030742406845\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 47 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([120])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 21.473684310913086\n",
            "Eval_StdReturn : 16.19411277770996\n",
            "Eval_MaxReturn : 45.0\n",
            "Eval_MinReturn : 4.0\n",
            "Eval_AverageEpLen : 21.473684210526315\n",
            "Train_AverageReturn : 30.0\n",
            "Train_StdReturn : 8.154753684997559\n",
            "Train_MaxReturn : 38.0\n",
            "Train_MinReturn : 18.0\n",
            "Train_AverageEpLen : 30.0\n",
            "Train_EnvstepsSoFar : 5680\n",
            "TimeSinceStart : 17.443883180618286\n",
            "Training Loss : -0.006474737543612719\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 48 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([130])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 37.54545593261719\n",
            "Eval_StdReturn : 15.732789039611816\n",
            "Eval_MaxReturn : 55.0\n",
            "Eval_MinReturn : 5.0\n",
            "Eval_AverageEpLen : 37.54545454545455\n",
            "Train_AverageReturn : 32.5\n",
            "Train_StdReturn : 15.628499984741211\n",
            "Train_MaxReturn : 46.0\n",
            "Train_MinReturn : 6.0\n",
            "Train_AverageEpLen : 32.5\n",
            "Train_EnvstepsSoFar : 5810\n",
            "TimeSinceStart : 17.768078565597534\n",
            "Training Loss : -0.04755564033985138\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 49 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([139])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 27.866666793823242\n",
            "Eval_StdReturn : 12.365903854370117\n",
            "Eval_MaxReturn : 44.0\n",
            "Eval_MinReturn : 6.0\n",
            "Eval_AverageEpLen : 27.866666666666667\n",
            "Train_AverageReturn : 46.33333206176758\n",
            "Train_StdReturn : 3.2998316287994385\n",
            "Train_MaxReturn : 50.0\n",
            "Train_MinReturn : 42.0\n",
            "Train_AverageEpLen : 46.333333333333336\n",
            "Train_EnvstepsSoFar : 5949\n",
            "TimeSinceStart : 18.173344612121582\n",
            "Training Loss : -0.1931818723678589\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 50 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([107])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 14.88888931274414\n",
            "Eval_StdReturn : 12.440475463867188\n",
            "Eval_MaxReturn : 49.0\n",
            "Eval_MinReturn : 4.0\n",
            "Eval_AverageEpLen : 14.88888888888889\n",
            "Train_AverageReturn : 21.399999618530273\n",
            "Train_StdReturn : 11.306634902954102\n",
            "Train_MaxReturn : 36.0\n",
            "Train_MinReturn : 10.0\n",
            "Train_AverageEpLen : 21.4\n",
            "Train_EnvstepsSoFar : 6056\n",
            "TimeSinceStart : 18.503092527389526\n",
            "Training Loss : 0.0013520115753635764\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 51 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([105])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 10.945945739746094\n",
            "Eval_StdReturn : 8.529585838317871\n",
            "Eval_MaxReturn : 44.0\n",
            "Eval_MinReturn : 4.0\n",
            "Eval_AverageEpLen : 10.945945945945946\n",
            "Train_AverageReturn : 15.0\n",
            "Train_StdReturn : 11.338933944702148\n",
            "Train_MaxReturn : 42.0\n",
            "Train_MinReturn : 6.0\n",
            "Train_AverageEpLen : 15.0\n",
            "Train_EnvstepsSoFar : 6161\n",
            "TimeSinceStart : 18.8205783367157\n",
            "Training Loss : -0.15378758311271667\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 52 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 11.941176414489746\n",
            "Eval_StdReturn : 8.804882049560547\n",
            "Eval_MaxReturn : 37.0\n",
            "Eval_MinReturn : 4.0\n",
            "Eval_AverageEpLen : 11.941176470588236\n",
            "Train_AverageReturn : 6.5625\n",
            "Train_StdReturn : 2.621277093887329\n",
            "Train_MaxReturn : 14.0\n",
            "Train_MinReturn : 4.0\n",
            "Train_AverageEpLen : 6.5625\n",
            "Train_EnvstepsSoFar : 6266\n",
            "TimeSinceStart : 19.15115785598755\n",
            "Training Loss : 0.11846727132797241\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 53 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([103])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 42.70000076293945\n",
            "Eval_StdReturn : 13.379462242126465\n",
            "Eval_MaxReturn : 57.0\n",
            "Eval_MinReturn : 8.0\n",
            "Eval_AverageEpLen : 42.7\n",
            "Train_AverageReturn : 9.363636016845703\n",
            "Train_StdReturn : 4.02882194519043\n",
            "Train_MaxReturn : 16.0\n",
            "Train_MinReturn : 5.0\n",
            "Train_AverageEpLen : 9.363636363636363\n",
            "Train_EnvstepsSoFar : 6369\n",
            "TimeSinceStart : 19.513303756713867\n",
            "Training Loss : -0.029864061623811722\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 54 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([140])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 67.0\n",
            "Eval_StdReturn : 7.505553245544434\n",
            "Eval_MaxReturn : 76.0\n",
            "Eval_MinReturn : 54.0\n",
            "Eval_AverageEpLen : 67.0\n",
            "Train_AverageReturn : 46.66666793823242\n",
            "Train_StdReturn : 2.054804801940918\n",
            "Train_MaxReturn : 49.0\n",
            "Train_MinReturn : 44.0\n",
            "Train_AverageEpLen : 46.666666666666664\n",
            "Train_EnvstepsSoFar : 6509\n",
            "TimeSinceStart : 19.839250087738037\n",
            "Training Loss : 0.01449836976826191\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 55 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([137])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 68.66666412353516\n",
            "Eval_StdReturn : 4.422166347503662\n",
            "Eval_MaxReturn : 78.0\n",
            "Eval_MinReturn : 66.0\n",
            "Eval_AverageEpLen : 68.66666666666667\n",
            "Train_AverageReturn : 68.5\n",
            "Train_StdReturn : 3.5\n",
            "Train_MaxReturn : 72.0\n",
            "Train_MinReturn : 65.0\n",
            "Train_AverageEpLen : 68.5\n",
            "Train_EnvstepsSoFar : 6646\n",
            "TimeSinceStart : 20.165032863616943\n",
            "Training Loss : -0.057496245950460434\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 56 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([135])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 99.4000015258789\n",
            "Eval_StdReturn : 18.006664276123047\n",
            "Eval_MaxReturn : 132.0\n",
            "Eval_MinReturn : 79.0\n",
            "Eval_AverageEpLen : 99.4\n",
            "Train_AverageReturn : 67.5\n",
            "Train_StdReturn : 12.5\n",
            "Train_MaxReturn : 80.0\n",
            "Train_MinReturn : 55.0\n",
            "Train_AverageEpLen : 67.5\n",
            "Train_EnvstepsSoFar : 6781\n",
            "TimeSinceStart : 20.537259340286255\n",
            "Training Loss : 0.03710108995437622\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 57 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([141])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 90.5999984741211\n",
            "Eval_StdReturn : 16.316864013671875\n",
            "Eval_MaxReturn : 122.0\n",
            "Eval_MinReturn : 78.0\n",
            "Eval_AverageEpLen : 90.6\n",
            "Train_AverageReturn : 70.5\n",
            "Train_StdReturn : 25.5\n",
            "Train_MaxReturn : 96.0\n",
            "Train_MinReturn : 45.0\n",
            "Train_AverageEpLen : 70.5\n",
            "Train_EnvstepsSoFar : 6922\n",
            "TimeSinceStart : 20.889294862747192\n",
            "Training Loss : 0.015047705732285976\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 58 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([107])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 64.0\n",
            "Eval_StdReturn : 6.480740547180176\n",
            "Eval_MaxReturn : 76.0\n",
            "Eval_MinReturn : 56.0\n",
            "Eval_AverageEpLen : 64.0\n",
            "Train_AverageReturn : 107.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 107.0\n",
            "Train_MinReturn : 107.0\n",
            "Train_AverageEpLen : 107.0\n",
            "Train_EnvstepsSoFar : 7029\n",
            "TimeSinceStart : 21.227374792099\n",
            "Training Loss : -0.12027929723262787\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 59 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([117])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 5.840579509735107\n",
            "Eval_StdReturn : 1.9899981021881104\n",
            "Eval_MaxReturn : 13.0\n",
            "Eval_MinReturn : 4.0\n",
            "Eval_AverageEpLen : 5.840579710144928\n",
            "Train_AverageReturn : 51.66666793823242\n",
            "Train_StdReturn : 10.338708877563477\n",
            "Train_MaxReturn : 63.0\n",
            "Train_MinReturn : 38.0\n",
            "Train_AverageEpLen : 51.666666666666664\n",
            "Train_EnvstepsSoFar : 7184\n",
            "TimeSinceStart : 21.582362174987793\n",
            "Training Loss : -0.05203244835138321\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 60 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([102])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 10.605262756347656\n",
            "Eval_StdReturn : 4.568423748016357\n",
            "Eval_MaxReturn : 22.0\n",
            "Eval_MinReturn : 5.0\n",
            "Eval_AverageEpLen : 10.605263157894736\n",
            "Train_AverageReturn : 6.0\n",
            "Train_StdReturn : 2.400980234146118\n",
            "Train_MaxReturn : 13.0\n",
            "Train_MinReturn : 4.0\n",
            "Train_AverageEpLen : 6.0\n",
            "Train_EnvstepsSoFar : 7286\n",
            "TimeSinceStart : 21.930217266082764\n",
            "Training Loss : -0.013408600352704525\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 61 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([104])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 45.77777862548828\n",
            "Eval_StdReturn : 30.176435470581055\n",
            "Eval_MaxReturn : 91.0\n",
            "Eval_MinReturn : 8.0\n",
            "Eval_AverageEpLen : 45.77777777777778\n",
            "Train_AverageReturn : 11.55555534362793\n",
            "Train_StdReturn : 3.685138702392578\n",
            "Train_MaxReturn : 18.0\n",
            "Train_MinReturn : 6.0\n",
            "Train_AverageEpLen : 11.555555555555555\n",
            "Train_EnvstepsSoFar : 7390\n",
            "TimeSinceStart : 22.324766635894775\n",
            "Training Loss : -0.14808185398578644\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 62 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 68.5\n",
            "Eval_StdReturn : 2.0615527629852295\n",
            "Eval_MaxReturn : 72.0\n",
            "Eval_MinReturn : 66.0\n",
            "Eval_AverageEpLen : 68.5\n",
            "Train_AverageReturn : 100.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 100.0\n",
            "Train_MinReturn : 100.0\n",
            "Train_AverageEpLen : 100.0\n",
            "Train_EnvstepsSoFar : 7490\n",
            "TimeSinceStart : 22.697158336639404\n",
            "Training Loss : 0.040604542940855026\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 63 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([129])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 55.25\n",
            "Eval_StdReturn : 2.817356824874878\n",
            "Eval_MaxReturn : 58.0\n",
            "Eval_MinReturn : 50.0\n",
            "Eval_AverageEpLen : 55.25\n",
            "Train_AverageReturn : 64.5\n",
            "Train_StdReturn : 6.5\n",
            "Train_MaxReturn : 71.0\n",
            "Train_MinReturn : 58.0\n",
            "Train_AverageEpLen : 64.5\n",
            "Train_EnvstepsSoFar : 7619\n",
            "TimeSinceStart : 23.06720471382141\n",
            "Training Loss : 0.01877599209547043\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 64 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([110])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 44.55555725097656\n",
            "Eval_StdReturn : 6.41372013092041\n",
            "Eval_MaxReturn : 50.0\n",
            "Eval_MinReturn : 33.0\n",
            "Eval_AverageEpLen : 44.55555555555556\n",
            "Train_AverageReturn : 55.0\n",
            "Train_StdReturn : 2.0\n",
            "Train_MaxReturn : 57.0\n",
            "Train_MinReturn : 53.0\n",
            "Train_AverageEpLen : 55.0\n",
            "Train_EnvstepsSoFar : 7729\n",
            "TimeSinceStart : 23.381678104400635\n",
            "Training Loss : 0.029829133301973343\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 65 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 42.29999923706055\n",
            "Eval_StdReturn : 5.040833473205566\n",
            "Eval_MaxReturn : 47.0\n",
            "Eval_MinReturn : 33.0\n",
            "Eval_AverageEpLen : 42.3\n",
            "Train_AverageReturn : 50.0\n",
            "Train_StdReturn : 3.0\n",
            "Train_MaxReturn : 53.0\n",
            "Train_MinReturn : 47.0\n",
            "Train_AverageEpLen : 50.0\n",
            "Train_EnvstepsSoFar : 7829\n",
            "TimeSinceStart : 23.680171728134155\n",
            "Training Loss : 0.03822822868824005\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 66 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([119])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 47.44444274902344\n",
            "Eval_StdReturn : 8.111872673034668\n",
            "Eval_MaxReturn : 57.0\n",
            "Eval_MinReturn : 31.0\n",
            "Eval_AverageEpLen : 47.44444444444444\n",
            "Train_AverageReturn : 39.66666793823242\n",
            "Train_StdReturn : 7.586537837982178\n",
            "Train_MaxReturn : 50.0\n",
            "Train_MinReturn : 32.0\n",
            "Train_AverageEpLen : 39.666666666666664\n",
            "Train_EnvstepsSoFar : 7948\n",
            "TimeSinceStart : 24.06560492515564\n",
            "Training Loss : 0.05967605859041214\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 67 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([102])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 51.375\n",
            "Eval_StdReturn : 5.633327007293701\n",
            "Eval_MaxReturn : 62.0\n",
            "Eval_MinReturn : 44.0\n",
            "Eval_AverageEpLen : 51.375\n",
            "Train_AverageReturn : 51.0\n",
            "Train_StdReturn : 1.0\n",
            "Train_MaxReturn : 52.0\n",
            "Train_MinReturn : 50.0\n",
            "Train_AverageEpLen : 51.0\n",
            "Train_EnvstepsSoFar : 8050\n",
            "TimeSinceStart : 24.376875162124634\n",
            "Training Loss : -0.05032375827431679\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 68 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([116])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 60.57143020629883\n",
            "Eval_StdReturn : 7.247800350189209\n",
            "Eval_MaxReturn : 74.0\n",
            "Eval_MinReturn : 54.0\n",
            "Eval_AverageEpLen : 60.57142857142857\n",
            "Train_AverageReturn : 58.0\n",
            "Train_StdReturn : 1.0\n",
            "Train_MaxReturn : 59.0\n",
            "Train_MinReturn : 57.0\n",
            "Train_AverageEpLen : 58.0\n",
            "Train_EnvstepsSoFar : 8166\n",
            "TimeSinceStart : 24.696975469589233\n",
            "Training Loss : 0.006169592496007681\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 69 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([119])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 55.875\n",
            "Eval_StdReturn : 4.754931449890137\n",
            "Eval_MaxReturn : 63.0\n",
            "Eval_MinReturn : 49.0\n",
            "Eval_AverageEpLen : 55.875\n",
            "Train_AverageReturn : 59.5\n",
            "Train_StdReturn : 0.5\n",
            "Train_MaxReturn : 60.0\n",
            "Train_MinReturn : 59.0\n",
            "Train_AverageEpLen : 59.5\n",
            "Train_EnvstepsSoFar : 8285\n",
            "TimeSinceStart : 25.079223155975342\n",
            "Training Loss : 0.029886098578572273\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 70 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([105])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 50.5\n",
            "Eval_StdReturn : 2.1794495582580566\n",
            "Eval_MaxReturn : 54.0\n",
            "Eval_MinReturn : 47.0\n",
            "Eval_AverageEpLen : 50.5\n",
            "Train_AverageReturn : 52.5\n",
            "Train_StdReturn : 3.5\n",
            "Train_MaxReturn : 56.0\n",
            "Train_MinReturn : 49.0\n",
            "Train_AverageEpLen : 52.5\n",
            "Train_EnvstepsSoFar : 8390\n",
            "TimeSinceStart : 25.480193376541138\n",
            "Training Loss : -0.019259013235569\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 71 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([111])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 75.0\n",
            "Eval_StdReturn : 7.187952995300293\n",
            "Eval_MaxReturn : 82.0\n",
            "Eval_MinReturn : 61.0\n",
            "Eval_AverageEpLen : 75.0\n",
            "Train_AverageReturn : 55.5\n",
            "Train_StdReturn : 3.5\n",
            "Train_MaxReturn : 59.0\n",
            "Train_MinReturn : 52.0\n",
            "Train_AverageEpLen : 55.5\n",
            "Train_EnvstepsSoFar : 8501\n",
            "TimeSinceStart : 25.902634620666504\n",
            "Training Loss : -0.09910668432712555\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 72 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([145])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 92.4000015258789\n",
            "Eval_StdReturn : 47.5083122253418\n",
            "Eval_MaxReturn : 166.0\n",
            "Eval_MinReturn : 26.0\n",
            "Eval_AverageEpLen : 92.4\n",
            "Train_AverageReturn : 72.5\n",
            "Train_StdReturn : 0.5\n",
            "Train_MaxReturn : 73.0\n",
            "Train_MinReturn : 72.0\n",
            "Train_AverageEpLen : 72.5\n",
            "Train_EnvstepsSoFar : 8646\n",
            "TimeSinceStart : 26.28608536720276\n",
            "Training Loss : 0.0582345649600029\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 73 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([162])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 73.5\n",
            "Eval_StdReturn : 11.557825088500977\n",
            "Eval_MaxReturn : 91.0\n",
            "Eval_MinReturn : 54.0\n",
            "Eval_AverageEpLen : 73.5\n",
            "Train_AverageReturn : 81.0\n",
            "Train_StdReturn : 2.0\n",
            "Train_MaxReturn : 83.0\n",
            "Train_MinReturn : 79.0\n",
            "Train_AverageEpLen : 81.0\n",
            "Train_EnvstepsSoFar : 8808\n",
            "TimeSinceStart : 26.635539531707764\n",
            "Training Loss : 0.03675198182463646\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 74 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([170])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 60.0\n",
            "Eval_StdReturn : 36.488746643066406\n",
            "Eval_MaxReturn : 93.0\n",
            "Eval_MinReturn : 3.0\n",
            "Eval_AverageEpLen : 60.0\n",
            "Train_AverageReturn : 85.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 85.0\n",
            "Train_MinReturn : 85.0\n",
            "Train_AverageEpLen : 85.0\n",
            "Train_EnvstepsSoFar : 8978\n",
            "TimeSinceStart : 27.022069215774536\n",
            "Training Loss : 0.018966281786561012\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 75 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([145])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 36.58333206176758\n",
            "Eval_StdReturn : 32.05583190917969\n",
            "Eval_MaxReturn : 76.0\n",
            "Eval_MinReturn : 3.0\n",
            "Eval_AverageEpLen : 36.583333333333336\n",
            "Train_AverageReturn : 72.5\n",
            "Train_StdReturn : 1.5\n",
            "Train_MaxReturn : 74.0\n",
            "Train_MinReturn : 71.0\n",
            "Train_AverageEpLen : 72.5\n",
            "Train_EnvstepsSoFar : 9123\n",
            "TimeSinceStart : 27.383837699890137\n",
            "Training Loss : 0.09747175872325897\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 76 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([137])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 68.85713958740234\n",
            "Eval_StdReturn : 58.57700729370117\n",
            "Eval_MaxReturn : 162.0\n",
            "Eval_MinReturn : 4.0\n",
            "Eval_AverageEpLen : 68.85714285714286\n",
            "Train_AverageReturn : 14.699999809265137\n",
            "Train_StdReturn : 22.004772186279297\n",
            "Train_MaxReturn : 68.0\n",
            "Train_MinReturn : 3.0\n",
            "Train_AverageEpLen : 14.7\n",
            "Train_EnvstepsSoFar : 9270\n",
            "TimeSinceStart : 27.7457275390625\n",
            "Training Loss : -0.010009897872805595\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 77 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([111])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 75.0\n",
            "Eval_StdReturn : 37.59432601928711\n",
            "Eval_MaxReturn : 131.0\n",
            "Eval_MinReturn : 32.0\n",
            "Eval_AverageEpLen : 75.0\n",
            "Train_AverageReturn : 111.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 111.0\n",
            "Train_MinReturn : 111.0\n",
            "Train_AverageEpLen : 111.0\n",
            "Train_EnvstepsSoFar : 9381\n",
            "TimeSinceStart : 28.137036085128784\n",
            "Training Loss : -0.023789290338754654\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 78 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([136])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 107.0\n",
            "Eval_StdReturn : 41.29890823364258\n",
            "Eval_MaxReturn : 158.0\n",
            "Eval_MinReturn : 50.0\n",
            "Eval_AverageEpLen : 107.0\n",
            "Train_AverageReturn : 136.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 136.0\n",
            "Train_MinReturn : 136.0\n",
            "Train_AverageEpLen : 136.0\n",
            "Train_EnvstepsSoFar : 9517\n",
            "TimeSinceStart : 28.61035919189453\n",
            "Training Loss : -0.051879558712244034\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 79 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([171])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 135.5\n",
            "Eval_StdReturn : 60.027076721191406\n",
            "Eval_MaxReturn : 186.0\n",
            "Eval_MinReturn : 33.0\n",
            "Eval_AverageEpLen : 135.5\n",
            "Train_AverageReturn : 171.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 171.0\n",
            "Train_MinReturn : 171.0\n",
            "Train_AverageEpLen : 171.0\n",
            "Train_EnvstepsSoFar : 9688\n",
            "TimeSinceStart : 29.03542947769165\n",
            "Training Loss : 0.06370019167661667\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 80 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([113])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 105.5\n",
            "Eval_StdReturn : 3.640054941177368\n",
            "Eval_MaxReturn : 111.0\n",
            "Eval_MinReturn : 101.0\n",
            "Eval_AverageEpLen : 105.5\n",
            "Train_AverageReturn : 37.66666793823242\n",
            "Train_StdReturn : 25.31578254699707\n",
            "Train_MaxReturn : 73.0\n",
            "Train_MinReturn : 15.0\n",
            "Train_AverageEpLen : 37.666666666666664\n",
            "Train_EnvstepsSoFar : 9801\n",
            "TimeSinceStart : 29.356142044067383\n",
            "Training Loss : -0.05338108912110329\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 81 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([106])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 41.818180084228516\n",
            "Eval_StdReturn : 30.16565704345703\n",
            "Eval_MaxReturn : 70.0\n",
            "Eval_MinReturn : 2.0\n",
            "Eval_AverageEpLen : 41.81818181818182\n",
            "Train_AverageReturn : 106.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 106.0\n",
            "Train_MinReturn : 106.0\n",
            "Train_AverageEpLen : 106.0\n",
            "Train_EnvstepsSoFar : 9907\n",
            "TimeSinceStart : 29.68386173248291\n",
            "Training Loss : -0.02306307666003704\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 82 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([130])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 8.416666984558105\n",
            "Eval_StdReturn : 15.255918502807617\n",
            "Eval_MaxReturn : 48.0\n",
            "Eval_MinReturn : 2.0\n",
            "Eval_AverageEpLen : 8.416666666666666\n",
            "Train_AverageReturn : 33.5\n",
            "Train_StdReturn : 31.53173065185547\n",
            "Train_MaxReturn : 67.0\n",
            "Train_MinReturn : 2.0\n",
            "Train_AverageEpLen : 33.5\n",
            "Train_EnvstepsSoFar : 10041\n",
            "TimeSinceStart : 30.050103664398193\n",
            "Training Loss : 0.08876112848520279\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 83 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([108])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 52.875\n",
            "Eval_StdReturn : 3.9191038608551025\n",
            "Eval_MaxReturn : 59.0\n",
            "Eval_MinReturn : 47.0\n",
            "Eval_AverageEpLen : 52.875\n",
            "Train_AverageReturn : 9.076923370361328\n",
            "Train_StdReturn : 16.76287841796875\n",
            "Train_MaxReturn : 54.0\n",
            "Train_MinReturn : 2.0\n",
            "Train_AverageEpLen : 9.076923076923077\n",
            "Train_EnvstepsSoFar : 10159\n",
            "TimeSinceStart : 30.379148483276367\n",
            "Training Loss : -0.13064223527908325\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 84 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([102])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 53.625\n",
            "Eval_StdReturn : 1.8666480779647827\n",
            "Eval_MaxReturn : 57.0\n",
            "Eval_MinReturn : 51.0\n",
            "Eval_AverageEpLen : 53.625\n",
            "Train_AverageReturn : 49.66666793823242\n",
            "Train_StdReturn : 1.885617971420288\n",
            "Train_MaxReturn : 51.0\n",
            "Train_MinReturn : 47.0\n",
            "Train_AverageEpLen : 49.666666666666664\n",
            "Train_EnvstepsSoFar : 10308\n",
            "TimeSinceStart : 30.722166061401367\n",
            "Training Loss : -0.0494028739631176\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 85 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([123])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 266.25\n",
            "Eval_StdReturn : 312.9851379394531\n",
            "Eval_MaxReturn : 808.0\n",
            "Eval_MinReturn : 69.0\n",
            "Eval_AverageEpLen : 266.25\n",
            "Train_AverageReturn : 61.5\n",
            "Train_StdReturn : 4.5\n",
            "Train_MaxReturn : 66.0\n",
            "Train_MinReturn : 57.0\n",
            "Train_AverageEpLen : 61.5\n",
            "Train_EnvstepsSoFar : 10431\n",
            "TimeSinceStart : 31.51284432411194\n",
            "Training Loss : 0.006305361166596413\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 86 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 549.5\n",
            "Eval_StdReturn : 450.5\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 99.0\n",
            "Eval_AverageEpLen : 549.5\n",
            "Train_AverageReturn : 549.0\n",
            "Train_StdReturn : 451.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 98.0\n",
            "Train_AverageEpLen : 549.0\n",
            "Train_EnvstepsSoFar : 11529\n",
            "TimeSinceStart : 32.82272148132324\n",
            "Training Loss : -0.0075930445455014706\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 87 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 12529\n",
            "TimeSinceStart : 34.06617283821106\n",
            "Training Loss : -0.013895412907004356\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 88 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 420.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 420.0\n",
            "Eval_MinReturn : 420.0\n",
            "Eval_AverageEpLen : 420.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 13529\n",
            "TimeSinceStart : 34.94970655441284\n",
            "Training Loss : 0.004860969725996256\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 89 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([701])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 481.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 481.0\n",
            "Eval_MinReturn : 481.0\n",
            "Eval_AverageEpLen : 481.0\n",
            "Train_AverageReturn : 701.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 701.0\n",
            "Train_MinReturn : 701.0\n",
            "Train_AverageEpLen : 701.0\n",
            "Train_EnvstepsSoFar : 14230\n",
            "TimeSinceStart : 35.73855638504028\n",
            "Training Loss : -0.05038381367921829\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 90 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([830])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 222.0\n",
            "Eval_StdReturn : 9.0\n",
            "Eval_MaxReturn : 231.0\n",
            "Eval_MinReturn : 213.0\n",
            "Eval_AverageEpLen : 222.0\n",
            "Train_AverageReturn : 830.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 830.0\n",
            "Train_MinReturn : 830.0\n",
            "Train_AverageEpLen : 830.0\n",
            "Train_EnvstepsSoFar : 15060\n",
            "TimeSinceStart : 36.5421826839447\n",
            "Training Loss : 0.04442765936255455\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 91 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([304])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 172.0\n",
            "Eval_StdReturn : 50.405025482177734\n",
            "Eval_MaxReturn : 243.0\n",
            "Eval_MinReturn : 131.0\n",
            "Eval_AverageEpLen : 172.0\n",
            "Train_AverageReturn : 304.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 304.0\n",
            "Train_MinReturn : 304.0\n",
            "Train_AverageEpLen : 304.0\n",
            "Train_EnvstepsSoFar : 15364\n",
            "TimeSinceStart : 37.01080918312073\n",
            "Training Loss : 0.03833000734448433\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 92 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([174])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 653.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 653.0\n",
            "Eval_MinReturn : 653.0\n",
            "Eval_AverageEpLen : 653.0\n",
            "Train_AverageReturn : 174.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 174.0\n",
            "Train_MinReturn : 174.0\n",
            "Train_AverageEpLen : 174.0\n",
            "Train_EnvstepsSoFar : 15538\n",
            "TimeSinceStart : 37.6022834777832\n",
            "Training Loss : -0.09461922198534012\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 93 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([547])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 472.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 472.0\n",
            "Eval_MinReturn : 472.0\n",
            "Eval_AverageEpLen : 472.0\n",
            "Train_AverageReturn : 547.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 547.0\n",
            "Train_MinReturn : 547.0\n",
            "Train_AverageEpLen : 547.0\n",
            "Train_EnvstepsSoFar : 16085\n",
            "TimeSinceStart : 38.34773659706116\n",
            "Training Loss : 0.004462496843189001\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 94 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([617])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 379.5\n",
            "Eval_StdReturn : 108.5\n",
            "Eval_MaxReturn : 488.0\n",
            "Eval_MinReturn : 271.0\n",
            "Eval_AverageEpLen : 379.5\n",
            "Train_AverageReturn : 617.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 617.0\n",
            "Train_MinReturn : 617.0\n",
            "Train_AverageEpLen : 617.0\n",
            "Train_EnvstepsSoFar : 16702\n",
            "TimeSinceStart : 39.24307084083557\n",
            "Training Loss : 0.00334872561506927\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 95 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([403])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 257.5\n",
            "Eval_StdReturn : 9.5\n",
            "Eval_MaxReturn : 267.0\n",
            "Eval_MinReturn : 248.0\n",
            "Eval_AverageEpLen : 257.5\n",
            "Train_AverageReturn : 403.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 403.0\n",
            "Train_MinReturn : 403.0\n",
            "Train_AverageEpLen : 403.0\n",
            "Train_EnvstepsSoFar : 17105\n",
            "TimeSinceStart : 39.8025279045105\n",
            "Training Loss : -0.02697041817009449\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 96 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([261])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 346.0\n",
            "Eval_StdReturn : 27.0\n",
            "Eval_MaxReturn : 373.0\n",
            "Eval_MinReturn : 319.0\n",
            "Eval_AverageEpLen : 346.0\n",
            "Train_AverageReturn : 261.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 261.0\n",
            "Train_MinReturn : 261.0\n",
            "Train_AverageEpLen : 261.0\n",
            "Train_EnvstepsSoFar : 17366\n",
            "TimeSinceStart : 40.37279295921326\n",
            "Training Loss : 0.0174399521201849\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 97 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([309])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 443.0\n",
            "Eval_StdReturn : 84.0\n",
            "Eval_MaxReturn : 527.0\n",
            "Eval_MinReturn : 359.0\n",
            "Eval_AverageEpLen : 443.0\n",
            "Train_AverageReturn : 309.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 309.0\n",
            "Train_MinReturn : 309.0\n",
            "Train_AverageEpLen : 309.0\n",
            "Train_EnvstepsSoFar : 17675\n",
            "TimeSinceStart : 41.11332583427429\n",
            "Training Loss : 0.017182033509016037\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 98 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([356])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 485.0\n",
            "Eval_StdReturn : 478.0\n",
            "Eval_MaxReturn : 963.0\n",
            "Eval_MinReturn : 7.0\n",
            "Eval_AverageEpLen : 485.0\n",
            "Train_AverageReturn : 356.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 356.0\n",
            "Train_MinReturn : 356.0\n",
            "Train_AverageEpLen : 356.0\n",
            "Train_EnvstepsSoFar : 18031\n",
            "TimeSinceStart : 42.077966928482056\n",
            "Training Loss : -0.017157310619950294\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 99 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([387])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 132.25\n",
            "Eval_StdReturn : 125.66100311279297\n",
            "Eval_MaxReturn : 300.0\n",
            "Eval_MinReturn : 7.0\n",
            "Eval_AverageEpLen : 132.25\n",
            "Train_AverageReturn : 387.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 387.0\n",
            "Train_MinReturn : 387.0\n",
            "Train_AverageEpLen : 387.0\n",
            "Train_EnvstepsSoFar : 18418\n",
            "TimeSinceStart : 42.73561191558838\n",
            "Training Loss : -0.036828286945819855\n",
            "Initial_DataCollection_AverageReturn : 7.4285712242126465\n",
            "Done logging...\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python cs285/scripts/run_hw2.py --env_name InvertedPendulum-v2 \\\n",
        "--ep_len 1000 --discount 0.9 -n 100 -l 2 -s 64 -b 100 -lr 0.05 -rtg \\\n",
        "--exp_name q2_b100_r05"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbHnyB5enSR7",
        "outputId": "392a82cd-d37b-4f58-a6f1-42a5c08c2cac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "########################\n",
            "logging outputs to  /content/gdrive/My Drive/cs285_f2021/DRL_policy_grads/cs285/scripts/../../data/q2_b120_r03_InvertedPendulum-v2_06-02-2022_17-31-34\n",
            "########################\n",
            "Using GPU id 0\n",
            "Sequential(\n",
            "  (0): Linear(in_features=4, out_features=64, bias=True)\n",
            "  (1): Tanh()\n",
            "  (2): Linear(in_features=64, out_features=64, bias=True)\n",
            "  (3): Tanh()\n",
            "  (4): Linear(in_features=64, out_features=1, bias=True)\n",
            "  (5): Identity()\n",
            ")\n",
            "\n",
            "\n",
            "********** Iteration 0 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([121])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 19.619047164916992\n",
            "Eval_StdReturn : 8.008781433105469\n",
            "Eval_MaxReturn : 38.0\n",
            "Eval_MinReturn : 9.0\n",
            "Eval_AverageEpLen : 19.61904761904762\n",
            "Train_AverageReturn : 7.875\n",
            "Train_StdReturn : 3.2379584312438965\n",
            "Train_MaxReturn : 14.0\n",
            "Train_MinReturn : 4.0\n",
            "Train_AverageEpLen : 7.875\n",
            "Train_EnvstepsSoFar : 126\n",
            "TimeSinceStart : 0.3564140796661377\n",
            "Training Loss : -0.05899066478013992\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 1 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([131])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 18.227272033691406\n",
            "Eval_StdReturn : 10.13962459564209\n",
            "Eval_MaxReturn : 49.0\n",
            "Eval_MinReturn : 7.0\n",
            "Eval_AverageEpLen : 18.227272727272727\n",
            "Train_AverageReturn : 21.83333396911621\n",
            "Train_StdReturn : 4.980517387390137\n",
            "Train_MaxReturn : 31.0\n",
            "Train_MinReturn : 17.0\n",
            "Train_AverageEpLen : 21.833333333333332\n",
            "Train_EnvstepsSoFar : 257\n",
            "TimeSinceStart : 0.7549517154693604\n",
            "Training Loss : -0.07144071161746979\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 2 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([127])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 11.685714721679688\n",
            "Eval_StdReturn : 6.675205707550049\n",
            "Eval_MaxReturn : 30.0\n",
            "Eval_MinReturn : 5.0\n",
            "Eval_AverageEpLen : 11.685714285714285\n",
            "Train_AverageReturn : 15.875\n",
            "Train_StdReturn : 8.880280494689941\n",
            "Train_MaxReturn : 34.0\n",
            "Train_MinReturn : 5.0\n",
            "Train_AverageEpLen : 15.875\n",
            "Train_EnvstepsSoFar : 384\n",
            "TimeSinceStart : 1.0808606147766113\n",
            "Training Loss : -0.1315620392560959\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 3 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([127])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 9.928571701049805\n",
            "Eval_StdReturn : 4.651639938354492\n",
            "Eval_MaxReturn : 24.0\n",
            "Eval_MinReturn : 5.0\n",
            "Eval_AverageEpLen : 9.928571428571429\n",
            "Train_AverageReturn : 9.071428298950195\n",
            "Train_StdReturn : 5.270731449127197\n",
            "Train_MaxReturn : 24.0\n",
            "Train_MinReturn : 4.0\n",
            "Train_AverageEpLen : 9.071428571428571\n",
            "Train_EnvstepsSoFar : 511\n",
            "TimeSinceStart : 1.413412094116211\n",
            "Training Loss : -0.09554676711559296\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 4 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([124])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 9.651163101196289\n",
            "Eval_StdReturn : 5.277789115905762\n",
            "Eval_MaxReturn : 24.0\n",
            "Eval_MinReturn : 3.0\n",
            "Eval_AverageEpLen : 9.651162790697674\n",
            "Train_AverageReturn : 6.888888835906982\n",
            "Train_StdReturn : 2.536158323287964\n",
            "Train_MaxReturn : 12.0\n",
            "Train_MinReturn : 4.0\n",
            "Train_AverageEpLen : 6.888888888888889\n",
            "Train_EnvstepsSoFar : 635\n",
            "TimeSinceStart : 1.7712352275848389\n",
            "Training Loss : 0.04056348279118538\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 5 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([123])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 8.395833015441895\n",
            "Eval_StdReturn : 6.088717460632324\n",
            "Eval_MaxReturn : 24.0\n",
            "Eval_MinReturn : 2.0\n",
            "Eval_AverageEpLen : 8.395833333333334\n",
            "Train_AverageReturn : 7.411764621734619\n",
            "Train_StdReturn : 4.983016014099121\n",
            "Train_MaxReturn : 21.0\n",
            "Train_MinReturn : 3.0\n",
            "Train_AverageEpLen : 7.411764705882353\n",
            "Train_EnvstepsSoFar : 761\n",
            "TimeSinceStart : 2.163341522216797\n",
            "Training Loss : -0.0724005475640297\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 6 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([121])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 8.702127456665039\n",
            "Eval_StdReturn : 8.163006782531738\n",
            "Eval_MaxReturn : 47.0\n",
            "Eval_MinReturn : 2.0\n",
            "Eval_AverageEpLen : 8.702127659574469\n",
            "Train_AverageReturn : 9.307692527770996\n",
            "Train_StdReturn : 6.144223213195801\n",
            "Train_MaxReturn : 21.0\n",
            "Train_MinReturn : 3.0\n",
            "Train_AverageEpLen : 9.307692307692308\n",
            "Train_EnvstepsSoFar : 882\n",
            "TimeSinceStart : 2.5694360733032227\n",
            "Training Loss : -0.13349796831607819\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 7 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([121])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 13.82758617401123\n",
            "Eval_StdReturn : 13.292645454406738\n",
            "Eval_MaxReturn : 58.0\n",
            "Eval_MinReturn : 3.0\n",
            "Eval_AverageEpLen : 13.827586206896552\n",
            "Train_AverageReturn : 15.125\n",
            "Train_StdReturn : 13.023416519165039\n",
            "Train_MaxReturn : 46.0\n",
            "Train_MinReturn : 3.0\n",
            "Train_AverageEpLen : 15.125\n",
            "Train_EnvstepsSoFar : 1003\n",
            "TimeSinceStart : 2.95410418510437\n",
            "Training Loss : -0.003714175196364522\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 8 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([121])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 14.925926208496094\n",
            "Eval_StdReturn : 11.67753791809082\n",
            "Eval_MaxReturn : 40.0\n",
            "Eval_MinReturn : 3.0\n",
            "Eval_AverageEpLen : 14.925925925925926\n",
            "Train_AverageReturn : 30.25\n",
            "Train_StdReturn : 16.40693473815918\n",
            "Train_MaxReturn : 46.0\n",
            "Train_MinReturn : 4.0\n",
            "Train_AverageEpLen : 30.25\n",
            "Train_EnvstepsSoFar : 1124\n",
            "TimeSinceStart : 3.3313181400299072\n",
            "Training Loss : 0.026367075741291046\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 9 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([122])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 18.18181800842285\n",
            "Eval_StdReturn : 14.74830150604248\n",
            "Eval_MaxReturn : 54.0\n",
            "Eval_MinReturn : 4.0\n",
            "Eval_AverageEpLen : 18.181818181818183\n",
            "Train_AverageReturn : 13.55555534362793\n",
            "Train_StdReturn : 11.53844928741455\n",
            "Train_MaxReturn : 44.0\n",
            "Train_MinReturn : 4.0\n",
            "Train_AverageEpLen : 13.555555555555555\n",
            "Train_EnvstepsSoFar : 1246\n",
            "TimeSinceStart : 3.7321648597717285\n",
            "Training Loss : -0.045267503708601\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 10 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([122])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 44.77777862548828\n",
            "Eval_StdReturn : 27.839929580688477\n",
            "Eval_MaxReturn : 82.0\n",
            "Eval_MinReturn : 4.0\n",
            "Eval_AverageEpLen : 44.77777777777778\n",
            "Train_AverageReturn : 20.33333396911621\n",
            "Train_StdReturn : 18.820791244506836\n",
            "Train_MaxReturn : 54.0\n",
            "Train_MinReturn : 4.0\n",
            "Train_AverageEpLen : 20.333333333333332\n",
            "Train_EnvstepsSoFar : 1368\n",
            "TimeSinceStart : 4.093866348266602\n",
            "Training Loss : -0.056252460926771164\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 11 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([152])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 43.900001525878906\n",
            "Eval_StdReturn : 17.037899017333984\n",
            "Eval_MaxReturn : 71.0\n",
            "Eval_MinReturn : 10.0\n",
            "Eval_AverageEpLen : 43.9\n",
            "Train_AverageReturn : 60.0\n",
            "Train_StdReturn : 65.56421661376953\n",
            "Train_MaxReturn : 152.0\n",
            "Train_MinReturn : 4.0\n",
            "Train_AverageEpLen : 60.0\n",
            "Train_EnvstepsSoFar : 1548\n",
            "TimeSinceStart : 4.5265116691589355\n",
            "Training Loss : -0.0877845510840416\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 12 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([170])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 102.19999694824219\n",
            "Eval_StdReturn : 44.485504150390625\n",
            "Eval_MaxReturn : 161.0\n",
            "Eval_MinReturn : 30.0\n",
            "Eval_AverageEpLen : 102.2\n",
            "Train_AverageReturn : 45.0\n",
            "Train_StdReturn : 21.201414108276367\n",
            "Train_MaxReturn : 65.0\n",
            "Train_MinReturn : 10.0\n",
            "Train_AverageEpLen : 45.0\n",
            "Train_EnvstepsSoFar : 1728\n",
            "TimeSinceStart : 5.017862796783447\n",
            "Training Loss : -0.05401318147778511\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 13 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([203])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 136.3333282470703\n",
            "Eval_StdReturn : 51.699989318847656\n",
            "Eval_MaxReturn : 209.0\n",
            "Eval_MinReturn : 93.0\n",
            "Eval_AverageEpLen : 136.33333333333334\n",
            "Train_AverageReturn : 101.5\n",
            "Train_StdReturn : 4.5\n",
            "Train_MaxReturn : 106.0\n",
            "Train_MinReturn : 97.0\n",
            "Train_AverageEpLen : 101.5\n",
            "Train_EnvstepsSoFar : 1931\n",
            "TimeSinceStart : 5.409235715866089\n",
            "Training Loss : -0.021648650988936424\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 14 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([133])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 186.3333282470703\n",
            "Eval_StdReturn : 16.006942749023438\n",
            "Eval_MaxReturn : 207.0\n",
            "Eval_MinReturn : 168.0\n",
            "Eval_AverageEpLen : 186.33333333333334\n",
            "Train_AverageReturn : 73.33333587646484\n",
            "Train_StdReturn : 43.60683059692383\n",
            "Train_MaxReturn : 133.0\n",
            "Train_MinReturn : 30.0\n",
            "Train_AverageEpLen : 73.33333333333333\n",
            "Train_EnvstepsSoFar : 2151\n",
            "TimeSinceStart : 5.883222818374634\n",
            "Training Loss : -0.033014994114637375\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 15 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([199])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 210.3333282470703\n",
            "Eval_StdReturn : 97.65699768066406\n",
            "Eval_MaxReturn : 313.0\n",
            "Eval_MinReturn : 79.0\n",
            "Eval_AverageEpLen : 210.33333333333334\n",
            "Train_AverageReturn : 199.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 199.0\n",
            "Train_MinReturn : 199.0\n",
            "Train_AverageEpLen : 199.0\n",
            "Train_EnvstepsSoFar : 2350\n",
            "TimeSinceStart : 6.413978099822998\n",
            "Training Loss : 0.02762480638921261\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 16 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([260])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 317.0\n",
            "Eval_StdReturn : 63.0\n",
            "Eval_MaxReturn : 380.0\n",
            "Eval_MinReturn : 254.0\n",
            "Eval_AverageEpLen : 317.0\n",
            "Train_AverageReturn : 260.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 260.0\n",
            "Train_MinReturn : 260.0\n",
            "Train_AverageEpLen : 260.0\n",
            "Train_EnvstepsSoFar : 2610\n",
            "TimeSinceStart : 7.028867721557617\n",
            "Training Loss : -0.10953067243099213\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 17 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([153])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 259.0\n",
            "Eval_StdReturn : 43.0\n",
            "Eval_MaxReturn : 302.0\n",
            "Eval_MinReturn : 216.0\n",
            "Eval_AverageEpLen : 259.0\n",
            "Train_AverageReturn : 153.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 153.0\n",
            "Train_MinReturn : 153.0\n",
            "Train_AverageEpLen : 153.0\n",
            "Train_EnvstepsSoFar : 2763\n",
            "TimeSinceStart : 7.407674312591553\n",
            "Training Loss : -0.08574174344539642\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 18 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([225])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 241.0\n",
            "Eval_StdReturn : 247.2620086669922\n",
            "Eval_MaxReturn : 664.0\n",
            "Eval_MinReturn : 41.0\n",
            "Eval_AverageEpLen : 241.0\n",
            "Train_AverageReturn : 225.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 225.0\n",
            "Train_MinReturn : 225.0\n",
            "Train_AverageEpLen : 225.0\n",
            "Train_EnvstepsSoFar : 2988\n",
            "TimeSinceStart : 8.160664796829224\n",
            "Training Loss : -0.006016049068421125\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 19 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([352])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 352.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 352.0\n",
            "Train_MinReturn : 352.0\n",
            "Train_AverageEpLen : 352.0\n",
            "Train_EnvstepsSoFar : 3340\n",
            "TimeSinceStart : 9.083828210830688\n",
            "Training Loss : -0.06114515662193298\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 20 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([601])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 601.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 601.0\n",
            "Train_MinReturn : 601.0\n",
            "Train_AverageEpLen : 601.0\n",
            "Train_EnvstepsSoFar : 3941\n",
            "TimeSinceStart : 10.005553483963013\n",
            "Training Loss : -0.10246609151363373\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 21 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 4941\n",
            "TimeSinceStart : 11.190220832824707\n",
            "Training Loss : -0.01361354161053896\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 22 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 5941\n",
            "TimeSinceStart : 12.434927463531494\n",
            "Training Loss : -0.016253266483545303\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 23 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 417.5\n",
            "Eval_StdReturn : 200.5\n",
            "Eval_MaxReturn : 618.0\n",
            "Eval_MinReturn : 217.0\n",
            "Eval_AverageEpLen : 417.5\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 6941\n",
            "TimeSinceStart : 13.574551105499268\n",
            "Training Loss : 0.011666554026305676\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 24 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([376])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 376.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 376.0\n",
            "Train_MinReturn : 376.0\n",
            "Train_AverageEpLen : 376.0\n",
            "Train_EnvstepsSoFar : 7317\n",
            "TimeSinceStart : 14.393925905227661\n",
            "Training Loss : 0.035073451697826385\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 25 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 8317\n",
            "TimeSinceStart : 15.589620351791382\n",
            "Training Loss : 0.010518616065382957\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 26 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 9317\n",
            "TimeSinceStart : 16.821504831314087\n",
            "Training Loss : 0.015202377922832966\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 27 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 10317\n",
            "TimeSinceStart : 18.087493658065796\n",
            "Training Loss : 0.008580425754189491\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 28 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 11317\n",
            "TimeSinceStart : 19.315948724746704\n",
            "Training Loss : -0.002494045300409198\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 29 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 12317\n",
            "TimeSinceStart : 20.587061405181885\n",
            "Training Loss : -0.010664951987564564\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 30 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 13317\n",
            "TimeSinceStart : 21.897937297821045\n",
            "Training Loss : 0.011420349590480328\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 31 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 14317\n",
            "TimeSinceStart : 23.243217945098877\n",
            "Training Loss : -0.030145760625600815\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 32 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 15317\n",
            "TimeSinceStart : 24.621282815933228\n",
            "Training Loss : -0.057170383632183075\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 33 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 16317\n",
            "TimeSinceStart : 25.97772240638733\n",
            "Training Loss : 0.011699703522026539\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 34 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 17317\n",
            "TimeSinceStart : 27.342493534088135\n",
            "Training Loss : -0.017408380284905434\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 35 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 254.5\n",
            "Eval_StdReturn : 430.4151916503906\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 5.0\n",
            "Eval_AverageEpLen : 254.5\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 18317\n",
            "TimeSinceStart : 28.522116661071777\n",
            "Training Loss : 0.024462822824716568\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 36 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 21.087718963623047\n",
            "Eval_StdReturn : 130.81394958496094\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 2.0\n",
            "Eval_AverageEpLen : 21.087719298245613\n",
            "Train_AverageReturn : 503.0\n",
            "Train_StdReturn : 497.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 6.0\n",
            "Train_AverageEpLen : 503.0\n",
            "Train_EnvstepsSoFar : 19323\n",
            "TimeSinceStart : 30.007412672042847\n",
            "Training Loss : 0.023385537788271904\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 37 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([120])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 87.83333587646484\n",
            "Eval_StdReturn : 275.0302429199219\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 3.0\n",
            "Eval_AverageEpLen : 87.83333333333333\n",
            "Train_AverageReturn : 3.4285714626312256\n",
            "Train_StdReturn : 0.599319338798523\n",
            "Train_MaxReturn : 5.0\n",
            "Train_MinReturn : 2.0\n",
            "Train_AverageEpLen : 3.4285714285714284\n",
            "Train_EnvstepsSoFar : 19443\n",
            "TimeSinceStart : 30.754859447479248\n",
            "Training Loss : 0.006843456067144871\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 38 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 502.0\n",
            "Eval_StdReturn : 498.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 4.0\n",
            "Eval_AverageEpLen : 502.0\n",
            "Train_AverageReturn : 104.69999694824219\n",
            "Train_StdReturn : 298.4352722167969\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 4.0\n",
            "Train_AverageEpLen : 104.7\n",
            "Train_EnvstepsSoFar : 20490\n",
            "TimeSinceStart : 31.989257335662842\n",
            "Training Loss : 0.018076492473483086\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 39 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 118.5999984741211\n",
            "Eval_StdReturn : 293.94122314453125\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 5.0\n",
            "Eval_AverageEpLen : 118.6\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 21490\n",
            "TimeSinceStart : 33.31532526016235\n",
            "Training Loss : -0.004284557420760393\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 40 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 22490\n",
            "TimeSinceStart : 34.58764600753784\n",
            "Training Loss : -0.00482929265126586\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 41 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 512.5\n",
            "Eval_StdReturn : 487.5\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 25.0\n",
            "Eval_AverageEpLen : 512.5\n",
            "Train_AverageReturn : 271.5\n",
            "Train_StdReturn : 420.61175537109375\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 24.0\n",
            "Train_AverageEpLen : 271.5\n",
            "Train_EnvstepsSoFar : 23576\n",
            "TimeSinceStart : 35.94543790817261\n",
            "Training Loss : 0.01577872596681118\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 42 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 236.60000610351562\n",
            "Eval_StdReturn : 382.21282958984375\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 31.0\n",
            "Eval_AverageEpLen : 236.6\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 24576\n",
            "TimeSinceStart : 37.287925243377686\n",
            "Training Loss : -0.03135845437645912\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 43 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([129])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 504.0\n",
            "Eval_StdReturn : 496.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 8.0\n",
            "Eval_AverageEpLen : 504.0\n",
            "Train_AverageReturn : 51.0\n",
            "Train_StdReturn : 30.735429763793945\n",
            "Train_MaxReturn : 94.0\n",
            "Train_MinReturn : 24.0\n",
            "Train_AverageEpLen : 51.0\n",
            "Train_EnvstepsSoFar : 24729\n",
            "TimeSinceStart : 37.99114990234375\n",
            "Training Loss : -0.08322379738092422\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 44 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 66.0\n",
            "Eval_StdReturn : 82.4836654663086\n",
            "Eval_MaxReturn : 295.0\n",
            "Eval_MinReturn : 7.0\n",
            "Eval_AverageEpLen : 66.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 25729\n",
            "TimeSinceStart : 39.07595705986023\n",
            "Training Loss : 0.013449291698634624\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 45 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([711])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 22.5\n",
            "Eval_StdReturn : 15.88587760925293\n",
            "Eval_MaxReturn : 43.0\n",
            "Eval_MinReturn : 7.0\n",
            "Eval_AverageEpLen : 22.5\n",
            "Train_AverageReturn : 711.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 711.0\n",
            "Train_MinReturn : 711.0\n",
            "Train_AverageEpLen : 711.0\n",
            "Train_EnvstepsSoFar : 26440\n",
            "TimeSinceStart : 39.82132315635681\n",
            "Training Loss : -0.010083128698170185\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 46 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([121])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 10.810811042785645\n",
            "Eval_StdReturn : 8.889222145080566\n",
            "Eval_MaxReturn : 37.0\n",
            "Eval_MinReturn : 4.0\n",
            "Eval_AverageEpLen : 10.81081081081081\n",
            "Train_AverageReturn : 39.5\n",
            "Train_StdReturn : 1.658312439918518\n",
            "Train_MaxReturn : 41.0\n",
            "Train_MinReturn : 37.0\n",
            "Train_AverageEpLen : 39.5\n",
            "Train_EnvstepsSoFar : 26598\n",
            "TimeSinceStart : 40.158618450164795\n",
            "Training Loss : 0.021144645288586617\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 47 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([122])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 7.943396091461182\n",
            "Eval_StdReturn : 4.5863423347473145\n",
            "Eval_MaxReturn : 34.0\n",
            "Eval_MinReturn : 4.0\n",
            "Eval_AverageEpLen : 7.943396226415095\n",
            "Train_AverageReturn : 9.84615421295166\n",
            "Train_StdReturn : 7.950290203094482\n",
            "Train_MaxReturn : 36.0\n",
            "Train_MinReturn : 4.0\n",
            "Train_AverageEpLen : 9.846153846153847\n",
            "Train_EnvstepsSoFar : 26726\n",
            "TimeSinceStart : 40.56038308143616\n",
            "Training Loss : -0.1458289921283722\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 48 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([123])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 11.45714282989502\n",
            "Eval_StdReturn : 9.66390323638916\n",
            "Eval_MaxReturn : 36.0\n",
            "Eval_MinReturn : 4.0\n",
            "Eval_AverageEpLen : 11.457142857142857\n",
            "Train_AverageReturn : 6.473684310913086\n",
            "Train_StdReturn : 1.7879250049591064\n",
            "Train_MaxReturn : 12.0\n",
            "Train_MinReturn : 4.0\n",
            "Train_AverageEpLen : 6.473684210526316\n",
            "Train_EnvstepsSoFar : 26849\n",
            "TimeSinceStart : 40.92136597633362\n",
            "Training Loss : 0.04459894821047783\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 49 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([124])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 41.099998474121094\n",
            "Eval_StdReturn : 2.586503505706787\n",
            "Eval_MaxReturn : 47.0\n",
            "Eval_MinReturn : 38.0\n",
            "Eval_AverageEpLen : 41.1\n",
            "Train_AverageReturn : 12.399999618530273\n",
            "Train_StdReturn : 11.092339515686035\n",
            "Train_MaxReturn : 35.0\n",
            "Train_MinReturn : 6.0\n",
            "Train_AverageEpLen : 12.4\n",
            "Train_EnvstepsSoFar : 26973\n",
            "TimeSinceStart : 41.32850670814514\n",
            "Training Loss : 0.05195443704724312\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 50 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([122])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 107.5\n",
            "Eval_StdReturn : 21.289669036865234\n",
            "Eval_MaxReturn : 140.0\n",
            "Eval_MinReturn : 87.0\n",
            "Eval_AverageEpLen : 107.5\n",
            "Train_AverageReturn : 40.66666793823242\n",
            "Train_StdReturn : 3.7712361812591553\n",
            "Train_MaxReturn : 46.0\n",
            "Train_MinReturn : 38.0\n",
            "Train_AverageEpLen : 40.666666666666664\n",
            "Train_EnvstepsSoFar : 27095\n",
            "TimeSinceStart : 41.73309135437012\n",
            "Training Loss : 0.03860989585518837\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 51 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([217])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 108.5\n",
            "Train_StdReturn : 4.5\n",
            "Train_MaxReturn : 113.0\n",
            "Train_MinReturn : 104.0\n",
            "Train_AverageEpLen : 108.5\n",
            "Train_EnvstepsSoFar : 27312\n",
            "TimeSinceStart : 42.4933443069458\n",
            "Training Loss : 0.010110811330378056\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 52 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 28312\n",
            "TimeSinceStart : 43.91621661186218\n",
            "Training Loss : -0.000484756485093385\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 53 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 574.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 574.0\n",
            "Eval_MinReturn : 574.0\n",
            "Eval_AverageEpLen : 574.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 29312\n",
            "TimeSinceStart : 44.97674250602722\n",
            "Training Loss : -0.024182450026273727\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 54 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 85.4000015258789\n",
            "Eval_StdReturn : 77.86038970947266\n",
            "Eval_MaxReturn : 228.0\n",
            "Eval_MinReturn : 18.0\n",
            "Eval_AverageEpLen : 85.4\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 30312\n",
            "TimeSinceStart : 45.93822693824768\n",
            "Training Loss : -0.023213990032672882\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 55 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([193])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 169.3333282470703\n",
            "Eval_StdReturn : 10.077478408813477\n",
            "Eval_MaxReturn : 183.0\n",
            "Eval_MinReturn : 159.0\n",
            "Eval_AverageEpLen : 169.33333333333334\n",
            "Train_AverageReturn : 90.66666412353516\n",
            "Train_StdReturn : 72.61924743652344\n",
            "Train_MaxReturn : 193.0\n",
            "Train_MinReturn : 32.0\n",
            "Train_AverageEpLen : 90.66666666666667\n",
            "Train_EnvstepsSoFar : 30584\n",
            "TimeSinceStart : 46.451098680496216\n",
            "Training Loss : 0.04549325257539749\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 56 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([140])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 80.5999984741211\n",
            "Eval_StdReturn : 37.918861389160156\n",
            "Eval_MaxReturn : 107.0\n",
            "Eval_MinReturn : 6.0\n",
            "Eval_AverageEpLen : 80.6\n",
            "Train_AverageReturn : 140.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 140.0\n",
            "Train_MinReturn : 140.0\n",
            "Train_AverageEpLen : 140.0\n",
            "Train_EnvstepsSoFar : 30724\n",
            "TimeSinceStart : 46.806476354599\n",
            "Training Loss : 0.017438506707549095\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 57 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([213])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 70.14286041259766\n",
            "Eval_StdReturn : 41.329437255859375\n",
            "Eval_MaxReturn : 102.0\n",
            "Eval_MinReturn : 4.0\n",
            "Eval_AverageEpLen : 70.14285714285714\n",
            "Train_AverageReturn : 106.5\n",
            "Train_StdReturn : 1.5\n",
            "Train_MaxReturn : 108.0\n",
            "Train_MinReturn : 105.0\n",
            "Train_AverageEpLen : 106.5\n",
            "Train_EnvstepsSoFar : 30937\n",
            "TimeSinceStart : 47.228416442871094\n",
            "Training Loss : -0.05889821797609329\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 58 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([187])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 54.11111068725586\n",
            "Eval_StdReturn : 42.41447448730469\n",
            "Eval_MaxReturn : 122.0\n",
            "Eval_MinReturn : 8.0\n",
            "Eval_AverageEpLen : 54.111111111111114\n",
            "Train_AverageReturn : 93.5\n",
            "Train_StdReturn : 5.5\n",
            "Train_MaxReturn : 99.0\n",
            "Train_MinReturn : 88.0\n",
            "Train_AverageEpLen : 93.5\n",
            "Train_EnvstepsSoFar : 31124\n",
            "TimeSinceStart : 47.635258436203\n",
            "Training Loss : -0.05968054383993149\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 59 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([151])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 180.3333282470703\n",
            "Eval_StdReturn : 19.601587295532227\n",
            "Eval_MaxReturn : 204.0\n",
            "Eval_MinReturn : 156.0\n",
            "Eval_AverageEpLen : 180.33333333333334\n",
            "Train_AverageReturn : 65.33333587646484\n",
            "Train_StdReturn : 20.85399055480957\n",
            "Train_MaxReturn : 94.0\n",
            "Train_MinReturn : 45.0\n",
            "Train_AverageEpLen : 65.33333333333333\n",
            "Train_EnvstepsSoFar : 31320\n",
            "TimeSinceStart : 48.06881260871887\n",
            "Training Loss : -0.047997165471315384\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 60 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([237])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 237.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 237.0\n",
            "Train_MinReturn : 237.0\n",
            "Train_AverageEpLen : 237.0\n",
            "Train_EnvstepsSoFar : 31557\n",
            "TimeSinceStart : 48.81076693534851\n",
            "Training Loss : -0.022670168429613113\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 61 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 32557\n",
            "TimeSinceStart : 50.02598237991333\n",
            "Training Loss : -0.03858048841357231\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 62 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([469])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 3.6036036014556885\n",
            "Eval_StdReturn : 1.561238408088684\n",
            "Eval_MaxReturn : 12.0\n",
            "Eval_MinReturn : 3.0\n",
            "Eval_AverageEpLen : 3.6036036036036037\n",
            "Train_AverageReturn : 469.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 469.0\n",
            "Train_MinReturn : 469.0\n",
            "Train_AverageEpLen : 469.0\n",
            "Train_EnvstepsSoFar : 33026\n",
            "TimeSinceStart : 50.57463264465332\n",
            "Training Loss : -0.014944424852728844\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 63 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([122])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 46.79999923706055\n",
            "Eval_StdReturn : 26.648828506469727\n",
            "Eval_MaxReturn : 87.0\n",
            "Eval_MinReturn : 4.0\n",
            "Eval_AverageEpLen : 46.8\n",
            "Train_AverageReturn : 3.297297239303589\n",
            "Train_StdReturn : 0.865709125995636\n",
            "Train_MaxReturn : 8.0\n",
            "Train_MinReturn : 3.0\n",
            "Train_AverageEpLen : 3.2972972972972974\n",
            "Train_EnvstepsSoFar : 33148\n",
            "TimeSinceStart : 50.99448871612549\n",
            "Training Loss : 0.022586539387702942\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 64 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([135])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 67.5\n",
            "Train_StdReturn : 51.5\n",
            "Train_MaxReturn : 119.0\n",
            "Train_MinReturn : 16.0\n",
            "Train_AverageEpLen : 67.5\n",
            "Train_EnvstepsSoFar : 33283\n",
            "TimeSinceStart : 51.71463751792908\n",
            "Training Loss : -0.0863647311925888\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 65 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 34283\n",
            "TimeSinceStart : 52.97288370132446\n",
            "Training Loss : 0.009105103090405464\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 66 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 408.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 408.0\n",
            "Eval_MinReturn : 408.0\n",
            "Eval_AverageEpLen : 408.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 35283\n",
            "TimeSinceStart : 53.851476430892944\n",
            "Training Loss : 0.016702687367796898\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 67 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([579])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 17.15999984741211\n",
            "Eval_StdReturn : 15.527215957641602\n",
            "Eval_MaxReturn : 68.0\n",
            "Eval_MinReturn : 4.0\n",
            "Eval_AverageEpLen : 17.16\n",
            "Train_AverageReturn : 334.0\n",
            "Train_StdReturn : 245.0\n",
            "Train_MaxReturn : 579.0\n",
            "Train_MinReturn : 89.0\n",
            "Train_AverageEpLen : 334.0\n",
            "Train_EnvstepsSoFar : 35951\n",
            "TimeSinceStart : 54.556665897369385\n",
            "Training Loss : 0.03399781882762909\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 68 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([131])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 10.6578950881958\n",
            "Eval_StdReturn : 9.95324993133545\n",
            "Eval_MaxReturn : 38.0\n",
            "Eval_MinReturn : 2.0\n",
            "Eval_AverageEpLen : 10.657894736842104\n",
            "Train_AverageReturn : 13.100000381469727\n",
            "Train_StdReturn : 8.882003784179688\n",
            "Train_MaxReturn : 28.0\n",
            "Train_MinReturn : 4.0\n",
            "Train_AverageEpLen : 13.1\n",
            "Train_EnvstepsSoFar : 36082\n",
            "TimeSinceStart : 54.91739296913147\n",
            "Training Loss : -0.022448280826210976\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 69 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([120])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 4.210526466369629\n",
            "Eval_StdReturn : 3.5979371070861816\n",
            "Eval_MaxReturn : 29.0\n",
            "Eval_MinReturn : 2.0\n",
            "Eval_AverageEpLen : 4.2105263157894735\n",
            "Train_AverageReturn : 12.0\n",
            "Train_StdReturn : 14.59451961517334\n",
            "Train_MaxReturn : 44.0\n",
            "Train_MinReturn : 4.0\n",
            "Train_AverageEpLen : 12.0\n",
            "Train_EnvstepsSoFar : 36202\n",
            "TimeSinceStart : 55.253650188446045\n",
            "Training Loss : 0.14011624455451965\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 70 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([122])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 3.200000047683716\n",
            "Eval_StdReturn : 1.734358787536621\n",
            "Eval_MaxReturn : 14.0\n",
            "Eval_MinReturn : 2.0\n",
            "Eval_AverageEpLen : 3.2\n",
            "Train_AverageReturn : 5.115384578704834\n",
            "Train_StdReturn : 6.930017948150635\n",
            "Train_MaxReturn : 30.0\n",
            "Train_MinReturn : 2.0\n",
            "Train_AverageEpLen : 5.115384615384615\n",
            "Train_EnvstepsSoFar : 36335\n",
            "TimeSinceStart : 55.614712953567505\n",
            "Training Loss : -0.10179131478071213\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 71 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([120])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 4.556818008422852\n",
            "Eval_StdReturn : 1.4682855606079102\n",
            "Eval_MaxReturn : 11.0\n",
            "Eval_MinReturn : 3.0\n",
            "Eval_AverageEpLen : 4.556818181818182\n",
            "Train_AverageReturn : 2.97560977935791\n",
            "Train_StdReturn : 0.7804877758026123\n",
            "Train_MaxReturn : 5.0\n",
            "Train_MinReturn : 2.0\n",
            "Train_AverageEpLen : 2.975609756097561\n",
            "Train_EnvstepsSoFar : 36457\n",
            "TimeSinceStart : 55.99746298789978\n",
            "Training Loss : 0.053631410002708435\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 72 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([123])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 6.014925479888916\n",
            "Eval_StdReturn : 2.2159030437469482\n",
            "Eval_MaxReturn : 17.0\n",
            "Eval_MinReturn : 3.0\n",
            "Eval_AverageEpLen : 6.014925373134329\n",
            "Train_AverageReturn : 3.9677419662475586\n",
            "Train_StdReturn : 0.7822166085243225\n",
            "Train_MaxReturn : 6.0\n",
            "Train_MinReturn : 3.0\n",
            "Train_AverageEpLen : 3.967741935483871\n",
            "Train_EnvstepsSoFar : 36580\n",
            "TimeSinceStart : 56.33730435371399\n",
            "Training Loss : -0.11326020956039429\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 73 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([122])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 12.303030014038086\n",
            "Eval_StdReturn : 5.2770795822143555\n",
            "Eval_MaxReturn : 24.0\n",
            "Eval_MinReturn : 5.0\n",
            "Eval_AverageEpLen : 12.303030303030303\n",
            "Train_AverageReturn : 6.099999904632568\n",
            "Train_StdReturn : 1.9209372997283936\n",
            "Train_MaxReturn : 13.0\n",
            "Train_MinReturn : 4.0\n",
            "Train_AverageEpLen : 6.1\n",
            "Train_EnvstepsSoFar : 36702\n",
            "TimeSinceStart : 56.69636535644531\n",
            "Training Loss : -0.02810096926987171\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 74 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([125])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 12.65625\n",
            "Eval_StdReturn : 5.966622829437256\n",
            "Eval_MaxReturn : 28.0\n",
            "Eval_MinReturn : 5.0\n",
            "Eval_AverageEpLen : 12.65625\n",
            "Train_AverageReturn : 11.0\n",
            "Train_StdReturn : 3.605551242828369\n",
            "Train_MaxReturn : 16.0\n",
            "Train_MinReturn : 5.0\n",
            "Train_AverageEpLen : 11.0\n",
            "Train_EnvstepsSoFar : 36834\n",
            "TimeSinceStart : 57.04561758041382\n",
            "Training Loss : 0.0713319405913353\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 75 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([123])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 19.14285659790039\n",
            "Eval_StdReturn : 7.356795787811279\n",
            "Eval_MaxReturn : 36.0\n",
            "Eval_MinReturn : 9.0\n",
            "Eval_AverageEpLen : 19.142857142857142\n",
            "Train_AverageReturn : 11.636363983154297\n",
            "Train_StdReturn : 6.2416887283325195\n",
            "Train_MaxReturn : 21.0\n",
            "Train_MinReturn : 5.0\n",
            "Train_AverageEpLen : 11.636363636363637\n",
            "Train_EnvstepsSoFar : 36962\n",
            "TimeSinceStart : 57.36747360229492\n",
            "Training Loss : 0.06459712982177734\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 76 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([122])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 19.81818199157715\n",
            "Eval_StdReturn : 11.895898818969727\n",
            "Eval_MaxReturn : 54.0\n",
            "Eval_MinReturn : 9.0\n",
            "Eval_AverageEpLen : 19.818181818181817\n",
            "Train_AverageReturn : 22.83333396911621\n",
            "Train_StdReturn : 11.79571533203125\n",
            "Train_MaxReturn : 49.0\n",
            "Train_MinReturn : 15.0\n",
            "Train_AverageEpLen : 22.833333333333332\n",
            "Train_EnvstepsSoFar : 37099\n",
            "TimeSinceStart : 57.72336769104004\n",
            "Training Loss : -0.03024766780436039\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 77 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([122])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 93.0\n",
            "Eval_StdReturn : 39.25811767578125\n",
            "Eval_MaxReturn : 153.0\n",
            "Eval_MinReturn : 36.0\n",
            "Eval_AverageEpLen : 93.0\n",
            "Train_AverageReturn : 40.66666793823242\n",
            "Train_StdReturn : 22.291006088256836\n",
            "Train_MaxReturn : 70.0\n",
            "Train_MinReturn : 16.0\n",
            "Train_AverageEpLen : 40.666666666666664\n",
            "Train_EnvstepsSoFar : 37221\n",
            "TimeSinceStart : 58.07000684738159\n",
            "Training Loss : 0.0049715470522642136\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 78 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([253])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 253.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 253.0\n",
            "Train_MinReturn : 253.0\n",
            "Train_AverageEpLen : 253.0\n",
            "Train_EnvstepsSoFar : 37474\n",
            "TimeSinceStart : 58.91362810134888\n",
            "Training Loss : 0.002940754871815443\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 79 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 38474\n",
            "TimeSinceStart : 60.14424967765808\n",
            "Training Loss : -0.007265613880008459\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 80 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 39474\n",
            "TimeSinceStart : 61.3930938243866\n",
            "Training Loss : -0.01762985996901989\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 81 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 40474\n",
            "TimeSinceStart : 62.71144652366638\n",
            "Training Loss : 0.019634900614619255\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 82 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 41474\n",
            "TimeSinceStart : 64.03191328048706\n",
            "Training Loss : 0.008906242437660694\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 83 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 663.0\n",
            "Eval_StdReturn : 337.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 326.0\n",
            "Eval_AverageEpLen : 663.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 42474\n",
            "TimeSinceStart : 65.52604651451111\n",
            "Training Loss : 0.00527547113597393\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 84 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([697])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 478.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 478.0\n",
            "Eval_MinReturn : 478.0\n",
            "Eval_AverageEpLen : 478.0\n",
            "Train_AverageReturn : 697.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 697.0\n",
            "Train_MinReturn : 697.0\n",
            "Train_AverageEpLen : 697.0\n",
            "Train_EnvstepsSoFar : 43171\n",
            "TimeSinceStart : 66.23094606399536\n",
            "Training Loss : 0.00845084898173809\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 85 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 44171\n",
            "TimeSinceStart : 67.58321928977966\n",
            "Training Loss : 0.007555450778454542\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 86 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 45171\n",
            "TimeSinceStart : 68.90539026260376\n",
            "Training Loss : -0.032976143062114716\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 87 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 46171\n",
            "TimeSinceStart : 70.0926730632782\n",
            "Training Loss : -0.019415294751524925\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 88 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 47171\n",
            "TimeSinceStart : 71.361328125\n",
            "Training Loss : 0.0177531186491251\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 89 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 48171\n",
            "TimeSinceStart : 72.54416179656982\n",
            "Training Loss : -0.00676257349550724\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 90 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 49171\n",
            "TimeSinceStart : 73.8451726436615\n",
            "Training Loss : -0.02286427468061447\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 91 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 50171\n",
            "TimeSinceStart : 75.3158528804779\n",
            "Training Loss : -0.003096424276009202\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 92 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 51171\n",
            "TimeSinceStart : 76.5792133808136\n",
            "Training Loss : 0.008849498815834522\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 93 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 52171\n",
            "TimeSinceStart : 77.74961113929749\n",
            "Training Loss : -0.06346779316663742\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 94 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 53171\n",
            "TimeSinceStart : 79.02547764778137\n",
            "Training Loss : -0.022678261622786522\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 95 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 54171\n",
            "TimeSinceStart : 80.2638771533966\n",
            "Training Loss : -0.00847215298563242\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 96 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 55171\n",
            "TimeSinceStart : 81.49094080924988\n",
            "Training Loss : 0.025302210822701454\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 97 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 56171\n",
            "TimeSinceStart : 82.71158838272095\n",
            "Training Loss : 0.003447837894782424\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 98 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 344.5\n",
            "Eval_StdReturn : 273.5\n",
            "Eval_MaxReturn : 618.0\n",
            "Eval_MinReturn : 71.0\n",
            "Eval_AverageEpLen : 344.5\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 57171\n",
            "TimeSinceStart : 83.74905061721802\n",
            "Training Loss : 0.012279118411242962\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 99 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 57.71428680419922\n",
            "Eval_StdReturn : 37.52985382080078\n",
            "Eval_MaxReturn : 127.0\n",
            "Eval_MinReturn : 15.0\n",
            "Eval_AverageEpLen : 57.714285714285715\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 58171\n",
            "TimeSinceStart : 84.60631084442139\n",
            "Training Loss : -0.021383684128522873\n",
            "Initial_DataCollection_AverageReturn : 7.875\n",
            "Done logging...\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python cs285/scripts/run_hw2.py --env_name InvertedPendulum-v2 \\\n",
        "--ep_len 1000 --discount 0.9 -n 100 -l 2 -s 64 -b 120 -lr 0.03 -rtg \\\n",
        "--exp_name q2_b120_r03"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WL9RZH-xyX-H",
        "outputId": "67ddfa99-25e0-4f9a-f41a-aa363107adf8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "########################\n",
            "logging outputs to  /content/gdrive/My Drive/cs285_f2021/DRL_policy_grads/cs285/scripts/../../data/q2_b200_r03_InvertedPendulum-v2_06-02-2022_17-33-03\n",
            "########################\n",
            "Using GPU id 0\n",
            "Sequential(\n",
            "  (0): Linear(in_features=4, out_features=64, bias=True)\n",
            "  (1): Tanh()\n",
            "  (2): Linear(in_features=64, out_features=64, bias=True)\n",
            "  (3): Tanh()\n",
            "  (4): Linear(in_features=64, out_features=1, bias=True)\n",
            "  (5): Identity()\n",
            ")\n",
            "\n",
            "\n",
            "********** Iteration 0 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([200])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 14.678571701049805\n",
            "Eval_StdReturn : 5.3722405433654785\n",
            "Eval_MaxReturn : 32.0\n",
            "Eval_MinReturn : 6.0\n",
            "Eval_AverageEpLen : 14.678571428571429\n",
            "Train_AverageReturn : 8.038461685180664\n",
            "Train_StdReturn : 4.164693832397461\n",
            "Train_MaxReturn : 20.0\n",
            "Train_MinReturn : 3.0\n",
            "Train_AverageEpLen : 8.038461538461538\n",
            "Train_EnvstepsSoFar : 209\n",
            "TimeSinceStart : 0.468656063079834\n",
            "Training Loss : -0.06062722206115723\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 1 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([210])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 18.590909957885742\n",
            "Eval_StdReturn : 11.080938339233398\n",
            "Eval_MaxReturn : 52.0\n",
            "Eval_MinReturn : 6.0\n",
            "Eval_AverageEpLen : 18.59090909090909\n",
            "Train_AverageReturn : 17.5\n",
            "Train_StdReturn : 9.242114067077637\n",
            "Train_MaxReturn : 46.0\n",
            "Train_MinReturn : 9.0\n",
            "Train_AverageEpLen : 17.5\n",
            "Train_EnvstepsSoFar : 419\n",
            "TimeSinceStart : 0.8973236083984375\n",
            "Training Loss : 0.05423596873879433\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 2 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([200])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 15.142857551574707\n",
            "Eval_StdReturn : 8.911126136779785\n",
            "Eval_MaxReturn : 36.0\n",
            "Eval_MinReturn : 6.0\n",
            "Eval_AverageEpLen : 15.142857142857142\n",
            "Train_AverageReturn : 19.0\n",
            "Train_StdReturn : 12.090567588806152\n",
            "Train_MaxReturn : 53.0\n",
            "Train_MinReturn : 8.0\n",
            "Train_AverageEpLen : 19.0\n",
            "Train_EnvstepsSoFar : 628\n",
            "TimeSinceStart : 1.3058807849884033\n",
            "Training Loss : -0.08390727639198303\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 3 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([204])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 13.866666793823242\n",
            "Eval_StdReturn : 6.211458683013916\n",
            "Eval_MaxReturn : 30.0\n",
            "Eval_MinReturn : 4.0\n",
            "Eval_AverageEpLen : 13.866666666666667\n",
            "Train_AverageReturn : 14.571428298950195\n",
            "Train_StdReturn : 7.5281782150268555\n",
            "Train_MaxReturn : 36.0\n",
            "Train_MinReturn : 5.0\n",
            "Train_AverageEpLen : 14.571428571428571\n",
            "Train_EnvstepsSoFar : 832\n",
            "TimeSinceStart : 1.769090175628662\n",
            "Training Loss : -0.029833490028977394\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 4 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([224])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 17.16666603088379\n",
            "Eval_StdReturn : 8.749603271484375\n",
            "Eval_MaxReturn : 39.0\n",
            "Eval_MinReturn : 5.0\n",
            "Eval_AverageEpLen : 17.166666666666668\n",
            "Train_AverageReturn : 19.384614944458008\n",
            "Train_StdReturn : 13.770305633544922\n",
            "Train_MaxReturn : 57.0\n",
            "Train_MinReturn : 5.0\n",
            "Train_AverageEpLen : 19.384615384615383\n",
            "Train_EnvstepsSoFar : 1084\n",
            "TimeSinceStart : 2.1797709465026855\n",
            "Training Loss : -0.008065283298492432\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 5 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([200])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 21.157894134521484\n",
            "Eval_StdReturn : 12.575093269348145\n",
            "Eval_MaxReturn : 59.0\n",
            "Eval_MinReturn : 8.0\n",
            "Eval_AverageEpLen : 21.157894736842106\n",
            "Train_AverageReturn : 21.899999618530273\n",
            "Train_StdReturn : 16.41615104675293\n",
            "Train_MaxReturn : 60.0\n",
            "Train_MinReturn : 8.0\n",
            "Train_AverageEpLen : 21.9\n",
            "Train_EnvstepsSoFar : 1303\n",
            "TimeSinceStart : 2.5577239990234375\n",
            "Training Loss : -0.09240169078111649\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 6 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([203])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 30.769229888916016\n",
            "Eval_StdReturn : 13.1392183303833\n",
            "Eval_MaxReturn : 55.0\n",
            "Eval_MinReturn : 11.0\n",
            "Eval_AverageEpLen : 30.76923076923077\n",
            "Train_AverageReturn : 16.30769157409668\n",
            "Train_StdReturn : 6.614489555358887\n",
            "Train_MaxReturn : 31.0\n",
            "Train_MinReturn : 8.0\n",
            "Train_AverageEpLen : 16.307692307692307\n",
            "Train_EnvstepsSoFar : 1515\n",
            "TimeSinceStart : 2.9374828338623047\n",
            "Training Loss : -0.07962997257709503\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 7 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([208])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 33.75\n",
            "Eval_StdReturn : 17.224618911743164\n",
            "Eval_MaxReturn : 70.0\n",
            "Eval_MinReturn : 14.0\n",
            "Eval_AverageEpLen : 33.75\n",
            "Train_AverageReturn : 20.799999237060547\n",
            "Train_StdReturn : 8.704021453857422\n",
            "Train_MaxReturn : 39.0\n",
            "Train_MinReturn : 8.0\n",
            "Train_AverageEpLen : 20.8\n",
            "Train_EnvstepsSoFar : 1723\n",
            "TimeSinceStart : 3.3022708892822266\n",
            "Training Loss : -0.05597677826881409\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 8 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([274])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 33.58333206176758\n",
            "Eval_StdReturn : 9.446853637695312\n",
            "Eval_MaxReturn : 47.0\n",
            "Eval_MinReturn : 21.0\n",
            "Eval_AverageEpLen : 33.583333333333336\n",
            "Train_AverageReturn : 54.79999923706055\n",
            "Train_StdReturn : 26.663833618164062\n",
            "Train_MaxReturn : 94.0\n",
            "Train_MinReturn : 18.0\n",
            "Train_AverageEpLen : 54.8\n",
            "Train_EnvstepsSoFar : 1997\n",
            "TimeSinceStart : 3.762080430984497\n",
            "Training Loss : 0.009285321459174156\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 9 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([206])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 41.70000076293945\n",
            "Eval_StdReturn : 18.27046775817871\n",
            "Eval_MaxReturn : 69.0\n",
            "Eval_MinReturn : 14.0\n",
            "Eval_AverageEpLen : 41.7\n",
            "Train_AverageReturn : 25.75\n",
            "Train_StdReturn : 13.112494468688965\n",
            "Train_MaxReturn : 58.0\n",
            "Train_MinReturn : 13.0\n",
            "Train_AverageEpLen : 25.75\n",
            "Train_EnvstepsSoFar : 2203\n",
            "TimeSinceStart : 4.142462730407715\n",
            "Training Loss : -0.07659408450126648\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 10 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([227])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 73.14286041259766\n",
            "Eval_StdReturn : 49.490055084228516\n",
            "Eval_MaxReturn : 151.0\n",
            "Eval_MinReturn : 17.0\n",
            "Eval_AverageEpLen : 73.14285714285714\n",
            "Train_AverageReturn : 32.42856979370117\n",
            "Train_StdReturn : 16.568965911865234\n",
            "Train_MaxReturn : 63.0\n",
            "Train_MinReturn : 16.0\n",
            "Train_AverageEpLen : 32.42857142857143\n",
            "Train_EnvstepsSoFar : 2430\n",
            "TimeSinceStart : 4.583080530166626\n",
            "Training Loss : 0.011562329716980457\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 11 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([254])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 72.16666412353516\n",
            "Eval_StdReturn : 20.152889251708984\n",
            "Eval_MaxReturn : 104.0\n",
            "Eval_MinReturn : 42.0\n",
            "Eval_AverageEpLen : 72.16666666666667\n",
            "Train_AverageReturn : 66.25\n",
            "Train_StdReturn : 37.28521728515625\n",
            "Train_MaxReturn : 116.0\n",
            "Train_MinReturn : 11.0\n",
            "Train_AverageEpLen : 66.25\n",
            "Train_EnvstepsSoFar : 2695\n",
            "TimeSinceStart : 5.020525217056274\n",
            "Training Loss : 0.015302334912121296\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 12 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([226])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 90.80000305175781\n",
            "Eval_StdReturn : 26.3165340423584\n",
            "Eval_MaxReturn : 134.0\n",
            "Eval_MinReturn : 56.0\n",
            "Eval_AverageEpLen : 90.8\n",
            "Train_AverageReturn : 95.33333587646484\n",
            "Train_StdReturn : 25.31578254699707\n",
            "Train_MaxReturn : 118.0\n",
            "Train_MinReturn : 60.0\n",
            "Train_AverageEpLen : 95.33333333333333\n",
            "Train_EnvstepsSoFar : 2981\n",
            "TimeSinceStart : 5.570441007614136\n",
            "Training Loss : 0.043516479432582855\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 13 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([229])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 67.85713958740234\n",
            "Eval_StdReturn : 11.217697143554688\n",
            "Eval_MaxReturn : 87.0\n",
            "Eval_MinReturn : 47.0\n",
            "Eval_AverageEpLen : 67.85714285714286\n",
            "Train_AverageReturn : 76.33333587646484\n",
            "Train_StdReturn : 10.873004913330078\n",
            "Train_MaxReturn : 91.0\n",
            "Train_MinReturn : 65.0\n",
            "Train_AverageEpLen : 76.33333333333333\n",
            "Train_EnvstepsSoFar : 3210\n",
            "TimeSinceStart : 6.029619932174683\n",
            "Training Loss : -0.06976287811994553\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 14 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([251])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 91.4000015258789\n",
            "Eval_StdReturn : 25.996923446655273\n",
            "Eval_MaxReturn : 132.0\n",
            "Eval_MinReturn : 59.0\n",
            "Eval_AverageEpLen : 91.4\n",
            "Train_AverageReturn : 83.66666412353516\n",
            "Train_StdReturn : 16.81930160522461\n",
            "Train_MaxReturn : 107.0\n",
            "Train_MinReturn : 68.0\n",
            "Train_AverageEpLen : 83.66666666666667\n",
            "Train_EnvstepsSoFar : 3461\n",
            "TimeSinceStart : 6.464925527572632\n",
            "Training Loss : -0.009484629146754742\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 15 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([212])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 66.14286041259766\n",
            "Eval_StdReturn : 24.781494140625\n",
            "Eval_MaxReturn : 84.0\n",
            "Eval_MinReturn : 8.0\n",
            "Eval_AverageEpLen : 66.14285714285714\n",
            "Train_AverageReturn : 72.75\n",
            "Train_StdReturn : 20.620075225830078\n",
            "Train_MaxReturn : 95.0\n",
            "Train_MinReturn : 39.0\n",
            "Train_AverageEpLen : 72.75\n",
            "Train_EnvstepsSoFar : 3752\n",
            "TimeSinceStart : 6.964357376098633\n",
            "Training Loss : 0.007952510379254818\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 16 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([249])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 68.5\n",
            "Eval_StdReturn : 20.742467880249023\n",
            "Eval_MaxReturn : 89.0\n",
            "Eval_MinReturn : 30.0\n",
            "Eval_AverageEpLen : 68.5\n",
            "Train_AverageReturn : 62.25\n",
            "Train_StdReturn : 10.328964233398438\n",
            "Train_MaxReturn : 73.0\n",
            "Train_MinReturn : 46.0\n",
            "Train_AverageEpLen : 62.25\n",
            "Train_EnvstepsSoFar : 4001\n",
            "TimeSinceStart : 7.3614113330841064\n",
            "Training Loss : -0.18821243941783905\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 17 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([229])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 71.16666412353516\n",
            "Eval_StdReturn : 43.18339538574219\n",
            "Eval_MaxReturn : 119.0\n",
            "Eval_MinReturn : 7.0\n",
            "Eval_AverageEpLen : 71.16666666666667\n",
            "Train_AverageReturn : 76.33333587646484\n",
            "Train_StdReturn : 26.233989715576172\n",
            "Train_MaxReturn : 110.0\n",
            "Train_MinReturn : 46.0\n",
            "Train_AverageEpLen : 76.33333333333333\n",
            "Train_EnvstepsSoFar : 4230\n",
            "TimeSinceStart : 7.781648874282837\n",
            "Training Loss : 0.002826690673828125\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 18 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([224])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 98.0\n",
            "Eval_StdReturn : 42.71767807006836\n",
            "Eval_MaxReturn : 155.0\n",
            "Eval_MinReturn : 42.0\n",
            "Eval_AverageEpLen : 98.0\n",
            "Train_AverageReturn : 112.0\n",
            "Train_StdReturn : 7.0\n",
            "Train_MaxReturn : 119.0\n",
            "Train_MinReturn : 105.0\n",
            "Train_AverageEpLen : 112.0\n",
            "Train_EnvstepsSoFar : 4454\n",
            "TimeSinceStart : 8.239406824111938\n",
            "Training Loss : -0.08916119486093521\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 19 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([202])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 269.5\n",
            "Eval_StdReturn : 178.5\n",
            "Eval_MaxReturn : 448.0\n",
            "Eval_MinReturn : 91.0\n",
            "Eval_AverageEpLen : 269.5\n",
            "Train_AverageReturn : 101.0\n",
            "Train_StdReturn : 66.0\n",
            "Train_MaxReturn : 167.0\n",
            "Train_MinReturn : 35.0\n",
            "Train_AverageEpLen : 101.0\n",
            "Train_EnvstepsSoFar : 4656\n",
            "TimeSinceStart : 8.72419023513794\n",
            "Training Loss : -0.14500318467617035\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 20 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([626])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 523.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 523.0\n",
            "Eval_MinReturn : 523.0\n",
            "Eval_AverageEpLen : 523.0\n",
            "Train_AverageReturn : 352.0\n",
            "Train_StdReturn : 274.0\n",
            "Train_MaxReturn : 626.0\n",
            "Train_MinReturn : 78.0\n",
            "Train_AverageEpLen : 352.0\n",
            "Train_EnvstepsSoFar : 5360\n",
            "TimeSinceStart : 9.519728899002075\n",
            "Training Loss : 0.030596604570746422\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 21 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([416])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 416.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 416.0\n",
            "Train_MinReturn : 416.0\n",
            "Train_AverageEpLen : 416.0\n",
            "Train_EnvstepsSoFar : 5776\n",
            "TimeSinceStart : 10.346869945526123\n",
            "Training Loss : 0.004614647012203932\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 22 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 412.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 412.0\n",
            "Eval_MinReturn : 412.0\n",
            "Eval_AverageEpLen : 412.0\n",
            "Train_AverageReturn : 524.0\n",
            "Train_StdReturn : 476.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 48.0\n",
            "Train_AverageEpLen : 524.0\n",
            "Train_EnvstepsSoFar : 6824\n",
            "TimeSinceStart : 11.246994972229004\n",
            "Training Loss : 0.007863403297960758\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 23 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([638])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 638.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 638.0\n",
            "Train_MinReturn : 638.0\n",
            "Train_AverageEpLen : 638.0\n",
            "Train_EnvstepsSoFar : 7462\n",
            "TimeSinceStart : 12.30837368965149\n",
            "Training Loss : -0.06433028727769852\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 24 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([463])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 261.0\n",
            "Train_StdReturn : 202.0\n",
            "Train_MaxReturn : 463.0\n",
            "Train_MinReturn : 59.0\n",
            "Train_AverageEpLen : 261.0\n",
            "Train_EnvstepsSoFar : 7984\n",
            "TimeSinceStart : 13.262215375900269\n",
            "Training Loss : -0.08682535588741302\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 25 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 442.5\n",
            "Eval_StdReturn : 256.5\n",
            "Eval_MaxReturn : 699.0\n",
            "Eval_MinReturn : 186.0\n",
            "Eval_AverageEpLen : 442.5\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 8984\n",
            "TimeSinceStart : 14.483965873718262\n",
            "Training Loss : -0.007176208775490522\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 26 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([253])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 253.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 253.0\n",
            "Train_MinReturn : 253.0\n",
            "Train_AverageEpLen : 253.0\n",
            "Train_EnvstepsSoFar : 9237\n",
            "TimeSinceStart : 15.201859951019287\n",
            "Training Loss : -0.016618330031633377\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 27 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 10237\n",
            "TimeSinceStart : 16.401428699493408\n",
            "Training Loss : -0.046343181282281876\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 28 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 11237\n",
            "TimeSinceStart : 17.83454465866089\n",
            "Training Loss : -0.026336297392845154\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 29 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 12237\n",
            "TimeSinceStart : 19.07384991645813\n",
            "Training Loss : 0.022986451163887978\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 30 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 13237\n",
            "TimeSinceStart : 20.222577810287476\n",
            "Training Loss : -0.029422733932733536\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 31 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 14237\n",
            "TimeSinceStart : 21.465174913406372\n",
            "Training Loss : 0.029950883239507675\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 32 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 15237\n",
            "TimeSinceStart : 22.7498037815094\n",
            "Training Loss : -0.024355264380574226\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 33 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 16237\n",
            "TimeSinceStart : 23.92997670173645\n",
            "Training Loss : 0.03133435919880867\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 34 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 17237\n",
            "TimeSinceStart : 25.078336477279663\n",
            "Training Loss : 0.020160550251603127\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 35 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 18237\n",
            "TimeSinceStart : 26.288726329803467\n",
            "Training Loss : -0.016181305050849915\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 36 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 19237\n",
            "TimeSinceStart : 27.44353151321411\n",
            "Training Loss : 0.01891493611037731\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 37 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 20237\n",
            "TimeSinceStart : 28.7649827003479\n",
            "Training Loss : -0.042825013399124146\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 38 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 21237\n",
            "TimeSinceStart : 30.13013243675232\n",
            "Training Loss : 0.016961446031928062\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 39 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 6.639344215393066\n",
            "Eval_StdReturn : 13.18597412109375\n",
            "Eval_MaxReturn : 84.0\n",
            "Eval_MinReturn : 2.0\n",
            "Eval_AverageEpLen : 6.639344262295082\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 22237\n",
            "TimeSinceStart : 31.013442993164062\n",
            "Training Loss : 0.008546581491827965\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 40 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([222])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 11.0\n",
            "Train_StdReturn : 27.17491912841797\n",
            "Train_MaxReturn : 124.0\n",
            "Train_MinReturn : 2.0\n",
            "Train_AverageEpLen : 11.0\n",
            "Train_EnvstepsSoFar : 22468\n",
            "TimeSinceStart : 31.782746076583862\n",
            "Training Loss : -0.003006316488608718\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 41 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 23468\n",
            "TimeSinceStart : 33.07958459854126\n",
            "Training Loss : -0.017440315335989\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 42 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 24468\n",
            "TimeSinceStart : 34.379212856292725\n",
            "Training Loss : 0.004380985628813505\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 43 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 25468\n",
            "TimeSinceStart : 35.77769351005554\n",
            "Training Loss : 0.02232595905661583\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 44 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 248.6666717529297\n",
            "Eval_StdReturn : 280.79925537109375\n",
            "Eval_MaxReturn : 645.0\n",
            "Eval_MinReturn : 29.0\n",
            "Eval_AverageEpLen : 248.66666666666666\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 26468\n",
            "TimeSinceStart : 37.00015664100647\n",
            "Training Loss : -0.015730176120996475\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 45 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([388])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 563.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 563.0\n",
            "Eval_MinReturn : 563.0\n",
            "Eval_AverageEpLen : 563.0\n",
            "Train_AverageReturn : 263.5\n",
            "Train_StdReturn : 124.5\n",
            "Train_MaxReturn : 388.0\n",
            "Train_MinReturn : 139.0\n",
            "Train_AverageEpLen : 263.5\n",
            "Train_EnvstepsSoFar : 26995\n",
            "TimeSinceStart : 37.77054047584534\n",
            "Training Loss : 0.025799328461289406\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 46 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([263])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 263.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 263.0\n",
            "Train_MinReturn : 263.0\n",
            "Train_AverageEpLen : 263.0\n",
            "Train_EnvstepsSoFar : 27258\n",
            "TimeSinceStart : 38.6442973613739\n",
            "Training Loss : 0.03460744023323059\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 47 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 28258\n",
            "TimeSinceStart : 39.839848279953\n",
            "Training Loss : -0.018375786021351814\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 48 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 29258\n",
            "TimeSinceStart : 41.01647758483887\n",
            "Training Loss : 0.013320496305823326\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 49 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 30258\n",
            "TimeSinceStart : 42.26650047302246\n",
            "Training Loss : -0.016593018546700478\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 50 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 31258\n",
            "TimeSinceStart : 43.54559135437012\n",
            "Training Loss : 0.007249405141919851\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 51 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 32258\n",
            "TimeSinceStart : 44.73253130912781\n",
            "Training Loss : 0.004558223765343428\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 52 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 33258\n",
            "TimeSinceStart : 45.89670014381409\n",
            "Training Loss : 0.0033427660819143057\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 53 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 34258\n",
            "TimeSinceStart : 47.130093812942505\n",
            "Training Loss : 0.011019039899110794\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 54 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 35258\n",
            "TimeSinceStart : 48.434077501297\n",
            "Training Loss : -0.0411498136818409\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 55 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 36258\n",
            "TimeSinceStart : 49.60449743270874\n",
            "Training Loss : 0.006210502702742815\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 56 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 37258\n",
            "TimeSinceStart : 50.7963707447052\n",
            "Training Loss : 0.01761774905025959\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 57 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 38258\n",
            "TimeSinceStart : 52.07761764526367\n",
            "Training Loss : 0.005906833801418543\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 58 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 39258\n",
            "TimeSinceStart : 53.43019199371338\n",
            "Training Loss : 0.011682968586683273\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 59 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 40258\n",
            "TimeSinceStart : 54.61580729484558\n",
            "Training Loss : 0.02375842072069645\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 60 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 41258\n",
            "TimeSinceStart : 55.89210391044617\n",
            "Training Loss : -0.014331822283565998\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 61 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 42258\n",
            "TimeSinceStart : 57.16282606124878\n",
            "Training Loss : 0.021301334723830223\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 62 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 651.0\n",
            "Eval_StdReturn : 349.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 302.0\n",
            "Eval_AverageEpLen : 651.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 43258\n",
            "TimeSinceStart : 58.67629671096802\n",
            "Training Loss : 0.015549134463071823\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 63 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 44258\n",
            "TimeSinceStart : 60.023797273635864\n",
            "Training Loss : 0.005396328400820494\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 64 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 503.0\n",
            "Train_StdReturn : 497.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 6.0\n",
            "Train_AverageEpLen : 503.0\n",
            "Train_EnvstepsSoFar : 45264\n",
            "TimeSinceStart : 61.218811988830566\n",
            "Training Loss : 0.030696682631969452\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 65 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 46264\n",
            "TimeSinceStart : 62.587520122528076\n",
            "Training Loss : 0.03570316359400749\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 66 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 47264\n",
            "TimeSinceStart : 63.86301112174988\n",
            "Training Loss : 0.02453307807445526\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 67 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 515.5\n",
            "Eval_StdReturn : 484.5\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 31.0\n",
            "Eval_AverageEpLen : 515.5\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 48264\n",
            "TimeSinceStart : 65.19447875022888\n",
            "Training Loss : 0.012550671584904194\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 68 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 512.5\n",
            "Train_StdReturn : 487.5\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 25.0\n",
            "Train_AverageEpLen : 512.5\n",
            "Train_EnvstepsSoFar : 49289\n",
            "TimeSinceStart : 66.40788650512695\n",
            "Training Loss : -0.007425377145409584\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 69 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([415])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 415.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 415.0\n",
            "Train_MinReturn : 415.0\n",
            "Train_AverageEpLen : 415.0\n",
            "Train_EnvstepsSoFar : 49704\n",
            "TimeSinceStart : 67.24780535697937\n",
            "Training Loss : -0.047888800501823425\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 70 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 50704\n",
            "TimeSinceStart : 68.42964720726013\n",
            "Training Loss : -0.00396225368604064\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 71 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 455.6666564941406\n",
            "Eval_StdReturn : 411.5712585449219\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 5.0\n",
            "Eval_AverageEpLen : 455.6666666666667\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 51704\n",
            "TimeSinceStart : 70.05760145187378\n",
            "Training Loss : 0.0016833344707265496\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 72 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 52704\n",
            "TimeSinceStart : 71.38368725776672\n",
            "Training Loss : 0.012621628120541573\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 73 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 53704\n",
            "TimeSinceStart : 72.58188819885254\n",
            "Training Loss : 0.02513127215206623\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 74 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 511.5\n",
            "Train_StdReturn : 488.5\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 23.0\n",
            "Train_AverageEpLen : 511.5\n",
            "Train_EnvstepsSoFar : 54727\n",
            "TimeSinceStart : 73.88210439682007\n",
            "Training Loss : -0.0011080780532211065\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 75 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 503.0\n",
            "Eval_StdReturn : 497.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 6.0\n",
            "Eval_AverageEpLen : 503.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 55727\n",
            "TimeSinceStart : 75.18885397911072\n",
            "Training Loss : -0.005270103923976421\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 76 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 341.6666564941406\n",
            "Eval_StdReturn : 465.57659912109375\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 3.0\n",
            "Eval_AverageEpLen : 341.6666666666667\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 56727\n",
            "TimeSinceStart : 76.4112160205841\n",
            "Training Loss : 0.02975018508732319\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 77 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 253.75\n",
            "Eval_StdReturn : 430.84820556640625\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 4.0\n",
            "Eval_AverageEpLen : 253.75\n",
            "Train_AverageReturn : 337.6666564941406\n",
            "Train_StdReturn : 468.3420104980469\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 5.0\n",
            "Train_AverageEpLen : 337.6666666666667\n",
            "Train_EnvstepsSoFar : 57740\n",
            "TimeSinceStart : 77.81628680229187\n",
            "Training Loss : -0.019247381016612053\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 78 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 128.875\n",
            "Eval_StdReturn : 329.25726318359375\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 3.0\n",
            "Eval_AverageEpLen : 128.875\n",
            "Train_AverageReturn : 502.5\n",
            "Train_StdReturn : 497.5\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 5.0\n",
            "Train_AverageEpLen : 502.5\n",
            "Train_EnvstepsSoFar : 58745\n",
            "TimeSinceStart : 79.2598648071289\n",
            "Training Loss : 0.010231987573206425\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 79 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 203.60000610351562\n",
            "Eval_StdReturn : 398.20074462890625\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 3.0\n",
            "Eval_AverageEpLen : 203.6\n",
            "Train_AverageReturn : 147.14285278320312\n",
            "Train_StdReturn : 348.17913818359375\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 3.0\n",
            "Train_AverageEpLen : 147.14285714285714\n",
            "Train_EnvstepsSoFar : 59775\n",
            "TimeSinceStart : 80.7326021194458\n",
            "Training Loss : -0.010412769392132759\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 80 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 501.5\n",
            "Train_StdReturn : 498.5\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 3.0\n",
            "Train_AverageEpLen : 501.5\n",
            "Train_EnvstepsSoFar : 60778\n",
            "TimeSinceStart : 81.92862272262573\n",
            "Training Loss : 0.036217980086803436\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 81 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 252.5\n",
            "Eval_StdReturn : 431.56951904296875\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 3.0\n",
            "Eval_AverageEpLen : 252.5\n",
            "Train_AverageReturn : 170.0\n",
            "Train_StdReturn : 371.1882019042969\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 3.0\n",
            "Train_AverageEpLen : 170.0\n",
            "Train_EnvstepsSoFar : 61798\n",
            "TimeSinceStart : 83.24344444274902\n",
            "Training Loss : -0.015486378222703934\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 82 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 336.6666564941406\n",
            "Train_StdReturn : 469.05035400390625\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 3.0\n",
            "Train_AverageEpLen : 336.6666666666667\n",
            "Train_EnvstepsSoFar : 62808\n",
            "TimeSinceStart : 84.58451509475708\n",
            "Training Loss : -0.03711187466979027\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 83 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 501.5\n",
            "Eval_StdReturn : 498.5\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 3.0\n",
            "Eval_AverageEpLen : 501.5\n",
            "Train_AverageReturn : 115.0\n",
            "Train_StdReturn : 312.89898681640625\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 2.0\n",
            "Train_AverageEpLen : 115.0\n",
            "Train_EnvstepsSoFar : 63843\n",
            "TimeSinceStart : 85.86148476600647\n",
            "Training Loss : -0.010399124585092068\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 84 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 501.5\n",
            "Eval_StdReturn : 498.5\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 3.0\n",
            "Eval_AverageEpLen : 501.5\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 64843\n",
            "TimeSinceStart : 87.03770089149475\n",
            "Training Loss : 0.0003582611388992518\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 85 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 335.6666564941406\n",
            "Eval_StdReturn : 469.7547912597656\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 3.0\n",
            "Eval_AverageEpLen : 335.6666666666667\n",
            "Train_AverageReturn : 254.25\n",
            "Train_StdReturn : 430.5603332519531\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 4.0\n",
            "Train_AverageEpLen : 254.25\n",
            "Train_EnvstepsSoFar : 65860\n",
            "TimeSinceStart : 88.27336359024048\n",
            "Training Loss : 0.019372643902897835\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 86 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 170.5\n",
            "Eval_StdReturn : 370.9657287597656\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 3.0\n",
            "Eval_AverageEpLen : 170.5\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 66860\n",
            "TimeSinceStart : 89.5925407409668\n",
            "Training Loss : -0.022382523864507675\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 87 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 67860\n",
            "TimeSinceStart : 90.87312650680542\n",
            "Training Loss : -0.023974206298589706\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 88 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 502.5\n",
            "Train_StdReturn : 497.5\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 5.0\n",
            "Train_AverageEpLen : 502.5\n",
            "Train_EnvstepsSoFar : 68865\n",
            "TimeSinceStart : 92.13606667518616\n",
            "Training Loss : -0.0008954773657023907\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 89 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 501.5\n",
            "Train_StdReturn : 498.5\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 3.0\n",
            "Train_AverageEpLen : 501.5\n",
            "Train_EnvstepsSoFar : 69868\n",
            "TimeSinceStart : 93.35377168655396\n",
            "Training Loss : -0.02539839595556259\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 90 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 70868\n",
            "TimeSinceStart : 94.59729623794556\n",
            "Training Loss : 0.03337014466524124\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 91 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 71868\n",
            "TimeSinceStart : 95.92545819282532\n",
            "Training Loss : -0.031341299414634705\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 92 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 464.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 464.0\n",
            "Eval_MinReturn : 464.0\n",
            "Eval_AverageEpLen : 464.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 72868\n",
            "TimeSinceStart : 96.82443809509277\n",
            "Training Loss : 0.01943093165755272\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 93 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 94.4000015258789\n",
            "Eval_StdReturn : 80.76534271240234\n",
            "Eval_MaxReturn : 240.0\n",
            "Eval_MinReturn : 19.0\n",
            "Eval_AverageEpLen : 94.4\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 73868\n",
            "TimeSinceStart : 97.75242519378662\n",
            "Training Loss : -0.023088471964001656\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 94 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([217])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 97.19999694824219\n",
            "Eval_StdReturn : 38.509220123291016\n",
            "Eval_MaxReturn : 158.0\n",
            "Eval_MinReturn : 53.0\n",
            "Eval_AverageEpLen : 97.2\n",
            "Train_AverageReturn : 54.25\n",
            "Train_StdReturn : 38.97675704956055\n",
            "Train_MaxReturn : 113.0\n",
            "Train_MinReturn : 18.0\n",
            "Train_AverageEpLen : 54.25\n",
            "Train_EnvstepsSoFar : 74085\n",
            "TimeSinceStart : 98.26512360572815\n",
            "Training Loss : -0.05057159811258316\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 95 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([226])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 910.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 910.0\n",
            "Eval_MinReturn : 910.0\n",
            "Eval_AverageEpLen : 910.0\n",
            "Train_AverageReturn : 113.0\n",
            "Train_StdReturn : 22.0\n",
            "Train_MaxReturn : 135.0\n",
            "Train_MinReturn : 91.0\n",
            "Train_AverageEpLen : 113.0\n",
            "Train_EnvstepsSoFar : 74311\n",
            "TimeSinceStart : 99.01449155807495\n",
            "Training Loss : -0.006012148689478636\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 96 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([232])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 232.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 232.0\n",
            "Train_MinReturn : 232.0\n",
            "Train_AverageEpLen : 232.0\n",
            "Train_EnvstepsSoFar : 74543\n",
            "TimeSinceStart : 99.75198316574097\n",
            "Training Loss : 0.02751980908215046\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 97 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 75543\n",
            "TimeSinceStart : 100.99432969093323\n",
            "Training Loss : -0.00046406176988966763\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 98 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 76543\n",
            "TimeSinceStart : 102.30147051811218\n",
            "Training Loss : 0.014642632566392422\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 99 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 512.0\n",
            "Eval_StdReturn : 488.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 24.0\n",
            "Eval_AverageEpLen : 512.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 77543\n",
            "TimeSinceStart : 103.58585810661316\n",
            "Training Loss : 0.0004366302746348083\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python cs285/scripts/run_hw2.py --env_name InvertedPendulum-v2 \\\n",
        "--ep_len 1000 --discount 0.9 -n 100 -l 2 -s 64 -b 200 -lr 0.03 -rtg \\\n",
        "--exp_name q2_b200_r03"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZcn92jNygh0",
        "outputId": "d19016c1-a890-438d-cb04-28c6d81767ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "########################\n",
            "logging outputs to  /content/gdrive/My Drive/cs285_f2021/DRL_policy_grads/cs285/scripts/../../data/q2_b200_r01_InvertedPendulum-v2_06-02-2022_17-34-51\n",
            "########################\n",
            "Using GPU id 0\n",
            "Sequential(\n",
            "  (0): Linear(in_features=4, out_features=64, bias=True)\n",
            "  (1): Tanh()\n",
            "  (2): Linear(in_features=64, out_features=64, bias=True)\n",
            "  (3): Tanh()\n",
            "  (4): Linear(in_features=64, out_features=1, bias=True)\n",
            "  (5): Identity()\n",
            ")\n",
            "\n",
            "\n",
            "********** Iteration 0 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([200])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 15.037036895751953\n",
            "Eval_StdReturn : 8.225892066955566\n",
            "Eval_MaxReturn : 35.0\n",
            "Eval_MinReturn : 4.0\n",
            "Eval_AverageEpLen : 15.037037037037036\n",
            "Train_AverageReturn : 8.038461685180664\n",
            "Train_StdReturn : 4.164693832397461\n",
            "Train_MaxReturn : 20.0\n",
            "Train_MinReturn : 3.0\n",
            "Train_AverageEpLen : 8.038461538461538\n",
            "Train_EnvstepsSoFar : 209\n",
            "TimeSinceStart : 0.4386000633239746\n",
            "Training Loss : -0.06062722206115723\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 1 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([212])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 26.5\n",
            "Eval_StdReturn : 12.961481094360352\n",
            "Eval_MaxReturn : 54.0\n",
            "Eval_MinReturn : 10.0\n",
            "Eval_AverageEpLen : 26.5\n",
            "Train_AverageReturn : 21.200000762939453\n",
            "Train_StdReturn : 9.421252250671387\n",
            "Train_MaxReturn : 38.0\n",
            "Train_MinReturn : 8.0\n",
            "Train_AverageEpLen : 21.2\n",
            "Train_EnvstepsSoFar : 421\n",
            "TimeSinceStart : 0.8352124691009521\n",
            "Training Loss : -0.012315966188907623\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 2 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([220])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 31.0\n",
            "Eval_StdReturn : 12.867456436157227\n",
            "Eval_MaxReturn : 52.0\n",
            "Eval_MinReturn : 7.0\n",
            "Eval_AverageEpLen : 31.0\n",
            "Train_AverageReturn : 27.5\n",
            "Train_StdReturn : 6.422616481781006\n",
            "Train_MaxReturn : 39.0\n",
            "Train_MinReturn : 19.0\n",
            "Train_AverageEpLen : 27.5\n",
            "Train_EnvstepsSoFar : 641\n",
            "TimeSinceStart : 1.2272615432739258\n",
            "Training Loss : -0.07944077998399734\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 3 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([208])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 31.384614944458008\n",
            "Eval_StdReturn : 15.494606971740723\n",
            "Eval_MaxReturn : 58.0\n",
            "Eval_MinReturn : 10.0\n",
            "Eval_AverageEpLen : 31.384615384615383\n",
            "Train_AverageReturn : 52.0\n",
            "Train_StdReturn : 15.394804000854492\n",
            "Train_MaxReturn : 77.0\n",
            "Train_MinReturn : 35.0\n",
            "Train_AverageEpLen : 52.0\n",
            "Train_EnvstepsSoFar : 849\n",
            "TimeSinceStart : 1.6105656623840332\n",
            "Training Loss : 0.06358494609594345\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 4 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([200])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 29.0\n",
            "Eval_StdReturn : 19.81341552734375\n",
            "Eval_MaxReturn : 79.0\n",
            "Eval_MinReturn : 6.0\n",
            "Eval_AverageEpLen : 29.0\n",
            "Train_AverageReturn : 45.79999923706055\n",
            "Train_StdReturn : 11.788128852844238\n",
            "Train_MaxReturn : 65.0\n",
            "Train_MinReturn : 29.0\n",
            "Train_AverageEpLen : 45.8\n",
            "Train_EnvstepsSoFar : 1078\n",
            "TimeSinceStart : 2.013214111328125\n",
            "Training Loss : -0.022688664495944977\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 5 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([203])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 34.66666793823242\n",
            "Eval_StdReturn : 32.1696891784668\n",
            "Eval_MaxReturn : 132.0\n",
            "Eval_MinReturn : 10.0\n",
            "Eval_AverageEpLen : 34.666666666666664\n",
            "Train_AverageReturn : 50.75\n",
            "Train_StdReturn : 10.779030799865723\n",
            "Train_MaxReturn : 67.0\n",
            "Train_MinReturn : 38.0\n",
            "Train_AverageEpLen : 50.75\n",
            "Train_EnvstepsSoFar : 1281\n",
            "TimeSinceStart : 2.4063804149627686\n",
            "Training Loss : 0.005149254109710455\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 6 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([204])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 35.75\n",
            "Eval_StdReturn : 31.51752281188965\n",
            "Eval_MaxReturn : 123.0\n",
            "Eval_MinReturn : 9.0\n",
            "Eval_AverageEpLen : 35.75\n",
            "Train_AverageReturn : 30.571428298950195\n",
            "Train_StdReturn : 14.588225364685059\n",
            "Train_MaxReturn : 59.0\n",
            "Train_MinReturn : 10.0\n",
            "Train_AverageEpLen : 30.571428571428573\n",
            "Train_EnvstepsSoFar : 1495\n",
            "TimeSinceStart : 2.8776113986968994\n",
            "Training Loss : -0.02434602566063404\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 7 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([207])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 27.33333396911621\n",
            "Eval_StdReturn : 13.917215347290039\n",
            "Eval_MaxReturn : 54.0\n",
            "Eval_MinReturn : 8.0\n",
            "Eval_AverageEpLen : 27.333333333333332\n",
            "Train_AverageReturn : 25.875\n",
            "Train_StdReturn : 9.700998306274414\n",
            "Train_MaxReturn : 41.0\n",
            "Train_MinReturn : 12.0\n",
            "Train_AverageEpLen : 25.875\n",
            "Train_EnvstepsSoFar : 1702\n",
            "TimeSinceStart : 3.361595869064331\n",
            "Training Loss : 0.0493118092417717\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 8 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([209])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 33.66666793823242\n",
            "Eval_StdReturn : 14.901528358459473\n",
            "Eval_MaxReturn : 58.0\n",
            "Eval_MinReturn : 14.0\n",
            "Eval_AverageEpLen : 33.666666666666664\n",
            "Train_AverageReturn : 29.85714340209961\n",
            "Train_StdReturn : 16.95732879638672\n",
            "Train_MaxReturn : 57.0\n",
            "Train_MinReturn : 7.0\n",
            "Train_AverageEpLen : 29.857142857142858\n",
            "Train_EnvstepsSoFar : 1911\n",
            "TimeSinceStart : 3.7944796085357666\n",
            "Training Loss : -0.07335684448480606\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 9 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([211])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 36.75\n",
            "Eval_StdReturn : 31.77295684814453\n",
            "Eval_MaxReturn : 110.0\n",
            "Eval_MinReturn : 7.0\n",
            "Eval_AverageEpLen : 36.75\n",
            "Train_AverageReturn : 30.14285659790039\n",
            "Train_StdReturn : 13.367643356323242\n",
            "Train_MaxReturn : 49.0\n",
            "Train_MinReturn : 13.0\n",
            "Train_AverageEpLen : 30.142857142857142\n",
            "Train_EnvstepsSoFar : 2122\n",
            "TimeSinceStart : 4.18462610244751\n",
            "Training Loss : -0.03014696203172207\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 10 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([216])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 38.272727966308594\n",
            "Eval_StdReturn : 19.0792179107666\n",
            "Eval_MaxReturn : 76.0\n",
            "Eval_MinReturn : 10.0\n",
            "Eval_AverageEpLen : 38.27272727272727\n",
            "Train_AverageReturn : 24.0\n",
            "Train_StdReturn : 13.848384857177734\n",
            "Train_MaxReturn : 48.0\n",
            "Train_MinReturn : 9.0\n",
            "Train_AverageEpLen : 24.0\n",
            "Train_EnvstepsSoFar : 2338\n",
            "TimeSinceStart : 4.647956848144531\n",
            "Training Loss : 0.014298651367425919\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 11 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([222])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 50.75\n",
            "Eval_StdReturn : 27.141986846923828\n",
            "Eval_MaxReturn : 95.0\n",
            "Eval_MinReturn : 18.0\n",
            "Eval_AverageEpLen : 50.75\n",
            "Train_AverageReturn : 44.400001525878906\n",
            "Train_StdReturn : 21.657331466674805\n",
            "Train_MaxReturn : 74.0\n",
            "Train_MinReturn : 14.0\n",
            "Train_AverageEpLen : 44.4\n",
            "Train_EnvstepsSoFar : 2560\n",
            "TimeSinceStart : 5.0477917194366455\n",
            "Training Loss : -0.020091602578759193\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 12 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([229])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 75.5\n",
            "Eval_StdReturn : 21.5154972076416\n",
            "Eval_MaxReturn : 112.0\n",
            "Eval_MinReturn : 47.0\n",
            "Eval_AverageEpLen : 75.5\n",
            "Train_AverageReturn : 76.33333587646484\n",
            "Train_StdReturn : 50.02887725830078\n",
            "Train_MaxReturn : 147.0\n",
            "Train_MinReturn : 38.0\n",
            "Train_AverageEpLen : 76.33333333333333\n",
            "Train_EnvstepsSoFar : 2789\n",
            "TimeSinceStart : 5.481949090957642\n",
            "Training Loss : 0.028270471841096878\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 13 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([202])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 92.0\n",
            "Eval_StdReturn : 38.54867172241211\n",
            "Eval_MaxReturn : 134.0\n",
            "Eval_MinReturn : 20.0\n",
            "Eval_AverageEpLen : 92.0\n",
            "Train_AverageReturn : 60.25\n",
            "Train_StdReturn : 31.791311264038086\n",
            "Train_MaxReturn : 101.0\n",
            "Train_MinReturn : 21.0\n",
            "Train_AverageEpLen : 60.25\n",
            "Train_EnvstepsSoFar : 3030\n",
            "TimeSinceStart : 5.974467515945435\n",
            "Training Loss : -0.020822713151574135\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 14 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([227])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 93.5999984741211\n",
            "Eval_StdReturn : 40.072933197021484\n",
            "Eval_MaxReturn : 152.0\n",
            "Eval_MinReturn : 36.0\n",
            "Eval_AverageEpLen : 93.6\n",
            "Train_AverageReturn : 75.66666412353516\n",
            "Train_StdReturn : 34.836124420166016\n",
            "Train_MaxReturn : 116.0\n",
            "Train_MinReturn : 31.0\n",
            "Train_AverageEpLen : 75.66666666666667\n",
            "Train_EnvstepsSoFar : 3257\n",
            "TimeSinceStart : 6.499515533447266\n",
            "Training Loss : -0.037143051624298096\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 15 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([203])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 67.71428680419922\n",
            "Eval_StdReturn : 37.957550048828125\n",
            "Eval_MaxReturn : 123.0\n",
            "Eval_MinReturn : 25.0\n",
            "Eval_AverageEpLen : 67.71428571428571\n",
            "Train_AverageReturn : 203.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 203.0\n",
            "Train_MinReturn : 203.0\n",
            "Train_AverageEpLen : 203.0\n",
            "Train_EnvstepsSoFar : 3460\n",
            "TimeSinceStart : 6.970069408416748\n",
            "Training Loss : 0.039969757199287415\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 16 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([241])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 55.5\n",
            "Eval_StdReturn : 11.811012268066406\n",
            "Eval_MaxReturn : 66.0\n",
            "Eval_MinReturn : 28.0\n",
            "Eval_AverageEpLen : 55.5\n",
            "Train_AverageReturn : 53.0\n",
            "Train_StdReturn : 21.872356414794922\n",
            "Train_MaxReturn : 90.0\n",
            "Train_MinReturn : 24.0\n",
            "Train_AverageEpLen : 53.0\n",
            "Train_EnvstepsSoFar : 3725\n",
            "TimeSinceStart : 7.517212867736816\n",
            "Training Loss : -0.03647661581635475\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 17 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([206])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 41.16666793823242\n",
            "Eval_StdReturn : 22.456748962402344\n",
            "Eval_MaxReturn : 103.0\n",
            "Eval_MinReturn : 17.0\n",
            "Eval_AverageEpLen : 41.166666666666664\n",
            "Train_AverageReturn : 68.66666412353516\n",
            "Train_StdReturn : 35.31131362915039\n",
            "Train_MaxReturn : 109.0\n",
            "Train_MinReturn : 23.0\n",
            "Train_AverageEpLen : 68.66666666666667\n",
            "Train_EnvstepsSoFar : 3931\n",
            "TimeSinceStart : 8.033201694488525\n",
            "Training Loss : -0.07393264025449753\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 18 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([218])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 41.0\n",
            "Eval_StdReturn : 22.930328369140625\n",
            "Eval_MaxReturn : 97.0\n",
            "Eval_MinReturn : 19.0\n",
            "Eval_AverageEpLen : 41.0\n",
            "Train_AverageReturn : 41.83333206176758\n",
            "Train_StdReturn : 12.44208812713623\n",
            "Train_MaxReturn : 60.0\n",
            "Train_MinReturn : 24.0\n",
            "Train_AverageEpLen : 41.833333333333336\n",
            "Train_EnvstepsSoFar : 4182\n",
            "TimeSinceStart : 8.519781827926636\n",
            "Training Loss : -0.015764741227030754\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 19 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([204])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 43.0\n",
            "Eval_StdReturn : 25.27845001220703\n",
            "Eval_MaxReturn : 108.0\n",
            "Eval_MinReturn : 23.0\n",
            "Eval_AverageEpLen : 43.0\n",
            "Train_AverageReturn : 25.5\n",
            "Train_StdReturn : 15.256146430969238\n",
            "Train_MaxReturn : 51.0\n",
            "Train_MinReturn : 7.0\n",
            "Train_AverageEpLen : 25.5\n",
            "Train_EnvstepsSoFar : 4386\n",
            "TimeSinceStart : 8.915181875228882\n",
            "Training Loss : -0.08615834265947342\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 20 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([202])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 44.20000076293945\n",
            "Eval_StdReturn : 34.69812774658203\n",
            "Eval_MaxReturn : 122.0\n",
            "Eval_MinReturn : 8.0\n",
            "Eval_AverageEpLen : 44.2\n",
            "Train_AverageReturn : 50.5\n",
            "Train_StdReturn : 23.07054328918457\n",
            "Train_MaxReturn : 76.0\n",
            "Train_MinReturn : 13.0\n",
            "Train_AverageEpLen : 50.5\n",
            "Train_EnvstepsSoFar : 4588\n",
            "TimeSinceStart : 9.322419166564941\n",
            "Training Loss : -0.03048289567232132\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 21 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([254])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 90.4000015258789\n",
            "Eval_StdReturn : 74.04755401611328\n",
            "Eval_MaxReturn : 229.0\n",
            "Eval_MinReturn : 29.0\n",
            "Eval_AverageEpLen : 90.4\n",
            "Train_AverageReturn : 84.66666412353516\n",
            "Train_StdReturn : 4.642796039581299\n",
            "Train_MaxReturn : 91.0\n",
            "Train_MinReturn : 80.0\n",
            "Train_AverageEpLen : 84.66666666666667\n",
            "Train_EnvstepsSoFar : 4842\n",
            "TimeSinceStart : 9.78549599647522\n",
            "Training Loss : 0.01150765735656023\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 22 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([232])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 80.5999984741211\n",
            "Eval_StdReturn : 23.627103805541992\n",
            "Eval_MaxReturn : 104.0\n",
            "Eval_MinReturn : 39.0\n",
            "Eval_AverageEpLen : 80.6\n",
            "Train_AverageReturn : 77.33333587646484\n",
            "Train_StdReturn : 26.081069946289062\n",
            "Train_MaxReturn : 101.0\n",
            "Train_MinReturn : 41.0\n",
            "Train_AverageEpLen : 77.33333333333333\n",
            "Train_EnvstepsSoFar : 5074\n",
            "TimeSinceStart : 10.257467031478882\n",
            "Training Loss : -0.02637595124542713\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 23 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([206])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 81.5999984741211\n",
            "Eval_StdReturn : 28.97308921813965\n",
            "Eval_MaxReturn : 106.0\n",
            "Eval_MinReturn : 25.0\n",
            "Eval_AverageEpLen : 81.6\n",
            "Train_AverageReturn : 55.5\n",
            "Train_StdReturn : 35.83643341064453\n",
            "Train_MaxReturn : 135.0\n",
            "Train_MinReturn : 30.0\n",
            "Train_AverageEpLen : 55.5\n",
            "Train_EnvstepsSoFar : 5407\n",
            "TimeSinceStart : 10.794028997421265\n",
            "Training Loss : -0.01940167509019375\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 24 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([204])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 77.0\n",
            "Eval_StdReturn : 29.034461975097656\n",
            "Eval_MaxReturn : 125.0\n",
            "Eval_MinReturn : 29.0\n",
            "Eval_AverageEpLen : 77.0\n",
            "Train_AverageReturn : 51.0\n",
            "Train_StdReturn : 39.93745040893555\n",
            "Train_MaxReturn : 112.0\n",
            "Train_MinReturn : 8.0\n",
            "Train_AverageEpLen : 51.0\n",
            "Train_EnvstepsSoFar : 5611\n",
            "TimeSinceStart : 11.193644046783447\n",
            "Training Loss : -0.14925764501094818\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 25 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([203])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 92.80000305175781\n",
            "Eval_StdReturn : 20.419597625732422\n",
            "Eval_MaxReturn : 114.0\n",
            "Eval_MinReturn : 60.0\n",
            "Eval_AverageEpLen : 92.8\n",
            "Train_AverageReturn : 101.5\n",
            "Train_StdReturn : 65.5\n",
            "Train_MaxReturn : 167.0\n",
            "Train_MinReturn : 36.0\n",
            "Train_AverageEpLen : 101.5\n",
            "Train_EnvstepsSoFar : 5814\n",
            "TimeSinceStart : 11.605682373046875\n",
            "Training Loss : -0.0684293881058693\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 26 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([214])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 90.80000305175781\n",
            "Eval_StdReturn : 19.374208450317383\n",
            "Eval_MaxReturn : 117.0\n",
            "Eval_MinReturn : 57.0\n",
            "Eval_AverageEpLen : 90.8\n",
            "Train_AverageReturn : 87.0\n",
            "Train_StdReturn : 28.284271240234375\n",
            "Train_MaxReturn : 107.0\n",
            "Train_MinReturn : 47.0\n",
            "Train_AverageEpLen : 87.0\n",
            "Train_EnvstepsSoFar : 6075\n",
            "TimeSinceStart : 12.12826156616211\n",
            "Training Loss : -0.017289312556385994\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 27 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([279])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 78.83333587646484\n",
            "Eval_StdReturn : 8.591015815734863\n",
            "Eval_MaxReturn : 92.0\n",
            "Eval_MinReturn : 69.0\n",
            "Eval_AverageEpLen : 78.83333333333333\n",
            "Train_AverageReturn : 93.0\n",
            "Train_StdReturn : 14.16568660736084\n",
            "Train_MaxReturn : 113.0\n",
            "Train_MinReturn : 82.0\n",
            "Train_AverageEpLen : 93.0\n",
            "Train_EnvstepsSoFar : 6354\n",
            "TimeSinceStart : 12.603253841400146\n",
            "Training Loss : -0.05563822016119957\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 28 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([224])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 69.0\n",
            "Eval_StdReturn : 17.37814712524414\n",
            "Eval_MaxReturn : 95.0\n",
            "Eval_MinReturn : 45.0\n",
            "Eval_AverageEpLen : 69.0\n",
            "Train_AverageReturn : 74.66666412353516\n",
            "Train_StdReturn : 27.45096778869629\n",
            "Train_MaxReturn : 97.0\n",
            "Train_MinReturn : 36.0\n",
            "Train_AverageEpLen : 74.66666666666667\n",
            "Train_EnvstepsSoFar : 6578\n",
            "TimeSinceStart : 13.049375772476196\n",
            "Training Loss : -0.09962043911218643\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 29 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([235])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 65.42857360839844\n",
            "Eval_StdReturn : 15.962967872619629\n",
            "Eval_MaxReturn : 87.0\n",
            "Eval_MinReturn : 36.0\n",
            "Eval_AverageEpLen : 65.42857142857143\n",
            "Train_AverageReturn : 78.33333587646484\n",
            "Train_StdReturn : 23.15647315979004\n",
            "Train_MaxReturn : 111.0\n",
            "Train_MinReturn : 60.0\n",
            "Train_AverageEpLen : 78.33333333333333\n",
            "Train_EnvstepsSoFar : 6813\n",
            "TimeSinceStart : 13.508808851242065\n",
            "Training Loss : -0.059303298592567444\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 30 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([209])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 83.80000305175781\n",
            "Eval_StdReturn : 19.823219299316406\n",
            "Eval_MaxReturn : 114.0\n",
            "Eval_MinReturn : 58.0\n",
            "Eval_AverageEpLen : 83.8\n",
            "Train_AverageReturn : 69.66666412353516\n",
            "Train_StdReturn : 8.178563117980957\n",
            "Train_MaxReturn : 80.0\n",
            "Train_MinReturn : 60.0\n",
            "Train_AverageEpLen : 69.66666666666667\n",
            "Train_EnvstepsSoFar : 7022\n",
            "TimeSinceStart : 13.93026065826416\n",
            "Training Loss : -0.07746047526597977\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 31 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([245])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 117.0\n",
            "Eval_StdReturn : 71.07038879394531\n",
            "Eval_MaxReturn : 240.0\n",
            "Eval_MinReturn : 72.0\n",
            "Eval_AverageEpLen : 117.0\n",
            "Train_AverageReturn : 71.0\n",
            "Train_StdReturn : 19.235383987426758\n",
            "Train_MaxReturn : 87.0\n",
            "Train_MinReturn : 39.0\n",
            "Train_AverageEpLen : 71.0\n",
            "Train_EnvstepsSoFar : 7306\n",
            "TimeSinceStart : 14.378254652023315\n",
            "Training Loss : 0.036591097712516785\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 32 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([247])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 104.5\n",
            "Eval_StdReturn : 32.96589279174805\n",
            "Eval_MaxReturn : 157.0\n",
            "Eval_MinReturn : 71.0\n",
            "Eval_AverageEpLen : 104.5\n",
            "Train_AverageReturn : 61.75\n",
            "Train_StdReturn : 11.776565551757812\n",
            "Train_MaxReturn : 79.0\n",
            "Train_MinReturn : 49.0\n",
            "Train_AverageEpLen : 61.75\n",
            "Train_EnvstepsSoFar : 7553\n",
            "TimeSinceStart : 14.820501327514648\n",
            "Training Loss : 0.005397418513894081\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 33 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([284])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 152.6666717529297\n",
            "Eval_StdReturn : 49.5602912902832\n",
            "Eval_MaxReturn : 221.0\n",
            "Eval_MinReturn : 105.0\n",
            "Eval_AverageEpLen : 152.66666666666666\n",
            "Train_AverageReturn : 94.66666412353516\n",
            "Train_StdReturn : 8.339997291564941\n",
            "Train_MaxReturn : 102.0\n",
            "Train_MinReturn : 83.0\n",
            "Train_AverageEpLen : 94.66666666666667\n",
            "Train_EnvstepsSoFar : 7837\n",
            "TimeSinceStart : 15.370038270950317\n",
            "Training Loss : 0.04514684900641441\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 34 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([255])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 133.0\n",
            "Eval_StdReturn : 41.412559509277344\n",
            "Eval_MaxReturn : 172.0\n",
            "Eval_MinReturn : 64.0\n",
            "Eval_AverageEpLen : 133.0\n",
            "Train_AverageReturn : 85.0\n",
            "Train_StdReturn : 24.041629791259766\n",
            "Train_MaxReturn : 119.0\n",
            "Train_MinReturn : 68.0\n",
            "Train_AverageEpLen : 85.0\n",
            "Train_EnvstepsSoFar : 8092\n",
            "TimeSinceStart : 15.962703466415405\n",
            "Training Loss : -0.024776535108685493\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 35 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([203])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 245.0\n",
            "Eval_StdReturn : 46.0\n",
            "Eval_MaxReturn : 291.0\n",
            "Eval_MinReturn : 199.0\n",
            "Eval_AverageEpLen : 245.0\n",
            "Train_AverageReturn : 169.0\n",
            "Train_StdReturn : 34.0\n",
            "Train_MaxReturn : 203.0\n",
            "Train_MinReturn : 135.0\n",
            "Train_AverageEpLen : 169.0\n",
            "Train_EnvstepsSoFar : 8430\n",
            "TimeSinceStart : 16.556281089782715\n",
            "Training Loss : -0.001996639184653759\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 36 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([263])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 148.25\n",
            "Eval_StdReturn : 42.26331329345703\n",
            "Eval_MaxReturn : 214.0\n",
            "Eval_MinReturn : 106.0\n",
            "Eval_AverageEpLen : 148.25\n",
            "Train_AverageReturn : 131.5\n",
            "Train_StdReturn : 23.5\n",
            "Train_MaxReturn : 155.0\n",
            "Train_MinReturn : 108.0\n",
            "Train_AverageEpLen : 131.5\n",
            "Train_EnvstepsSoFar : 8693\n",
            "TimeSinceStart : 17.163100719451904\n",
            "Training Loss : 0.042842213064432144\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 37 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([289])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 134.0\n",
            "Eval_StdReturn : 25.524497985839844\n",
            "Eval_MaxReturn : 164.0\n",
            "Eval_MinReturn : 101.0\n",
            "Eval_AverageEpLen : 134.0\n",
            "Train_AverageReturn : 144.5\n",
            "Train_StdReturn : 1.5\n",
            "Train_MaxReturn : 146.0\n",
            "Train_MinReturn : 143.0\n",
            "Train_AverageEpLen : 144.5\n",
            "Train_EnvstepsSoFar : 8982\n",
            "TimeSinceStart : 17.753252267837524\n",
            "Training Loss : 0.007615640759468079\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 38 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([322])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 134.3333282470703\n",
            "Eval_StdReturn : 24.22579002380371\n",
            "Eval_MaxReturn : 168.0\n",
            "Eval_MinReturn : 112.0\n",
            "Eval_AverageEpLen : 134.33333333333334\n",
            "Train_AverageReturn : 161.0\n",
            "Train_StdReturn : 20.0\n",
            "Train_MaxReturn : 181.0\n",
            "Train_MinReturn : 141.0\n",
            "Train_AverageEpLen : 161.0\n",
            "Train_EnvstepsSoFar : 9304\n",
            "TimeSinceStart : 18.243221282958984\n",
            "Training Loss : 0.06651932746171951\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 39 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([236])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 168.6666717529297\n",
            "Eval_StdReturn : 11.264496803283691\n",
            "Eval_MaxReturn : 179.0\n",
            "Eval_MinReturn : 153.0\n",
            "Eval_AverageEpLen : 168.66666666666666\n",
            "Train_AverageReturn : 118.0\n",
            "Train_StdReturn : 65.0\n",
            "Train_MaxReturn : 183.0\n",
            "Train_MinReturn : 53.0\n",
            "Train_AverageEpLen : 118.0\n",
            "Train_EnvstepsSoFar : 9540\n",
            "TimeSinceStart : 18.729652404785156\n",
            "Training Loss : -0.04311031475663185\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 40 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([230])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 174.6666717529297\n",
            "Eval_StdReturn : 16.213848114013672\n",
            "Eval_MaxReturn : 197.0\n",
            "Eval_MinReturn : 159.0\n",
            "Eval_AverageEpLen : 174.66666666666666\n",
            "Train_AverageReturn : 193.5\n",
            "Train_StdReturn : 36.5\n",
            "Train_MaxReturn : 230.0\n",
            "Train_MinReturn : 157.0\n",
            "Train_AverageEpLen : 193.5\n",
            "Train_EnvstepsSoFar : 9927\n",
            "TimeSinceStart : 19.27823519706726\n",
            "Training Loss : 0.004001750145107508\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 41 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([208])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 172.3333282470703\n",
            "Eval_StdReturn : 9.53356647491455\n",
            "Eval_MaxReturn : 185.0\n",
            "Eval_MinReturn : 162.0\n",
            "Eval_AverageEpLen : 172.33333333333334\n",
            "Train_AverageReturn : 208.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 208.0\n",
            "Train_MinReturn : 208.0\n",
            "Train_AverageEpLen : 208.0\n",
            "Train_EnvstepsSoFar : 10135\n",
            "TimeSinceStart : 19.78297209739685\n",
            "Training Loss : -0.07492256164550781\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 42 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([238])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 151.3333282470703\n",
            "Eval_StdReturn : 11.085526466369629\n",
            "Eval_MaxReturn : 164.0\n",
            "Eval_MinReturn : 137.0\n",
            "Eval_AverageEpLen : 151.33333333333334\n",
            "Train_AverageReturn : 119.0\n",
            "Train_StdReturn : 48.0\n",
            "Train_MaxReturn : 167.0\n",
            "Train_MinReturn : 71.0\n",
            "Train_AverageEpLen : 119.0\n",
            "Train_EnvstepsSoFar : 10373\n",
            "TimeSinceStart : 20.192685842514038\n",
            "Training Loss : -0.03030753880739212\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 43 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([305])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 102.0\n",
            "Eval_StdReturn : 17.1318416595459\n",
            "Eval_MaxReturn : 124.0\n",
            "Eval_MinReturn : 77.0\n",
            "Eval_AverageEpLen : 102.0\n",
            "Train_AverageReturn : 152.5\n",
            "Train_StdReturn : 11.5\n",
            "Train_MaxReturn : 164.0\n",
            "Train_MinReturn : 141.0\n",
            "Train_AverageEpLen : 152.5\n",
            "Train_EnvstepsSoFar : 10678\n",
            "TimeSinceStart : 20.6133234500885\n",
            "Training Loss : -0.005371143575757742\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 44 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([249])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 120.75\n",
            "Eval_StdReturn : 19.214252471923828\n",
            "Eval_MaxReturn : 137.0\n",
            "Eval_MinReturn : 89.0\n",
            "Eval_AverageEpLen : 120.75\n",
            "Train_AverageReturn : 124.5\n",
            "Train_StdReturn : 4.5\n",
            "Train_MaxReturn : 129.0\n",
            "Train_MinReturn : 120.0\n",
            "Train_AverageEpLen : 124.5\n",
            "Train_EnvstepsSoFar : 10927\n",
            "TimeSinceStart : 21.111062049865723\n",
            "Training Loss : -0.01523885689675808\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 45 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([263])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 127.5\n",
            "Eval_StdReturn : 9.287087440490723\n",
            "Eval_MaxReturn : 143.0\n",
            "Eval_MinReturn : 119.0\n",
            "Eval_AverageEpLen : 127.5\n",
            "Train_AverageReturn : 131.5\n",
            "Train_StdReturn : 21.5\n",
            "Train_MaxReturn : 153.0\n",
            "Train_MinReturn : 110.0\n",
            "Train_AverageEpLen : 131.5\n",
            "Train_EnvstepsSoFar : 11190\n",
            "TimeSinceStart : 21.59071707725525\n",
            "Training Loss : 0.01914377510547638\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 46 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([291])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 97.80000305175781\n",
            "Eval_StdReturn : 43.87892532348633\n",
            "Eval_MaxReturn : 141.0\n",
            "Eval_MinReturn : 25.0\n",
            "Eval_AverageEpLen : 97.8\n",
            "Train_AverageReturn : 145.5\n",
            "Train_StdReturn : 13.5\n",
            "Train_MaxReturn : 159.0\n",
            "Train_MinReturn : 132.0\n",
            "Train_AverageEpLen : 145.5\n",
            "Train_EnvstepsSoFar : 11481\n",
            "TimeSinceStart : 22.178617477416992\n",
            "Training Loss : -0.011407537385821342\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 47 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([293])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 110.0\n",
            "Eval_StdReturn : 11.640446662902832\n",
            "Eval_MaxReturn : 129.0\n",
            "Eval_MinReturn : 98.0\n",
            "Eval_AverageEpLen : 110.0\n",
            "Train_AverageReturn : 97.66666412353516\n",
            "Train_StdReturn : 36.463069915771484\n",
            "Train_MaxReturn : 140.0\n",
            "Train_MinReturn : 51.0\n",
            "Train_AverageEpLen : 97.66666666666667\n",
            "Train_EnvstepsSoFar : 11774\n",
            "TimeSinceStart : 22.725066900253296\n",
            "Training Loss : -0.014283173717558384\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 48 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([210])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 133.3333282470703\n",
            "Eval_StdReturn : 22.60285186767578\n",
            "Eval_MaxReturn : 159.0\n",
            "Eval_MinReturn : 104.0\n",
            "Eval_AverageEpLen : 133.33333333333334\n",
            "Train_AverageReturn : 105.0\n",
            "Train_StdReturn : 20.0\n",
            "Train_MaxReturn : 125.0\n",
            "Train_MinReturn : 85.0\n",
            "Train_AverageEpLen : 105.0\n",
            "Train_EnvstepsSoFar : 11984\n",
            "TimeSinceStart : 23.16750478744507\n",
            "Training Loss : -0.05463671311736107\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 49 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([270])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 95.4000015258789\n",
            "Eval_StdReturn : 38.61916732788086\n",
            "Eval_MaxReturn : 137.0\n",
            "Eval_MinReturn : 43.0\n",
            "Eval_AverageEpLen : 95.4\n",
            "Train_AverageReturn : 135.0\n",
            "Train_StdReturn : 9.0\n",
            "Train_MaxReturn : 144.0\n",
            "Train_MinReturn : 126.0\n",
            "Train_AverageEpLen : 135.0\n",
            "Train_EnvstepsSoFar : 12254\n",
            "TimeSinceStart : 23.671648502349854\n",
            "Training Loss : 0.004110484384000301\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 50 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([220])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 123.0\n",
            "Eval_StdReturn : 15.89024829864502\n",
            "Eval_MaxReturn : 137.0\n",
            "Eval_MinReturn : 96.0\n",
            "Eval_AverageEpLen : 123.0\n",
            "Train_AverageReturn : 110.0\n",
            "Train_StdReturn : 4.0\n",
            "Train_MaxReturn : 114.0\n",
            "Train_MinReturn : 106.0\n",
            "Train_AverageEpLen : 110.0\n",
            "Train_EnvstepsSoFar : 12474\n",
            "TimeSinceStart : 24.20816421508789\n",
            "Training Loss : 0.01714727096259594\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 51 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([310])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 98.80000305175781\n",
            "Eval_StdReturn : 41.208736419677734\n",
            "Eval_MaxReturn : 147.0\n",
            "Eval_MinReturn : 26.0\n",
            "Eval_AverageEpLen : 98.8\n",
            "Train_AverageReturn : 103.33333587646484\n",
            "Train_StdReturn : 27.920522689819336\n",
            "Train_MaxReturn : 126.0\n",
            "Train_MinReturn : 64.0\n",
            "Train_AverageEpLen : 103.33333333333333\n",
            "Train_EnvstepsSoFar : 12784\n",
            "TimeSinceStart : 24.77236795425415\n",
            "Training Loss : -0.056156281381845474\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 52 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([231])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 177.3333282470703\n",
            "Eval_StdReturn : 18.372684478759766\n",
            "Eval_MaxReturn : 200.0\n",
            "Eval_MinReturn : 155.0\n",
            "Eval_AverageEpLen : 177.33333333333334\n",
            "Train_AverageReturn : 115.5\n",
            "Train_StdReturn : 47.5\n",
            "Train_MaxReturn : 163.0\n",
            "Train_MinReturn : 68.0\n",
            "Train_AverageEpLen : 115.5\n",
            "Train_EnvstepsSoFar : 13015\n",
            "TimeSinceStart : 25.226227521896362\n",
            "Training Loss : -0.14376015961170197\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 53 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([233])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 142.0\n",
            "Eval_StdReturn : 40.03331756591797\n",
            "Eval_MaxReturn : 190.0\n",
            "Eval_MinReturn : 92.0\n",
            "Eval_AverageEpLen : 142.0\n",
            "Train_AverageReturn : 77.66666412353516\n",
            "Train_StdReturn : 38.37823486328125\n",
            "Train_MaxReturn : 125.0\n",
            "Train_MinReturn : 31.0\n",
            "Train_AverageEpLen : 77.66666666666667\n",
            "Train_EnvstepsSoFar : 13248\n",
            "TimeSinceStart : 25.65300679206848\n",
            "Training Loss : -0.10172946006059647\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 54 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([232])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 239.0\n",
            "Eval_StdReturn : 18.0\n",
            "Eval_MaxReturn : 257.0\n",
            "Eval_MinReturn : 221.0\n",
            "Eval_AverageEpLen : 239.0\n",
            "Train_AverageReturn : 232.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 232.0\n",
            "Train_MinReturn : 232.0\n",
            "Train_AverageEpLen : 232.0\n",
            "Train_EnvstepsSoFar : 13480\n",
            "TimeSinceStart : 26.100688457489014\n",
            "Training Loss : -0.016704130917787552\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 55 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([248])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 466.0\n",
            "Eval_StdReturn : 99.0\n",
            "Eval_MaxReturn : 565.0\n",
            "Eval_MinReturn : 367.0\n",
            "Eval_AverageEpLen : 466.0\n",
            "Train_AverageReturn : 248.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 248.0\n",
            "Train_MinReturn : 248.0\n",
            "Train_AverageEpLen : 248.0\n",
            "Train_EnvstepsSoFar : 13728\n",
            "TimeSinceStart : 26.879366874694824\n",
            "Training Loss : 0.008495945483446121\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 56 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([387])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 387.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 387.0\n",
            "Train_MinReturn : 387.0\n",
            "Train_AverageEpLen : 387.0\n",
            "Train_EnvstepsSoFar : 14115\n",
            "TimeSinceStart : 27.727020502090454\n",
            "Training Loss : -0.014005424454808235\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 57 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 862.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 862.0\n",
            "Eval_MinReturn : 862.0\n",
            "Eval_AverageEpLen : 862.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 15115\n",
            "TimeSinceStart : 28.87522554397583\n",
            "Training Loss : -0.015266701579093933\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 58 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 428.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 428.0\n",
            "Eval_MinReturn : 428.0\n",
            "Eval_AverageEpLen : 428.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 16115\n",
            "TimeSinceStart : 29.805862426757812\n",
            "Training Loss : -0.004490585532039404\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 59 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([599])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 599.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 599.0\n",
            "Train_MinReturn : 599.0\n",
            "Train_AverageEpLen : 599.0\n",
            "Train_EnvstepsSoFar : 16714\n",
            "TimeSinceStart : 30.782430171966553\n",
            "Training Loss : -0.04426754638552666\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 60 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 749.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 749.0\n",
            "Eval_MinReturn : 749.0\n",
            "Eval_AverageEpLen : 749.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 17714\n",
            "TimeSinceStart : 31.94804859161377\n",
            "Training Loss : -0.02050330489873886\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 61 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 188.0\n",
            "Eval_StdReturn : 122.4744873046875\n",
            "Eval_MaxReturn : 338.0\n",
            "Eval_MinReturn : 38.0\n",
            "Eval_AverageEpLen : 188.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 18714\n",
            "TimeSinceStart : 32.96365261077881\n",
            "Training Loss : 0.0007252731593325734\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 62 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 217.0\n",
            "Eval_StdReturn : 150.9591522216797\n",
            "Eval_MaxReturn : 430.0\n",
            "Eval_MinReturn : 98.0\n",
            "Eval_AverageEpLen : 217.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 19714\n",
            "TimeSinceStart : 34.06710481643677\n",
            "Training Loss : -0.030979158356785774\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 63 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([813])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 518.5\n",
            "Eval_StdReturn : 190.5\n",
            "Eval_MaxReturn : 709.0\n",
            "Eval_MinReturn : 328.0\n",
            "Eval_AverageEpLen : 518.5\n",
            "Train_AverageReturn : 813.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 813.0\n",
            "Train_MinReturn : 813.0\n",
            "Train_AverageEpLen : 813.0\n",
            "Train_EnvstepsSoFar : 20527\n",
            "TimeSinceStart : 35.15845608711243\n",
            "Training Loss : -0.0706256851553917\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 64 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 250.5\n",
            "Eval_StdReturn : 97.5\n",
            "Eval_MaxReturn : 348.0\n",
            "Eval_MinReturn : 153.0\n",
            "Eval_AverageEpLen : 250.5\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 21527\n",
            "TimeSinceStart : 36.082191467285156\n",
            "Training Loss : 0.006996437441557646\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 65 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([453])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 977.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 977.0\n",
            "Eval_MinReturn : 977.0\n",
            "Eval_AverageEpLen : 977.0\n",
            "Train_AverageReturn : 453.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 453.0\n",
            "Train_MinReturn : 453.0\n",
            "Train_AverageEpLen : 453.0\n",
            "Train_EnvstepsSoFar : 21980\n",
            "TimeSinceStart : 36.994547605514526\n",
            "Training Loss : -0.0022611638996750116\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 66 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([234])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 234.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 234.0\n",
            "Train_MinReturn : 234.0\n",
            "Train_AverageEpLen : 234.0\n",
            "Train_EnvstepsSoFar : 22214\n",
            "TimeSinceStart : 37.75900626182556\n",
            "Training Loss : -0.0029510760214179754\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 67 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([355])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 990.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 990.0\n",
            "Eval_MinReturn : 990.0\n",
            "Eval_AverageEpLen : 990.0\n",
            "Train_AverageReturn : 177.5\n",
            "Train_StdReturn : 13.5\n",
            "Train_MaxReturn : 191.0\n",
            "Train_MinReturn : 164.0\n",
            "Train_AverageEpLen : 177.5\n",
            "Train_EnvstepsSoFar : 22569\n",
            "TimeSinceStart : 38.535520792007446\n",
            "Training Loss : -0.01442625466734171\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 68 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 23569\n",
            "TimeSinceStart : 39.7844352722168\n",
            "Training Loss : 0.01122504472732544\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 69 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 24569\n",
            "TimeSinceStart : 40.94701170921326\n",
            "Training Loss : -0.020720627158880234\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 70 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 25569\n",
            "TimeSinceStart : 42.120668172836304\n",
            "Training Loss : 0.014421746134757996\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 71 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 703.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 703.0\n",
            "Eval_MinReturn : 703.0\n",
            "Eval_AverageEpLen : 703.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 26569\n",
            "TimeSinceStart : 43.17204523086548\n",
            "Training Loss : -0.0010155029594898224\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 72 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 27569\n",
            "TimeSinceStart : 44.37728023529053\n",
            "Training Loss : 0.003371696686372161\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 73 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 221.3333282470703\n",
            "Eval_StdReturn : 66.81982421875\n",
            "Eval_MaxReturn : 288.0\n",
            "Eval_MinReturn : 130.0\n",
            "Eval_AverageEpLen : 221.33333333333334\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 28569\n",
            "TimeSinceStart : 45.461360692977905\n",
            "Training Loss : -0.004292976576834917\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 74 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([836])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 196.3333282470703\n",
            "Eval_StdReturn : 44.289451599121094\n",
            "Eval_MaxReturn : 258.0\n",
            "Eval_MinReturn : 156.0\n",
            "Eval_AverageEpLen : 196.33333333333334\n",
            "Train_AverageReturn : 836.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 836.0\n",
            "Train_MinReturn : 836.0\n",
            "Train_AverageEpLen : 836.0\n",
            "Train_EnvstepsSoFar : 29405\n",
            "TimeSinceStart : 46.41187906265259\n",
            "Training Loss : 0.005617234855890274\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 75 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([340])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 204.3333282470703\n",
            "Eval_StdReturn : 106.5655746459961\n",
            "Eval_MaxReturn : 355.0\n",
            "Eval_MinReturn : 126.0\n",
            "Eval_AverageEpLen : 204.33333333333334\n",
            "Train_AverageReturn : 170.0\n",
            "Train_StdReturn : 7.0\n",
            "Train_MaxReturn : 177.0\n",
            "Train_MinReturn : 163.0\n",
            "Train_AverageEpLen : 170.0\n",
            "Train_EnvstepsSoFar : 29745\n",
            "TimeSinceStart : 46.9782338142395\n",
            "Training Loss : 0.03547951206564903\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 76 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([218])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 188.3333282470703\n",
            "Eval_StdReturn : 34.12070083618164\n",
            "Eval_MaxReturn : 236.0\n",
            "Eval_MinReturn : 158.0\n",
            "Eval_AverageEpLen : 188.33333333333334\n",
            "Train_AverageReturn : 218.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 218.0\n",
            "Train_MinReturn : 218.0\n",
            "Train_AverageEpLen : 218.0\n",
            "Train_EnvstepsSoFar : 29963\n",
            "TimeSinceStart : 47.45002746582031\n",
            "Training Loss : 0.060618747025728226\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 77 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([355])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 147.0\n",
            "Eval_StdReturn : 93.69364929199219\n",
            "Eval_MaxReturn : 292.0\n",
            "Eval_MinReturn : 33.0\n",
            "Eval_AverageEpLen : 147.0\n",
            "Train_AverageReturn : 177.5\n",
            "Train_StdReturn : 20.5\n",
            "Train_MaxReturn : 198.0\n",
            "Train_MinReturn : 157.0\n",
            "Train_AverageEpLen : 177.5\n",
            "Train_EnvstepsSoFar : 30318\n",
            "TimeSinceStart : 48.05405592918396\n",
            "Training Loss : -0.012660297565162182\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 78 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([227])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 310.5\n",
            "Eval_StdReturn : 41.5\n",
            "Eval_MaxReturn : 352.0\n",
            "Eval_MinReturn : 269.0\n",
            "Eval_AverageEpLen : 310.5\n",
            "Train_AverageReturn : 113.5\n",
            "Train_StdReturn : 2.5\n",
            "Train_MaxReturn : 116.0\n",
            "Train_MinReturn : 111.0\n",
            "Train_AverageEpLen : 113.5\n",
            "Train_EnvstepsSoFar : 30545\n",
            "TimeSinceStart : 48.556150674819946\n",
            "Training Loss : -0.07684050500392914\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 79 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([271])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 54.0\n",
            "Eval_StdReturn : 48.47886276245117\n",
            "Eval_MaxReturn : 177.0\n",
            "Eval_MinReturn : 7.0\n",
            "Eval_AverageEpLen : 54.0\n",
            "Train_AverageReturn : 271.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 271.0\n",
            "Train_MinReturn : 271.0\n",
            "Train_AverageEpLen : 271.0\n",
            "Train_EnvstepsSoFar : 30816\n",
            "TimeSinceStart : 49.05235266685486\n",
            "Training Loss : -0.015240236185491085\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 80 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([213])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 103.0\n",
            "Eval_StdReturn : 117.8961410522461\n",
            "Eval_MaxReturn : 298.0\n",
            "Eval_MinReturn : 6.0\n",
            "Eval_AverageEpLen : 103.0\n",
            "Train_AverageReturn : 106.5\n",
            "Train_StdReturn : 72.5\n",
            "Train_MaxReturn : 179.0\n",
            "Train_MinReturn : 34.0\n",
            "Train_AverageEpLen : 106.5\n",
            "Train_EnvstepsSoFar : 31029\n",
            "TimeSinceStart : 49.45539975166321\n",
            "Training Loss : -0.04437880218029022\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 81 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([245])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 176.0\n",
            "Eval_StdReturn : 48.13176345825195\n",
            "Eval_MaxReturn : 241.0\n",
            "Eval_MinReturn : 126.0\n",
            "Eval_AverageEpLen : 176.0\n",
            "Train_AverageReturn : 42.5\n",
            "Train_StdReturn : 36.99887466430664\n",
            "Train_MaxReturn : 110.0\n",
            "Train_MinReturn : 9.0\n",
            "Train_AverageEpLen : 42.5\n",
            "Train_EnvstepsSoFar : 31284\n",
            "TimeSinceStart : 49.95773482322693\n",
            "Training Loss : 0.00022294958762358874\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 82 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([266])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 129.60000610351562\n",
            "Eval_StdReturn : 121.19834899902344\n",
            "Eval_MaxReturn : 286.0\n",
            "Eval_MinReturn : 15.0\n",
            "Eval_AverageEpLen : 129.6\n",
            "Train_AverageReturn : 266.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 266.0\n",
            "Train_MinReturn : 266.0\n",
            "Train_AverageEpLen : 266.0\n",
            "Train_EnvstepsSoFar : 31550\n",
            "TimeSinceStart : 50.49115180969238\n",
            "Training Loss : -0.06898733973503113\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 83 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([223])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 301.5\n",
            "Eval_StdReturn : 22.5\n",
            "Eval_MaxReturn : 324.0\n",
            "Eval_MinReturn : 279.0\n",
            "Eval_AverageEpLen : 301.5\n",
            "Train_AverageReturn : 74.33333587646484\n",
            "Train_StdReturn : 31.794479370117188\n",
            "Train_MaxReturn : 103.0\n",
            "Train_MinReturn : 30.0\n",
            "Train_AverageEpLen : 74.33333333333333\n",
            "Train_EnvstepsSoFar : 31773\n",
            "TimeSinceStart : 50.97889542579651\n",
            "Training Loss : -0.042995255440473557\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 84 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([325])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 325.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 325.0\n",
            "Train_MinReturn : 325.0\n",
            "Train_AverageEpLen : 325.0\n",
            "Train_EnvstepsSoFar : 32098\n",
            "TimeSinceStart : 51.761499643325806\n",
            "Training Loss : 0.05039282143115997\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 85 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([329])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 599.0\n",
            "Eval_StdReturn : 401.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 198.0\n",
            "Eval_AverageEpLen : 599.0\n",
            "Train_AverageReturn : 329.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 329.0\n",
            "Train_MinReturn : 329.0\n",
            "Train_AverageEpLen : 329.0\n",
            "Train_EnvstepsSoFar : 32427\n",
            "TimeSinceStart : 52.716416358947754\n",
            "Training Loss : 0.002191117499023676\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 86 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 33427\n",
            "TimeSinceStart : 53.98336958885193\n",
            "Training Loss : -0.0007223205757327378\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 87 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 641.5\n",
            "Eval_StdReturn : 358.5\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 283.0\n",
            "Eval_AverageEpLen : 641.5\n",
            "Train_AverageReturn : 519.5\n",
            "Train_StdReturn : 480.5\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 39.0\n",
            "Train_AverageEpLen : 519.5\n",
            "Train_EnvstepsSoFar : 34466\n",
            "TimeSinceStart : 55.53816485404968\n",
            "Training Loss : -0.0051530152559280396\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 88 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 35466\n",
            "TimeSinceStart : 56.77586269378662\n",
            "Training Loss : 0.01693614199757576\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 89 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 36466\n",
            "TimeSinceStart : 58.23337125778198\n",
            "Training Loss : 0.03263109177350998\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 90 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 37466\n",
            "TimeSinceStart : 59.46378970146179\n",
            "Training Loss : 0.035612717270851135\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 91 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 38466\n",
            "TimeSinceStart : 60.76930642127991\n",
            "Training Loss : -0.0002924881118815392\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 92 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 437.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 437.0\n",
            "Eval_MinReturn : 437.0\n",
            "Eval_AverageEpLen : 437.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 39466\n",
            "TimeSinceStart : 61.73755383491516\n",
            "Training Loss : -0.009345551021397114\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 93 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([555])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 555.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 555.0\n",
            "Train_MinReturn : 555.0\n",
            "Train_AverageEpLen : 555.0\n",
            "Train_EnvstepsSoFar : 40021\n",
            "TimeSinceStart : 62.891886472702026\n",
            "Training Loss : -0.03216085582971573\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 94 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 358.0\n",
            "Eval_StdReturn : 112.0\n",
            "Eval_MaxReturn : 470.0\n",
            "Eval_MinReturn : 246.0\n",
            "Eval_AverageEpLen : 358.0\n",
            "Train_AverageReturn : 594.0\n",
            "Train_StdReturn : 406.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 188.0\n",
            "Train_AverageEpLen : 594.0\n",
            "Train_EnvstepsSoFar : 41209\n",
            "TimeSinceStart : 64.21837759017944\n",
            "Training Loss : -0.0370941087603569\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 95 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([301])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 207.6666717529297\n",
            "Eval_StdReturn : 66.3843994140625\n",
            "Eval_MaxReturn : 297.0\n",
            "Eval_MinReturn : 138.0\n",
            "Eval_AverageEpLen : 207.66666666666666\n",
            "Train_AverageReturn : 185.5\n",
            "Train_StdReturn : 115.5\n",
            "Train_MaxReturn : 301.0\n",
            "Train_MinReturn : 70.0\n",
            "Train_AverageEpLen : 185.5\n",
            "Train_EnvstepsSoFar : 41580\n",
            "TimeSinceStart : 64.86426401138306\n",
            "Training Loss : -0.11746121942996979\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 96 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([215])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 88.5999984741211\n",
            "Eval_StdReturn : 36.401100158691406\n",
            "Eval_MaxReturn : 142.0\n",
            "Eval_MinReturn : 57.0\n",
            "Eval_AverageEpLen : 88.6\n",
            "Train_AverageReturn : 96.66666412353516\n",
            "Train_StdReturn : 33.5095329284668\n",
            "Train_MaxReturn : 144.0\n",
            "Train_MinReturn : 71.0\n",
            "Train_AverageEpLen : 96.66666666666667\n",
            "Train_EnvstepsSoFar : 41870\n",
            "TimeSinceStart : 65.29380631446838\n",
            "Training Loss : -0.0334983766078949\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 97 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([245])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 64.0\n",
            "Eval_StdReturn : 14.342742919921875\n",
            "Eval_MaxReturn : 89.0\n",
            "Eval_MinReturn : 43.0\n",
            "Eval_AverageEpLen : 64.0\n",
            "Train_AverageReturn : 61.25\n",
            "Train_StdReturn : 38.61589813232422\n",
            "Train_MaxReturn : 125.0\n",
            "Train_MinReturn : 21.0\n",
            "Train_AverageEpLen : 61.25\n",
            "Train_EnvstepsSoFar : 42115\n",
            "TimeSinceStart : 65.72202110290527\n",
            "Training Loss : -0.0114334337413311\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 98 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([213])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 53.5\n",
            "Eval_StdReturn : 9.082950592041016\n",
            "Eval_MaxReturn : 72.0\n",
            "Eval_MinReturn : 43.0\n",
            "Eval_AverageEpLen : 53.5\n",
            "Train_AverageReturn : 71.0\n",
            "Train_StdReturn : 11.518101692199707\n",
            "Train_MaxReturn : 84.0\n",
            "Train_MinReturn : 56.0\n",
            "Train_AverageEpLen : 71.0\n",
            "Train_EnvstepsSoFar : 42328\n",
            "TimeSinceStart : 66.10680437088013\n",
            "Training Loss : 0.052600737661123276\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 99 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([228])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 56.125\n",
            "Eval_StdReturn : 21.825658798217773\n",
            "Eval_MaxReturn : 106.0\n",
            "Eval_MinReturn : 26.0\n",
            "Eval_AverageEpLen : 56.125\n",
            "Train_AverageReturn : 57.0\n",
            "Train_StdReturn : 4.242640495300293\n",
            "Train_MaxReturn : 61.0\n",
            "Train_MinReturn : 51.0\n",
            "Train_AverageEpLen : 57.0\n",
            "Train_EnvstepsSoFar : 42556\n",
            "TimeSinceStart : 66.5080451965332\n",
            "Training Loss : 0.09094161540269852\n",
            "Initial_DataCollection_AverageReturn : 8.038461685180664\n",
            "Done logging...\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python cs285/scripts/run_hw2.py --env_name InvertedPendulum-v2 \\\n",
        "--ep_len 1000 --discount 0.9 -n 100 -l 2 -s 64 -b 200 -lr 0.01 -rtg \\\n",
        "--exp_name q2_b200_r01"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_dlE26yAH0sd",
        "outputId": "6de551d2-d0d7-414a-cfeb-0ce7fadadd29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "########################\n",
            "logging outputs to  /content/gdrive/My Drive/cs285_f2021/DRL_policy_grads/cs285/scripts/../../data/q2_b1000_r01_InvertedPendulum-v2_06-02-2022_17-41-06\n",
            "########################\n",
            "Using GPU id 0\n",
            "Sequential(\n",
            "  (0): Linear(in_features=4, out_features=64, bias=True)\n",
            "  (1): Tanh()\n",
            "  (2): Linear(in_features=64, out_features=64, bias=True)\n",
            "  (3): Tanh()\n",
            "  (4): Linear(in_features=64, out_features=1, bias=True)\n",
            "  (5): Identity()\n",
            ")\n",
            "\n",
            "\n",
            "********** Iteration 0 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 21.36842155456543\n",
            "Eval_StdReturn : 12.654146194458008\n",
            "Eval_MaxReturn : 57.0\n",
            "Eval_MinReturn : 5.0\n",
            "Eval_AverageEpLen : 21.36842105263158\n",
            "Train_AverageReturn : 8.885965347290039\n",
            "Train_StdReturn : 5.4752373695373535\n",
            "Train_MaxReturn : 29.0\n",
            "Train_MinReturn : 3.0\n",
            "Train_AverageEpLen : 8.885964912280702\n",
            "Train_EnvstepsSoFar : 1013\n",
            "TimeSinceStart : 0.8687598705291748\n",
            "Training Loss : -0.06583564728498459\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 1 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1009])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 25.875\n",
            "Eval_StdReturn : 10.117280960083008\n",
            "Eval_MaxReturn : 42.0\n",
            "Eval_MinReturn : 12.0\n",
            "Eval_AverageEpLen : 25.875\n",
            "Train_AverageReturn : 16.095237731933594\n",
            "Train_StdReturn : 9.067146301269531\n",
            "Train_MaxReturn : 43.0\n",
            "Train_MinReturn : 4.0\n",
            "Train_AverageEpLen : 16.095238095238095\n",
            "Train_EnvstepsSoFar : 2027\n",
            "TimeSinceStart : 1.756544828414917\n",
            "Training Loss : -0.09676511585712433\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 2 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1009])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 45.55555725097656\n",
            "Eval_StdReturn : 21.858692169189453\n",
            "Eval_MaxReturn : 92.0\n",
            "Eval_MinReturn : 15.0\n",
            "Eval_AverageEpLen : 45.55555555555556\n",
            "Train_AverageReturn : 32.54838562011719\n",
            "Train_StdReturn : 20.725297927856445\n",
            "Train_MaxReturn : 108.0\n",
            "Train_MinReturn : 11.0\n",
            "Train_AverageEpLen : 32.54838709677419\n",
            "Train_EnvstepsSoFar : 3036\n",
            "TimeSinceStart : 2.625277042388916\n",
            "Training Loss : -0.05831250175833702\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 3 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1054])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 55.75\n",
            "Eval_StdReturn : 15.943259239196777\n",
            "Eval_MaxReturn : 95.0\n",
            "Eval_MinReturn : 42.0\n",
            "Eval_AverageEpLen : 55.75\n",
            "Train_AverageReturn : 55.47368240356445\n",
            "Train_StdReturn : 21.31065559387207\n",
            "Train_MaxReturn : 105.0\n",
            "Train_MinReturn : 23.0\n",
            "Train_AverageEpLen : 55.473684210526315\n",
            "Train_EnvstepsSoFar : 4090\n",
            "TimeSinceStart : 3.8846518993377686\n",
            "Training Loss : -0.018125472590327263\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 4 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1004])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 41.29999923706055\n",
            "Eval_StdReturn : 22.623218536376953\n",
            "Eval_MaxReturn : 73.0\n",
            "Eval_MinReturn : 12.0\n",
            "Eval_AverageEpLen : 41.3\n",
            "Train_AverageReturn : 36.67856979370117\n",
            "Train_StdReturn : 23.558517456054688\n",
            "Train_MaxReturn : 111.0\n",
            "Train_MinReturn : 12.0\n",
            "Train_AverageEpLen : 36.67857142857143\n",
            "Train_EnvstepsSoFar : 5117\n",
            "TimeSinceStart : 4.86957311630249\n",
            "Training Loss : -0.01823979616165161\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 5 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1026])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 39.3636360168457\n",
            "Eval_StdReturn : 8.182827949523926\n",
            "Eval_MaxReturn : 48.0\n",
            "Eval_MinReturn : 17.0\n",
            "Eval_AverageEpLen : 39.36363636363637\n",
            "Train_AverageReturn : 48.85714340209961\n",
            "Train_StdReturn : 21.220577239990234\n",
            "Train_MaxReturn : 98.0\n",
            "Train_MinReturn : 14.0\n",
            "Train_AverageEpLen : 48.857142857142854\n",
            "Train_EnvstepsSoFar : 6143\n",
            "TimeSinceStart : 5.760864734649658\n",
            "Training Loss : -0.028227457776665688\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 6 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1004])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 33.46154022216797\n",
            "Eval_StdReturn : 19.95231056213379\n",
            "Eval_MaxReturn : 81.0\n",
            "Eval_MinReturn : 11.0\n",
            "Eval_AverageEpLen : 33.46153846153846\n",
            "Train_AverageReturn : 47.6363639831543\n",
            "Train_StdReturn : 23.453136444091797\n",
            "Train_MaxReturn : 98.0\n",
            "Train_MinReturn : 11.0\n",
            "Train_AverageEpLen : 47.63636363636363\n",
            "Train_EnvstepsSoFar : 7191\n",
            "TimeSinceStart : 6.652188301086426\n",
            "Training Loss : -0.05727328732609749\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 7 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1016])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 42.5\n",
            "Eval_StdReturn : 24.828411102294922\n",
            "Eval_MaxReturn : 107.0\n",
            "Eval_MinReturn : 15.0\n",
            "Eval_AverageEpLen : 42.5\n",
            "Train_AverageReturn : 35.86206817626953\n",
            "Train_StdReturn : 27.49009132385254\n",
            "Train_MaxReturn : 149.0\n",
            "Train_MinReturn : 10.0\n",
            "Train_AverageEpLen : 35.86206896551724\n",
            "Train_EnvstepsSoFar : 8231\n",
            "TimeSinceStart : 7.536818742752075\n",
            "Training Loss : -0.03056478127837181\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 8 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1020])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 49.11111068725586\n",
            "Eval_StdReturn : 20.712017059326172\n",
            "Eval_MaxReturn : 101.0\n",
            "Eval_MinReturn : 28.0\n",
            "Eval_AverageEpLen : 49.111111111111114\n",
            "Train_AverageReturn : 42.5\n",
            "Train_StdReturn : 22.00568199157715\n",
            "Train_MaxReturn : 87.0\n",
            "Train_MinReturn : 9.0\n",
            "Train_AverageEpLen : 42.5\n",
            "Train_EnvstepsSoFar : 9251\n",
            "TimeSinceStart : 8.412281036376953\n",
            "Training Loss : -0.03908080235123634\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 9 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1065])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 71.16666412353516\n",
            "Eval_StdReturn : 33.76100540161133\n",
            "Eval_MaxReturn : 123.0\n",
            "Eval_MinReturn : 31.0\n",
            "Eval_AverageEpLen : 71.16666666666667\n",
            "Train_AverageReturn : 50.71428680419922\n",
            "Train_StdReturn : 23.18074607849121\n",
            "Train_MaxReturn : 102.0\n",
            "Train_MinReturn : 10.0\n",
            "Train_AverageEpLen : 50.714285714285715\n",
            "Train_EnvstepsSoFar : 10316\n",
            "TimeSinceStart : 9.349357604980469\n",
            "Training Loss : -0.021666234359145164\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 10 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1024])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 85.0\n",
            "Eval_StdReturn : 32.280025482177734\n",
            "Eval_MaxReturn : 135.0\n",
            "Eval_MinReturn : 54.0\n",
            "Eval_AverageEpLen : 85.0\n",
            "Train_AverageReturn : 68.26667022705078\n",
            "Train_StdReturn : 29.009117126464844\n",
            "Train_MaxReturn : 144.0\n",
            "Train_MinReturn : 28.0\n",
            "Train_AverageEpLen : 68.26666666666667\n",
            "Train_EnvstepsSoFar : 11340\n",
            "TimeSinceStart : 10.329505681991577\n",
            "Training Loss : -0.004977822303771973\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 11 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1081])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 84.4000015258789\n",
            "Eval_StdReturn : 26.56764793395996\n",
            "Eval_MaxReturn : 129.0\n",
            "Eval_MinReturn : 57.0\n",
            "Eval_AverageEpLen : 84.4\n",
            "Train_AverageReturn : 72.06666564941406\n",
            "Train_StdReturn : 37.79323959350586\n",
            "Train_MaxReturn : 168.0\n",
            "Train_MinReturn : 28.0\n",
            "Train_AverageEpLen : 72.06666666666666\n",
            "Train_EnvstepsSoFar : 12421\n",
            "TimeSinceStart : 11.27094054222107\n",
            "Training Loss : -0.04424450173974037\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 12 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1036])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 79.33333587646484\n",
            "Eval_StdReturn : 21.21058464050293\n",
            "Eval_MaxReturn : 117.0\n",
            "Eval_MinReturn : 50.0\n",
            "Eval_AverageEpLen : 79.33333333333333\n",
            "Train_AverageReturn : 82.38461303710938\n",
            "Train_StdReturn : 35.786842346191406\n",
            "Train_MaxReturn : 151.0\n",
            "Train_MinReturn : 35.0\n",
            "Train_AverageEpLen : 82.38461538461539\n",
            "Train_EnvstepsSoFar : 13492\n",
            "TimeSinceStart : 12.193994522094727\n",
            "Training Loss : -0.05165117606520653\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 13 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1065])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 76.83333587646484\n",
            "Eval_StdReturn : 34.23164367675781\n",
            "Eval_MaxReturn : 111.0\n",
            "Eval_MinReturn : 8.0\n",
            "Eval_AverageEpLen : 76.83333333333333\n",
            "Train_AverageReturn : 59.16666793823242\n",
            "Train_StdReturn : 24.109127044677734\n",
            "Train_MaxReturn : 103.0\n",
            "Train_MinReturn : 26.0\n",
            "Train_AverageEpLen : 59.166666666666664\n",
            "Train_EnvstepsSoFar : 14557\n",
            "TimeSinceStart : 13.168347835540771\n",
            "Training Loss : -0.0605563186109066\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 14 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1051])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 119.0\n",
            "Eval_StdReturn : 47.953102111816406\n",
            "Eval_MaxReturn : 182.0\n",
            "Eval_MinReturn : 59.0\n",
            "Eval_AverageEpLen : 119.0\n",
            "Train_AverageReturn : 87.58333587646484\n",
            "Train_StdReturn : 46.494544982910156\n",
            "Train_MaxReturn : 232.0\n",
            "Train_MinReturn : 43.0\n",
            "Train_AverageEpLen : 87.58333333333333\n",
            "Train_EnvstepsSoFar : 15608\n",
            "TimeSinceStart : 14.216240644454956\n",
            "Training Loss : -0.021960871294140816\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 15 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1005])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 112.4000015258789\n",
            "Eval_StdReturn : 40.00299835205078\n",
            "Eval_MaxReturn : 187.0\n",
            "Eval_MinReturn : 71.0\n",
            "Eval_AverageEpLen : 112.4\n",
            "Train_AverageReturn : 91.0\n",
            "Train_StdReturn : 30.82206916809082\n",
            "Train_MaxReturn : 146.0\n",
            "Train_MinReturn : 47.0\n",
            "Train_AverageEpLen : 91.0\n",
            "Train_EnvstepsSoFar : 16700\n",
            "TimeSinceStart : 15.253070592880249\n",
            "Training Loss : -0.030120015144348145\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 16 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 100.4000015258789\n",
            "Eval_StdReturn : 24.727312088012695\n",
            "Eval_MaxReturn : 130.0\n",
            "Eval_MinReturn : 69.0\n",
            "Eval_AverageEpLen : 100.4\n",
            "Train_AverageReturn : 105.0\n",
            "Train_StdReturn : 50.13980484008789\n",
            "Train_MaxReturn : 235.0\n",
            "Train_MinReturn : 54.0\n",
            "Train_AverageEpLen : 105.0\n",
            "Train_EnvstepsSoFar : 17750\n",
            "TimeSinceStart : 16.386770009994507\n",
            "Training Loss : -0.027501873672008514\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 17 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1058])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 80.66666412353516\n",
            "Eval_StdReturn : 13.337498664855957\n",
            "Eval_MaxReturn : 105.0\n",
            "Eval_MinReturn : 66.0\n",
            "Eval_AverageEpLen : 80.66666666666667\n",
            "Train_AverageReturn : 132.25\n",
            "Train_StdReturn : 46.24324417114258\n",
            "Train_MaxReturn : 234.0\n",
            "Train_MinReturn : 73.0\n",
            "Train_AverageEpLen : 132.25\n",
            "Train_EnvstepsSoFar : 18808\n",
            "TimeSinceStart : 17.408990144729614\n",
            "Training Loss : -0.003434540005400777\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 18 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1049])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 88.80000305175781\n",
            "Eval_StdReturn : 30.71416664123535\n",
            "Eval_MaxReturn : 147.0\n",
            "Eval_MinReturn : 58.0\n",
            "Eval_AverageEpLen : 88.8\n",
            "Train_AverageReturn : 104.9000015258789\n",
            "Train_StdReturn : 19.185670852661133\n",
            "Train_MaxReturn : 137.0\n",
            "Train_MinReturn : 75.0\n",
            "Train_AverageEpLen : 104.9\n",
            "Train_EnvstepsSoFar : 19857\n",
            "TimeSinceStart : 18.338696718215942\n",
            "Training Loss : -0.06402693688869476\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 19 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1007])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 63.14285659790039\n",
            "Eval_StdReturn : 7.356795787811279\n",
            "Eval_MaxReturn : 75.0\n",
            "Eval_MinReturn : 51.0\n",
            "Eval_AverageEpLen : 63.142857142857146\n",
            "Train_AverageReturn : 71.92857360839844\n",
            "Train_StdReturn : 12.58380126953125\n",
            "Train_MaxReturn : 97.0\n",
            "Train_MinReturn : 52.0\n",
            "Train_AverageEpLen : 71.92857142857143\n",
            "Train_EnvstepsSoFar : 20864\n",
            "TimeSinceStart : 19.298065423965454\n",
            "Training Loss : 0.011358107440173626\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 20 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1009])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 64.42857360839844\n",
            "Eval_StdReturn : 26.720012664794922\n",
            "Eval_MaxReturn : 109.0\n",
            "Eval_MinReturn : 23.0\n",
            "Eval_AverageEpLen : 64.42857142857143\n",
            "Train_AverageReturn : 67.26667022705078\n",
            "Train_StdReturn : 11.509222984313965\n",
            "Train_MaxReturn : 83.0\n",
            "Train_MinReturn : 50.0\n",
            "Train_AverageEpLen : 67.26666666666667\n",
            "Train_EnvstepsSoFar : 21873\n",
            "TimeSinceStart : 20.18243980407715\n",
            "Training Loss : -0.0033493817318230867\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 21 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1012])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 78.66666412353516\n",
            "Eval_StdReturn : 44.161319732666016\n",
            "Eval_MaxReturn : 150.0\n",
            "Eval_MinReturn : 11.0\n",
            "Eval_AverageEpLen : 78.66666666666667\n",
            "Train_AverageReturn : 66.0\n",
            "Train_StdReturn : 12.444878578186035\n",
            "Train_MaxReturn : 91.0\n",
            "Train_MinReturn : 44.0\n",
            "Train_AverageEpLen : 66.0\n",
            "Train_EnvstepsSoFar : 22929\n",
            "TimeSinceStart : 21.2522451877594\n",
            "Training Loss : 0.02041284553706646\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 22 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1002])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 80.0\n",
            "Eval_StdReturn : 11.366617202758789\n",
            "Eval_MaxReturn : 94.0\n",
            "Eval_MinReturn : 68.0\n",
            "Eval_AverageEpLen : 80.0\n",
            "Train_AverageReturn : 65.375\n",
            "Train_StdReturn : 12.898037910461426\n",
            "Train_MaxReturn : 81.0\n",
            "Train_MinReturn : 33.0\n",
            "Train_AverageEpLen : 65.375\n",
            "Train_EnvstepsSoFar : 23975\n",
            "TimeSinceStart : 22.201295375823975\n",
            "Training Loss : -0.03900187835097313\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 23 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1070])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 112.25\n",
            "Eval_StdReturn : 15.658464431762695\n",
            "Eval_MaxReturn : 135.0\n",
            "Eval_MinReturn : 92.0\n",
            "Eval_AverageEpLen : 112.25\n",
            "Train_AverageReturn : 71.33333587646484\n",
            "Train_StdReturn : 18.90913963317871\n",
            "Train_MaxReturn : 116.0\n",
            "Train_MinReturn : 39.0\n",
            "Train_AverageEpLen : 71.33333333333333\n",
            "Train_EnvstepsSoFar : 25045\n",
            "TimeSinceStart : 23.173120975494385\n",
            "Training Loss : -0.013590207323431969\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 24 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1034])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 294.0\n",
            "Eval_StdReturn : 57.0\n",
            "Eval_MaxReturn : 351.0\n",
            "Eval_MinReturn : 237.0\n",
            "Eval_AverageEpLen : 294.0\n",
            "Train_AverageReturn : 103.4000015258789\n",
            "Train_StdReturn : 43.54813766479492\n",
            "Train_MaxReturn : 160.0\n",
            "Train_MinReturn : 12.0\n",
            "Train_AverageEpLen : 103.4\n",
            "Train_EnvstepsSoFar : 26079\n",
            "TimeSinceStart : 24.343726873397827\n",
            "Training Loss : -0.04086047038435936\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 25 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1075])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 134.3333282470703\n",
            "Eval_StdReturn : 26.53718376159668\n",
            "Eval_MaxReturn : 167.0\n",
            "Eval_MinReturn : 102.0\n",
            "Eval_AverageEpLen : 134.33333333333334\n",
            "Train_AverageReturn : 153.57142639160156\n",
            "Train_StdReturn : 48.165950775146484\n",
            "Train_MaxReturn : 230.0\n",
            "Train_MinReturn : 83.0\n",
            "Train_AverageEpLen : 153.57142857142858\n",
            "Train_EnvstepsSoFar : 27154\n",
            "TimeSinceStart : 25.310382843017578\n",
            "Training Loss : -0.038611434400081635\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 26 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1024])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 114.5\n",
            "Eval_StdReturn : 23.457408905029297\n",
            "Eval_MaxReturn : 143.0\n",
            "Eval_MinReturn : 78.0\n",
            "Eval_AverageEpLen : 114.5\n",
            "Train_AverageReturn : 146.2857208251953\n",
            "Train_StdReturn : 34.532447814941406\n",
            "Train_MaxReturn : 192.0\n",
            "Train_MinReturn : 88.0\n",
            "Train_AverageEpLen : 146.28571428571428\n",
            "Train_EnvstepsSoFar : 28178\n",
            "TimeSinceStart : 26.16349768638611\n",
            "Training Loss : -0.025998208671808243\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 27 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1001])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 137.0\n",
            "Eval_StdReturn : 19.79899024963379\n",
            "Eval_MaxReturn : 163.0\n",
            "Eval_MinReturn : 115.0\n",
            "Eval_AverageEpLen : 137.0\n",
            "Train_AverageReturn : 111.22222137451172\n",
            "Train_StdReturn : 39.2110481262207\n",
            "Train_MaxReturn : 177.0\n",
            "Train_MinReturn : 27.0\n",
            "Train_AverageEpLen : 111.22222222222223\n",
            "Train_EnvstepsSoFar : 29179\n",
            "TimeSinceStart : 26.999266624450684\n",
            "Training Loss : -0.0436607301235199\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 28 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1019])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 225.3333282470703\n",
            "Eval_StdReturn : 177.4510955810547\n",
            "Eval_MaxReturn : 472.0\n",
            "Eval_MinReturn : 62.0\n",
            "Eval_AverageEpLen : 225.33333333333334\n",
            "Train_AverageReturn : 145.57142639160156\n",
            "Train_StdReturn : 51.43333435058594\n",
            "Train_MaxReturn : 243.0\n",
            "Train_MinReturn : 58.0\n",
            "Train_AverageEpLen : 145.57142857142858\n",
            "Train_EnvstepsSoFar : 30198\n",
            "TimeSinceStart : 27.995014190673828\n",
            "Training Loss : -0.010552744381129742\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 29 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1019])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 86.80000305175781\n",
            "Eval_StdReturn : 39.004615783691406\n",
            "Eval_MaxReturn : 148.0\n",
            "Eval_MinReturn : 39.0\n",
            "Eval_AverageEpLen : 86.8\n",
            "Train_AverageReturn : 168.375\n",
            "Train_StdReturn : 100.29448699951172\n",
            "Train_MaxReturn : 368.0\n",
            "Train_MinReturn : 65.0\n",
            "Train_AverageEpLen : 168.375\n",
            "Train_EnvstepsSoFar : 31545\n",
            "TimeSinceStart : 29.045518398284912\n",
            "Training Loss : -0.01863490417599678\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 30 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1007])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 92.19999694824219\n",
            "Eval_StdReturn : 73.99027252197266\n",
            "Eval_MaxReturn : 237.0\n",
            "Eval_MinReturn : 31.0\n",
            "Eval_AverageEpLen : 92.2\n",
            "Train_AverageReturn : 122.88888549804688\n",
            "Train_StdReturn : 106.28102111816406\n",
            "Train_MaxReturn : 397.0\n",
            "Train_MinReturn : 30.0\n",
            "Train_AverageEpLen : 122.88888888888889\n",
            "Train_EnvstepsSoFar : 32651\n",
            "TimeSinceStart : 30.148853063583374\n",
            "Training Loss : -0.0413823127746582\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 31 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1001])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 105.25\n",
            "Eval_StdReturn : 23.604820251464844\n",
            "Eval_MaxReturn : 135.0\n",
            "Eval_MinReturn : 77.0\n",
            "Eval_AverageEpLen : 105.25\n",
            "Train_AverageReturn : 71.5\n",
            "Train_StdReturn : 38.085899353027344\n",
            "Train_MaxReturn : 149.0\n",
            "Train_MinReturn : 32.0\n",
            "Train_AverageEpLen : 71.5\n",
            "Train_EnvstepsSoFar : 33652\n",
            "TimeSinceStart : 31.15082597732544\n",
            "Training Loss : -0.017546944320201874\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 32 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1056])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 53.5\n",
            "Eval_StdReturn : 14.924811363220215\n",
            "Eval_MaxReturn : 77.0\n",
            "Eval_MinReturn : 36.0\n",
            "Eval_AverageEpLen : 53.5\n",
            "Train_AverageReturn : 75.42857360839844\n",
            "Train_StdReturn : 50.439090728759766\n",
            "Train_MaxReturn : 181.0\n",
            "Train_MinReturn : 24.0\n",
            "Train_AverageEpLen : 75.42857142857143\n",
            "Train_EnvstepsSoFar : 34708\n",
            "TimeSinceStart : 32.067729234695435\n",
            "Training Loss : -0.005509680137038231\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 33 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1033])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 53.375\n",
            "Eval_StdReturn : 29.584360122680664\n",
            "Eval_MaxReturn : 86.0\n",
            "Eval_MinReturn : 10.0\n",
            "Eval_AverageEpLen : 53.375\n",
            "Train_AverageReturn : 79.46154022216797\n",
            "Train_StdReturn : 44.19818115234375\n",
            "Train_MaxReturn : 177.0\n",
            "Train_MinReturn : 30.0\n",
            "Train_AverageEpLen : 79.46153846153847\n",
            "Train_EnvstepsSoFar : 35741\n",
            "TimeSinceStart : 33.05768299102783\n",
            "Training Loss : -0.02399570867419243\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 34 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1029])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 59.375\n",
            "Eval_StdReturn : 21.33622169494629\n",
            "Eval_MaxReturn : 88.0\n",
            "Eval_MinReturn : 33.0\n",
            "Eval_AverageEpLen : 59.375\n",
            "Train_AverageReturn : 84.69230651855469\n",
            "Train_StdReturn : 25.637666702270508\n",
            "Train_MaxReturn : 139.0\n",
            "Train_MinReturn : 45.0\n",
            "Train_AverageEpLen : 84.6923076923077\n",
            "Train_EnvstepsSoFar : 36842\n",
            "TimeSinceStart : 34.12261176109314\n",
            "Training Loss : -0.02233452908694744\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 35 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1018])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 34.16666793823242\n",
            "Eval_StdReturn : 16.087434768676758\n",
            "Eval_MaxReturn : 52.0\n",
            "Eval_MinReturn : 8.0\n",
            "Eval_AverageEpLen : 34.166666666666664\n",
            "Train_AverageReturn : 50.85714340209961\n",
            "Train_StdReturn : 15.201146125793457\n",
            "Train_MaxReturn : 84.0\n",
            "Train_MinReturn : 15.0\n",
            "Train_AverageEpLen : 50.857142857142854\n",
            "Train_EnvstepsSoFar : 37910\n",
            "TimeSinceStart : 35.06884527206421\n",
            "Training Loss : -0.010367223061621189\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 36 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1004])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 60.57143020629883\n",
            "Eval_StdReturn : 11.549362182617188\n",
            "Eval_MaxReturn : 86.0\n",
            "Eval_MinReturn : 50.0\n",
            "Eval_AverageEpLen : 60.57142857142857\n",
            "Train_AverageReturn : 38.61538314819336\n",
            "Train_StdReturn : 17.617904663085938\n",
            "Train_MaxReturn : 65.0\n",
            "Train_MinReturn : 5.0\n",
            "Train_AverageEpLen : 38.61538461538461\n",
            "Train_EnvstepsSoFar : 38914\n",
            "TimeSinceStart : 35.98312282562256\n",
            "Training Loss : -0.047436535358428955\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 37 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1038])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 70.0\n",
            "Eval_StdReturn : 6.244997978210449\n",
            "Eval_MaxReturn : 78.0\n",
            "Eval_MinReturn : 60.0\n",
            "Eval_AverageEpLen : 70.0\n",
            "Train_AverageReturn : 51.900001525878906\n",
            "Train_StdReturn : 12.078493118286133\n",
            "Train_MaxReturn : 71.0\n",
            "Train_MinReturn : 10.0\n",
            "Train_AverageEpLen : 51.9\n",
            "Train_EnvstepsSoFar : 39952\n",
            "TimeSinceStart : 37.004021644592285\n",
            "Training Loss : 0.03270266577601433\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 38 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1032])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 77.16666412353516\n",
            "Eval_StdReturn : 11.809835433959961\n",
            "Eval_MaxReturn : 93.0\n",
            "Eval_MinReturn : 57.0\n",
            "Eval_AverageEpLen : 77.16666666666667\n",
            "Train_AverageReturn : 68.80000305175781\n",
            "Train_StdReturn : 14.316424369812012\n",
            "Train_MaxReturn : 93.0\n",
            "Train_MinReturn : 48.0\n",
            "Train_AverageEpLen : 68.8\n",
            "Train_EnvstepsSoFar : 40984\n",
            "TimeSinceStart : 37.9234082698822\n",
            "Training Loss : 0.017376311123371124\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 39 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1015])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 101.0\n",
            "Eval_StdReturn : 9.486832618713379\n",
            "Eval_MaxReturn : 111.0\n",
            "Eval_MinReturn : 89.0\n",
            "Eval_AverageEpLen : 101.0\n",
            "Train_AverageReturn : 84.23076629638672\n",
            "Train_StdReturn : 11.570212364196777\n",
            "Train_MaxReturn : 104.0\n",
            "Train_MinReturn : 65.0\n",
            "Train_AverageEpLen : 84.23076923076923\n",
            "Train_EnvstepsSoFar : 42079\n",
            "TimeSinceStart : 38.89238500595093\n",
            "Training Loss : -0.043654147535562515\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 40 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1064])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 242.0\n",
            "Eval_StdReturn : 12.0\n",
            "Eval_MaxReturn : 254.0\n",
            "Eval_MinReturn : 230.0\n",
            "Eval_AverageEpLen : 242.0\n",
            "Train_AverageReturn : 106.4000015258789\n",
            "Train_StdReturn : 18.49432373046875\n",
            "Train_MaxReturn : 141.0\n",
            "Train_MinReturn : 78.0\n",
            "Train_AverageEpLen : 106.4\n",
            "Train_EnvstepsSoFar : 43143\n",
            "TimeSinceStart : 39.90966463088989\n",
            "Training Loss : 0.030525632202625275\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 41 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1073])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 268.25\n",
            "Train_StdReturn : 137.93182373046875\n",
            "Train_MaxReturn : 506.0\n",
            "Train_MinReturn : 176.0\n",
            "Train_AverageEpLen : 268.25\n",
            "Train_EnvstepsSoFar : 44216\n",
            "TimeSinceStart : 41.34161877632141\n",
            "Training Loss : 0.04185209795832634\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 42 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 45216\n",
            "TimeSinceStart : 42.78489065170288\n",
            "Training Loss : -0.02515401504933834\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 43 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 520.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 520.0\n",
            "Eval_MinReturn : 520.0\n",
            "Eval_AverageEpLen : 520.0\n",
            "Train_AverageReturn : 608.0\n",
            "Train_StdReturn : 392.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 216.0\n",
            "Train_AverageEpLen : 608.0\n",
            "Train_EnvstepsSoFar : 46432\n",
            "TimeSinceStart : 43.99267315864563\n",
            "Training Loss : -0.0006211090367287397\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 44 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 47432\n",
            "TimeSinceStart : 45.22082281112671\n",
            "Training Loss : -0.003578422823920846\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 45 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 48432\n",
            "TimeSinceStart : 46.529409646987915\n",
            "Training Loss : 0.001711525022983551\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 46 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 600.0\n",
            "Eval_StdReturn : 400.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 200.0\n",
            "Eval_AverageEpLen : 600.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 49432\n",
            "TimeSinceStart : 48.04518103599548\n",
            "Training Loss : 0.03641299903392792\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 47 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 699.5\n",
            "Eval_StdReturn : 300.5\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 399.0\n",
            "Eval_AverageEpLen : 699.5\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 50432\n",
            "TimeSinceStart : 49.70429348945618\n",
            "Training Loss : -0.0572311133146286\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 48 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 440.0\n",
            "Eval_StdReturn : 103.0\n",
            "Eval_MaxReturn : 543.0\n",
            "Eval_MinReturn : 337.0\n",
            "Eval_AverageEpLen : 440.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 51432\n",
            "TimeSinceStart : 50.99471664428711\n",
            "Training Loss : -0.005446846131235361\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 49 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1856])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 300.0\n",
            "Eval_StdReturn : 85.0\n",
            "Eval_MaxReturn : 385.0\n",
            "Eval_MinReturn : 215.0\n",
            "Eval_AverageEpLen : 300.0\n",
            "Train_AverageReturn : 928.0\n",
            "Train_StdReturn : 37.0\n",
            "Train_MaxReturn : 965.0\n",
            "Train_MinReturn : 891.0\n",
            "Train_AverageEpLen : 928.0\n",
            "Train_EnvstepsSoFar : 53288\n",
            "TimeSinceStart : 52.47740983963013\n",
            "Training Loss : -0.0445626936852932\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 50 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 281.0\n",
            "Eval_StdReturn : 12.0\n",
            "Eval_MaxReturn : 293.0\n",
            "Eval_MinReturn : 269.0\n",
            "Eval_AverageEpLen : 281.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 54288\n",
            "TimeSinceStart : 53.38339352607727\n",
            "Training Loss : -0.02135554514825344\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 51 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 55288\n",
            "TimeSinceStart : 54.59495663642883\n",
            "Training Loss : 0.026213940232992172\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 52 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 579.3333129882812\n",
            "Train_StdReturn : 317.50732421875\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 233.0\n",
            "Train_AverageEpLen : 579.3333333333334\n",
            "Train_EnvstepsSoFar : 57026\n",
            "TimeSinceStart : 56.243136405944824\n",
            "Training Loss : 0.018327057361602783\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 53 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1107])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 553.5\n",
            "Train_StdReturn : 154.5\n",
            "Train_MaxReturn : 708.0\n",
            "Train_MinReturn : 399.0\n",
            "Train_AverageEpLen : 553.5\n",
            "Train_EnvstepsSoFar : 58133\n",
            "TimeSinceStart : 57.50045657157898\n",
            "Training Loss : -0.009446724317967892\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 54 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 975.0\n",
            "Train_StdReturn : 25.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 950.0\n",
            "Train_AverageEpLen : 975.0\n",
            "Train_EnvstepsSoFar : 60083\n",
            "TimeSinceStart : 59.26066446304321\n",
            "Training Loss : -0.008894058875739574\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 55 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 61083\n",
            "TimeSinceStart : 60.44222092628479\n",
            "Training Loss : -0.023995263502001762\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 56 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 62083\n",
            "TimeSinceStart : 61.62519931793213\n",
            "Training Loss : 0.01682644709944725\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 57 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 63083\n",
            "TimeSinceStart : 62.89807748794556\n",
            "Training Loss : 0.002474372973665595\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 58 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 64083\n",
            "TimeSinceStart : 64.13551115989685\n",
            "Training Loss : 0.028478967025876045\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 59 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 65083\n",
            "TimeSinceStart : 65.32907557487488\n",
            "Training Loss : 0.013623497448861599\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 60 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 66083\n",
            "TimeSinceStart : 66.52509808540344\n",
            "Training Loss : 0.015448220074176788\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 61 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 912.5\n",
            "Train_StdReturn : 87.5\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 825.0\n",
            "Train_AverageEpLen : 912.5\n",
            "Train_EnvstepsSoFar : 67908\n",
            "TimeSinceStart : 69.00430083274841\n",
            "Training Loss : 0.02475859969854355\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 62 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 68908\n",
            "TimeSinceStart : 70.96276378631592\n",
            "Training Loss : -0.014996201731264591\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 63 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 69908\n",
            "TimeSinceStart : 72.10203671455383\n",
            "Training Loss : -0.020308075472712517\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 64 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 149.0\n",
            "Eval_StdReturn : 132.99874877929688\n",
            "Eval_MaxReturn : 337.0\n",
            "Eval_MinReturn : 50.0\n",
            "Eval_AverageEpLen : 149.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 70908\n",
            "TimeSinceStart : 72.9806866645813\n",
            "Training Loss : -0.00547881331294775\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 65 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1035])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 53.5\n",
            "Eval_StdReturn : 17.291616439819336\n",
            "Eval_MaxReturn : 96.0\n",
            "Eval_MinReturn : 37.0\n",
            "Eval_AverageEpLen : 53.5\n",
            "Train_AverageReturn : 141.125\n",
            "Train_StdReturn : 115.46366882324219\n",
            "Train_MaxReturn : 364.0\n",
            "Train_MinReturn : 45.0\n",
            "Train_AverageEpLen : 141.125\n",
            "Train_EnvstepsSoFar : 72037\n",
            "TimeSinceStart : 74.09345650672913\n",
            "Training Loss : 0.014908017590641975\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 66 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1041])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 87.4000015258789\n",
            "Eval_StdReturn : 36.428558349609375\n",
            "Eval_MaxReturn : 135.0\n",
            "Eval_MinReturn : 50.0\n",
            "Eval_AverageEpLen : 87.4\n",
            "Train_AverageReturn : 78.93333435058594\n",
            "Train_StdReturn : 45.33205795288086\n",
            "Train_MaxReturn : 194.0\n",
            "Train_MinReturn : 10.0\n",
            "Train_AverageEpLen : 78.93333333333334\n",
            "Train_EnvstepsSoFar : 73221\n",
            "TimeSinceStart : 75.1123321056366\n",
            "Training Loss : -0.029818106442689896\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 67 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1021])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 148.6666717529297\n",
            "Eval_StdReturn : 49.775047302246094\n",
            "Eval_MaxReturn : 219.0\n",
            "Eval_MinReturn : 111.0\n",
            "Eval_AverageEpLen : 148.66666666666666\n",
            "Train_AverageReturn : 60.05882263183594\n",
            "Train_StdReturn : 32.39548110961914\n",
            "Train_MaxReturn : 132.0\n",
            "Train_MinReturn : 7.0\n",
            "Train_AverageEpLen : 60.05882352941177\n",
            "Train_EnvstepsSoFar : 74242\n",
            "TimeSinceStart : 76.18461728096008\n",
            "Training Loss : -0.03655925765633583\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 68 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1018])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 113.11111450195312\n",
            "Train_StdReturn : 97.55846405029297\n",
            "Train_MaxReturn : 266.0\n",
            "Train_MinReturn : 8.0\n",
            "Train_AverageEpLen : 113.11111111111111\n",
            "Train_EnvstepsSoFar : 75260\n",
            "TimeSinceStart : 77.4196572303772\n",
            "Training Loss : -0.011738470755517483\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 69 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 465.5\n",
            "Train_StdReturn : 318.5\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 159.0\n",
            "Train_AverageEpLen : 465.5\n",
            "Train_EnvstepsSoFar : 77122\n",
            "TimeSinceStart : 79.20787930488586\n",
            "Training Loss : 0.0018750382587313652\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 70 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 78122\n",
            "TimeSinceStart : 80.51322817802429\n",
            "Training Loss : -0.003470810130238533\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 71 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 79122\n",
            "TimeSinceStart : 81.7886004447937\n",
            "Training Loss : 0.007973938249051571\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 72 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 80122\n",
            "TimeSinceStart : 83.02805089950562\n",
            "Training Loss : 0.023794453591108322\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 73 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 81122\n",
            "TimeSinceStart : 84.27591156959534\n",
            "Training Loss : 0.024218525737524033\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 74 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 82122\n",
            "TimeSinceStart : 85.4966049194336\n",
            "Training Loss : -0.001694122445769608\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 75 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 83122\n",
            "TimeSinceStart : 86.6988434791565\n",
            "Training Loss : -0.0206145029515028\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 76 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 84122\n",
            "TimeSinceStart : 87.97637176513672\n",
            "Training Loss : -0.027473757043480873\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 77 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 85122\n",
            "TimeSinceStart : 89.17007255554199\n",
            "Training Loss : 0.02100120298564434\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 78 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 86122\n",
            "TimeSinceStart : 90.42412853240967\n",
            "Training Loss : -0.017797531560063362\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 79 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 87122\n",
            "TimeSinceStart : 91.88503742218018\n",
            "Training Loss : -0.03938454017043114\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 80 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 88122\n",
            "TimeSinceStart : 93.1410744190216\n",
            "Training Loss : -0.0031840973533689976\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 81 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 89122\n",
            "TimeSinceStart : 94.33043122291565\n",
            "Training Loss : 0.01317792572081089\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 82 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 90122\n",
            "TimeSinceStart : 95.60789251327515\n",
            "Training Loss : 0.02715393155813217\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 83 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 91122\n",
            "TimeSinceStart : 96.78329396247864\n",
            "Training Loss : -0.006896500010043383\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 84 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 92122\n",
            "TimeSinceStart : 98.06105852127075\n",
            "Training Loss : 0.022967075929045677\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 85 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 93122\n",
            "TimeSinceStart : 99.323086977005\n",
            "Training Loss : -0.0034442064352333546\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 86 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1150])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 575.0\n",
            "Train_StdReturn : 283.0\n",
            "Train_MaxReturn : 858.0\n",
            "Train_MinReturn : 292.0\n",
            "Train_AverageEpLen : 575.0\n",
            "Train_EnvstepsSoFar : 94272\n",
            "TimeSinceStart : 100.59337067604065\n",
            "Training Loss : -0.08643931150436401\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 87 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 675.5\n",
            "Train_StdReturn : 324.5\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 351.0\n",
            "Train_AverageEpLen : 675.5\n",
            "Train_EnvstepsSoFar : 95623\n",
            "TimeSinceStart : 102.098384141922\n",
            "Training Loss : 0.02113547921180725\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 88 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 96623\n",
            "TimeSinceStart : 103.28418946266174\n",
            "Training Loss : 0.008386993780732155\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 89 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 888.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 888.0\n",
            "Eval_MinReturn : 888.0\n",
            "Eval_AverageEpLen : 888.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 97623\n",
            "TimeSinceStart : 104.40236282348633\n",
            "Training Loss : -0.005372131709009409\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 90 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 98623\n",
            "TimeSinceStart : 105.62083911895752\n",
            "Training Loss : 0.01061820238828659\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 91 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 509.0\n",
            "Eval_StdReturn : 491.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 18.0\n",
            "Eval_AverageEpLen : 509.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 99623\n",
            "TimeSinceStart : 106.78758573532104\n",
            "Training Loss : -0.014320534653961658\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 92 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 100623\n",
            "TimeSinceStart : 108.05031228065491\n",
            "Training Loss : -0.005741272121667862\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 93 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 101623\n",
            "TimeSinceStart : 109.3696539402008\n",
            "Training Loss : 0.007391945458948612\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 94 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 102623\n",
            "TimeSinceStart : 110.70253729820251\n",
            "Training Loss : -0.029548432677984238\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 95 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 103623\n",
            "TimeSinceStart : 112.00556135177612\n",
            "Training Loss : 0.007777191698551178\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 96 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 104623\n",
            "TimeSinceStart : 113.43421697616577\n",
            "Training Loss : -0.023616807535290718\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 97 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 105623\n",
            "TimeSinceStart : 114.76517295837402\n",
            "Training Loss : 0.028728311881422997\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 98 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 106623\n",
            "TimeSinceStart : 116.09058952331543\n",
            "Training Loss : 0.01879618875682354\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 99 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 107623\n",
            "TimeSinceStart : 117.41403698921204\n",
            "Training Loss : -0.011144508607685566\n",
            "Initial_DataCollection_AverageReturn : 8.885965347290039\n",
            "Done logging...\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python cs285/scripts/run_hw2.py --env_name InvertedPendulum-v2 \\\n",
        "--ep_len 1000 --discount 0.9 -n 100 -l 2 -s 64 -b 1000 -lr 0.01 -rtg \\\n",
        "--exp_name q2_b1000_r01"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKe5HdYDHU70",
        "outputId": "97e33373-45ed-44e7-ffe9-3b85a6557c12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "########################\n",
            "logging outputs to  /content/gdrive/My Drive/cs285_f2021/DRL_policy_grads/cs285/scripts/../../data/q2_b300_r01_InvertedPendulum-v2_06-02-2022_17-43-08\n",
            "########################\n",
            "Using GPU id 0\n",
            "Sequential(\n",
            "  (0): Linear(in_features=4, out_features=64, bias=True)\n",
            "  (1): Tanh()\n",
            "  (2): Linear(in_features=64, out_features=64, bias=True)\n",
            "  (3): Tanh()\n",
            "  (4): Linear(in_features=64, out_features=1, bias=True)\n",
            "  (5): Identity()\n",
            ")\n",
            "\n",
            "\n",
            "********** Iteration 0 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([302])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 14.892857551574707\n",
            "Eval_StdReturn : 11.662942886352539\n",
            "Eval_MaxReturn : 49.0\n",
            "Eval_MinReturn : 4.0\n",
            "Eval_AverageEpLen : 14.892857142857142\n",
            "Train_AverageReturn : 7.947368621826172\n",
            "Train_StdReturn : 3.755328416824341\n",
            "Train_MaxReturn : 20.0\n",
            "Train_MinReturn : 3.0\n",
            "Train_AverageEpLen : 7.947368421052632\n",
            "Train_EnvstepsSoFar : 302\n",
            "TimeSinceStart : 0.44890284538269043\n",
            "Training Loss : -0.04502498731017113\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 1 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([300])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 27.066667556762695\n",
            "Eval_StdReturn : 14.011741638183594\n",
            "Eval_MaxReturn : 59.0\n",
            "Eval_MinReturn : 9.0\n",
            "Eval_AverageEpLen : 27.066666666666666\n",
            "Train_AverageReturn : 14.5\n",
            "Train_StdReturn : 6.013243198394775\n",
            "Train_MaxReturn : 25.0\n",
            "Train_MinReturn : 5.0\n",
            "Train_AverageEpLen : 14.5\n",
            "Train_EnvstepsSoFar : 621\n",
            "TimeSinceStart : 0.9095826148986816\n",
            "Training Loss : -0.03936474397778511\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 2 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([313])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 32.0\n",
            "Eval_StdReturn : 11.428709030151367\n",
            "Eval_MaxReturn : 59.0\n",
            "Eval_MinReturn : 16.0\n",
            "Eval_AverageEpLen : 32.0\n",
            "Train_AverageReturn : 22.35714340209961\n",
            "Train_StdReturn : 10.417067527770996\n",
            "Train_MaxReturn : 40.0\n",
            "Train_MinReturn : 5.0\n",
            "Train_AverageEpLen : 22.357142857142858\n",
            "Train_EnvstepsSoFar : 934\n",
            "TimeSinceStart : 1.3751344680786133\n",
            "Training Loss : -0.18818016350269318\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 3 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([307])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 40.400001525878906\n",
            "Eval_StdReturn : 22.401784896850586\n",
            "Eval_MaxReturn : 84.0\n",
            "Eval_MinReturn : 16.0\n",
            "Eval_AverageEpLen : 40.4\n",
            "Train_AverageReturn : 30.700000762939453\n",
            "Train_StdReturn : 22.410043716430664\n",
            "Train_MaxReturn : 91.0\n",
            "Train_MinReturn : 10.0\n",
            "Train_AverageEpLen : 30.7\n",
            "Train_EnvstepsSoFar : 1241\n",
            "TimeSinceStart : 1.8106462955474854\n",
            "Training Loss : -0.10143974423408508\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 4 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([320])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 33.38461685180664\n",
            "Eval_StdReturn : 19.40475082397461\n",
            "Eval_MaxReturn : 66.0\n",
            "Eval_MinReturn : 9.0\n",
            "Eval_AverageEpLen : 33.38461538461539\n",
            "Train_AverageReturn : 45.71428680419922\n",
            "Train_StdReturn : 16.984987258911133\n",
            "Train_MaxReturn : 73.0\n",
            "Train_MinReturn : 17.0\n",
            "Train_AverageEpLen : 45.714285714285715\n",
            "Train_EnvstepsSoFar : 1561\n",
            "TimeSinceStart : 2.359868049621582\n",
            "Training Loss : -0.056104253977537155\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 5 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([302])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 26.875\n",
            "Eval_StdReturn : 14.734631538391113\n",
            "Eval_MaxReturn : 59.0\n",
            "Eval_MinReturn : 9.0\n",
            "Eval_AverageEpLen : 26.875\n",
            "Train_AverageReturn : 28.727272033691406\n",
            "Train_StdReturn : 16.874353408813477\n",
            "Train_MaxReturn : 63.0\n",
            "Train_MinReturn : 10.0\n",
            "Train_AverageEpLen : 28.727272727272727\n",
            "Train_EnvstepsSoFar : 1877\n",
            "TimeSinceStart : 2.8259799480438232\n",
            "Training Loss : -0.02184821106493473\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 6 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([333])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 25.294116973876953\n",
            "Eval_StdReturn : 14.112009048461914\n",
            "Eval_MaxReturn : 53.0\n",
            "Eval_MinReturn : 9.0\n",
            "Eval_AverageEpLen : 25.294117647058822\n",
            "Train_AverageReturn : 37.0\n",
            "Train_StdReturn : 14.16568660736084\n",
            "Train_MaxReturn : 56.0\n",
            "Train_MinReturn : 7.0\n",
            "Train_AverageEpLen : 37.0\n",
            "Train_EnvstepsSoFar : 2210\n",
            "TimeSinceStart : 3.295436382293701\n",
            "Training Loss : 0.0008948157192207873\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 7 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([310])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 28.0\n",
            "Eval_StdReturn : 15.156956672668457\n",
            "Eval_MaxReturn : 51.0\n",
            "Eval_MinReturn : 7.0\n",
            "Eval_AverageEpLen : 28.0\n",
            "Train_AverageReturn : 30.090909957885742\n",
            "Train_StdReturn : 13.33112907409668\n",
            "Train_MaxReturn : 47.0\n",
            "Train_MinReturn : 8.0\n",
            "Train_AverageEpLen : 30.09090909090909\n",
            "Train_EnvstepsSoFar : 2541\n",
            "TimeSinceStart : 3.758234739303589\n",
            "Training Loss : -0.019425464794039726\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 8 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([316])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 36.54545593261719\n",
            "Eval_StdReturn : 32.53351974487305\n",
            "Eval_MaxReturn : 126.0\n",
            "Eval_MinReturn : 11.0\n",
            "Eval_AverageEpLen : 36.54545454545455\n",
            "Train_AverageReturn : 22.571428298950195\n",
            "Train_StdReturn : 11.549362182617188\n",
            "Train_MaxReturn : 43.0\n",
            "Train_MinReturn : 8.0\n",
            "Train_AverageEpLen : 22.571428571428573\n",
            "Train_EnvstepsSoFar : 2857\n",
            "TimeSinceStart : 4.235017776489258\n",
            "Training Loss : -0.0600479356944561\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 9 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([321])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 35.41666793823242\n",
            "Eval_StdReturn : 22.077360153198242\n",
            "Eval_MaxReturn : 91.0\n",
            "Eval_MinReturn : 10.0\n",
            "Eval_AverageEpLen : 35.416666666666664\n",
            "Train_AverageReturn : 29.33333396911621\n",
            "Train_StdReturn : 22.73518943786621\n",
            "Train_MaxReturn : 74.0\n",
            "Train_MinReturn : 7.0\n",
            "Train_AverageEpLen : 29.333333333333332\n",
            "Train_EnvstepsSoFar : 3209\n",
            "TimeSinceStart : 4.750197172164917\n",
            "Training Loss : -0.1307782083749771\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 10 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([314])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 41.20000076293945\n",
            "Eval_StdReturn : 20.399999618530273\n",
            "Eval_MaxReturn : 75.0\n",
            "Eval_MinReturn : 14.0\n",
            "Eval_AverageEpLen : 41.2\n",
            "Train_AverageReturn : 28.545454025268555\n",
            "Train_StdReturn : 18.62727165222168\n",
            "Train_MaxReturn : 65.0\n",
            "Train_MinReturn : 8.0\n",
            "Train_AverageEpLen : 28.545454545454547\n",
            "Train_EnvstepsSoFar : 3523\n",
            "TimeSinceStart : 5.2133119106292725\n",
            "Training Loss : -0.06751104444265366\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 11 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([313])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 61.71428680419922\n",
            "Eval_StdReturn : 34.19989013671875\n",
            "Eval_MaxReturn : 113.0\n",
            "Eval_MinReturn : 8.0\n",
            "Eval_AverageEpLen : 61.714285714285715\n",
            "Train_AverageReturn : 62.16666793823242\n",
            "Train_StdReturn : 35.31485366821289\n",
            "Train_MaxReturn : 114.0\n",
            "Train_MinReturn : 9.0\n",
            "Train_AverageEpLen : 62.166666666666664\n",
            "Train_EnvstepsSoFar : 3896\n",
            "TimeSinceStart : 5.723993301391602\n",
            "Training Loss : -0.014212757349014282\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 12 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([313])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 72.83333587646484\n",
            "Eval_StdReturn : 25.07599639892578\n",
            "Eval_MaxReturn : 117.0\n",
            "Eval_MinReturn : 41.0\n",
            "Eval_AverageEpLen : 72.83333333333333\n",
            "Train_AverageReturn : 62.599998474121094\n",
            "Train_StdReturn : 18.42389678955078\n",
            "Train_MaxReturn : 87.0\n",
            "Train_MinReturn : 36.0\n",
            "Train_AverageEpLen : 62.6\n",
            "Train_EnvstepsSoFar : 4209\n",
            "TimeSinceStart : 6.202723503112793\n",
            "Training Loss : -0.052376244217157364\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 13 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([305])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 54.0\n",
            "Eval_StdReturn : 23.140872955322266\n",
            "Eval_MaxReturn : 88.0\n",
            "Eval_MinReturn : 29.0\n",
            "Eval_AverageEpLen : 54.0\n",
            "Train_AverageReturn : 61.0\n",
            "Train_StdReturn : 11.224971771240234\n",
            "Train_MaxReturn : 76.0\n",
            "Train_MinReturn : 43.0\n",
            "Train_AverageEpLen : 61.0\n",
            "Train_EnvstepsSoFar : 4514\n",
            "TimeSinceStart : 6.6411659717559814\n",
            "Training Loss : -0.008706371299922466\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 14 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([323])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 69.5\n",
            "Eval_StdReturn : 31.063108444213867\n",
            "Eval_MaxReturn : 125.0\n",
            "Eval_MinReturn : 36.0\n",
            "Eval_AverageEpLen : 69.5\n",
            "Train_AverageReturn : 64.5999984741211\n",
            "Train_StdReturn : 53.68649673461914\n",
            "Train_MaxReturn : 171.0\n",
            "Train_MinReturn : 29.0\n",
            "Train_AverageEpLen : 64.6\n",
            "Train_EnvstepsSoFar : 4837\n",
            "TimeSinceStart : 7.085175275802612\n",
            "Training Loss : -0.032988693565130234\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 15 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([302])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 67.57142639160156\n",
            "Eval_StdReturn : 32.4603385925293\n",
            "Eval_MaxReturn : 115.0\n",
            "Eval_MinReturn : 13.0\n",
            "Eval_AverageEpLen : 67.57142857142857\n",
            "Train_AverageReturn : 77.0\n",
            "Train_StdReturn : 17.899721145629883\n",
            "Train_MaxReturn : 98.0\n",
            "Train_MinReturn : 44.0\n",
            "Train_AverageEpLen : 77.0\n",
            "Train_EnvstepsSoFar : 5222\n",
            "TimeSinceStart : 7.595423460006714\n",
            "Training Loss : 0.04008760675787926\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 16 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([327])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 88.80000305175781\n",
            "Eval_StdReturn : 44.963985443115234\n",
            "Eval_MaxReturn : 173.0\n",
            "Eval_MinReturn : 47.0\n",
            "Eval_AverageEpLen : 88.8\n",
            "Train_AverageReturn : 65.4000015258789\n",
            "Train_StdReturn : 27.207353591918945\n",
            "Train_MaxReturn : 101.0\n",
            "Train_MinReturn : 34.0\n",
            "Train_AverageEpLen : 65.4\n",
            "Train_EnvstepsSoFar : 5549\n",
            "TimeSinceStart : 8.060279130935669\n",
            "Training Loss : -0.025345368310809135\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 17 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([325])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 54.875\n",
            "Eval_StdReturn : 28.108884811401367\n",
            "Eval_MaxReturn : 119.0\n",
            "Eval_MinReturn : 29.0\n",
            "Eval_AverageEpLen : 54.875\n",
            "Train_AverageReturn : 65.0\n",
            "Train_StdReturn : 21.372879028320312\n",
            "Train_MaxReturn : 88.0\n",
            "Train_MinReturn : 34.0\n",
            "Train_AverageEpLen : 65.0\n",
            "Train_EnvstepsSoFar : 5874\n",
            "TimeSinceStart : 8.520312547683716\n",
            "Training Loss : -0.03845011815428734\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 18 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([391])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 86.5999984741211\n",
            "Eval_StdReturn : 30.335458755493164\n",
            "Eval_MaxReturn : 129.0\n",
            "Eval_MinReturn : 49.0\n",
            "Eval_AverageEpLen : 86.6\n",
            "Train_AverageReturn : 97.75\n",
            "Train_StdReturn : 30.970752716064453\n",
            "Train_MaxReturn : 128.0\n",
            "Train_MinReturn : 46.0\n",
            "Train_AverageEpLen : 97.75\n",
            "Train_EnvstepsSoFar : 6265\n",
            "TimeSinceStart : 9.032011032104492\n",
            "Training Loss : -0.05252521112561226\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 19 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([324])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 85.4000015258789\n",
            "Eval_StdReturn : 14.221110343933105\n",
            "Eval_MaxReturn : 109.0\n",
            "Eval_MinReturn : 65.0\n",
            "Eval_AverageEpLen : 85.4\n",
            "Train_AverageReturn : 64.80000305175781\n",
            "Train_StdReturn : 33.14453125\n",
            "Train_MaxReturn : 99.0\n",
            "Train_MinReturn : 5.0\n",
            "Train_AverageEpLen : 64.8\n",
            "Train_EnvstepsSoFar : 6589\n",
            "TimeSinceStart : 9.508708953857422\n",
            "Training Loss : -0.02117498405277729\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 20 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([302])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 67.5\n",
            "Eval_StdReturn : 32.71976852416992\n",
            "Eval_MaxReturn : 130.0\n",
            "Eval_MinReturn : 24.0\n",
            "Eval_AverageEpLen : 67.5\n",
            "Train_AverageReturn : 75.5\n",
            "Train_StdReturn : 24.601829528808594\n",
            "Train_MaxReturn : 108.0\n",
            "Train_MinReturn : 39.0\n",
            "Train_AverageEpLen : 75.5\n",
            "Train_EnvstepsSoFar : 6891\n",
            "TimeSinceStart : 10.020982265472412\n",
            "Training Loss : 0.002186112105846405\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 21 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([333])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 86.4000015258789\n",
            "Eval_StdReturn : 14.065560340881348\n",
            "Eval_MaxReturn : 104.0\n",
            "Eval_MinReturn : 68.0\n",
            "Eval_AverageEpLen : 86.4\n",
            "Train_AverageReturn : 83.25\n",
            "Train_StdReturn : 25.897634506225586\n",
            "Train_MaxReturn : 124.0\n",
            "Train_MinReturn : 52.0\n",
            "Train_AverageEpLen : 83.25\n",
            "Train_EnvstepsSoFar : 7224\n",
            "TimeSinceStart : 10.494434595108032\n",
            "Training Loss : -0.08746278285980225\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 22 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([319])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 93.0\n",
            "Eval_StdReturn : 29.58378028869629\n",
            "Eval_MaxReturn : 147.0\n",
            "Eval_MinReturn : 65.0\n",
            "Eval_AverageEpLen : 93.0\n",
            "Train_AverageReturn : 77.19999694824219\n",
            "Train_StdReturn : 15.57433795928955\n",
            "Train_MaxReturn : 104.0\n",
            "Train_MinReturn : 61.0\n",
            "Train_AverageEpLen : 77.2\n",
            "Train_EnvstepsSoFar : 7610\n",
            "TimeSinceStart : 11.011353969573975\n",
            "Training Loss : -0.029423637315630913\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 23 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([301])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 54.75\n",
            "Eval_StdReturn : 18.932445526123047\n",
            "Eval_MaxReturn : 84.0\n",
            "Eval_MinReturn : 27.0\n",
            "Eval_AverageEpLen : 54.75\n",
            "Train_AverageReturn : 64.0\n",
            "Train_StdReturn : 36.03886795043945\n",
            "Train_MaxReturn : 116.0\n",
            "Train_MinReturn : 19.0\n",
            "Train_AverageEpLen : 64.0\n",
            "Train_EnvstepsSoFar : 7930\n",
            "TimeSinceStart : 11.462654113769531\n",
            "Training Loss : -0.09915575385093689\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 24 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([341])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 52.0\n",
            "Eval_StdReturn : 22.79802703857422\n",
            "Eval_MaxReturn : 75.0\n",
            "Eval_MinReturn : 11.0\n",
            "Eval_AverageEpLen : 52.0\n",
            "Train_AverageReturn : 68.19999694824219\n",
            "Train_StdReturn : 32.0774040222168\n",
            "Train_MaxReturn : 126.0\n",
            "Train_MinReturn : 29.0\n",
            "Train_AverageEpLen : 68.2\n",
            "Train_EnvstepsSoFar : 8271\n",
            "TimeSinceStart : 11.942156076431274\n",
            "Training Loss : -0.07743150740861893\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 25 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([310])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 41.29999923706055\n",
            "Eval_StdReturn : 19.884918212890625\n",
            "Eval_MaxReturn : 81.0\n",
            "Eval_MinReturn : 10.0\n",
            "Eval_AverageEpLen : 41.3\n",
            "Train_AverageReturn : 44.28571319580078\n",
            "Train_StdReturn : 13.4027099609375\n",
            "Train_MaxReturn : 62.0\n",
            "Train_MinReturn : 20.0\n",
            "Train_AverageEpLen : 44.285714285714285\n",
            "Train_EnvstepsSoFar : 8581\n",
            "TimeSinceStart : 12.391355752944946\n",
            "Training Loss : -0.02654232457280159\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 26 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([312])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 60.85714340209961\n",
            "Eval_StdReturn : 14.287142753601074\n",
            "Eval_MaxReturn : 89.0\n",
            "Eval_MinReturn : 46.0\n",
            "Eval_AverageEpLen : 60.857142857142854\n",
            "Train_AverageReturn : 39.0\n",
            "Train_StdReturn : 13.31352710723877\n",
            "Train_MaxReturn : 58.0\n",
            "Train_MinReturn : 13.0\n",
            "Train_AverageEpLen : 39.0\n",
            "Train_EnvstepsSoFar : 8893\n",
            "TimeSinceStart : 12.880099058151245\n",
            "Training Loss : -0.07607664167881012\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 27 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([331])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 60.85714340209961\n",
            "Eval_StdReturn : 6.197432041168213\n",
            "Eval_MaxReturn : 68.0\n",
            "Eval_MinReturn : 51.0\n",
            "Eval_AverageEpLen : 60.857142857142854\n",
            "Train_AverageReturn : 43.125\n",
            "Train_StdReturn : 11.493884086608887\n",
            "Train_MaxReturn : 51.0\n",
            "Train_MinReturn : 14.0\n",
            "Train_AverageEpLen : 43.125\n",
            "Train_EnvstepsSoFar : 9238\n",
            "TimeSinceStart : 13.43010401725769\n",
            "Training Loss : -0.06861737370491028\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 28 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([308])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 106.75\n",
            "Eval_StdReturn : 24.386215209960938\n",
            "Eval_MaxReturn : 132.0\n",
            "Eval_MinReturn : 79.0\n",
            "Eval_AverageEpLen : 106.75\n",
            "Train_AverageReturn : 77.0\n",
            "Train_StdReturn : 13.87443733215332\n",
            "Train_MaxReturn : 96.0\n",
            "Train_MinReturn : 59.0\n",
            "Train_AverageEpLen : 77.0\n",
            "Train_EnvstepsSoFar : 9546\n",
            "TimeSinceStart : 13.890623092651367\n",
            "Training Loss : -0.014096699655056\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 29 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([343])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 168.3333282470703\n",
            "Eval_StdReturn : 20.434175491333008\n",
            "Eval_MaxReturn : 194.0\n",
            "Eval_MinReturn : 144.0\n",
            "Eval_AverageEpLen : 168.33333333333334\n",
            "Train_AverageReturn : 114.33333587646484\n",
            "Train_StdReturn : 9.741092681884766\n",
            "Train_MaxReturn : 128.0\n",
            "Train_MinReturn : 106.0\n",
            "Train_AverageEpLen : 114.33333333333333\n",
            "Train_EnvstepsSoFar : 9889\n",
            "TimeSinceStart : 14.423084020614624\n",
            "Training Loss : -0.008148794062435627\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 30 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([369])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 76.0\n",
            "Eval_StdReturn : 38.27096176147461\n",
            "Eval_MaxReturn : 140.0\n",
            "Eval_MinReturn : 9.0\n",
            "Eval_AverageEpLen : 76.0\n",
            "Train_AverageReturn : 92.25\n",
            "Train_StdReturn : 20.05461311340332\n",
            "Train_MaxReturn : 124.0\n",
            "Train_MinReturn : 70.0\n",
            "Train_AverageEpLen : 92.25\n",
            "Train_EnvstepsSoFar : 10258\n",
            "TimeSinceStart : 14.92634129524231\n",
            "Training Loss : 0.007192410062998533\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 31 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([340])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 89.80000305175781\n",
            "Eval_StdReturn : 29.157503128051758\n",
            "Eval_MaxReturn : 147.0\n",
            "Eval_MinReturn : 68.0\n",
            "Eval_AverageEpLen : 89.8\n",
            "Train_AverageReturn : 113.33333587646484\n",
            "Train_StdReturn : 16.110727310180664\n",
            "Train_MaxReturn : 136.0\n",
            "Train_MinReturn : 100.0\n",
            "Train_AverageEpLen : 113.33333333333333\n",
            "Train_EnvstepsSoFar : 10598\n",
            "TimeSinceStart : 15.41188645362854\n",
            "Training Loss : -0.052719924598932266\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 32 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([320])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 78.5\n",
            "Eval_StdReturn : 12.737739562988281\n",
            "Eval_MaxReturn : 98.0\n",
            "Eval_MinReturn : 59.0\n",
            "Eval_AverageEpLen : 78.5\n",
            "Train_AverageReturn : 80.0\n",
            "Train_StdReturn : 4.949747562408447\n",
            "Train_MaxReturn : 85.0\n",
            "Train_MinReturn : 72.0\n",
            "Train_AverageEpLen : 80.0\n",
            "Train_EnvstepsSoFar : 10918\n",
            "TimeSinceStart : 15.906898736953735\n",
            "Training Loss : 0.033063050359487534\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 33 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([308])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 73.66666412353516\n",
            "Eval_StdReturn : 9.067646980285645\n",
            "Eval_MaxReturn : 86.0\n",
            "Eval_MinReturn : 59.0\n",
            "Eval_AverageEpLen : 73.66666666666667\n",
            "Train_AverageReturn : 77.0\n",
            "Train_StdReturn : 11.247221946716309\n",
            "Train_MaxReturn : 96.0\n",
            "Train_MinReturn : 67.0\n",
            "Train_AverageEpLen : 77.0\n",
            "Train_EnvstepsSoFar : 11226\n",
            "TimeSinceStart : 16.424123287200928\n",
            "Training Loss : 0.04377231001853943\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 34 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([343])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 69.5\n",
            "Eval_StdReturn : 8.118907928466797\n",
            "Eval_MaxReturn : 86.0\n",
            "Eval_MinReturn : 61.0\n",
            "Eval_AverageEpLen : 69.5\n",
            "Train_AverageReturn : 68.5999984741211\n",
            "Train_StdReturn : 6.711184978485107\n",
            "Train_MaxReturn : 76.0\n",
            "Train_MinReturn : 56.0\n",
            "Train_AverageEpLen : 68.6\n",
            "Train_EnvstepsSoFar : 11569\n",
            "TimeSinceStart : 16.93484377861023\n",
            "Training Loss : -0.08282359689474106\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 35 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([324])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 69.83333587646484\n",
            "Eval_StdReturn : 7.733405113220215\n",
            "Eval_MaxReturn : 81.0\n",
            "Eval_MinReturn : 60.0\n",
            "Eval_AverageEpLen : 69.83333333333333\n",
            "Train_AverageReturn : 64.80000305175781\n",
            "Train_StdReturn : 3.9698867797851562\n",
            "Train_MaxReturn : 69.0\n",
            "Train_MinReturn : 60.0\n",
            "Train_AverageEpLen : 64.8\n",
            "Train_EnvstepsSoFar : 11893\n",
            "TimeSinceStart : 17.394963264465332\n",
            "Training Loss : 0.044131744652986526\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 36 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([333])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 76.83333587646484\n",
            "Eval_StdReturn : 9.28110408782959\n",
            "Eval_MaxReturn : 93.0\n",
            "Eval_MinReturn : 62.0\n",
            "Eval_AverageEpLen : 76.83333333333333\n",
            "Train_AverageReturn : 66.5999984741211\n",
            "Train_StdReturn : 10.091580390930176\n",
            "Train_MaxReturn : 81.0\n",
            "Train_MinReturn : 52.0\n",
            "Train_AverageEpLen : 66.6\n",
            "Train_EnvstepsSoFar : 12226\n",
            "TimeSinceStart : 17.881673336029053\n",
            "Training Loss : 0.029556652531027794\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 37 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([304])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 81.4000015258789\n",
            "Eval_StdReturn : 4.841487407684326\n",
            "Eval_MaxReturn : 91.0\n",
            "Eval_MinReturn : 78.0\n",
            "Eval_AverageEpLen : 81.4\n",
            "Train_AverageReturn : 76.0\n",
            "Train_StdReturn : 6.041522979736328\n",
            "Train_MaxReturn : 85.0\n",
            "Train_MinReturn : 70.0\n",
            "Train_AverageEpLen : 76.0\n",
            "Train_EnvstepsSoFar : 12530\n",
            "TimeSinceStart : 18.341856956481934\n",
            "Training Loss : -0.01392718218266964\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 38 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([363])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 100.19999694824219\n",
            "Eval_StdReturn : 7.359347820281982\n",
            "Eval_MaxReturn : 111.0\n",
            "Eval_MinReturn : 92.0\n",
            "Eval_AverageEpLen : 100.2\n",
            "Train_AverageReturn : 90.75\n",
            "Train_StdReturn : 9.256753921508789\n",
            "Train_MaxReturn : 104.0\n",
            "Train_MinReturn : 78.0\n",
            "Train_AverageEpLen : 90.75\n",
            "Train_EnvstepsSoFar : 12893\n",
            "TimeSinceStart : 18.852613925933838\n",
            "Training Loss : 0.003268985543400049\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 39 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([397])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 150.6666717529297\n",
            "Eval_StdReturn : 12.47219181060791\n",
            "Eval_MaxReturn : 164.0\n",
            "Eval_MinReturn : 134.0\n",
            "Eval_AverageEpLen : 150.66666666666666\n",
            "Train_AverageReturn : 99.25\n",
            "Train_StdReturn : 4.96865177154541\n",
            "Train_MaxReturn : 104.0\n",
            "Train_MinReturn : 91.0\n",
            "Train_AverageEpLen : 99.25\n",
            "Train_EnvstepsSoFar : 13290\n",
            "TimeSinceStart : 19.412999391555786\n",
            "Training Loss : 0.015436992980539799\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 40 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([300])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 203.5\n",
            "Eval_StdReturn : 0.5\n",
            "Eval_MaxReturn : 204.0\n",
            "Eval_MinReturn : 203.0\n",
            "Eval_AverageEpLen : 203.5\n",
            "Train_AverageReturn : 145.0\n",
            "Train_StdReturn : 16.309507369995117\n",
            "Train_MaxReturn : 168.0\n",
            "Train_MinReturn : 132.0\n",
            "Train_AverageEpLen : 145.0\n",
            "Train_EnvstepsSoFar : 13725\n",
            "TimeSinceStart : 19.907744646072388\n",
            "Training Loss : -0.025186017155647278\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 41 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([417])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 224.0\n",
            "Eval_StdReturn : 31.0\n",
            "Eval_MaxReturn : 255.0\n",
            "Eval_MinReturn : 193.0\n",
            "Eval_AverageEpLen : 224.0\n",
            "Train_AverageReturn : 208.5\n",
            "Train_StdReturn : 6.5\n",
            "Train_MaxReturn : 215.0\n",
            "Train_MinReturn : 202.0\n",
            "Train_AverageEpLen : 208.5\n",
            "Train_EnvstepsSoFar : 14142\n",
            "TimeSinceStart : 20.545231819152832\n",
            "Training Loss : -0.019722890108823776\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 42 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([301])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 236.0\n",
            "Eval_StdReturn : 131.2580108642578\n",
            "Eval_MaxReturn : 387.0\n",
            "Eval_MinReturn : 67.0\n",
            "Eval_AverageEpLen : 236.0\n",
            "Train_AverageReturn : 301.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 301.0\n",
            "Train_MinReturn : 301.0\n",
            "Train_AverageEpLen : 301.0\n",
            "Train_EnvstepsSoFar : 14443\n",
            "TimeSinceStart : 21.220183849334717\n",
            "Training Loss : -0.002056337194517255\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 43 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([331])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 318.0\n",
            "Eval_StdReturn : 52.0\n",
            "Eval_MaxReturn : 370.0\n",
            "Eval_MinReturn : 266.0\n",
            "Eval_AverageEpLen : 318.0\n",
            "Train_AverageReturn : 331.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 331.0\n",
            "Train_MinReturn : 331.0\n",
            "Train_AverageEpLen : 331.0\n",
            "Train_EnvstepsSoFar : 14774\n",
            "TimeSinceStart : 21.79995560646057\n",
            "Training Loss : -0.025990892201662064\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 44 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([314])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 136.3333282470703\n",
            "Eval_StdReturn : 72.82093811035156\n",
            "Eval_MaxReturn : 222.0\n",
            "Eval_MinReturn : 44.0\n",
            "Eval_AverageEpLen : 136.33333333333334\n",
            "Train_AverageReturn : 157.0\n",
            "Train_StdReturn : 7.0\n",
            "Train_MaxReturn : 164.0\n",
            "Train_MinReturn : 150.0\n",
            "Train_AverageEpLen : 157.0\n",
            "Train_EnvstepsSoFar : 15088\n",
            "TimeSinceStart : 22.27387046813965\n",
            "Training Loss : -0.19654124975204468\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 45 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([328])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 678.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 678.0\n",
            "Eval_MinReturn : 678.0\n",
            "Eval_AverageEpLen : 678.0\n",
            "Train_AverageReturn : 164.0\n",
            "Train_StdReturn : 12.0\n",
            "Train_MaxReturn : 176.0\n",
            "Train_MinReturn : 152.0\n",
            "Train_AverageEpLen : 164.0\n",
            "Train_EnvstepsSoFar : 15416\n",
            "TimeSinceStart : 22.929187774658203\n",
            "Training Loss : 0.004211029969155788\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 46 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([871])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 430.0\n",
            "Eval_StdReturn : 145.0\n",
            "Eval_MaxReturn : 575.0\n",
            "Eval_MinReturn : 285.0\n",
            "Eval_AverageEpLen : 430.0\n",
            "Train_AverageReturn : 511.0\n",
            "Train_StdReturn : 360.0\n",
            "Train_MaxReturn : 871.0\n",
            "Train_MinReturn : 151.0\n",
            "Train_AverageEpLen : 511.0\n",
            "Train_EnvstepsSoFar : 16438\n",
            "TimeSinceStart : 24.064855098724365\n",
            "Training Loss : -0.02625475823879242\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 47 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([639])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 569.5\n",
            "Eval_StdReturn : 430.5\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 139.0\n",
            "Eval_AverageEpLen : 569.5\n",
            "Train_AverageReturn : 639.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 639.0\n",
            "Train_MinReturn : 639.0\n",
            "Train_AverageEpLen : 639.0\n",
            "Train_EnvstepsSoFar : 17077\n",
            "TimeSinceStart : 25.098634481430054\n",
            "Training Loss : -0.04684673994779587\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 48 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 486.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 486.0\n",
            "Eval_MinReturn : 486.0\n",
            "Eval_AverageEpLen : 486.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 18077\n",
            "TimeSinceStart : 26.01181435585022\n",
            "Training Loss : -0.004512794781476259\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 49 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 543.5\n",
            "Train_StdReturn : 456.5\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 87.0\n",
            "Train_AverageEpLen : 543.5\n",
            "Train_EnvstepsSoFar : 19164\n",
            "TimeSinceStart : 27.474029541015625\n",
            "Training Loss : 0.018042756244540215\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 50 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 20164\n",
            "TimeSinceStart : 28.743104219436646\n",
            "Training Loss : 0.012043899856507778\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 51 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([473])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 473.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 473.0\n",
            "Train_MinReturn : 473.0\n",
            "Train_AverageEpLen : 473.0\n",
            "Train_EnvstepsSoFar : 20637\n",
            "TimeSinceStart : 29.732123613357544\n",
            "Training Loss : -0.13178302347660065\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 52 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 21637\n",
            "TimeSinceStart : 31.024141788482666\n",
            "Training Loss : 0.015465675853192806\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 53 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 22637\n",
            "TimeSinceStart : 32.32253646850586\n",
            "Training Loss : 0.025840317830443382\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 54 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 23637\n",
            "TimeSinceStart : 33.54534649848938\n",
            "Training Loss : 0.020561501383781433\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 55 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 24637\n",
            "TimeSinceStart : 34.772603034973145\n",
            "Training Loss : 0.00789114460349083\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 56 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 25637\n",
            "TimeSinceStart : 35.951441049575806\n",
            "Training Loss : -0.037467699497938156\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 57 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 26637\n",
            "TimeSinceStart : 37.12609648704529\n",
            "Training Loss : 0.026879997923970222\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 58 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 27637\n",
            "TimeSinceStart : 38.342862606048584\n",
            "Training Loss : 0.026154251769185066\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 59 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 28637\n",
            "TimeSinceStart : 39.56354641914368\n",
            "Training Loss : -0.04148662090301514\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 60 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 29637\n",
            "TimeSinceStart : 40.784323930740356\n",
            "Training Loss : -0.027722138911485672\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 61 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 57.57143020629883\n",
            "Eval_StdReturn : 94.34565734863281\n",
            "Eval_MaxReturn : 267.0\n",
            "Eval_MinReturn : 3.0\n",
            "Eval_AverageEpLen : 57.57142857142857\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 30637\n",
            "TimeSinceStart : 41.66116285324097\n",
            "Training Loss : 0.027054402977228165\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 62 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([326])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 28.33333396911621\n",
            "Eval_StdReturn : 67.35066223144531\n",
            "Eval_MaxReturn : 281.0\n",
            "Eval_MinReturn : 3.0\n",
            "Eval_AverageEpLen : 28.333333333333332\n",
            "Train_AverageReturn : 30.125\n",
            "Train_StdReturn : 64.90750885009766\n",
            "Train_MaxReturn : 265.0\n",
            "Train_MinReturn : 3.0\n",
            "Train_AverageEpLen : 30.125\n",
            "Train_EnvstepsSoFar : 31119\n",
            "TimeSinceStart : 42.2975013256073\n",
            "Training Loss : 0.003846899839118123\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 63 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([301])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 15.850000381469727\n",
            "Train_StdReturn : 30.534040451049805\n",
            "Train_MaxReturn : 112.0\n",
            "Train_MinReturn : 3.0\n",
            "Train_AverageEpLen : 15.85\n",
            "Train_EnvstepsSoFar : 31436\n",
            "TimeSinceStart : 43.07479190826416\n",
            "Training Loss : -0.06433191150426865\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 64 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 32436\n",
            "TimeSinceStart : 44.32827925682068\n",
            "Training Loss : 0.01681923307478428\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 65 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 33436\n",
            "TimeSinceStart : 45.569600105285645\n",
            "Training Loss : -0.012151932343840599\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 66 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 34436\n",
            "TimeSinceStart : 46.78192591667175\n",
            "Training Loss : 0.01681637577712536\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 67 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 769.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 769.0\n",
            "Eval_MinReturn : 769.0\n",
            "Eval_AverageEpLen : 769.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 35436\n",
            "TimeSinceStart : 48.09044647216797\n",
            "Training Loss : 0.028873460367321968\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 68 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 98.0\n",
            "Eval_StdReturn : 80.63745880126953\n",
            "Eval_MaxReturn : 247.0\n",
            "Eval_MinReturn : 27.0\n",
            "Eval_AverageEpLen : 98.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 36436\n",
            "TimeSinceStart : 49.046058177948\n",
            "Training Loss : 0.002672492992132902\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 69 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([406])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 122.19999694824219\n",
            "Eval_StdReturn : 105.72303771972656\n",
            "Eval_MaxReturn : 306.0\n",
            "Eval_MinReturn : 8.0\n",
            "Eval_AverageEpLen : 122.2\n",
            "Train_AverageReturn : 67.66666412353516\n",
            "Train_StdReturn : 41.13663101196289\n",
            "Train_MaxReturn : 125.0\n",
            "Train_MinReturn : 24.0\n",
            "Train_AverageEpLen : 67.66666666666667\n",
            "Train_EnvstepsSoFar : 36842\n",
            "TimeSinceStart : 49.663158893585205\n",
            "Training Loss : 0.0150749571621418\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 70 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([475])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 98.0\n",
            "Eval_StdReturn : 103.50845336914062\n",
            "Eval_MaxReturn : 278.0\n",
            "Eval_MinReturn : 19.0\n",
            "Eval_AverageEpLen : 98.0\n",
            "Train_AverageReturn : 215.6666717529297\n",
            "Train_StdReturn : 188.22738647460938\n",
            "Train_MaxReturn : 475.0\n",
            "Train_MinReturn : 34.0\n",
            "Train_AverageEpLen : 215.66666666666666\n",
            "Train_EnvstepsSoFar : 37489\n",
            "TimeSinceStart : 50.34033179283142\n",
            "Training Loss : 0.025838341563940048\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 71 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([350])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 729.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 729.0\n",
            "Eval_MinReturn : 729.0\n",
            "Eval_AverageEpLen : 729.0\n",
            "Train_AverageReturn : 193.0\n",
            "Train_StdReturn : 157.0\n",
            "Train_MaxReturn : 350.0\n",
            "Train_MinReturn : 36.0\n",
            "Train_AverageEpLen : 193.0\n",
            "Train_EnvstepsSoFar : 37875\n",
            "TimeSinceStart : 51.02261400222778\n",
            "Training Loss : -0.10834136605262756\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 72 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([778])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 778.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 778.0\n",
            "Train_MinReturn : 778.0\n",
            "Train_AverageEpLen : 778.0\n",
            "Train_EnvstepsSoFar : 38653\n",
            "TimeSinceStart : 52.293575048446655\n",
            "Training Loss : -0.023254159837961197\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 73 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 39653\n",
            "TimeSinceStart : 53.768580198287964\n",
            "Training Loss : -0.019641868770122528\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 74 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 40653\n",
            "TimeSinceStart : 55.18925380706787\n",
            "Training Loss : -0.008154739625751972\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 75 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 41653\n",
            "TimeSinceStart : 56.54499936103821\n",
            "Training Loss : 0.010400451719760895\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 76 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 42653\n",
            "TimeSinceStart : 57.94206428527832\n",
            "Training Loss : 0.015934083610773087\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 77 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 43653\n",
            "TimeSinceStart : 59.262654304504395\n",
            "Training Loss : -0.0064592440612614155\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 78 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 44653\n",
            "TimeSinceStart : 60.65959453582764\n",
            "Training Loss : -0.024767456576228142\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 79 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 45653\n",
            "TimeSinceStart : 61.95684599876404\n",
            "Training Loss : -0.006269615609198809\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 80 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 46653\n",
            "TimeSinceStart : 63.25539565086365\n",
            "Training Loss : -0.005221214611083269\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 81 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 47653\n",
            "TimeSinceStart : 64.48150730133057\n",
            "Training Loss : -0.003528694389387965\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 82 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 48653\n",
            "TimeSinceStart : 65.67899703979492\n",
            "Training Loss : 0.04200388491153717\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 83 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 49653\n",
            "TimeSinceStart : 66.905601978302\n",
            "Training Loss : 0.022431092336773872\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 84 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 50653\n",
            "TimeSinceStart : 68.25334739685059\n",
            "Training Loss : 0.04237066209316254\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 85 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 648.5\n",
            "Eval_StdReturn : 351.5\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 297.0\n",
            "Eval_AverageEpLen : 648.5\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 51653\n",
            "TimeSinceStart : 69.70152807235718\n",
            "Training Loss : 0.025407982990145683\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 86 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([616])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 616.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 616.0\n",
            "Train_MinReturn : 616.0\n",
            "Train_AverageEpLen : 616.0\n",
            "Train_EnvstepsSoFar : 52269\n",
            "TimeSinceStart : 70.82017397880554\n",
            "Training Loss : -0.10196734219789505\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 87 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 599.5\n",
            "Train_StdReturn : 400.5\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 199.0\n",
            "Train_AverageEpLen : 599.5\n",
            "Train_EnvstepsSoFar : 53468\n",
            "TimeSinceStart : 72.23041081428528\n",
            "Training Loss : 0.028708230704069138\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 88 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 54468\n",
            "TimeSinceStart : 73.59042859077454\n",
            "Training Loss : -0.009966827929019928\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 89 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 55468\n",
            "TimeSinceStart : 74.99848413467407\n",
            "Training Loss : -0.01314138900488615\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 90 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 56468\n",
            "TimeSinceStart : 76.45102667808533\n",
            "Training Loss : -0.00995591003447771\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 91 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 57468\n",
            "TimeSinceStart : 77.76189756393433\n",
            "Training Loss : -0.04301311820745468\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 92 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 58468\n",
            "TimeSinceStart : 79.05708932876587\n",
            "Training Loss : -0.0018533631227910519\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 93 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 59468\n",
            "TimeSinceStart : 80.30615592002869\n",
            "Training Loss : 0.011055221781134605\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 94 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 60468\n",
            "TimeSinceStart : 81.49897170066833\n",
            "Training Loss : 0.008704681880772114\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 95 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 61468\n",
            "TimeSinceStart : 82.680988073349\n",
            "Training Loss : 0.018256353214383125\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 96 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 62468\n",
            "TimeSinceStart : 83.91781711578369\n",
            "Training Loss : -0.018081657588481903\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 97 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 63468\n",
            "TimeSinceStart : 85.13346076011658\n",
            "Training Loss : -0.026155121624469757\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 98 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 64468\n",
            "TimeSinceStart : 86.31950211524963\n",
            "Training Loss : 0.02054445818066597\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 99 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([1000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1000.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1000.0\n",
            "Eval_MinReturn : 1000.0\n",
            "Eval_AverageEpLen : 1000.0\n",
            "Train_AverageReturn : 1000.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1000.0\n",
            "Train_MinReturn : 1000.0\n",
            "Train_AverageEpLen : 1000.0\n",
            "Train_EnvstepsSoFar : 65468\n",
            "TimeSinceStart : 87.54713344573975\n",
            "Training Loss : -0.014934265986084938\n",
            "Initial_DataCollection_AverageReturn : 7.947368621826172\n",
            "Done logging...\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python cs285/scripts/run_hw2.py --env_name InvertedPendulum-v2 \\\n",
        "--ep_len 1000 --discount 0.9 -n 100 -l 2 -s 64 -b 300 -lr 0.01 -rtg \\\n",
        "--exp_name q2_b300_r01"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYgNPxIiH3k3",
        "outputId": "4a984a87-e36d-42c1-ccf4-d6879135379b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "########################\n",
            "logging outputs to  /content/gdrive/My Drive/cs285_f2021/DRL_policy_grads/cs285/scripts/../../data/q2_b50_r07_InvertedPendulum-v2_06-02-2022_17-44-40\n",
            "########################\n",
            "Using GPU id 0\n",
            "Sequential(\n",
            "  (0): Linear(in_features=4, out_features=64, bias=True)\n",
            "  (1): Tanh()\n",
            "  (2): Linear(in_features=64, out_features=64, bias=True)\n",
            "  (3): Tanh()\n",
            "  (4): Linear(in_features=64, out_features=1, bias=True)\n",
            "  (5): Identity()\n",
            ")\n",
            "\n",
            "\n",
            "********** Iteration 0 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([52])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 12.5625\n",
            "Eval_StdReturn : 7.110456466674805\n",
            "Eval_MaxReturn : 31.0\n",
            "Eval_MinReturn : 4.0\n",
            "Eval_AverageEpLen : 12.5625\n",
            "Train_AverageReturn : 6.5\n",
            "Train_StdReturn : 3.1224989891052246\n",
            "Train_MaxReturn : 14.0\n",
            "Train_MinReturn : 4.0\n",
            "Train_AverageEpLen : 6.5\n",
            "Train_EnvstepsSoFar : 52\n",
            "TimeSinceStart : 0.3298768997192383\n",
            "Training Loss : -0.06009094789624214\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 1 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([52])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 10.390243530273438\n",
            "Eval_StdReturn : 8.023982048034668\n",
            "Eval_MaxReturn : 34.0\n",
            "Eval_MinReturn : 3.0\n",
            "Eval_AverageEpLen : 10.390243902439025\n",
            "Train_AverageReturn : 13.0\n",
            "Train_StdReturn : 5.0\n",
            "Train_MaxReturn : 18.0\n",
            "Train_MinReturn : 8.0\n",
            "Train_AverageEpLen : 13.0\n",
            "Train_EnvstepsSoFar : 104\n",
            "TimeSinceStart : 0.6552889347076416\n",
            "Training Loss : -0.04347970709204674\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 2 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([53])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 10.100000381469727\n",
            "Eval_StdReturn : 4.742362022399902\n",
            "Eval_MaxReturn : 23.0\n",
            "Eval_MinReturn : 4.0\n",
            "Eval_AverageEpLen : 10.1\n",
            "Train_AverageReturn : 9.5\n",
            "Train_StdReturn : 6.601767539978027\n",
            "Train_MaxReturn : 21.0\n",
            "Train_MinReturn : 4.0\n",
            "Train_AverageEpLen : 9.5\n",
            "Train_EnvstepsSoFar : 161\n",
            "TimeSinceStart : 0.9611022472381592\n",
            "Training Loss : -0.002813042374327779\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 3 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([55])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 8.583333015441895\n",
            "Eval_StdReturn : 6.126558780670166\n",
            "Eval_MaxReturn : 34.0\n",
            "Eval_MinReturn : 2.0\n",
            "Eval_AverageEpLen : 8.583333333333334\n",
            "Train_AverageReturn : 11.0\n",
            "Train_StdReturn : 6.033241271972656\n",
            "Train_MaxReturn : 21.0\n",
            "Train_MinReturn : 5.0\n",
            "Train_AverageEpLen : 11.0\n",
            "Train_EnvstepsSoFar : 216\n",
            "TimeSinceStart : 1.317823886871338\n",
            "Training Loss : -0.13385580480098724\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 4 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([51])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 17.125\n",
            "Eval_StdReturn : 11.748448371887207\n",
            "Eval_MaxReturn : 47.0\n",
            "Eval_MinReturn : 3.0\n",
            "Eval_AverageEpLen : 17.125\n",
            "Train_AverageReturn : 10.199999809265137\n",
            "Train_StdReturn : 5.670978546142578\n",
            "Train_MaxReturn : 18.0\n",
            "Train_MinReturn : 4.0\n",
            "Train_AverageEpLen : 10.2\n",
            "Train_EnvstepsSoFar : 267\n",
            "TimeSinceStart : 1.6468393802642822\n",
            "Training Loss : -0.035585153847932816\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 5 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([52])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 9.136363983154297\n",
            "Eval_StdReturn : 7.069753170013428\n",
            "Eval_MaxReturn : 36.0\n",
            "Eval_MinReturn : 2.0\n",
            "Eval_AverageEpLen : 9.136363636363637\n",
            "Train_AverageReturn : 13.0\n",
            "Train_StdReturn : 5.612485885620117\n",
            "Train_MaxReturn : 20.0\n",
            "Train_MinReturn : 7.0\n",
            "Train_AverageEpLen : 13.0\n",
            "Train_EnvstepsSoFar : 319\n",
            "TimeSinceStart : 1.9377353191375732\n",
            "Training Loss : 0.019181912764906883\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 6 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([53])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 3.3553719520568848\n",
            "Eval_StdReturn : 2.7719359397888184\n",
            "Eval_MaxReturn : 17.0\n",
            "Eval_MinReturn : 2.0\n",
            "Eval_AverageEpLen : 3.355371900826446\n",
            "Train_AverageReturn : 13.25\n",
            "Train_StdReturn : 15.105875968933105\n",
            "Train_MaxReturn : 39.0\n",
            "Train_MinReturn : 2.0\n",
            "Train_AverageEpLen : 13.25\n",
            "Train_EnvstepsSoFar : 372\n",
            "TimeSinceStart : 2.247695207595825\n",
            "Training Loss : -0.2750203609466553\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 7 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 5.037036895751953\n",
            "Eval_StdReturn : 4.97262716293335\n",
            "Eval_MaxReturn : 25.0\n",
            "Eval_MinReturn : 2.0\n",
            "Eval_AverageEpLen : 5.037037037037037\n",
            "Train_AverageReturn : 2.5999999046325684\n",
            "Train_StdReturn : 0.5830951929092407\n",
            "Train_MaxReturn : 4.0\n",
            "Train_MinReturn : 2.0\n",
            "Train_AverageEpLen : 2.6\n",
            "Train_EnvstepsSoFar : 424\n",
            "TimeSinceStart : 2.557612895965576\n",
            "Training Loss : 5.015134593122639e-05\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 8 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([52])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 9.340909004211426\n",
            "Eval_StdReturn : 6.090018272399902\n",
            "Eval_MaxReturn : 26.0\n",
            "Eval_MinReturn : 3.0\n",
            "Eval_AverageEpLen : 9.340909090909092\n",
            "Train_AverageReturn : 5.699999809265137\n",
            "Train_StdReturn : 6.245798587799072\n",
            "Train_MaxReturn : 22.0\n",
            "Train_MinReturn : 2.0\n",
            "Train_AverageEpLen : 5.7\n",
            "Train_EnvstepsSoFar : 481\n",
            "TimeSinceStart : 2.854569673538208\n",
            "Training Loss : 0.07969273626804352\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 9 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([53])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 14.75\n",
            "Eval_StdReturn : 8.403337478637695\n",
            "Eval_MaxReturn : 31.0\n",
            "Eval_MinReturn : 3.0\n",
            "Eval_AverageEpLen : 14.75\n",
            "Train_AverageReturn : 11.5\n",
            "Train_StdReturn : 6.626965045928955\n",
            "Train_MaxReturn : 24.0\n",
            "Train_MinReturn : 4.0\n",
            "Train_AverageEpLen : 11.5\n",
            "Train_EnvstepsSoFar : 550\n",
            "TimeSinceStart : 3.1673262119293213\n",
            "Training Loss : -0.12488385289907455\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 10 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([62])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 14.785714149475098\n",
            "Eval_StdReturn : 6.613606929779053\n",
            "Eval_MaxReturn : 40.0\n",
            "Eval_MinReturn : 5.0\n",
            "Eval_AverageEpLen : 14.785714285714286\n",
            "Train_AverageReturn : 23.5\n",
            "Train_StdReturn : 14.924811363220215\n",
            "Train_MaxReturn : 49.0\n",
            "Train_MinReturn : 13.0\n",
            "Train_AverageEpLen : 23.5\n",
            "Train_EnvstepsSoFar : 644\n",
            "TimeSinceStart : 3.4957058429718018\n",
            "Training Loss : -0.09116343408823013\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 11 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([54])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 16.68000030517578\n",
            "Eval_StdReturn : 8.960892677307129\n",
            "Eval_MaxReturn : 42.0\n",
            "Eval_MinReturn : 6.0\n",
            "Eval_AverageEpLen : 16.68\n",
            "Train_AverageReturn : 19.25\n",
            "Train_StdReturn : 8.317902565002441\n",
            "Train_MaxReturn : 31.0\n",
            "Train_MinReturn : 10.0\n",
            "Train_AverageEpLen : 19.25\n",
            "Train_EnvstepsSoFar : 721\n",
            "TimeSinceStart : 3.8014848232269287\n",
            "Training Loss : -0.09477871656417847\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 12 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([52])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 17.478260040283203\n",
            "Eval_StdReturn : 7.790013313293457\n",
            "Eval_MaxReturn : 30.0\n",
            "Eval_MinReturn : 6.0\n",
            "Eval_AverageEpLen : 17.47826086956522\n",
            "Train_AverageReturn : 10.399999618530273\n",
            "Train_StdReturn : 3.6110939979553223\n",
            "Train_MaxReturn : 16.0\n",
            "Train_MinReturn : 6.0\n",
            "Train_AverageEpLen : 10.4\n",
            "Train_EnvstepsSoFar : 773\n",
            "TimeSinceStart : 4.088220596313477\n",
            "Training Loss : 0.08084477484226227\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 13 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([51])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 3.174603223800659\n",
            "Eval_StdReturn : 0.4193602204322815\n",
            "Eval_MaxReturn : 4.0\n",
            "Eval_MinReturn : 2.0\n",
            "Eval_AverageEpLen : 3.1746031746031744\n",
            "Train_AverageReturn : 17.0\n",
            "Train_StdReturn : 2.943920373916626\n",
            "Train_MaxReturn : 20.0\n",
            "Train_MinReturn : 13.0\n",
            "Train_AverageEpLen : 17.0\n",
            "Train_EnvstepsSoFar : 824\n",
            "TimeSinceStart : 4.445176362991333\n",
            "Training Loss : 0.06220600754022598\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 14 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 2.8439717292785645\n",
            "Eval_StdReturn : 0.4000653624534607\n",
            "Eval_MaxReturn : 4.0\n",
            "Eval_MinReturn : 2.0\n",
            "Eval_AverageEpLen : 2.8439716312056738\n",
            "Train_AverageReturn : 3.125\n",
            "Train_StdReturn : 0.4841229319572449\n",
            "Train_MaxReturn : 4.0\n",
            "Train_MinReturn : 2.0\n",
            "Train_AverageEpLen : 3.125\n",
            "Train_EnvstepsSoFar : 874\n",
            "TimeSinceStart : 4.78552770614624\n",
            "Training Loss : 0.03983229398727417\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 15 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([51])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 2.5806450843811035\n",
            "Eval_StdReturn : 0.4934535026550293\n",
            "Eval_MaxReturn : 3.0\n",
            "Eval_MinReturn : 2.0\n",
            "Eval_AverageEpLen : 2.5806451612903225\n",
            "Train_AverageReturn : 2.8333332538604736\n",
            "Train_StdReturn : 0.3726780116558075\n",
            "Train_MaxReturn : 3.0\n",
            "Train_MinReturn : 2.0\n",
            "Train_AverageEpLen : 2.8333333333333335\n",
            "Train_EnvstepsSoFar : 925\n",
            "TimeSinceStart : 5.115415096282959\n",
            "Training Loss : -0.06456536054611206\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 16 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([51])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 2.992537260055542\n",
            "Eval_StdReturn : 0.08606389909982681\n",
            "Eval_MaxReturn : 3.0\n",
            "Eval_MinReturn : 2.0\n",
            "Eval_AverageEpLen : 2.9925373134328357\n",
            "Train_AverageReturn : 2.6842105388641357\n",
            "Train_StdReturn : 0.4648295044898987\n",
            "Train_MaxReturn : 3.0\n",
            "Train_MinReturn : 2.0\n",
            "Train_AverageEpLen : 2.6842105263157894\n",
            "Train_EnvstepsSoFar : 976\n",
            "TimeSinceStart : 5.429979562759399\n",
            "Training Loss : -0.022633101791143417\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 17 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([51])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 3.9509804248809814\n",
            "Eval_StdReturn : 0.38033658266067505\n",
            "Eval_MaxReturn : 5.0\n",
            "Eval_MinReturn : 3.0\n",
            "Eval_AverageEpLen : 3.950980392156863\n",
            "Train_AverageReturn : 3.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 3.0\n",
            "Train_MinReturn : 3.0\n",
            "Train_AverageEpLen : 3.0\n",
            "Train_EnvstepsSoFar : 1027\n",
            "TimeSinceStart : 5.747359752655029\n",
            "Training Loss : -0.1984463334083557\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 18 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 5.7971014976501465\n",
            "Eval_StdReturn : 1.357530951499939\n",
            "Eval_MaxReturn : 12.0\n",
            "Eval_MinReturn : 4.0\n",
            "Eval_AverageEpLen : 5.797101449275362\n",
            "Train_AverageReturn : 3.846153736114502\n",
            "Train_StdReturn : 0.36080119013786316\n",
            "Train_MaxReturn : 4.0\n",
            "Train_MinReturn : 3.0\n",
            "Train_AverageEpLen : 3.8461538461538463\n",
            "Train_EnvstepsSoFar : 1077\n",
            "TimeSinceStart : 6.0575478076934814\n",
            "Training Loss : 0.060951754450798035\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 19 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 4.395604610443115\n",
            "Eval_StdReturn : 0.7394551038742065\n",
            "Eval_MaxReturn : 7.0\n",
            "Eval_MinReturn : 3.0\n",
            "Eval_AverageEpLen : 4.395604395604396\n",
            "Train_AverageReturn : 5.5\n",
            "Train_StdReturn : 1.8027756214141846\n",
            "Train_MaxReturn : 9.0\n",
            "Train_MinReturn : 3.0\n",
            "Train_AverageEpLen : 5.5\n",
            "Train_EnvstepsSoFar : 1132\n",
            "TimeSinceStart : 6.389084815979004\n",
            "Training Loss : -0.011855611577630043\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 20 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([51])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 4.15463924407959\n",
            "Eval_StdReturn : 0.7084208130836487\n",
            "Eval_MaxReturn : 6.0\n",
            "Eval_MinReturn : 3.0\n",
            "Eval_AverageEpLen : 4.154639175257732\n",
            "Train_AverageReturn : 4.25\n",
            "Train_StdReturn : 0.4330126941204071\n",
            "Train_MaxReturn : 5.0\n",
            "Train_MinReturn : 4.0\n",
            "Train_AverageEpLen : 4.25\n",
            "Train_EnvstepsSoFar : 1183\n",
            "TimeSinceStart : 6.748138666152954\n",
            "Training Loss : -0.109002023935318\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 21 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([52])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 4.210526466369629\n",
            "Eval_StdReturn : 0.596388041973114\n",
            "Eval_MaxReturn : 6.0\n",
            "Eval_MinReturn : 3.0\n",
            "Eval_AverageEpLen : 4.2105263157894735\n",
            "Train_AverageReturn : 3.7142856121063232\n",
            "Train_StdReturn : 0.5890150666236877\n",
            "Train_MaxReturn : 5.0\n",
            "Train_MinReturn : 3.0\n",
            "Train_AverageEpLen : 3.7142857142857144\n",
            "Train_EnvstepsSoFar : 1235\n",
            "TimeSinceStart : 7.075277328491211\n",
            "Training Loss : -0.09985355287790298\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 22 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 6.896551609039307\n",
            "Eval_StdReturn : 1.9448398351669312\n",
            "Eval_MaxReturn : 13.0\n",
            "Eval_MinReturn : 4.0\n",
            "Eval_AverageEpLen : 6.896551724137931\n",
            "Train_AverageReturn : 4.545454502105713\n",
            "Train_StdReturn : 0.8907235264778137\n",
            "Train_MaxReturn : 6.0\n",
            "Train_MinReturn : 3.0\n",
            "Train_AverageEpLen : 4.545454545454546\n",
            "Train_EnvstepsSoFar : 1285\n",
            "TimeSinceStart : 7.414769172668457\n",
            "Training Loss : 0.07736167311668396\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 23 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([54])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 13.258064270019531\n",
            "Eval_StdReturn : 2.7234675884246826\n",
            "Eval_MaxReturn : 25.0\n",
            "Eval_MinReturn : 9.0\n",
            "Eval_AverageEpLen : 13.258064516129032\n",
            "Train_AverageReturn : 6.0\n",
            "Train_StdReturn : 0.9428090453147888\n",
            "Train_MaxReturn : 8.0\n",
            "Train_MinReturn : 5.0\n",
            "Train_AverageEpLen : 6.0\n",
            "Train_EnvstepsSoFar : 1339\n",
            "TimeSinceStart : 7.750443935394287\n",
            "Training Loss : -0.04155449941754341\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 24 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([59])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 20.100000381469727\n",
            "Eval_StdReturn : 6.1717095375061035\n",
            "Eval_MaxReturn : 42.0\n",
            "Eval_MinReturn : 13.0\n",
            "Eval_AverageEpLen : 20.1\n",
            "Train_AverageReturn : 14.75\n",
            "Train_StdReturn : 1.9202864170074463\n",
            "Train_MaxReturn : 17.0\n",
            "Train_MinReturn : 12.0\n",
            "Train_AverageEpLen : 14.75\n",
            "Train_EnvstepsSoFar : 1398\n",
            "TimeSinceStart : 8.064208745956421\n",
            "Training Loss : 0.03780269995331764\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 25 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 25.625\n",
            "Eval_StdReturn : 11.95760726928711\n",
            "Eval_MaxReturn : 60.0\n",
            "Eval_MinReturn : 13.0\n",
            "Eval_AverageEpLen : 25.625\n",
            "Train_AverageReturn : 16.66666603088379\n",
            "Train_StdReturn : 0.471404492855072\n",
            "Train_MaxReturn : 17.0\n",
            "Train_MinReturn : 16.0\n",
            "Train_AverageEpLen : 16.666666666666668\n",
            "Train_EnvstepsSoFar : 1448\n",
            "TimeSinceStart : 8.342179775238037\n",
            "Training Loss : -0.029339956119656563\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 26 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([55])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 13.862069129943848\n",
            "Eval_StdReturn : 2.096370220184326\n",
            "Eval_MaxReturn : 18.0\n",
            "Eval_MinReturn : 9.0\n",
            "Eval_AverageEpLen : 13.862068965517242\n",
            "Train_AverageReturn : 23.66666603088379\n",
            "Train_StdReturn : 5.557777404785156\n",
            "Train_MaxReturn : 29.0\n",
            "Train_MinReturn : 16.0\n",
            "Train_AverageEpLen : 23.666666666666668\n",
            "Train_EnvstepsSoFar : 1519\n",
            "TimeSinceStart : 8.631020545959473\n",
            "Training Loss : -0.19513800740242004\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 27 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([58])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 7.2727274894714355\n",
            "Eval_StdReturn : 1.2277776002883911\n",
            "Eval_MaxReturn : 13.0\n",
            "Eval_MinReturn : 5.0\n",
            "Eval_AverageEpLen : 7.2727272727272725\n",
            "Train_AverageReturn : 14.5\n",
            "Train_StdReturn : 1.5\n",
            "Train_MaxReturn : 16.0\n",
            "Train_MinReturn : 13.0\n",
            "Train_AverageEpLen : 14.5\n",
            "Train_EnvstepsSoFar : 1577\n",
            "TimeSinceStart : 8.929505586624146\n",
            "Training Loss : -0.013529605232179165\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 28 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 4.809523582458496\n",
            "Eval_StdReturn : 0.5870870351791382\n",
            "Eval_MaxReturn : 6.0\n",
            "Eval_MinReturn : 4.0\n",
            "Eval_AverageEpLen : 4.809523809523809\n",
            "Train_AverageReturn : 7.142857074737549\n",
            "Train_StdReturn : 1.2453995943069458\n",
            "Train_MaxReturn : 9.0\n",
            "Train_MinReturn : 6.0\n",
            "Train_AverageEpLen : 7.142857142857143\n",
            "Train_EnvstepsSoFar : 1627\n",
            "TimeSinceStart : 9.224731922149658\n",
            "Training Loss : 0.08876463770866394\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 29 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([53])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 5.050000190734863\n",
            "Eval_StdReturn : 0.7053368091583252\n",
            "Eval_MaxReturn : 8.0\n",
            "Eval_MinReturn : 4.0\n",
            "Eval_AverageEpLen : 5.05\n",
            "Train_AverageReturn : 4.818181991577148\n",
            "Train_StdReturn : 0.38569462299346924\n",
            "Train_MaxReturn : 5.0\n",
            "Train_MinReturn : 4.0\n",
            "Train_AverageEpLen : 4.818181818181818\n",
            "Train_EnvstepsSoFar : 1680\n",
            "TimeSinceStart : 9.522270441055298\n",
            "Training Loss : -0.07156127691268921\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 30 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([51])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 6.4285712242126465\n",
            "Eval_StdReturn : 0.9547589421272278\n",
            "Eval_MaxReturn : 9.0\n",
            "Eval_MinReturn : 5.0\n",
            "Eval_AverageEpLen : 6.428571428571429\n",
            "Train_AverageReturn : 4.636363506317139\n",
            "Train_StdReturn : 0.4810456931591034\n",
            "Train_MaxReturn : 5.0\n",
            "Train_MinReturn : 4.0\n",
            "Train_AverageEpLen : 4.636363636363637\n",
            "Train_EnvstepsSoFar : 1731\n",
            "TimeSinceStart : 9.815699100494385\n",
            "Training Loss : -0.11543306708335876\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 31 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 11.45714282989502\n",
            "Eval_StdReturn : 2.195357084274292\n",
            "Eval_MaxReturn : 22.0\n",
            "Eval_MinReturn : 9.0\n",
            "Eval_AverageEpLen : 11.457142857142857\n",
            "Train_AverageReturn : 6.25\n",
            "Train_StdReturn : 0.9682458639144897\n",
            "Train_MaxReturn : 8.0\n",
            "Train_MinReturn : 5.0\n",
            "Train_AverageEpLen : 6.25\n",
            "Train_EnvstepsSoFar : 1781\n",
            "TimeSinceStart : 10.096364259719849\n",
            "Training Loss : -0.02474258281290531\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 32 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([55])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 24.352941513061523\n",
            "Eval_StdReturn : 5.656242370605469\n",
            "Eval_MaxReturn : 36.0\n",
            "Eval_MinReturn : 17.0\n",
            "Eval_AverageEpLen : 24.352941176470587\n",
            "Train_AverageReturn : 11.0\n",
            "Train_StdReturn : 1.6733200550079346\n",
            "Train_MaxReturn : 14.0\n",
            "Train_MinReturn : 9.0\n",
            "Train_AverageEpLen : 11.0\n",
            "Train_EnvstepsSoFar : 1836\n",
            "TimeSinceStart : 10.370336771011353\n",
            "Training Loss : -0.0901663526892662\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 33 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([53])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 12.029411315917969\n",
            "Eval_StdReturn : 1.8388822078704834\n",
            "Eval_MaxReturn : 15.0\n",
            "Eval_MinReturn : 8.0\n",
            "Eval_AverageEpLen : 12.029411764705882\n",
            "Train_AverageReturn : 25.0\n",
            "Train_StdReturn : 2.1602468490600586\n",
            "Train_MaxReturn : 27.0\n",
            "Train_MinReturn : 22.0\n",
            "Train_AverageEpLen : 25.0\n",
            "Train_EnvstepsSoFar : 1911\n",
            "TimeSinceStart : 10.673068046569824\n",
            "Training Loss : 0.07549106329679489\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 34 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([61])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 3.0378787517547607\n",
            "Eval_StdReturn : 0.19090308248996735\n",
            "Eval_MaxReturn : 4.0\n",
            "Eval_MinReturn : 3.0\n",
            "Eval_AverageEpLen : 3.037878787878788\n",
            "Train_AverageReturn : 12.199999809265137\n",
            "Train_StdReturn : 0.3999999761581421\n",
            "Train_MaxReturn : 13.0\n",
            "Train_MinReturn : 12.0\n",
            "Train_AverageEpLen : 12.2\n",
            "Train_EnvstepsSoFar : 1972\n",
            "TimeSinceStart : 11.000145435333252\n",
            "Training Loss : -0.0440099760890007\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 35 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([51])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 2.6733334064483643\n",
            "Eval_StdReturn : 0.4689942002296448\n",
            "Eval_MaxReturn : 3.0\n",
            "Eval_MinReturn : 2.0\n",
            "Eval_AverageEpLen : 2.6733333333333333\n",
            "Train_AverageReturn : 3.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 3.0\n",
            "Train_MinReturn : 3.0\n",
            "Train_AverageEpLen : 3.0\n",
            "Train_EnvstepsSoFar : 2023\n",
            "TimeSinceStart : 11.357982158660889\n",
            "Training Loss : -0.06591562181711197\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 36 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 2.9270071983337402\n",
            "Eval_StdReturn : 0.2601245045661926\n",
            "Eval_MaxReturn : 3.0\n",
            "Eval_MinReturn : 2.0\n",
            "Eval_AverageEpLen : 2.927007299270073\n",
            "Train_AverageReturn : 2.777777671813965\n",
            "Train_StdReturn : 0.41573968529701233\n",
            "Train_MaxReturn : 3.0\n",
            "Train_MinReturn : 2.0\n",
            "Train_AverageEpLen : 2.7777777777777777\n",
            "Train_EnvstepsSoFar : 2073\n",
            "TimeSinceStart : 11.748416662216187\n",
            "Training Loss : 0.05733944848179817\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 37 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([52])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 4.060606002807617\n",
            "Eval_StdReturn : 0.44536176323890686\n",
            "Eval_MaxReturn : 5.0\n",
            "Eval_MinReturn : 3.0\n",
            "Eval_AverageEpLen : 4.0606060606060606\n",
            "Train_AverageReturn : 2.8888888359069824\n",
            "Train_StdReturn : 0.31426966190338135\n",
            "Train_MaxReturn : 3.0\n",
            "Train_MinReturn : 2.0\n",
            "Train_AverageEpLen : 2.888888888888889\n",
            "Train_EnvstepsSoFar : 2125\n",
            "TimeSinceStart : 12.10165524482727\n",
            "Training Loss : -0.16367697715759277\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 38 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 7.3818182945251465\n",
            "Eval_StdReturn : 0.9437046647071838\n",
            "Eval_MaxReturn : 9.0\n",
            "Eval_MinReturn : 6.0\n",
            "Eval_AverageEpLen : 7.381818181818182\n",
            "Train_AverageReturn : 3.857142925262451\n",
            "Train_StdReturn : 0.6388765573501587\n",
            "Train_MaxReturn : 5.0\n",
            "Train_MinReturn : 3.0\n",
            "Train_AverageEpLen : 3.857142857142857\n",
            "Train_EnvstepsSoFar : 2179\n",
            "TimeSinceStart : 12.399380207061768\n",
            "Training Loss : -0.013148033060133457\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 39 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([55])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 6.779661178588867\n",
            "Eval_StdReturn : 1.4505146741867065\n",
            "Eval_MaxReturn : 13.0\n",
            "Eval_MinReturn : 5.0\n",
            "Eval_AverageEpLen : 6.779661016949152\n",
            "Train_AverageReturn : 7.857142925262451\n",
            "Train_StdReturn : 1.1248582601547241\n",
            "Train_MaxReturn : 10.0\n",
            "Train_MinReturn : 6.0\n",
            "Train_AverageEpLen : 7.857142857142857\n",
            "Train_EnvstepsSoFar : 2234\n",
            "TimeSinceStart : 12.691108465194702\n",
            "Training Loss : -0.02121717855334282\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 40 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 4.4175825119018555\n",
            "Eval_StdReturn : 0.5560048818588257\n",
            "Eval_MaxReturn : 6.0\n",
            "Eval_MinReturn : 4.0\n",
            "Eval_AverageEpLen : 4.417582417582418\n",
            "Train_AverageReturn : 7.142857074737549\n",
            "Train_StdReturn : 1.7261494398117065\n",
            "Train_MaxReturn : 10.0\n",
            "Train_MinReturn : 5.0\n",
            "Train_AverageEpLen : 7.142857142857143\n",
            "Train_EnvstepsSoFar : 2284\n",
            "TimeSinceStart : 13.01867389678955\n",
            "Training Loss : 0.07323776930570602\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 41 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([53])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 21.649999618530273\n",
            "Eval_StdReturn : 6.8649468421936035\n",
            "Eval_MaxReturn : 37.0\n",
            "Eval_MinReturn : 13.0\n",
            "Eval_AverageEpLen : 21.65\n",
            "Train_AverageReturn : 4.818181991577148\n",
            "Train_StdReturn : 0.5749595761299133\n",
            "Train_MaxReturn : 6.0\n",
            "Train_MinReturn : 4.0\n",
            "Train_AverageEpLen : 4.818181818181818\n",
            "Train_EnvstepsSoFar : 2337\n",
            "TimeSinceStart : 13.321252822875977\n",
            "Training Loss : 0.06747105717658997\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 42 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([59])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 19.5238094329834\n",
            "Eval_StdReturn : 6.441081523895264\n",
            "Eval_MaxReturn : 40.0\n",
            "Eval_MinReturn : 10.0\n",
            "Eval_AverageEpLen : 19.523809523809526\n",
            "Train_AverageReturn : 19.66666603088379\n",
            "Train_StdReturn : 8.055363655090332\n",
            "Train_MaxReturn : 31.0\n",
            "Train_MinReturn : 13.0\n",
            "Train_AverageEpLen : 19.666666666666668\n",
            "Train_EnvstepsSoFar : 2396\n",
            "TimeSinceStart : 13.612717151641846\n",
            "Training Loss : -0.05556398630142212\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 43 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([65])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 16.15999984741211\n",
            "Eval_StdReturn : 3.0289273262023926\n",
            "Eval_MaxReturn : 21.0\n",
            "Eval_MinReturn : 11.0\n",
            "Eval_AverageEpLen : 16.16\n",
            "Train_AverageReturn : 21.66666603088379\n",
            "Train_StdReturn : 9.392668724060059\n",
            "Train_MaxReturn : 33.0\n",
            "Train_MinReturn : 10.0\n",
            "Train_AverageEpLen : 21.666666666666668\n",
            "Train_EnvstepsSoFar : 2461\n",
            "TimeSinceStart : 13.909387826919556\n",
            "Training Loss : 0.04536857455968857\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 44 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([59])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 32.46154022216797\n",
            "Eval_StdReturn : 7.238947868347168\n",
            "Eval_MaxReturn : 44.0\n",
            "Eval_MinReturn : 17.0\n",
            "Eval_AverageEpLen : 32.46153846153846\n",
            "Train_AverageReturn : 14.75\n",
            "Train_StdReturn : 2.2776083946228027\n",
            "Train_MaxReturn : 17.0\n",
            "Train_MinReturn : 12.0\n",
            "Train_AverageEpLen : 14.75\n",
            "Train_EnvstepsSoFar : 2520\n",
            "TimeSinceStart : 14.227742433547974\n",
            "Training Loss : -0.13129302859306335\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 45 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([55])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 33.33333206176758\n",
            "Eval_StdReturn : 7.180219650268555\n",
            "Eval_MaxReturn : 47.0\n",
            "Eval_MinReturn : 20.0\n",
            "Eval_AverageEpLen : 33.333333333333336\n",
            "Train_AverageReturn : 27.5\n",
            "Train_StdReturn : 4.5\n",
            "Train_MaxReturn : 32.0\n",
            "Train_MinReturn : 23.0\n",
            "Train_AverageEpLen : 27.5\n",
            "Train_EnvstepsSoFar : 2575\n",
            "TimeSinceStart : 14.512275695800781\n",
            "Training Loss : 0.11966696381568909\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 46 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([73])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 25.6875\n",
            "Eval_StdReturn : 8.213698387145996\n",
            "Eval_MaxReturn : 49.0\n",
            "Eval_MinReturn : 13.0\n",
            "Eval_AverageEpLen : 25.6875\n",
            "Train_AverageReturn : 36.5\n",
            "Train_StdReturn : 7.5\n",
            "Train_MaxReturn : 44.0\n",
            "Train_MinReturn : 29.0\n",
            "Train_AverageEpLen : 36.5\n",
            "Train_EnvstepsSoFar : 2648\n",
            "TimeSinceStart : 14.82079792022705\n",
            "Training Loss : -0.02128412202000618\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 47 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 16.70833396911621\n",
            "Eval_StdReturn : 10.195910453796387\n",
            "Eval_MaxReturn : 57.0\n",
            "Eval_MinReturn : 7.0\n",
            "Eval_AverageEpLen : 16.708333333333332\n",
            "Train_AverageReturn : 21.0\n",
            "Train_StdReturn : 6.531972885131836\n",
            "Train_MaxReturn : 29.0\n",
            "Train_MinReturn : 13.0\n",
            "Train_AverageEpLen : 21.0\n",
            "Train_EnvstepsSoFar : 2711\n",
            "TimeSinceStart : 15.119964838027954\n",
            "Training Loss : -0.15632735192775726\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 48 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([56])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 10.891891479492188\n",
            "Eval_StdReturn : 3.9027626514434814\n",
            "Eval_MaxReturn : 23.0\n",
            "Eval_MinReturn : 6.0\n",
            "Eval_AverageEpLen : 10.891891891891891\n",
            "Train_AverageReturn : 15.600000381469727\n",
            "Train_StdReturn : 7.391887187957764\n",
            "Train_MaxReturn : 29.0\n",
            "Train_MinReturn : 8.0\n",
            "Train_AverageEpLen : 15.6\n",
            "Train_EnvstepsSoFar : 2789\n",
            "TimeSinceStart : 15.490819692611694\n",
            "Training Loss : 0.014401117339730263\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 49 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([56])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 7.711538314819336\n",
            "Eval_StdReturn : 2.8778767585754395\n",
            "Eval_MaxReturn : 18.0\n",
            "Eval_MinReturn : 4.0\n",
            "Eval_AverageEpLen : 7.711538461538462\n",
            "Train_AverageReturn : 11.199999809265137\n",
            "Train_StdReturn : 3.7094473838806152\n",
            "Train_MaxReturn : 16.0\n",
            "Train_MinReturn : 6.0\n",
            "Train_AverageEpLen : 11.2\n",
            "Train_EnvstepsSoFar : 2845\n",
            "TimeSinceStart : 15.857430219650269\n",
            "Training Loss : -0.22855722904205322\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 50 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 9.780488014221191\n",
            "Eval_StdReturn : 0.7812496423721313\n",
            "Eval_MaxReturn : 12.0\n",
            "Eval_MinReturn : 9.0\n",
            "Eval_AverageEpLen : 9.78048780487805\n",
            "Train_AverageReturn : 9.666666984558105\n",
            "Train_StdReturn : 1.885617971420288\n",
            "Train_MaxReturn : 12.0\n",
            "Train_MinReturn : 7.0\n",
            "Train_AverageEpLen : 9.666666666666666\n",
            "Train_EnvstepsSoFar : 2903\n",
            "TimeSinceStart : 16.200995683670044\n",
            "Training Loss : -0.15808449685573578\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 51 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 2.992537260055542\n",
            "Eval_StdReturn : 0.08606389909982681\n",
            "Eval_MaxReturn : 3.0\n",
            "Eval_MinReturn : 2.0\n",
            "Eval_AverageEpLen : 2.9925373134328357\n",
            "Train_AverageReturn : 10.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 10.0\n",
            "Train_MinReturn : 10.0\n",
            "Train_AverageEpLen : 10.0\n",
            "Train_EnvstepsSoFar : 2953\n",
            "TimeSinceStart : 16.527401208877563\n",
            "Training Loss : -0.04986915364861488\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 52 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([51])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 2.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 2.0\n",
            "Eval_MinReturn : 2.0\n",
            "Eval_AverageEpLen : 2.0\n",
            "Train_AverageReturn : 3.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 3.0\n",
            "Train_MinReturn : 3.0\n",
            "Train_AverageEpLen : 3.0\n",
            "Train_EnvstepsSoFar : 3004\n",
            "TimeSinceStart : 16.894256353378296\n",
            "Training Loss : -0.020059464499354362\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 53 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 2.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 2.0\n",
            "Eval_MinReturn : 2.0\n",
            "Eval_AverageEpLen : 2.0\n",
            "Train_AverageReturn : 2.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 2.0\n",
            "Train_MinReturn : 2.0\n",
            "Train_AverageEpLen : 2.0\n",
            "Train_EnvstepsSoFar : 3054\n",
            "TimeSinceStart : 17.230390071868896\n",
            "Training Loss : -0.0914243683218956\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 54 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 2.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 2.0\n",
            "Eval_MinReturn : 2.0\n",
            "Eval_AverageEpLen : 2.0\n",
            "Train_AverageReturn : 2.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 2.0\n",
            "Train_MinReturn : 2.0\n",
            "Train_AverageEpLen : 2.0\n",
            "Train_EnvstepsSoFar : 3104\n",
            "TimeSinceStart : 17.578919649124146\n",
            "Training Loss : -0.016400586813688278\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 55 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 2.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 2.0\n",
            "Eval_MinReturn : 2.0\n",
            "Eval_AverageEpLen : 2.0\n",
            "Train_AverageReturn : 2.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 2.0\n",
            "Train_MinReturn : 2.0\n",
            "Train_AverageEpLen : 2.0\n",
            "Train_EnvstepsSoFar : 3154\n",
            "TimeSinceStart : 17.91107439994812\n",
            "Training Loss : 0.13060262799263\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 56 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 2.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 2.0\n",
            "Eval_MinReturn : 2.0\n",
            "Eval_AverageEpLen : 2.0\n",
            "Train_AverageReturn : 2.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 2.0\n",
            "Train_MinReturn : 2.0\n",
            "Train_AverageEpLen : 2.0\n",
            "Train_EnvstepsSoFar : 3204\n",
            "TimeSinceStart : 18.285795211791992\n",
            "Training Loss : 0.05316523090004921\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 57 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1.659751057624817\n",
            "Eval_StdReturn : 0.47379282116889954\n",
            "Eval_MaxReturn : 2.0\n",
            "Eval_MinReturn : 1.0\n",
            "Eval_AverageEpLen : 1.6597510373443984\n",
            "Train_AverageReturn : 2.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 2.0\n",
            "Train_MinReturn : 2.0\n",
            "Train_AverageEpLen : 2.0\n",
            "Train_EnvstepsSoFar : 3254\n",
            "TimeSinceStart : 18.69928550720215\n",
            "Training Loss : 0.03564636781811714\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 58 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([51])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1.9950249195098877\n",
            "Eval_StdReturn : 0.07035887241363525\n",
            "Eval_MaxReturn : 2.0\n",
            "Eval_MinReturn : 1.0\n",
            "Eval_AverageEpLen : 1.9950248756218905\n",
            "Train_AverageReturn : 1.8214285373687744\n",
            "Train_StdReturn : 0.38299301266670227\n",
            "Train_MaxReturn : 2.0\n",
            "Train_MinReturn : 1.0\n",
            "Train_AverageEpLen : 1.8214285714285714\n",
            "Train_EnvstepsSoFar : 3305\n",
            "TimeSinceStart : 19.086647748947144\n",
            "Training Loss : -0.1931995153427124\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 59 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 2.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 2.0\n",
            "Eval_MinReturn : 2.0\n",
            "Eval_AverageEpLen : 2.0\n",
            "Train_AverageReturn : 2.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 2.0\n",
            "Train_MinReturn : 2.0\n",
            "Train_AverageEpLen : 2.0\n",
            "Train_EnvstepsSoFar : 3355\n",
            "TimeSinceStart : 19.488300323486328\n",
            "Training Loss : -0.117159403860569\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 60 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 2.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 2.0\n",
            "Eval_MinReturn : 2.0\n",
            "Eval_AverageEpLen : 2.0\n",
            "Train_AverageReturn : 2.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 2.0\n",
            "Train_MinReturn : 2.0\n",
            "Train_AverageEpLen : 2.0\n",
            "Train_EnvstepsSoFar : 3405\n",
            "TimeSinceStart : 19.905843019485474\n",
            "Training Loss : 0.07171630859375\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 61 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 2.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 2.0\n",
            "Eval_MinReturn : 2.0\n",
            "Eval_AverageEpLen : 2.0\n",
            "Train_AverageReturn : 2.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 2.0\n",
            "Train_MinReturn : 2.0\n",
            "Train_AverageEpLen : 2.0\n",
            "Train_EnvstepsSoFar : 3455\n",
            "TimeSinceStart : 20.300453901290894\n",
            "Training Loss : -0.034790463745594025\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 62 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 2.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 2.0\n",
            "Eval_MinReturn : 2.0\n",
            "Eval_AverageEpLen : 2.0\n",
            "Train_AverageReturn : 2.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 2.0\n",
            "Train_MinReturn : 2.0\n",
            "Train_AverageEpLen : 2.0\n",
            "Train_EnvstepsSoFar : 3505\n",
            "TimeSinceStart : 20.681077241897583\n",
            "Training Loss : 0.13850723206996918\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 63 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 2.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 2.0\n",
            "Eval_MinReturn : 2.0\n",
            "Eval_AverageEpLen : 2.0\n",
            "Train_AverageReturn : 2.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 2.0\n",
            "Train_MinReturn : 2.0\n",
            "Train_AverageEpLen : 2.0\n",
            "Train_EnvstepsSoFar : 3555\n",
            "TimeSinceStart : 21.026785612106323\n",
            "Training Loss : -0.03542472794651985\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 64 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 2.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 2.0\n",
            "Eval_MinReturn : 2.0\n",
            "Eval_AverageEpLen : 2.0\n",
            "Train_AverageReturn : 2.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 2.0\n",
            "Train_MinReturn : 2.0\n",
            "Train_AverageEpLen : 2.0\n",
            "Train_EnvstepsSoFar : 3605\n",
            "TimeSinceStart : 21.372386932373047\n",
            "Training Loss : -0.05495636165142059\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 65 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 2.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 2.0\n",
            "Eval_MinReturn : 2.0\n",
            "Eval_AverageEpLen : 2.0\n",
            "Train_AverageReturn : 2.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 2.0\n",
            "Train_MinReturn : 2.0\n",
            "Train_AverageEpLen : 2.0\n",
            "Train_EnvstepsSoFar : 3655\n",
            "TimeSinceStart : 21.719250202178955\n",
            "Training Loss : 0.04490404948592186\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 66 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 2.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 2.0\n",
            "Eval_MinReturn : 2.0\n",
            "Eval_AverageEpLen : 2.0\n",
            "Train_AverageReturn : 2.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 2.0\n",
            "Train_MinReturn : 2.0\n",
            "Train_AverageEpLen : 2.0\n",
            "Train_EnvstepsSoFar : 3705\n",
            "TimeSinceStart : 22.087478160858154\n",
            "Training Loss : -0.039615094661712646\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 67 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1.8691588640213013\n",
            "Eval_StdReturn : 0.3372265100479126\n",
            "Eval_MaxReturn : 2.0\n",
            "Eval_MinReturn : 1.0\n",
            "Eval_AverageEpLen : 1.8691588785046729\n",
            "Train_AverageReturn : 2.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 2.0\n",
            "Train_MinReturn : 2.0\n",
            "Train_AverageEpLen : 2.0\n",
            "Train_EnvstepsSoFar : 3755\n",
            "TimeSinceStart : 22.44569754600525\n",
            "Training Loss : -0.10739493370056152\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 68 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1.0\n",
            "Eval_MinReturn : 1.0\n",
            "Eval_AverageEpLen : 1.0\n",
            "Train_AverageReturn : 1.8518518209457397\n",
            "Train_StdReturn : 0.35524675250053406\n",
            "Train_MaxReturn : 2.0\n",
            "Train_MinReturn : 1.0\n",
            "Train_AverageEpLen : 1.8518518518518519\n",
            "Train_EnvstepsSoFar : 3805\n",
            "TimeSinceStart : 22.83705735206604\n",
            "Training Loss : -0.10140445828437805\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 69 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1.0\n",
            "Eval_MinReturn : 1.0\n",
            "Eval_AverageEpLen : 1.0\n",
            "Train_AverageReturn : 1.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1.0\n",
            "Train_MinReturn : 1.0\n",
            "Train_AverageEpLen : 1.0\n",
            "Train_EnvstepsSoFar : 3855\n",
            "TimeSinceStart : 23.245452642440796\n",
            "Training Loss : -0.0\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 70 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1.0\n",
            "Eval_MinReturn : 1.0\n",
            "Eval_AverageEpLen : 1.0\n",
            "Train_AverageReturn : 1.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1.0\n",
            "Train_MinReturn : 1.0\n",
            "Train_AverageEpLen : 1.0\n",
            "Train_EnvstepsSoFar : 3905\n",
            "TimeSinceStart : 23.63021731376648\n",
            "Training Loss : -0.0\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 71 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1.0\n",
            "Eval_MinReturn : 1.0\n",
            "Eval_AverageEpLen : 1.0\n",
            "Train_AverageReturn : 1.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1.0\n",
            "Train_MinReturn : 1.0\n",
            "Train_AverageEpLen : 1.0\n",
            "Train_EnvstepsSoFar : 3955\n",
            "TimeSinceStart : 24.02031373977661\n",
            "Training Loss : -0.0\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 72 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1.0\n",
            "Eval_MinReturn : 1.0\n",
            "Eval_AverageEpLen : 1.0\n",
            "Train_AverageReturn : 1.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1.0\n",
            "Train_MinReturn : 1.0\n",
            "Train_AverageEpLen : 1.0\n",
            "Train_EnvstepsSoFar : 4005\n",
            "TimeSinceStart : 24.492255687713623\n",
            "Training Loss : -0.0\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 73 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1.0\n",
            "Eval_MinReturn : 1.0\n",
            "Eval_AverageEpLen : 1.0\n",
            "Train_AverageReturn : 1.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1.0\n",
            "Train_MinReturn : 1.0\n",
            "Train_AverageEpLen : 1.0\n",
            "Train_EnvstepsSoFar : 4055\n",
            "TimeSinceStart : 24.966537952423096\n",
            "Training Loss : -0.0\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 74 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1.0\n",
            "Eval_MinReturn : 1.0\n",
            "Eval_AverageEpLen : 1.0\n",
            "Train_AverageReturn : 1.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1.0\n",
            "Train_MinReturn : 1.0\n",
            "Train_AverageEpLen : 1.0\n",
            "Train_EnvstepsSoFar : 4105\n",
            "TimeSinceStart : 25.39306139945984\n",
            "Training Loss : -0.0\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 75 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1.0\n",
            "Eval_MinReturn : 1.0\n",
            "Eval_AverageEpLen : 1.0\n",
            "Train_AverageReturn : 1.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1.0\n",
            "Train_MinReturn : 1.0\n",
            "Train_AverageEpLen : 1.0\n",
            "Train_EnvstepsSoFar : 4155\n",
            "TimeSinceStart : 25.80425477027893\n",
            "Training Loss : -0.0\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 76 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1.0\n",
            "Eval_MinReturn : 1.0\n",
            "Eval_AverageEpLen : 1.0\n",
            "Train_AverageReturn : 1.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1.0\n",
            "Train_MinReturn : 1.0\n",
            "Train_AverageEpLen : 1.0\n",
            "Train_EnvstepsSoFar : 4205\n",
            "TimeSinceStart : 26.24945640563965\n",
            "Training Loss : -0.0\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 77 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1.0\n",
            "Eval_MinReturn : 1.0\n",
            "Eval_AverageEpLen : 1.0\n",
            "Train_AverageReturn : 1.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1.0\n",
            "Train_MinReturn : 1.0\n",
            "Train_AverageEpLen : 1.0\n",
            "Train_EnvstepsSoFar : 4255\n",
            "TimeSinceStart : 26.72523593902588\n",
            "Training Loss : -0.0\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 78 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1.0\n",
            "Eval_MinReturn : 1.0\n",
            "Eval_AverageEpLen : 1.0\n",
            "Train_AverageReturn : 1.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1.0\n",
            "Train_MinReturn : 1.0\n",
            "Train_AverageEpLen : 1.0\n",
            "Train_EnvstepsSoFar : 4305\n",
            "TimeSinceStart : 27.17910623550415\n",
            "Training Loss : -0.0\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 79 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1.0\n",
            "Eval_MinReturn : 1.0\n",
            "Eval_AverageEpLen : 1.0\n",
            "Train_AverageReturn : 1.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1.0\n",
            "Train_MinReturn : 1.0\n",
            "Train_AverageEpLen : 1.0\n",
            "Train_EnvstepsSoFar : 4355\n",
            "TimeSinceStart : 27.577635765075684\n",
            "Training Loss : -0.0\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 80 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1.0\n",
            "Eval_MinReturn : 1.0\n",
            "Eval_AverageEpLen : 1.0\n",
            "Train_AverageReturn : 1.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1.0\n",
            "Train_MinReturn : 1.0\n",
            "Train_AverageEpLen : 1.0\n",
            "Train_EnvstepsSoFar : 4405\n",
            "TimeSinceStart : 27.974376440048218\n",
            "Training Loss : -0.0\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 81 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1.0\n",
            "Eval_MinReturn : 1.0\n",
            "Eval_AverageEpLen : 1.0\n",
            "Train_AverageReturn : 1.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1.0\n",
            "Train_MinReturn : 1.0\n",
            "Train_AverageEpLen : 1.0\n",
            "Train_EnvstepsSoFar : 4455\n",
            "TimeSinceStart : 28.37275457382202\n",
            "Training Loss : -0.0\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 82 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1.0\n",
            "Eval_MinReturn : 1.0\n",
            "Eval_AverageEpLen : 1.0\n",
            "Train_AverageReturn : 1.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1.0\n",
            "Train_MinReturn : 1.0\n",
            "Train_AverageEpLen : 1.0\n",
            "Train_EnvstepsSoFar : 4505\n",
            "TimeSinceStart : 28.846328020095825\n",
            "Training Loss : -0.0\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 83 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1.0\n",
            "Eval_MinReturn : 1.0\n",
            "Eval_AverageEpLen : 1.0\n",
            "Train_AverageReturn : 1.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1.0\n",
            "Train_MinReturn : 1.0\n",
            "Train_AverageEpLen : 1.0\n",
            "Train_EnvstepsSoFar : 4555\n",
            "TimeSinceStart : 29.315744876861572\n",
            "Training Loss : -0.0\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 84 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1.0\n",
            "Eval_MinReturn : 1.0\n",
            "Eval_AverageEpLen : 1.0\n",
            "Train_AverageReturn : 1.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1.0\n",
            "Train_MinReturn : 1.0\n",
            "Train_AverageEpLen : 1.0\n",
            "Train_EnvstepsSoFar : 4605\n",
            "TimeSinceStart : 29.770951986312866\n",
            "Training Loss : -0.0\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 85 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1.0\n",
            "Eval_MinReturn : 1.0\n",
            "Eval_AverageEpLen : 1.0\n",
            "Train_AverageReturn : 1.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1.0\n",
            "Train_MinReturn : 1.0\n",
            "Train_AverageEpLen : 1.0\n",
            "Train_EnvstepsSoFar : 4655\n",
            "TimeSinceStart : 30.213965892791748\n",
            "Training Loss : -0.0\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 86 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1.0\n",
            "Eval_MinReturn : 1.0\n",
            "Eval_AverageEpLen : 1.0\n",
            "Train_AverageReturn : 1.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1.0\n",
            "Train_MinReturn : 1.0\n",
            "Train_AverageEpLen : 1.0\n",
            "Train_EnvstepsSoFar : 4705\n",
            "TimeSinceStart : 30.605040788650513\n",
            "Training Loss : -0.0\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 87 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1.0\n",
            "Eval_MinReturn : 1.0\n",
            "Eval_AverageEpLen : 1.0\n",
            "Train_AverageReturn : 1.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1.0\n",
            "Train_MinReturn : 1.0\n",
            "Train_AverageEpLen : 1.0\n",
            "Train_EnvstepsSoFar : 4755\n",
            "TimeSinceStart : 31.00342106819153\n",
            "Training Loss : -0.0\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 88 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1.0\n",
            "Eval_MinReturn : 1.0\n",
            "Eval_AverageEpLen : 1.0\n",
            "Train_AverageReturn : 1.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1.0\n",
            "Train_MinReturn : 1.0\n",
            "Train_AverageEpLen : 1.0\n",
            "Train_EnvstepsSoFar : 4805\n",
            "TimeSinceStart : 31.41146183013916\n",
            "Training Loss : -0.0\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 89 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1.0\n",
            "Eval_MinReturn : 1.0\n",
            "Eval_AverageEpLen : 1.0\n",
            "Train_AverageReturn : 1.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1.0\n",
            "Train_MinReturn : 1.0\n",
            "Train_AverageEpLen : 1.0\n",
            "Train_EnvstepsSoFar : 4855\n",
            "TimeSinceStart : 31.806457042694092\n",
            "Training Loss : -0.0\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 90 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1.0\n",
            "Eval_MinReturn : 1.0\n",
            "Eval_AverageEpLen : 1.0\n",
            "Train_AverageReturn : 1.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1.0\n",
            "Train_MinReturn : 1.0\n",
            "Train_AverageEpLen : 1.0\n",
            "Train_EnvstepsSoFar : 4905\n",
            "TimeSinceStart : 32.215054512023926\n",
            "Training Loss : -0.0\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 91 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1.0\n",
            "Eval_MinReturn : 1.0\n",
            "Eval_AverageEpLen : 1.0\n",
            "Train_AverageReturn : 1.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1.0\n",
            "Train_MinReturn : 1.0\n",
            "Train_AverageEpLen : 1.0\n",
            "Train_EnvstepsSoFar : 4955\n",
            "TimeSinceStart : 32.649166107177734\n",
            "Training Loss : -0.0\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 92 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1.0\n",
            "Eval_MinReturn : 1.0\n",
            "Eval_AverageEpLen : 1.0\n",
            "Train_AverageReturn : 1.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1.0\n",
            "Train_MinReturn : 1.0\n",
            "Train_AverageEpLen : 1.0\n",
            "Train_EnvstepsSoFar : 5005\n",
            "TimeSinceStart : 33.08293390274048\n",
            "Training Loss : -0.0\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 93 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1.0\n",
            "Eval_MinReturn : 1.0\n",
            "Eval_AverageEpLen : 1.0\n",
            "Train_AverageReturn : 1.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1.0\n",
            "Train_MinReturn : 1.0\n",
            "Train_AverageEpLen : 1.0\n",
            "Train_EnvstepsSoFar : 5055\n",
            "TimeSinceStart : 33.50030183792114\n",
            "Training Loss : -0.0\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 94 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1.0\n",
            "Eval_MinReturn : 1.0\n",
            "Eval_AverageEpLen : 1.0\n",
            "Train_AverageReturn : 1.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1.0\n",
            "Train_MinReturn : 1.0\n",
            "Train_AverageEpLen : 1.0\n",
            "Train_EnvstepsSoFar : 5105\n",
            "TimeSinceStart : 33.894301891326904\n",
            "Training Loss : -0.0\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 95 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1.0\n",
            "Eval_MinReturn : 1.0\n",
            "Eval_AverageEpLen : 1.0\n",
            "Train_AverageReturn : 1.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1.0\n",
            "Train_MinReturn : 1.0\n",
            "Train_AverageEpLen : 1.0\n",
            "Train_EnvstepsSoFar : 5155\n",
            "TimeSinceStart : 34.31890606880188\n",
            "Training Loss : -0.0\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 96 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1.0\n",
            "Eval_MinReturn : 1.0\n",
            "Eval_AverageEpLen : 1.0\n",
            "Train_AverageReturn : 1.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1.0\n",
            "Train_MinReturn : 1.0\n",
            "Train_AverageEpLen : 1.0\n",
            "Train_EnvstepsSoFar : 5205\n",
            "TimeSinceStart : 34.72346544265747\n",
            "Training Loss : -0.0\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 97 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1.0\n",
            "Eval_MinReturn : 1.0\n",
            "Eval_AverageEpLen : 1.0\n",
            "Train_AverageReturn : 1.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1.0\n",
            "Train_MinReturn : 1.0\n",
            "Train_AverageEpLen : 1.0\n",
            "Train_EnvstepsSoFar : 5255\n",
            "TimeSinceStart : 35.12024283409119\n",
            "Training Loss : -0.0\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 98 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1.0\n",
            "Eval_MinReturn : 1.0\n",
            "Eval_AverageEpLen : 1.0\n",
            "Train_AverageReturn : 1.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1.0\n",
            "Train_MinReturn : 1.0\n",
            "Train_AverageEpLen : 1.0\n",
            "Train_EnvstepsSoFar : 5305\n",
            "TimeSinceStart : 35.519715785980225\n",
            "Training Loss : -0.0\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 99 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1.0\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 1.0\n",
            "Eval_MinReturn : 1.0\n",
            "Eval_AverageEpLen : 1.0\n",
            "Train_AverageReturn : 1.0\n",
            "Train_StdReturn : 0.0\n",
            "Train_MaxReturn : 1.0\n",
            "Train_MinReturn : 1.0\n",
            "Train_AverageEpLen : 1.0\n",
            "Train_EnvstepsSoFar : 5355\n",
            "TimeSinceStart : 35.91198396682739\n",
            "Training Loss : -0.0\n",
            "Initial_DataCollection_AverageReturn : 6.5\n",
            "Done logging...\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python cs285/scripts/run_hw2.py --env_name InvertedPendulum-v2 \\\n",
        "--ep_len 1000 --discount 0.9 -n 100 -l 2 -s 64 -b 50 -lr 0.07 -rtg \\\n",
        "--exp_name q2_b50_r07"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9H_ueUtlzQcf"
      },
      "source": [
        "##Plots"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_q2 = read_data('','InvertedPendulum-v2',2)\n",
        "data_q2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "O_jCJVrQzt66",
        "outputId": "7ffae87b-8195-4f7b-d6cd-94d3b3381d59"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-8e7737a6-e3cf-49fd-a9cc-959c71cdcb7c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Iteration</th>\n",
              "      <th>Config</th>\n",
              "      <th>Train_EnvstepsSoFar</th>\n",
              "      <th>Eval_AverageReturn</th>\n",
              "      <th>Eval_AverageReturn_Smooth</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>b100_r05</td>\n",
              "      <td>104.0</td>\n",
              "      <td>15.178572</td>\n",
              "      <td>15.178572</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>b100_r05</td>\n",
              "      <td>206.0</td>\n",
              "      <td>9.204545</td>\n",
              "      <td>10.911410</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>b100_r05</td>\n",
              "      <td>310.0</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>31.481019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>b100_r05</td>\n",
              "      <td>419.0</td>\n",
              "      <td>9.159091</td>\n",
              "      <td>17.735989</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>b100_r05</td>\n",
              "      <td>522.0</td>\n",
              "      <td>13.333333</td>\n",
              "      <td>15.067066</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>895</th>\n",
              "      <td>95</td>\n",
              "      <td>b50_r07</td>\n",
              "      <td>5155.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>896</th>\n",
              "      <td>96</td>\n",
              "      <td>b50_r07</td>\n",
              "      <td>5205.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>897</th>\n",
              "      <td>97</td>\n",
              "      <td>b50_r07</td>\n",
              "      <td>5255.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>898</th>\n",
              "      <td>98</td>\n",
              "      <td>b50_r07</td>\n",
              "      <td>5305.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>899</th>\n",
              "      <td>99</td>\n",
              "      <td>b50_r07</td>\n",
              "      <td>5355.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>900 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8e7737a6-e3cf-49fd-a9cc-959c71cdcb7c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8e7737a6-e3cf-49fd-a9cc-959c71cdcb7c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8e7737a6-e3cf-49fd-a9cc-959c71cdcb7c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     Iteration    Config  ...  Eval_AverageReturn  Eval_AverageReturn_Smooth\n",
              "0            0  b100_r05  ...           15.178572                  15.178572\n",
              "1            1  b100_r05  ...            9.204545                  10.911410\n",
              "2            2  b100_r05  ...           43.000000                  31.481019\n",
              "3            3  b100_r05  ...            9.159091                  17.735989\n",
              "4            4  b100_r05  ...           13.333333                  15.067066\n",
              "..         ...       ...  ...                 ...                        ...\n",
              "895         95   b50_r07  ...            1.000000                   1.000000\n",
              "896         96   b50_r07  ...            1.000000                   1.000000\n",
              "897         97   b50_r07  ...            1.000000                   1.000000\n",
              "898         98   b50_r07  ...            1.000000                   1.000000\n",
              "899         99   b50_r07  ...            1.000000                   1.000000\n",
              "\n",
              "[900 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_t = data_q2.hist('Eval_AverageReturn', by = 'Config', sharey=True, figsize=(12,6))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "id": "dFeb6kiQ7l_x",
        "outputId": "7f119762-d80a-40c4-b508-2911d1ce3b45"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 9 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "l16qz4egzaUs",
        "outputId": "748f3f8e-209e-45fd-8d97-17cd62e1b6d5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fa4a09bf250>"
            ]
          },
          "metadata": {},
          "execution_count": 86
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x216 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#200 0.03\n",
        "plt.figure(figsize=figsize)\n",
        "sns.lineplot(data=data_q2, x='Iteration', y='Eval_AverageReturn', hue='Config')\n",
        "\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnBh8eChzfak"
      },
      "source": [
        "#Experiment 3 (LunarLanderContinuous-v2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YIMqsjlYzhih"
      },
      "outputs": [],
      "source": [
        "!python cs285/scripts/run_hw2.py \\\n",
        "--env_name LunarLanderContinuous-v2 --ep_len 1000 \\\n",
        "--discount 0.99 -n 100 -l 2 -s 64 -b 40000 -lr 0.005 \\\n",
        "--reward_to_go --nn_baseline --exp_name q3_b40000_r0.005"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tu650n0xziJf"
      },
      "source": [
        "##Plots"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_q3 = read_data('','LunarLanderContinuous-v2',3)\n",
        "data_q3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "QNKbc1RW0ADd",
        "outputId": "8aa179ef-0acf-4f79-d95e-a2b06f34f216"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-692f8097-c256-4e10-a983-5169afdf0a5d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Iteration</th>\n",
              "      <th>Config</th>\n",
              "      <th>Train_EnvstepsSoFar</th>\n",
              "      <th>Eval_AverageReturn</th>\n",
              "      <th>Eval_AverageReturn_Smooth</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>b40000_r0.005</td>\n",
              "      <td>40138.0</td>\n",
              "      <td>-162.545395</td>\n",
              "      <td>-162.545395</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>b40000_r0.005</td>\n",
              "      <td>80163.0</td>\n",
              "      <td>-231.308929</td>\n",
              "      <td>-211.662205</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>b40000_r0.005</td>\n",
              "      <td>120218.0</td>\n",
              "      <td>-94.400139</td>\n",
              "      <td>-136.494214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>b40000_r0.005</td>\n",
              "      <td>160251.0</td>\n",
              "      <td>-107.905647</td>\n",
              "      <td>-118.890417</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>b40000_r0.005</td>\n",
              "      <td>200330.0</td>\n",
              "      <td>-159.898773</td>\n",
              "      <td>-143.749993</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>95</td>\n",
              "      <td>b40000_r0.005</td>\n",
              "      <td>3873867.0</td>\n",
              "      <td>122.020035</td>\n",
              "      <td>127.278573</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>96</td>\n",
              "      <td>b40000_r0.005</td>\n",
              "      <td>3913909.0</td>\n",
              "      <td>84.841873</td>\n",
              "      <td>101.816553</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>97</td>\n",
              "      <td>b40000_r0.005</td>\n",
              "      <td>3954808.0</td>\n",
              "      <td>129.969269</td>\n",
              "      <td>118.708183</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>98</td>\n",
              "      <td>b40000_r0.005</td>\n",
              "      <td>3995328.0</td>\n",
              "      <td>124.454437</td>\n",
              "      <td>122.155935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>99</td>\n",
              "      <td>b40000_r0.005</td>\n",
              "      <td>4035485.0</td>\n",
              "      <td>125.307503</td>\n",
              "      <td>124.046876</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-692f8097-c256-4e10-a983-5169afdf0a5d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-692f8097-c256-4e10-a983-5169afdf0a5d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-692f8097-c256-4e10-a983-5169afdf0a5d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "    Iteration         Config  ...  Eval_AverageReturn  Eval_AverageReturn_Smooth\n",
              "0           0  b40000_r0.005  ...         -162.545395                -162.545395\n",
              "1           1  b40000_r0.005  ...         -231.308929                -211.662205\n",
              "2           2  b40000_r0.005  ...          -94.400139                -136.494214\n",
              "3           3  b40000_r0.005  ...         -107.905647                -118.890417\n",
              "4           4  b40000_r0.005  ...         -159.898773                -143.749993\n",
              "..        ...            ...  ...                 ...                        ...\n",
              "95         95  b40000_r0.005  ...          122.020035                 127.278573\n",
              "96         96  b40000_r0.005  ...           84.841873                 101.816553\n",
              "97         97  b40000_r0.005  ...          129.969269                 118.708183\n",
              "98         98  b40000_r0.005  ...          124.454437                 122.155935\n",
              "99         99  b40000_r0.005  ...          125.307503                 124.046876\n",
              "\n",
              "[100 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "hfw9m4gg0Xbq",
        "outputId": "24b89e3d-7fa4-4498-8176-ee798ca1fa59"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fa4a0a12b10>"
            ]
          },
          "metadata": {},
          "execution_count": 88
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x216 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.figure(figsize=figsize)\n",
        "sns.lineplot(data=data_q3, x='Iteration', y='Eval_AverageReturn', hue='Config')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtpB85Ml0sAE"
      },
      "source": [
        "#Expirement4 (HalfCheetah-v2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r7Lv3fFu0rrN",
        "outputId": "420e1aef-c9e1-49c2-8f92-82c15ef8bc22"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "########################\n",
            "logging outputs to  /content/gdrive/My Drive/cs285_f2021/DRL_policy_grads/cs285/scripts/../../data/q4_search_b10000_lr005_rtg_nnbaseline_HalfCheetah-v2_06-02-2022_17-46-27\n",
            "########################\n",
            "Using GPU id 0\n",
            "Sequential(\n",
            "  (0): Linear(in_features=17, out_features=32, bias=True)\n",
            "  (1): Tanh()\n",
            "  (2): Linear(in_features=32, out_features=32, bias=True)\n",
            "  (3): Tanh()\n",
            "  (4): Linear(in_features=32, out_features=6, bias=True)\n",
            "  (5): Identity()\n",
            ")\n",
            "Sequential(\n",
            "  (0): Linear(in_features=17, out_features=32, bias=True)\n",
            "  (1): Tanh()\n",
            "  (2): Linear(in_features=32, out_features=32, bias=True)\n",
            "  (3): Tanh()\n",
            "  (4): Linear(in_features=32, out_features=1, bias=True)\n",
            "  (5): Identity()\n",
            ")\n",
            "\n",
            "\n",
            "********** Iteration 0 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -87.08850860595703\n",
            "Eval_StdReturn : 15.034369468688965\n",
            "Eval_MaxReturn : -74.86231994628906\n",
            "Eval_MinReturn : -108.2660903930664\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -87.19107055664062\n",
            "Train_StdReturn : 35.025604248046875\n",
            "Train_MaxReturn : -3.671494245529175\n",
            "Train_MinReturn : -184.59756469726562\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 10050\n",
            "TimeSinceStart : 8.028455018997192\n",
            "Training Loss : -0.07260606437921524\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 1 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -68.32273864746094\n",
            "Eval_StdReturn : 7.52401065826416\n",
            "Eval_MaxReturn : -59.65873718261719\n",
            "Eval_MinReturn : -78.00426483154297\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -83.58442687988281\n",
            "Train_StdReturn : 32.87636184692383\n",
            "Train_MaxReturn : -16.73409652709961\n",
            "Train_MinReturn : -181.13729858398438\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 20100\n",
            "TimeSinceStart : 17.45913577079773\n",
            "Training Loss : -0.09101925790309906\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 2 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -56.56010437011719\n",
            "Eval_StdReturn : 22.647953033447266\n",
            "Eval_MaxReturn : -25.02851104736328\n",
            "Eval_MinReturn : -77.19556427001953\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -85.27812957763672\n",
            "Train_StdReturn : 36.76525115966797\n",
            "Train_MaxReturn : 7.291921615600586\n",
            "Train_MinReturn : -204.9813232421875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 30150\n",
            "TimeSinceStart : 25.60614776611328\n",
            "Training Loss : -0.12050239741802216\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 3 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -41.102298736572266\n",
            "Eval_StdReturn : 26.922399520874023\n",
            "Eval_MaxReturn : -21.600419998168945\n",
            "Eval_MinReturn : -79.1725082397461\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -86.33386993408203\n",
            "Train_StdReturn : 39.718997955322266\n",
            "Train_MaxReturn : 26.043167114257812\n",
            "Train_MinReturn : -195.34420776367188\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 40200\n",
            "TimeSinceStart : 32.9636869430542\n",
            "Training Loss : -0.09239095449447632\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 4 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -83.02780151367188\n",
            "Eval_StdReturn : 35.10204315185547\n",
            "Eval_MaxReturn : -49.91978454589844\n",
            "Eval_MinReturn : -131.614990234375\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -84.07455444335938\n",
            "Train_StdReturn : 38.82433319091797\n",
            "Train_MaxReturn : -28.848447799682617\n",
            "Train_MinReturn : -210.7850341796875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 50250\n",
            "TimeSinceStart : 40.64182901382446\n",
            "Training Loss : -0.050239112228155136\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 5 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -77.93212890625\n",
            "Eval_StdReturn : 16.67445945739746\n",
            "Eval_MaxReturn : -54.42012405395508\n",
            "Eval_MinReturn : -91.25200653076172\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -87.89962005615234\n",
            "Train_StdReturn : 43.712059020996094\n",
            "Train_MaxReturn : 0.16785717010498047\n",
            "Train_MinReturn : -185.07106018066406\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 60300\n",
            "TimeSinceStart : 48.17377281188965\n",
            "Training Loss : -0.08043798059225082\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 6 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -46.9637451171875\n",
            "Eval_StdReturn : 7.490499496459961\n",
            "Eval_MaxReturn : -36.381935119628906\n",
            "Eval_MinReturn : -52.6793212890625\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -73.37340545654297\n",
            "Train_StdReturn : 31.317319869995117\n",
            "Train_MaxReturn : -7.675897598266602\n",
            "Train_MinReturn : -166.55047607421875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 70350\n",
            "TimeSinceStart : 55.326515674591064\n",
            "Training Loss : -0.06795716285705566\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 7 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -99.6521224975586\n",
            "Eval_StdReturn : 13.235237121582031\n",
            "Eval_MaxReturn : -85.79983520507812\n",
            "Eval_MinReturn : -117.47977447509766\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -75.209716796875\n",
            "Train_StdReturn : 33.91105651855469\n",
            "Train_MaxReturn : 1.0051956176757812\n",
            "Train_MinReturn : -181.29696655273438\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 80400\n",
            "TimeSinceStart : 62.45363640785217\n",
            "Training Loss : -0.0878526121377945\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 8 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -44.71299743652344\n",
            "Eval_StdReturn : 36.580352783203125\n",
            "Eval_MaxReturn : -3.080721855163574\n",
            "Eval_MinReturn : -92.12328338623047\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -69.35397338867188\n",
            "Train_StdReturn : 37.096038818359375\n",
            "Train_MaxReturn : 4.641826629638672\n",
            "Train_MinReturn : -199.9740447998047\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 90450\n",
            "TimeSinceStart : 70.3853645324707\n",
            "Training Loss : -0.07498626410961151\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 9 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -47.56586837768555\n",
            "Eval_StdReturn : 51.50894546508789\n",
            "Eval_MaxReturn : 3.1248888969421387\n",
            "Eval_MinReturn : -118.216796875\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -71.75389862060547\n",
            "Train_StdReturn : 28.807859420776367\n",
            "Train_MaxReturn : -5.991731643676758\n",
            "Train_MinReturn : -144.8426513671875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 100500\n",
            "TimeSinceStart : 78.1521360874176\n",
            "Training Loss : -0.09431413561105728\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 10 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -60.180328369140625\n",
            "Eval_StdReturn : 43.83401107788086\n",
            "Eval_MaxReturn : -0.9345378875732422\n",
            "Eval_MinReturn : -105.60143280029297\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -67.95137023925781\n",
            "Train_StdReturn : 31.173057556152344\n",
            "Train_MaxReturn : -11.086210250854492\n",
            "Train_MinReturn : -156.02395629882812\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 110550\n",
            "TimeSinceStart : 85.85696148872375\n",
            "Training Loss : -0.08855478465557098\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 11 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -72.7225112915039\n",
            "Eval_StdReturn : 18.947704315185547\n",
            "Eval_MaxReturn : -52.611572265625\n",
            "Eval_MinReturn : -98.11375427246094\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -60.78453063964844\n",
            "Train_StdReturn : 32.03330993652344\n",
            "Train_MaxReturn : 14.128684997558594\n",
            "Train_MinReturn : -145.6456298828125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 120600\n",
            "TimeSinceStart : 93.25245881080627\n",
            "Training Loss : -0.05338611453771591\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 12 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -39.48136520385742\n",
            "Eval_StdReturn : 31.98707389831543\n",
            "Eval_MaxReturn : 5.5219831466674805\n",
            "Eval_MinReturn : -65.95585632324219\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -69.32550811767578\n",
            "Train_StdReturn : 29.640146255493164\n",
            "Train_MaxReturn : -4.915316581726074\n",
            "Train_MinReturn : -158.982666015625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 130650\n",
            "TimeSinceStart : 100.48838376998901\n",
            "Training Loss : -0.0741686224937439\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 13 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -75.52924346923828\n",
            "Eval_StdReturn : 33.77701950073242\n",
            "Eval_MaxReturn : -46.24842071533203\n",
            "Eval_MinReturn : -122.85459899902344\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -64.72422790527344\n",
            "Train_StdReturn : 34.441314697265625\n",
            "Train_MaxReturn : -0.8029193878173828\n",
            "Train_MinReturn : -171.37667846679688\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 140700\n",
            "TimeSinceStart : 107.56912779808044\n",
            "Training Loss : -0.07630836218595505\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 14 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -73.72924041748047\n",
            "Eval_StdReturn : 7.1350932121276855\n",
            "Eval_MaxReturn : -66.61329650878906\n",
            "Eval_MinReturn : -83.48292541503906\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -66.56226348876953\n",
            "Train_StdReturn : 27.00171661376953\n",
            "Train_MaxReturn : -4.461365699768066\n",
            "Train_MinReturn : -133.79083251953125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 150750\n",
            "TimeSinceStart : 115.1291151046753\n",
            "Training Loss : -0.09081719070672989\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 15 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -60.941680908203125\n",
            "Eval_StdReturn : 24.68511199951172\n",
            "Eval_MaxReturn : -33.69849395751953\n",
            "Eval_MinReturn : -93.46800231933594\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -66.83663940429688\n",
            "Train_StdReturn : 30.157657623291016\n",
            "Train_MaxReturn : 12.002338409423828\n",
            "Train_MinReturn : -146.97259521484375\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 160800\n",
            "TimeSinceStart : 123.19501161575317\n",
            "Training Loss : -0.05643707886338234\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 16 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -61.04115676879883\n",
            "Eval_StdReturn : 28.631296157836914\n",
            "Eval_MaxReturn : -35.46212387084961\n",
            "Eval_MinReturn : -101.01360321044922\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -68.32103729248047\n",
            "Train_StdReturn : 31.327022552490234\n",
            "Train_MaxReturn : 16.254493713378906\n",
            "Train_MinReturn : -142.69161987304688\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 170850\n",
            "TimeSinceStart : 130.66374802589417\n",
            "Training Loss : -0.049438029527664185\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 17 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -70.40880584716797\n",
            "Eval_StdReturn : 32.25233840942383\n",
            "Eval_MaxReturn : -24.89413833618164\n",
            "Eval_MinReturn : -95.74124145507812\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -62.46260452270508\n",
            "Train_StdReturn : 32.37135314941406\n",
            "Train_MaxReturn : 16.226669311523438\n",
            "Train_MinReturn : -166.61727905273438\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 180900\n",
            "TimeSinceStart : 137.91771793365479\n",
            "Training Loss : -0.08044300228357315\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 18 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -27.816843032836914\n",
            "Eval_StdReturn : 57.92382049560547\n",
            "Eval_MaxReturn : 50.903194427490234\n",
            "Eval_MinReturn : -86.80134582519531\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -57.54808044433594\n",
            "Train_StdReturn : 35.660888671875\n",
            "Train_MaxReturn : 39.713165283203125\n",
            "Train_MinReturn : -162.89794921875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 190950\n",
            "TimeSinceStart : 145.3032510280609\n",
            "Training Loss : -0.0634029358625412\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 19 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -67.6491470336914\n",
            "Eval_StdReturn : 23.10636329650879\n",
            "Eval_MaxReturn : -38.21773910522461\n",
            "Eval_MinReturn : -94.66120147705078\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -60.483882904052734\n",
            "Train_StdReturn : 31.957731246948242\n",
            "Train_MaxReturn : 19.13791275024414\n",
            "Train_MinReturn : -130.38072204589844\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 201000\n",
            "TimeSinceStart : 153.0451216697693\n",
            "Training Loss : -0.03455774113535881\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 20 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -65.9588394165039\n",
            "Eval_StdReturn : 5.552181243896484\n",
            "Eval_MaxReturn : -58.34751510620117\n",
            "Eval_MinReturn : -71.43509674072266\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -59.5552864074707\n",
            "Train_StdReturn : 33.12908935546875\n",
            "Train_MaxReturn : 34.17097091674805\n",
            "Train_MinReturn : -154.85000610351562\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 211050\n",
            "TimeSinceStart : 160.63022375106812\n",
            "Training Loss : -0.04767637699842453\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 21 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -50.52595138549805\n",
            "Eval_StdReturn : 16.167593002319336\n",
            "Eval_MaxReturn : -28.178028106689453\n",
            "Eval_MinReturn : -65.88493347167969\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -57.63399887084961\n",
            "Train_StdReturn : 32.05935287475586\n",
            "Train_MaxReturn : 21.075489044189453\n",
            "Train_MinReturn : -157.6777801513672\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 221100\n",
            "TimeSinceStart : 168.3118691444397\n",
            "Training Loss : -0.05259804427623749\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 22 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -56.699737548828125\n",
            "Eval_StdReturn : 13.246376037597656\n",
            "Eval_MaxReturn : -46.57862091064453\n",
            "Eval_MinReturn : -75.412109375\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -64.72611999511719\n",
            "Train_StdReturn : 29.741975784301758\n",
            "Train_MaxReturn : 2.8024373054504395\n",
            "Train_MinReturn : -167.24789428710938\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 231150\n",
            "TimeSinceStart : 176.01433682441711\n",
            "Training Loss : -0.05292285606265068\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 23 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -37.86080551147461\n",
            "Eval_StdReturn : 33.33946990966797\n",
            "Eval_MaxReturn : 9.28273868560791\n",
            "Eval_MinReturn : -62.06099319458008\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -58.595001220703125\n",
            "Train_StdReturn : 27.983957290649414\n",
            "Train_MaxReturn : -0.8367325663566589\n",
            "Train_MinReturn : -152.32723999023438\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 241200\n",
            "TimeSinceStart : 183.41984128952026\n",
            "Training Loss : -0.08331726491451263\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 24 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -55.88322830200195\n",
            "Eval_StdReturn : 9.159165382385254\n",
            "Eval_MaxReturn : -49.23185729980469\n",
            "Eval_MinReturn : -68.83465576171875\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -58.253719329833984\n",
            "Train_StdReturn : 32.08977127075195\n",
            "Train_MaxReturn : 11.800620079040527\n",
            "Train_MinReturn : -139.16500854492188\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 251250\n",
            "TimeSinceStart : 190.745863199234\n",
            "Training Loss : -0.055240098387002945\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 25 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -49.82145690917969\n",
            "Eval_StdReturn : 6.191688060760498\n",
            "Eval_MaxReturn : -42.13063049316406\n",
            "Eval_MinReturn : -57.292320251464844\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -53.22364807128906\n",
            "Train_StdReturn : 30.206552505493164\n",
            "Train_MaxReturn : 18.462093353271484\n",
            "Train_MinReturn : -131.349609375\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 261300\n",
            "TimeSinceStart : 198.52408933639526\n",
            "Training Loss : -0.03176508843898773\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 26 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -46.5887336730957\n",
            "Eval_StdReturn : 15.820902824401855\n",
            "Eval_MaxReturn : -25.32916259765625\n",
            "Eval_MinReturn : -63.25792694091797\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -49.30175018310547\n",
            "Train_StdReturn : 30.657512664794922\n",
            "Train_MaxReturn : 8.9006929397583\n",
            "Train_MinReturn : -143.74118041992188\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 271350\n",
            "TimeSinceStart : 206.23377084732056\n",
            "Training Loss : -0.07659506052732468\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 27 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -90.06451416015625\n",
            "Eval_StdReturn : 39.82709884643555\n",
            "Eval_MaxReturn : -34.42964172363281\n",
            "Eval_MinReturn : -125.48902893066406\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -50.420372009277344\n",
            "Train_StdReturn : 28.42888069152832\n",
            "Train_MaxReturn : 34.82642364501953\n",
            "Train_MinReturn : -120.02831268310547\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 281400\n",
            "TimeSinceStart : 214.01450991630554\n",
            "Training Loss : -0.03504166379570961\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 28 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -34.54219436645508\n",
            "Eval_StdReturn : 16.265527725219727\n",
            "Eval_MaxReturn : -12.002872467041016\n",
            "Eval_MinReturn : -49.791202545166016\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -56.478790283203125\n",
            "Train_StdReturn : 28.57037353515625\n",
            "Train_MaxReturn : 0.7046604156494141\n",
            "Train_MinReturn : -137.4732208251953\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 291450\n",
            "TimeSinceStart : 226.1892237663269\n",
            "Training Loss : -0.06826747953891754\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 29 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -68.0396728515625\n",
            "Eval_StdReturn : 19.01158332824707\n",
            "Eval_MaxReturn : -49.29741668701172\n",
            "Eval_MinReturn : -94.10530090332031\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -59.5137825012207\n",
            "Train_StdReturn : 27.75320816040039\n",
            "Train_MaxReturn : 0.6862449645996094\n",
            "Train_MinReturn : -121.9603500366211\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 301500\n",
            "TimeSinceStart : 240.2533359527588\n",
            "Training Loss : -0.056077323853969574\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 30 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -53.29388427734375\n",
            "Eval_StdReturn : 34.12519073486328\n",
            "Eval_MaxReturn : -18.5162353515625\n",
            "Eval_MinReturn : -99.65992736816406\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -49.053001403808594\n",
            "Train_StdReturn : 37.67770767211914\n",
            "Train_MaxReturn : 42.681549072265625\n",
            "Train_MinReturn : -170.78512573242188\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 311550\n",
            "TimeSinceStart : 249.28824853897095\n",
            "Training Loss : -0.06621980667114258\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 31 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -62.47775650024414\n",
            "Eval_StdReturn : 29.148157119750977\n",
            "Eval_MaxReturn : -23.471479415893555\n",
            "Eval_MinReturn : -93.52668762207031\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -46.61589050292969\n",
            "Train_StdReturn : 24.97359275817871\n",
            "Train_MaxReturn : 11.935101509094238\n",
            "Train_MinReturn : -105.84327697753906\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 321600\n",
            "TimeSinceStart : 257.9062626361847\n",
            "Training Loss : -0.0571320541203022\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 32 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -55.10297775268555\n",
            "Eval_StdReturn : 26.159717559814453\n",
            "Eval_MaxReturn : -29.265750885009766\n",
            "Eval_MinReturn : -90.95245361328125\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -51.58641052246094\n",
            "Train_StdReturn : 33.70684814453125\n",
            "Train_MaxReturn : 15.969532012939453\n",
            "Train_MinReturn : -178.55096435546875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 331650\n",
            "TimeSinceStart : 266.97969675064087\n",
            "Training Loss : -0.04437580332159996\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 33 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -38.276309967041016\n",
            "Eval_StdReturn : 9.812089920043945\n",
            "Eval_MaxReturn : -25.79595184326172\n",
            "Eval_MinReturn : -49.769691467285156\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -58.02932357788086\n",
            "Train_StdReturn : 30.881900787353516\n",
            "Train_MaxReturn : 6.052806854248047\n",
            "Train_MinReturn : -141.23583984375\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 341700\n",
            "TimeSinceStart : 275.0033452510834\n",
            "Training Loss : -0.055953074246644974\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 34 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -37.253883361816406\n",
            "Eval_StdReturn : 16.630159378051758\n",
            "Eval_MaxReturn : -23.210716247558594\n",
            "Eval_MinReturn : -60.613624572753906\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -50.08821105957031\n",
            "Train_StdReturn : 31.845380783081055\n",
            "Train_MaxReturn : 39.015750885009766\n",
            "Train_MinReturn : -142.55368041992188\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 351750\n",
            "TimeSinceStart : 285.854727268219\n",
            "Training Loss : -0.06483393907546997\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 35 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -58.50664138793945\n",
            "Eval_StdReturn : 31.31742286682129\n",
            "Eval_MaxReturn : -22.885896682739258\n",
            "Eval_MinReturn : -99.11051177978516\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -48.037689208984375\n",
            "Train_StdReturn : 27.54338264465332\n",
            "Train_MaxReturn : 12.076019287109375\n",
            "Train_MinReturn : -129.4303436279297\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 361800\n",
            "TimeSinceStart : 293.63164949417114\n",
            "Training Loss : -0.05817440152168274\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 36 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -72.19110870361328\n",
            "Eval_StdReturn : 26.154176712036133\n",
            "Eval_MaxReturn : -35.34999465942383\n",
            "Eval_MinReturn : -93.45955657958984\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -48.247276306152344\n",
            "Train_StdReturn : 28.197620391845703\n",
            "Train_MaxReturn : 6.519071578979492\n",
            "Train_MinReturn : -133.05160522460938\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 371850\n",
            "TimeSinceStart : 301.16152811050415\n",
            "Training Loss : -0.06196625530719757\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 37 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -31.950119018554688\n",
            "Eval_StdReturn : 13.947305679321289\n",
            "Eval_MaxReturn : -12.756855010986328\n",
            "Eval_MinReturn : -45.48438262939453\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -48.89218521118164\n",
            "Train_StdReturn : 28.344200134277344\n",
            "Train_MaxReturn : 9.637065887451172\n",
            "Train_MinReturn : -114.48800659179688\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 381900\n",
            "TimeSinceStart : 308.8159964084625\n",
            "Training Loss : -0.04654592275619507\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 38 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -68.18505859375\n",
            "Eval_StdReturn : 16.479185104370117\n",
            "Eval_MaxReturn : -51.85334777832031\n",
            "Eval_MinReturn : -90.74889373779297\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -48.18037796020508\n",
            "Train_StdReturn : 28.823814392089844\n",
            "Train_MaxReturn : 23.762920379638672\n",
            "Train_MinReturn : -166.03826904296875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 391950\n",
            "TimeSinceStart : 316.424188375473\n",
            "Training Loss : -0.07889287918806076\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 39 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -53.95343017578125\n",
            "Eval_StdReturn : 33.89252471923828\n",
            "Eval_MaxReturn : -6.58627986907959\n",
            "Eval_MinReturn : -83.98677062988281\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -45.68459701538086\n",
            "Train_StdReturn : 28.664064407348633\n",
            "Train_MaxReturn : 24.590362548828125\n",
            "Train_MinReturn : -145.89764404296875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 402000\n",
            "TimeSinceStart : 325.26614141464233\n",
            "Training Loss : -0.06310505419969559\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 40 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -46.66856002807617\n",
            "Eval_StdReturn : 13.50799560546875\n",
            "Eval_MaxReturn : -28.086376190185547\n",
            "Eval_MinReturn : -59.79706573486328\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -46.06306457519531\n",
            "Train_StdReturn : 28.668764114379883\n",
            "Train_MaxReturn : 13.495534896850586\n",
            "Train_MinReturn : -127.93916320800781\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 412050\n",
            "TimeSinceStart : 334.24160051345825\n",
            "Training Loss : -0.0612499825656414\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 41 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -50.12458801269531\n",
            "Eval_StdReturn : 24.20846939086914\n",
            "Eval_MaxReturn : -25.833698272705078\n",
            "Eval_MinReturn : -83.16355895996094\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -42.10886764526367\n",
            "Train_StdReturn : 33.07638931274414\n",
            "Train_MaxReturn : 60.35014724731445\n",
            "Train_MinReturn : -150.63214111328125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 422100\n",
            "TimeSinceStart : 341.85906457901\n",
            "Training Loss : -0.076951764523983\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 42 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -44.31681442260742\n",
            "Eval_StdReturn : 17.766448974609375\n",
            "Eval_MaxReturn : -21.727420806884766\n",
            "Eval_MinReturn : -65.13829040527344\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -47.46598434448242\n",
            "Train_StdReturn : 33.56710433959961\n",
            "Train_MaxReturn : 66.67557525634766\n",
            "Train_MinReturn : -116.69856262207031\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 432150\n",
            "TimeSinceStart : 349.98119616508484\n",
            "Training Loss : -0.05510317161679268\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 43 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -19.39119529724121\n",
            "Eval_StdReturn : 7.839752197265625\n",
            "Eval_MaxReturn : -8.308859825134277\n",
            "Eval_MinReturn : -25.213302612304688\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -39.7161865234375\n",
            "Train_StdReturn : 28.623151779174805\n",
            "Train_MaxReturn : 39.136863708496094\n",
            "Train_MinReturn : -145.75643920898438\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 442200\n",
            "TimeSinceStart : 357.46543860435486\n",
            "Training Loss : -0.02750733681023121\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 44 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -31.364913940429688\n",
            "Eval_StdReturn : 0.6473568081855774\n",
            "Eval_MaxReturn : -30.739381790161133\n",
            "Eval_MinReturn : -32.256591796875\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -50.23078155517578\n",
            "Train_StdReturn : 26.952655792236328\n",
            "Train_MaxReturn : 5.268129825592041\n",
            "Train_MinReturn : -130.37863159179688\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 452250\n",
            "TimeSinceStart : 365.1720094680786\n",
            "Training Loss : -0.06324893981218338\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 45 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -16.850502014160156\n",
            "Eval_StdReturn : 10.004344940185547\n",
            "Eval_MaxReturn : -2.7320632934570312\n",
            "Eval_MinReturn : -24.70511817932129\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -41.4221076965332\n",
            "Train_StdReturn : 30.42261505126953\n",
            "Train_MaxReturn : 37.64470291137695\n",
            "Train_MinReturn : -109.61509704589844\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 462300\n",
            "TimeSinceStart : 373.82535767555237\n",
            "Training Loss : -0.07302027940750122\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 46 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -70.66503143310547\n",
            "Eval_StdReturn : 15.488761901855469\n",
            "Eval_MaxReturn : -54.32439422607422\n",
            "Eval_MinReturn : -91.46825408935547\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -47.243629455566406\n",
            "Train_StdReturn : 23.959245681762695\n",
            "Train_MaxReturn : 27.029163360595703\n",
            "Train_MinReturn : -105.3301010131836\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 472350\n",
            "TimeSinceStart : 381.12737250328064\n",
            "Training Loss : -0.030382560566067696\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 47 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -25.292142868041992\n",
            "Eval_StdReturn : 10.468135833740234\n",
            "Eval_MaxReturn : -14.385154724121094\n",
            "Eval_MinReturn : -39.41460418701172\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -48.10035705566406\n",
            "Train_StdReturn : 25.611387252807617\n",
            "Train_MaxReturn : 12.652423858642578\n",
            "Train_MinReturn : -123.51302337646484\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 482400\n",
            "TimeSinceStart : 389.04600524902344\n",
            "Training Loss : -0.03660527989268303\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 48 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -32.5645637512207\n",
            "Eval_StdReturn : 12.740696907043457\n",
            "Eval_MaxReturn : -15.480297088623047\n",
            "Eval_MinReturn : -46.06491470336914\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -39.73576736450195\n",
            "Train_StdReturn : 27.186279296875\n",
            "Train_MaxReturn : 38.08774948120117\n",
            "Train_MinReturn : -105.60291290283203\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 492450\n",
            "TimeSinceStart : 396.50369906425476\n",
            "Training Loss : -0.05957203730940819\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 49 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -33.9627571105957\n",
            "Eval_StdReturn : 13.472517013549805\n",
            "Eval_MaxReturn : -19.564273834228516\n",
            "Eval_MinReturn : -51.968284606933594\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -44.410404205322266\n",
            "Train_StdReturn : 28.198448181152344\n",
            "Train_MaxReturn : 47.838077545166016\n",
            "Train_MinReturn : -127.67231750488281\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 502500\n",
            "TimeSinceStart : 404.06287121772766\n",
            "Training Loss : -0.04025421664118767\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 50 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -62.7359504699707\n",
            "Eval_StdReturn : 18.95983123779297\n",
            "Eval_MaxReturn : -46.183502197265625\n",
            "Eval_MinReturn : -89.28031921386719\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -40.012962341308594\n",
            "Train_StdReturn : 27.257648468017578\n",
            "Train_MaxReturn : 18.47008514404297\n",
            "Train_MinReturn : -120.30747985839844\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 512550\n",
            "TimeSinceStart : 411.6550660133362\n",
            "Training Loss : -0.05504791811108589\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 51 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -24.828752517700195\n",
            "Eval_StdReturn : 10.177163124084473\n",
            "Eval_MaxReturn : -11.182825088500977\n",
            "Eval_MinReturn : -35.614479064941406\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -43.35133361816406\n",
            "Train_StdReturn : 29.33631706237793\n",
            "Train_MaxReturn : 25.13335418701172\n",
            "Train_MinReturn : -140.39932250976562\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 522600\n",
            "TimeSinceStart : 419.2912333011627\n",
            "Training Loss : -0.04348943755030632\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 52 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -32.890235900878906\n",
            "Eval_StdReturn : 13.52079963684082\n",
            "Eval_MaxReturn : -18.1210994720459\n",
            "Eval_MinReturn : -50.79252624511719\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -44.86003494262695\n",
            "Train_StdReturn : 29.61224365234375\n",
            "Train_MaxReturn : 36.320281982421875\n",
            "Train_MinReturn : -138.26150512695312\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 532650\n",
            "TimeSinceStart : 427.042099237442\n",
            "Training Loss : -0.08065767586231232\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 53 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -45.81377029418945\n",
            "Eval_StdReturn : 24.056276321411133\n",
            "Eval_MaxReturn : -28.23393440246582\n",
            "Eval_MinReturn : -79.82805633544922\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -44.89192199707031\n",
            "Train_StdReturn : 23.37706184387207\n",
            "Train_MaxReturn : 4.3554277420043945\n",
            "Train_MinReturn : -96.10163879394531\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 542700\n",
            "TimeSinceStart : 435.1026756763458\n",
            "Training Loss : -0.053693629801273346\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 54 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -34.08958053588867\n",
            "Eval_StdReturn : 26.382356643676758\n",
            "Eval_MaxReturn : -11.642070770263672\n",
            "Eval_MinReturn : -71.12273406982422\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -35.22523498535156\n",
            "Train_StdReturn : 23.689058303833008\n",
            "Train_MaxReturn : 4.024884223937988\n",
            "Train_MinReturn : -96.0954818725586\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 552750\n",
            "TimeSinceStart : 442.5687608718872\n",
            "Training Loss : -0.05232973396778107\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 55 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -19.037294387817383\n",
            "Eval_StdReturn : 24.03572654724121\n",
            "Eval_MaxReturn : 14.328908920288086\n",
            "Eval_MinReturn : -41.34148025512695\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -40.54917907714844\n",
            "Train_StdReturn : 24.360815048217773\n",
            "Train_MaxReturn : 36.71477508544922\n",
            "Train_MinReturn : -115.90826416015625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 562800\n",
            "TimeSinceStart : 450.7008500099182\n",
            "Training Loss : -0.0375918373465538\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 56 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -28.038331985473633\n",
            "Eval_StdReturn : 11.935677528381348\n",
            "Eval_MaxReturn : -14.022468566894531\n",
            "Eval_MinReturn : -43.1922607421875\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -38.04512023925781\n",
            "Train_StdReturn : 22.115291595458984\n",
            "Train_MaxReturn : 38.46534729003906\n",
            "Train_MinReturn : -102.0249252319336\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 572850\n",
            "TimeSinceStart : 458.57391595840454\n",
            "Training Loss : -0.014448394067585468\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 57 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -51.383426666259766\n",
            "Eval_StdReturn : 27.06171417236328\n",
            "Eval_MaxReturn : -13.44827651977539\n",
            "Eval_MinReturn : -74.7325210571289\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -40.00336837768555\n",
            "Train_StdReturn : 26.660385131835938\n",
            "Train_MaxReturn : 37.2481575012207\n",
            "Train_MinReturn : -94.52879333496094\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 582900\n",
            "TimeSinceStart : 466.17344212532043\n",
            "Training Loss : -0.0446016862988472\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 58 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -51.562137603759766\n",
            "Eval_StdReturn : 20.47100257873535\n",
            "Eval_MaxReturn : -34.628746032714844\n",
            "Eval_MinReturn : -80.36447143554688\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -36.442718505859375\n",
            "Train_StdReturn : 18.452402114868164\n",
            "Train_MaxReturn : 17.181669235229492\n",
            "Train_MinReturn : -76.93685913085938\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 592950\n",
            "TimeSinceStart : 479.3902175426483\n",
            "Training Loss : -0.04351180046796799\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 59 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -53.05149459838867\n",
            "Eval_StdReturn : 20.692636489868164\n",
            "Eval_MaxReturn : -25.222408294677734\n",
            "Eval_MinReturn : -74.80403900146484\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -33.44820785522461\n",
            "Train_StdReturn : 26.783203125\n",
            "Train_MaxReturn : 47.811336517333984\n",
            "Train_MinReturn : -96.74485778808594\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 603000\n",
            "TimeSinceStart : 490.9635081291199\n",
            "Training Loss : -0.04231688380241394\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 60 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -45.968170166015625\n",
            "Eval_StdReturn : 33.635398864746094\n",
            "Eval_MaxReturn : -3.036233901977539\n",
            "Eval_MinReturn : -85.17241668701172\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -36.04828643798828\n",
            "Train_StdReturn : 29.9237003326416\n",
            "Train_MaxReturn : 22.82027244567871\n",
            "Train_MinReturn : -136.6328582763672\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 613050\n",
            "TimeSinceStart : 500.52982568740845\n",
            "Training Loss : -0.059470608830451965\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 61 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -38.68053436279297\n",
            "Eval_StdReturn : 18.283611297607422\n",
            "Eval_MaxReturn : -17.772964477539062\n",
            "Eval_MinReturn : -62.30970764160156\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -35.90803909301758\n",
            "Train_StdReturn : 24.771425247192383\n",
            "Train_MaxReturn : 21.41043472290039\n",
            "Train_MinReturn : -111.6492919921875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 623100\n",
            "TimeSinceStart : 509.8113558292389\n",
            "Training Loss : -0.057579170912504196\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 62 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -45.33732223510742\n",
            "Eval_StdReturn : 19.302396774291992\n",
            "Eval_MaxReturn : -18.39931297302246\n",
            "Eval_MinReturn : -62.63145065307617\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -37.852909088134766\n",
            "Train_StdReturn : 25.159643173217773\n",
            "Train_MaxReturn : 29.317121505737305\n",
            "Train_MinReturn : -108.70088958740234\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 633150\n",
            "TimeSinceStart : 520.0667581558228\n",
            "Training Loss : -0.058262601494789124\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 63 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -59.89878845214844\n",
            "Eval_StdReturn : 11.28506088256836\n",
            "Eval_MaxReturn : -47.841766357421875\n",
            "Eval_MinReturn : -74.9826889038086\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -36.66661834716797\n",
            "Train_StdReturn : 22.724149703979492\n",
            "Train_MaxReturn : 23.41029930114746\n",
            "Train_MinReturn : -85.7594223022461\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 643200\n",
            "TimeSinceStart : 532.3431832790375\n",
            "Training Loss : -0.07442941516637802\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 64 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -27.515029907226562\n",
            "Eval_StdReturn : 29.522560119628906\n",
            "Eval_MaxReturn : 11.41150951385498\n",
            "Eval_MinReturn : -60.05177307128906\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -32.144344329833984\n",
            "Train_StdReturn : 26.11575698852539\n",
            "Train_MaxReturn : 51.82464599609375\n",
            "Train_MinReturn : -112.38265991210938\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 653250\n",
            "TimeSinceStart : 539.7379236221313\n",
            "Training Loss : -0.03207840397953987\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 65 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -15.808178901672363\n",
            "Eval_StdReturn : 12.956396102905273\n",
            "Eval_MaxReturn : -6.198136329650879\n",
            "Eval_MinReturn : -34.12384796142578\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -30.548961639404297\n",
            "Train_StdReturn : 29.761659622192383\n",
            "Train_MaxReturn : 49.522071838378906\n",
            "Train_MinReturn : -111.96917724609375\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 663300\n",
            "TimeSinceStart : 547.1997485160828\n",
            "Training Loss : -0.025607436895370483\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 66 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -49.76338577270508\n",
            "Eval_StdReturn : 28.84139633178711\n",
            "Eval_MaxReturn : -13.710821151733398\n",
            "Eval_MinReturn : -84.30931091308594\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -38.520450592041016\n",
            "Train_StdReturn : 27.48330307006836\n",
            "Train_MaxReturn : 40.42766189575195\n",
            "Train_MinReturn : -108.21826934814453\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 673350\n",
            "TimeSinceStart : 555.0806601047516\n",
            "Training Loss : -0.02858768403530121\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 67 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -16.333209991455078\n",
            "Eval_StdReturn : 4.345292091369629\n",
            "Eval_MaxReturn : -10.206790924072266\n",
            "Eval_MinReturn : -19.81185531616211\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -33.52897644042969\n",
            "Train_StdReturn : 27.02506446838379\n",
            "Train_MaxReturn : 43.815731048583984\n",
            "Train_MinReturn : -119.56195831298828\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 683400\n",
            "TimeSinceStart : 562.3240661621094\n",
            "Training Loss : -0.045316070318222046\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 68 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -7.378721714019775\n",
            "Eval_StdReturn : 26.89559555053711\n",
            "Eval_MaxReturn : 30.645402908325195\n",
            "Eval_MinReturn : -27.217859268188477\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -31.751008987426758\n",
            "Train_StdReturn : 24.818946838378906\n",
            "Train_MaxReturn : 20.505916595458984\n",
            "Train_MinReturn : -91.99465942382812\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 693450\n",
            "TimeSinceStart : 569.7249705791473\n",
            "Training Loss : -0.023394295945763588\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 69 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -73.4620132446289\n",
            "Eval_StdReturn : 17.28901481628418\n",
            "Eval_MaxReturn : -53.28883361816406\n",
            "Eval_MinReturn : -95.51301574707031\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -39.158626556396484\n",
            "Train_StdReturn : 27.197158813476562\n",
            "Train_MaxReturn : 19.644804000854492\n",
            "Train_MinReturn : -109.59623718261719\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 703500\n",
            "TimeSinceStart : 577.5259606838226\n",
            "Training Loss : -0.02532377280294895\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 70 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -42.769535064697266\n",
            "Eval_StdReturn : 24.76982879638672\n",
            "Eval_MaxReturn : -9.60334587097168\n",
            "Eval_MinReturn : -69.11579895019531\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -35.76460266113281\n",
            "Train_StdReturn : 28.06142807006836\n",
            "Train_MaxReturn : 18.08050537109375\n",
            "Train_MinReturn : -126.40794372558594\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 713550\n",
            "TimeSinceStart : 585.3524899482727\n",
            "Training Loss : -0.025854650884866714\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 71 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -29.67076873779297\n",
            "Eval_StdReturn : 41.80283737182617\n",
            "Eval_MaxReturn : 11.671051979064941\n",
            "Eval_MinReturn : -86.93889617919922\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -30.70326042175293\n",
            "Train_StdReturn : 28.008129119873047\n",
            "Train_MaxReturn : 35.66383361816406\n",
            "Train_MinReturn : -130.55775451660156\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 723600\n",
            "TimeSinceStart : 593.0253365039825\n",
            "Training Loss : 0.0002697450399864465\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 72 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -42.57346725463867\n",
            "Eval_StdReturn : 3.250974416732788\n",
            "Eval_MaxReturn : -38.94049072265625\n",
            "Eval_MinReturn : -46.83011245727539\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -30.43107795715332\n",
            "Train_StdReturn : 33.47787094116211\n",
            "Train_MaxReturn : 51.10729217529297\n",
            "Train_MinReturn : -123.31159973144531\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 733650\n",
            "TimeSinceStart : 600.815376996994\n",
            "Training Loss : -0.047523822635412216\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 73 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -38.99482345581055\n",
            "Eval_StdReturn : 18.840818405151367\n",
            "Eval_MaxReturn : -18.426122665405273\n",
            "Eval_MinReturn : -63.94754409790039\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -41.05801010131836\n",
            "Train_StdReturn : 25.20793914794922\n",
            "Train_MaxReturn : 31.32587432861328\n",
            "Train_MinReturn : -130.78643798828125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 743700\n",
            "TimeSinceStart : 608.6689221858978\n",
            "Training Loss : -0.03454174846410751\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 74 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -48.12955856323242\n",
            "Eval_StdReturn : 7.535272598266602\n",
            "Eval_MaxReturn : -38.2645263671875\n",
            "Eval_MinReturn : -56.55225372314453\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -38.70151138305664\n",
            "Train_StdReturn : 31.184743881225586\n",
            "Train_MaxReturn : 45.325382232666016\n",
            "Train_MinReturn : -130.6936798095703\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 753750\n",
            "TimeSinceStart : 616.5038363933563\n",
            "Training Loss : -0.009773398749530315\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 75 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -52.00944137573242\n",
            "Eval_StdReturn : 29.243452072143555\n",
            "Eval_MaxReturn : -27.544292449951172\n",
            "Eval_MinReturn : -93.1186752319336\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -39.1611213684082\n",
            "Train_StdReturn : 28.331878662109375\n",
            "Train_MaxReturn : 26.107986450195312\n",
            "Train_MinReturn : -107.41744232177734\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 763800\n",
            "TimeSinceStart : 624.4927752017975\n",
            "Training Loss : -0.03503428399562836\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 76 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -23.00932502746582\n",
            "Eval_StdReturn : 22.193721771240234\n",
            "Eval_MaxReturn : 7.617976188659668\n",
            "Eval_MinReturn : -44.265899658203125\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -34.750370025634766\n",
            "Train_StdReturn : 29.929052352905273\n",
            "Train_MaxReturn : 49.74894714355469\n",
            "Train_MinReturn : -117.51992797851562\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 773850\n",
            "TimeSinceStart : 632.1097009181976\n",
            "Training Loss : -0.03531571850180626\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 77 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -42.59640121459961\n",
            "Eval_StdReturn : 10.723979949951172\n",
            "Eval_MaxReturn : -27.951072692871094\n",
            "Eval_MinReturn : -53.33101272583008\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -29.762243270874023\n",
            "Train_StdReturn : 26.302148818969727\n",
            "Train_MaxReturn : 30.060142517089844\n",
            "Train_MinReturn : -124.48809814453125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 783900\n",
            "TimeSinceStart : 640.0284686088562\n",
            "Training Loss : -0.08490438759326935\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 78 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -14.228583335876465\n",
            "Eval_StdReturn : 14.105875015258789\n",
            "Eval_MaxReturn : 3.9472999572753906\n",
            "Eval_MinReturn : -30.436323165893555\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -32.730403900146484\n",
            "Train_StdReturn : 26.176593780517578\n",
            "Train_MaxReturn : 19.271709442138672\n",
            "Train_MinReturn : -111.60307312011719\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 793950\n",
            "TimeSinceStart : 648.670215845108\n",
            "Training Loss : -0.017979366704821587\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 79 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -27.827550888061523\n",
            "Eval_StdReturn : 44.5971794128418\n",
            "Eval_MaxReturn : 22.177656173706055\n",
            "Eval_MinReturn : -86.11637115478516\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -35.08005142211914\n",
            "Train_StdReturn : 21.493013381958008\n",
            "Train_MaxReturn : 21.024860382080078\n",
            "Train_MinReturn : -107.45762634277344\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 804000\n",
            "TimeSinceStart : 656.1205470561981\n",
            "Training Loss : -0.03493500128388405\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 80 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -32.942039489746094\n",
            "Eval_StdReturn : 10.135644912719727\n",
            "Eval_MaxReturn : -22.961563110351562\n",
            "Eval_MinReturn : -46.84235763549805\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -31.897701263427734\n",
            "Train_StdReturn : 29.244915008544922\n",
            "Train_MaxReturn : 30.381183624267578\n",
            "Train_MinReturn : -148.72308349609375\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 814050\n",
            "TimeSinceStart : 663.5558135509491\n",
            "Training Loss : -0.04962604492902756\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 81 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -20.112253189086914\n",
            "Eval_StdReturn : 8.58682632446289\n",
            "Eval_MaxReturn : -8.854549407958984\n",
            "Eval_MinReturn : -29.68425941467285\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -25.390356063842773\n",
            "Train_StdReturn : 24.504369735717773\n",
            "Train_MaxReturn : 38.730499267578125\n",
            "Train_MinReturn : -89.65458679199219\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 824100\n",
            "TimeSinceStart : 672.4702868461609\n",
            "Training Loss : -0.061259783804416656\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 82 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -51.712860107421875\n",
            "Eval_StdReturn : 9.001222610473633\n",
            "Eval_MaxReturn : -40.07709884643555\n",
            "Eval_MinReturn : -62.001739501953125\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -30.75396728515625\n",
            "Train_StdReturn : 23.99904441833496\n",
            "Train_MaxReturn : 35.95851135253906\n",
            "Train_MinReturn : -105.5383529663086\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 834150\n",
            "TimeSinceStart : 680.2110879421234\n",
            "Training Loss : -0.02765371836721897\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 83 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -19.7253360748291\n",
            "Eval_StdReturn : 16.72847557067871\n",
            "Eval_MaxReturn : -0.46622228622436523\n",
            "Eval_MinReturn : -41.2535400390625\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -37.060325622558594\n",
            "Train_StdReturn : 19.93837547302246\n",
            "Train_MaxReturn : 13.464571952819824\n",
            "Train_MinReturn : -91.856201171875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 844200\n",
            "TimeSinceStart : 688.2684097290039\n",
            "Training Loss : -0.032477349042892456\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 84 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -46.328128814697266\n",
            "Eval_StdReturn : 6.888232707977295\n",
            "Eval_MaxReturn : -36.81387710571289\n",
            "Eval_MinReturn : -52.896575927734375\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -37.46342849731445\n",
            "Train_StdReturn : 23.577491760253906\n",
            "Train_MaxReturn : 2.7882590293884277\n",
            "Train_MinReturn : -115.89877319335938\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 854250\n",
            "TimeSinceStart : 695.8880705833435\n",
            "Training Loss : -0.021218614652752876\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 85 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1.4608486890792847\n",
            "Eval_StdReturn : 7.598947525024414\n",
            "Eval_MaxReturn : 11.596342086791992\n",
            "Eval_MinReturn : -6.700415134429932\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -33.40096664428711\n",
            "Train_StdReturn : 20.532543182373047\n",
            "Train_MaxReturn : 6.244942665100098\n",
            "Train_MinReturn : -91.1631088256836\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 864300\n",
            "TimeSinceStart : 703.3710741996765\n",
            "Training Loss : -0.033637966960668564\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 86 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -31.370119094848633\n",
            "Eval_StdReturn : 20.045753479003906\n",
            "Eval_MaxReturn : -8.335649490356445\n",
            "Eval_MinReturn : -57.19847869873047\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -29.63837432861328\n",
            "Train_StdReturn : 26.95903205871582\n",
            "Train_MaxReturn : 37.95362091064453\n",
            "Train_MinReturn : -109.01951599121094\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 874350\n",
            "TimeSinceStart : 711.3181643486023\n",
            "Training Loss : -0.061510976403951645\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 87 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -24.461578369140625\n",
            "Eval_StdReturn : 6.602841377258301\n",
            "Eval_MaxReturn : -16.132896423339844\n",
            "Eval_MinReturn : -32.28256607055664\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -29.577869415283203\n",
            "Train_StdReturn : 24.811351776123047\n",
            "Train_MaxReturn : 20.91254425048828\n",
            "Train_MinReturn : -99.64798736572266\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 884400\n",
            "TimeSinceStart : 718.9337763786316\n",
            "Training Loss : -0.034779950976371765\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 88 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -46.92667007446289\n",
            "Eval_StdReturn : 19.340747833251953\n",
            "Eval_MaxReturn : -22.908302307128906\n",
            "Eval_MinReturn : -70.26878356933594\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -33.62858963012695\n",
            "Train_StdReturn : 21.982885360717773\n",
            "Train_MaxReturn : 4.730068206787109\n",
            "Train_MinReturn : -113.79669189453125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 894450\n",
            "TimeSinceStart : 727.0645768642426\n",
            "Training Loss : -0.057099487632513046\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 89 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -28.316022872924805\n",
            "Eval_StdReturn : 39.22837448120117\n",
            "Eval_MaxReturn : 22.17510986328125\n",
            "Eval_MinReturn : -73.46842193603516\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -24.421016693115234\n",
            "Train_StdReturn : 21.28709602355957\n",
            "Train_MaxReturn : 21.243335723876953\n",
            "Train_MinReturn : -83.37275695800781\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 904500\n",
            "TimeSinceStart : 734.6862051486969\n",
            "Training Loss : -0.04125182330608368\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 90 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -18.35009765625\n",
            "Eval_StdReturn : 14.395779609680176\n",
            "Eval_MaxReturn : 0.6266049146652222\n",
            "Eval_MinReturn : -34.223690032958984\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -28.937171936035156\n",
            "Train_StdReturn : 18.50962257385254\n",
            "Train_MaxReturn : 20.762033462524414\n",
            "Train_MinReturn : -87.09992980957031\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 914550\n",
            "TimeSinceStart : 742.4400353431702\n",
            "Training Loss : -0.05871322378516197\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 91 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -32.37397766113281\n",
            "Eval_StdReturn : 15.690205574035645\n",
            "Eval_MaxReturn : -14.732693672180176\n",
            "Eval_MinReturn : -52.85063171386719\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -26.419952392578125\n",
            "Train_StdReturn : 22.830799102783203\n",
            "Train_MaxReturn : 46.722557067871094\n",
            "Train_MinReturn : -95.20977783203125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 924600\n",
            "TimeSinceStart : 750.4838862419128\n",
            "Training Loss : -0.014841320924460888\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 92 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -17.33670997619629\n",
            "Eval_StdReturn : 11.958911895751953\n",
            "Eval_MaxReturn : -0.45168161392211914\n",
            "Eval_MinReturn : -26.61301612854004\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -26.45644187927246\n",
            "Train_StdReturn : 18.91771125793457\n",
            "Train_MaxReturn : 14.58773422241211\n",
            "Train_MinReturn : -72.83058166503906\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 934650\n",
            "TimeSinceStart : 758.0693788528442\n",
            "Training Loss : -0.06655500829219818\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 93 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -9.718859672546387\n",
            "Eval_StdReturn : 7.626596927642822\n",
            "Eval_MaxReturn : 0.9585733413696289\n",
            "Eval_MinReturn : -16.377342224121094\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -24.457239151000977\n",
            "Train_StdReturn : 18.34929084777832\n",
            "Train_MaxReturn : 18.122013092041016\n",
            "Train_MinReturn : -78.10362243652344\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 944700\n",
            "TimeSinceStart : 766.4414341449738\n",
            "Training Loss : -0.02738330513238907\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 94 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -25.643463134765625\n",
            "Eval_StdReturn : 6.25577449798584\n",
            "Eval_MaxReturn : -17.454153060913086\n",
            "Eval_MinReturn : -32.636993408203125\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -27.512062072753906\n",
            "Train_StdReturn : 18.30368423461914\n",
            "Train_MaxReturn : 15.141120910644531\n",
            "Train_MinReturn : -71.45198059082031\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 954750\n",
            "TimeSinceStart : 774.1030764579773\n",
            "Training Loss : -0.018464647233486176\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 95 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -34.59550094604492\n",
            "Eval_StdReturn : 8.066439628601074\n",
            "Eval_MaxReturn : -26.196773529052734\n",
            "Eval_MinReturn : -45.48046112060547\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -22.740522384643555\n",
            "Train_StdReturn : 19.29775619506836\n",
            "Train_MaxReturn : 24.64997673034668\n",
            "Train_MinReturn : -69.0542984008789\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 964800\n",
            "TimeSinceStart : 781.5827674865723\n",
            "Training Loss : -0.062133219093084335\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 96 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -26.40033531188965\n",
            "Eval_StdReturn : 14.875880241394043\n",
            "Eval_MaxReturn : -9.187074661254883\n",
            "Eval_MinReturn : -45.48147964477539\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -25.67496109008789\n",
            "Train_StdReturn : 16.27989387512207\n",
            "Train_MaxReturn : 25.1884708404541\n",
            "Train_MinReturn : -62.7054328918457\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 974850\n",
            "TimeSinceStart : 789.2183549404144\n",
            "Training Loss : -0.03937045857310295\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 97 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -16.75449562072754\n",
            "Eval_StdReturn : 11.55799674987793\n",
            "Eval_MaxReturn : -1.1713180541992188\n",
            "Eval_MinReturn : -28.81859588623047\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -21.21456527709961\n",
            "Train_StdReturn : 16.675376892089844\n",
            "Train_MaxReturn : 19.477439880371094\n",
            "Train_MinReturn : -69.03238677978516\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 984900\n",
            "TimeSinceStart : 797.06525349617\n",
            "Training Loss : -0.03982780873775482\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 98 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -30.096603393554688\n",
            "Eval_StdReturn : 18.76365852355957\n",
            "Eval_MaxReturn : -10.958863258361816\n",
            "Eval_MinReturn : -55.584720611572266\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -29.23679542541504\n",
            "Train_StdReturn : 20.3327693939209\n",
            "Train_MaxReturn : 14.14202880859375\n",
            "Train_MinReturn : -90.86830139160156\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 994950\n",
            "TimeSinceStart : 804.792270898819\n",
            "Training Loss : -0.04794810339808464\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 99 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -46.8638916015625\n",
            "Eval_StdReturn : 13.819795608520508\n",
            "Eval_MaxReturn : -34.38351058959961\n",
            "Eval_MinReturn : -66.12944793701172\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -22.791568756103516\n",
            "Train_StdReturn : 23.4869327545166\n",
            "Train_MaxReturn : 75.36127471923828\n",
            "Train_MinReturn : -80.86571502685547\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1005000\n",
            "TimeSinceStart : 812.8781952857971\n",
            "Training Loss : -0.031203262507915497\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python cs285/scripts/run_hw2.py --env_name HalfCheetah-v2 --ep_len 150 \\\n",
        "--discount 0.95 -n 100 -l 2 -s 32 -b 10000 -lr 0.005 -rtg --nn_baseline \\\n",
        "--exp_name q4_search_b10000_lr005_rtg_nnbaseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VAdjfTss746S",
        "outputId": "80caaef3-7ae3-4211-d09a-da74744fd485"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "########################\n",
            "logging outputs to  /content/gdrive/My Drive/cs285_f2021/DRL_policy_grads/cs285/scripts/../../data/q4_search_b10000_lr01_rtg_nnbaseline_HalfCheetah-v2_06-02-2022_18-05-02\n",
            "########################\n",
            "Using GPU id 0\n",
            "Sequential(\n",
            "  (0): Linear(in_features=17, out_features=32, bias=True)\n",
            "  (1): Tanh()\n",
            "  (2): Linear(in_features=32, out_features=32, bias=True)\n",
            "  (3): Tanh()\n",
            "  (4): Linear(in_features=32, out_features=6, bias=True)\n",
            "  (5): Identity()\n",
            ")\n",
            "Sequential(\n",
            "  (0): Linear(in_features=17, out_features=32, bias=True)\n",
            "  (1): Tanh()\n",
            "  (2): Linear(in_features=32, out_features=32, bias=True)\n",
            "  (3): Tanh()\n",
            "  (4): Linear(in_features=32, out_features=1, bias=True)\n",
            "  (5): Identity()\n",
            ")\n",
            "\n",
            "\n",
            "********** Iteration 0 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -85.35540771484375\n",
            "Eval_StdReturn : 27.414653778076172\n",
            "Eval_MaxReturn : -46.792015075683594\n",
            "Eval_MinReturn : -108.10030364990234\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -87.19107055664062\n",
            "Train_StdReturn : 35.025604248046875\n",
            "Train_MaxReturn : -3.671494245529175\n",
            "Train_MinReturn : -184.59756469726562\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 10050\n",
            "TimeSinceStart : 7.372635364532471\n",
            "Training Loss : -0.07260606437921524\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 1 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -71.47059631347656\n",
            "Eval_StdReturn : 14.004693031311035\n",
            "Eval_MaxReturn : -61.56053924560547\n",
            "Eval_MinReturn : -91.2762222290039\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -92.56633758544922\n",
            "Train_StdReturn : 38.68610382080078\n",
            "Train_MaxReturn : -10.760847091674805\n",
            "Train_MinReturn : -174.70306396484375\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 20100\n",
            "TimeSinceStart : 14.656794786453247\n",
            "Training Loss : -0.08063855767250061\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 2 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -74.14533233642578\n",
            "Eval_StdReturn : 18.08232879638672\n",
            "Eval_MaxReturn : -60.86585998535156\n",
            "Eval_MinReturn : -99.711181640625\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -78.72834777832031\n",
            "Train_StdReturn : 31.250240325927734\n",
            "Train_MaxReturn : -20.78592872619629\n",
            "Train_MinReturn : -164.90061950683594\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 30150\n",
            "TimeSinceStart : 21.805161714553833\n",
            "Training Loss : -0.05414315313100815\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 3 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -40.4522819519043\n",
            "Eval_StdReturn : 18.76555824279785\n",
            "Eval_MaxReturn : -19.839078903198242\n",
            "Eval_MinReturn : -65.23442077636719\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -74.6988525390625\n",
            "Train_StdReturn : 40.92754364013672\n",
            "Train_MaxReturn : 2.247894287109375\n",
            "Train_MinReturn : -184.47303771972656\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 40200\n",
            "TimeSinceStart : 29.258933305740356\n",
            "Training Loss : -0.06310518085956573\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 4 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -43.45811080932617\n",
            "Eval_StdReturn : 13.0931978225708\n",
            "Eval_MaxReturn : -25.064109802246094\n",
            "Eval_MinReturn : -54.497222900390625\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -76.70978546142578\n",
            "Train_StdReturn : 31.195762634277344\n",
            "Train_MaxReturn : 5.110836029052734\n",
            "Train_MinReturn : -143.14169311523438\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 50250\n",
            "TimeSinceStart : 36.746750831604004\n",
            "Training Loss : -0.07741427421569824\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 5 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -67.22949981689453\n",
            "Eval_StdReturn : 8.204028129577637\n",
            "Eval_MaxReturn : -58.83940124511719\n",
            "Eval_MinReturn : -78.36456298828125\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -73.463134765625\n",
            "Train_StdReturn : 32.543941497802734\n",
            "Train_MaxReturn : -16.667377471923828\n",
            "Train_MinReturn : -182.66957092285156\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 60300\n",
            "TimeSinceStart : 44.29064869880676\n",
            "Training Loss : -0.06266788393259048\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 6 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -45.79459762573242\n",
            "Eval_StdReturn : 1.8831877708435059\n",
            "Eval_MaxReturn : -43.307186126708984\n",
            "Eval_MinReturn : -47.862430572509766\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -75.89950561523438\n",
            "Train_StdReturn : 31.102951049804688\n",
            "Train_MaxReturn : -4.081847667694092\n",
            "Train_MinReturn : -154.43637084960938\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 70350\n",
            "TimeSinceStart : 51.91892910003662\n",
            "Training Loss : -0.09529265016317368\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 7 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -60.34013748168945\n",
            "Eval_StdReturn : 32.938873291015625\n",
            "Eval_MaxReturn : -22.62628746032715\n",
            "Eval_MinReturn : -102.87623596191406\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -66.29354095458984\n",
            "Train_StdReturn : 33.0836296081543\n",
            "Train_MaxReturn : 29.452713012695312\n",
            "Train_MinReturn : -161.1830291748047\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 80400\n",
            "TimeSinceStart : 59.568835973739624\n",
            "Training Loss : -0.05841619521379471\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 8 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -66.82117462158203\n",
            "Eval_StdReturn : 13.636872291564941\n",
            "Eval_MaxReturn : -47.95882034301758\n",
            "Eval_MinReturn : -79.73159790039062\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -66.58284759521484\n",
            "Train_StdReturn : 33.21116638183594\n",
            "Train_MaxReturn : -5.545743942260742\n",
            "Train_MinReturn : -193.1562042236328\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 90450\n",
            "TimeSinceStart : 67.07981657981873\n",
            "Training Loss : -0.08184388279914856\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 9 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -69.77261352539062\n",
            "Eval_StdReturn : 45.303524017333984\n",
            "Eval_MaxReturn : -8.061256408691406\n",
            "Eval_MinReturn : -115.54121398925781\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -66.68354034423828\n",
            "Train_StdReturn : 29.886619567871094\n",
            "Train_MaxReturn : 5.6172943115234375\n",
            "Train_MinReturn : -151.96612548828125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 100500\n",
            "TimeSinceStart : 74.62770533561707\n",
            "Training Loss : -0.09912938624620438\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 10 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -85.40069580078125\n",
            "Eval_StdReturn : 29.399545669555664\n",
            "Eval_MaxReturn : -60.227752685546875\n",
            "Eval_MinReturn : -126.64448547363281\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -55.60512924194336\n",
            "Train_StdReturn : 32.0716438293457\n",
            "Train_MaxReturn : 15.001161575317383\n",
            "Train_MinReturn : -150.87896728515625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 110550\n",
            "TimeSinceStart : 82.07091546058655\n",
            "Training Loss : -0.10126382112503052\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 11 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -70.55047607421875\n",
            "Eval_StdReturn : 13.426589965820312\n",
            "Eval_MaxReturn : -56.290916442871094\n",
            "Eval_MinReturn : -88.53883361816406\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -56.2742805480957\n",
            "Train_StdReturn : 28.175729751586914\n",
            "Train_MaxReturn : 12.209188461303711\n",
            "Train_MinReturn : -129.08070373535156\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 120600\n",
            "TimeSinceStart : 89.36006331443787\n",
            "Training Loss : -0.0731111541390419\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 12 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -49.0102424621582\n",
            "Eval_StdReturn : 7.254086971282959\n",
            "Eval_MaxReturn : -40.34172058105469\n",
            "Eval_MinReturn : -58.09584045410156\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -63.351036071777344\n",
            "Train_StdReturn : 28.4578857421875\n",
            "Train_MaxReturn : 25.09769058227539\n",
            "Train_MinReturn : -125.51685333251953\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 130650\n",
            "TimeSinceStart : 97.09626507759094\n",
            "Training Loss : -0.06472283601760864\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 13 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -80.8058853149414\n",
            "Eval_StdReturn : 43.27853012084961\n",
            "Eval_MaxReturn : -46.827701568603516\n",
            "Eval_MinReturn : -141.88192749023438\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -56.40148162841797\n",
            "Train_StdReturn : 31.445646286010742\n",
            "Train_MaxReturn : 40.67229080200195\n",
            "Train_MinReturn : -145.34027099609375\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 140700\n",
            "TimeSinceStart : 104.59505319595337\n",
            "Training Loss : -0.07941707968711853\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 14 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -36.97501754760742\n",
            "Eval_StdReturn : 9.673449516296387\n",
            "Eval_MaxReturn : -24.548362731933594\n",
            "Eval_MinReturn : -48.14284896850586\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -52.82527160644531\n",
            "Train_StdReturn : 28.61266326904297\n",
            "Train_MaxReturn : 27.695404052734375\n",
            "Train_MinReturn : -116.52067565917969\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 150750\n",
            "TimeSinceStart : 112.01418662071228\n",
            "Training Loss : -0.08315152674913406\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 15 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -40.1117057800293\n",
            "Eval_StdReturn : 32.437355041503906\n",
            "Eval_MaxReturn : 2.9397850036621094\n",
            "Eval_MinReturn : -75.35604858398438\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -45.29925537109375\n",
            "Train_StdReturn : 31.92322540283203\n",
            "Train_MaxReturn : 22.87078094482422\n",
            "Train_MinReturn : -132.94229125976562\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 160800\n",
            "TimeSinceStart : 119.60103917121887\n",
            "Training Loss : -0.04751050844788551\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 16 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -56.48744583129883\n",
            "Eval_StdReturn : 14.130119323730469\n",
            "Eval_MaxReturn : -37.16756057739258\n",
            "Eval_MinReturn : -70.56857299804688\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -50.66450119018555\n",
            "Train_StdReturn : 28.251489639282227\n",
            "Train_MaxReturn : 0.7569026947021484\n",
            "Train_MinReturn : -144.29556274414062\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 170850\n",
            "TimeSinceStart : 126.91526126861572\n",
            "Training Loss : -0.06620962917804718\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 17 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -55.346710205078125\n",
            "Eval_StdReturn : 13.944196701049805\n",
            "Eval_MaxReturn : -36.181461334228516\n",
            "Eval_MinReturn : -68.95187377929688\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -46.33232116699219\n",
            "Train_StdReturn : 33.127342224121094\n",
            "Train_MaxReturn : 24.009197235107422\n",
            "Train_MinReturn : -176.11965942382812\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 180900\n",
            "TimeSinceStart : 134.61957335472107\n",
            "Training Loss : -0.08854593336582184\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 18 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -88.45606231689453\n",
            "Eval_StdReturn : 17.701435089111328\n",
            "Eval_MaxReturn : -63.74529266357422\n",
            "Eval_MinReturn : -104.2819595336914\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -54.296165466308594\n",
            "Train_StdReturn : 29.817293167114258\n",
            "Train_MaxReturn : 2.6090822219848633\n",
            "Train_MinReturn : -140.08758544921875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 190950\n",
            "TimeSinceStart : 141.94220280647278\n",
            "Training Loss : -0.07435084879398346\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 19 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -44.59934616088867\n",
            "Eval_StdReturn : 26.565956115722656\n",
            "Eval_MaxReturn : -12.610166549682617\n",
            "Eval_MinReturn : -77.65689086914062\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -52.14890670776367\n",
            "Train_StdReturn : 23.97011947631836\n",
            "Train_MaxReturn : 12.997511863708496\n",
            "Train_MinReturn : -121.11217498779297\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 201000\n",
            "TimeSinceStart : 149.22034549713135\n",
            "Training Loss : -0.04435233399271965\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 20 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -61.2145881652832\n",
            "Eval_StdReturn : 46.69062805175781\n",
            "Eval_MaxReturn : -19.085914611816406\n",
            "Eval_MinReturn : -126.31190490722656\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -44.70207977294922\n",
            "Train_StdReturn : 26.185712814331055\n",
            "Train_MaxReturn : 11.507047653198242\n",
            "Train_MinReturn : -113.68081665039062\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 211050\n",
            "TimeSinceStart : 156.90964031219482\n",
            "Training Loss : -0.05853753909468651\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 21 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -39.37309265136719\n",
            "Eval_StdReturn : 24.02275276184082\n",
            "Eval_MaxReturn : -19.29057502746582\n",
            "Eval_MinReturn : -73.14530944824219\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -50.05875778198242\n",
            "Train_StdReturn : 27.643157958984375\n",
            "Train_MaxReturn : 16.42258644104004\n",
            "Train_MinReturn : -132.31741333007812\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 221100\n",
            "TimeSinceStart : 164.07387804985046\n",
            "Training Loss : -0.04506537318229675\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 22 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -65.95091247558594\n",
            "Eval_StdReturn : 25.224403381347656\n",
            "Eval_MaxReturn : -44.84846496582031\n",
            "Eval_MinReturn : -101.41038513183594\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -45.764896392822266\n",
            "Train_StdReturn : 28.190828323364258\n",
            "Train_MaxReturn : 38.407012939453125\n",
            "Train_MinReturn : -123.83427429199219\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 231150\n",
            "TimeSinceStart : 171.80747294425964\n",
            "Training Loss : -0.04688705503940582\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 23 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -49.022003173828125\n",
            "Eval_StdReturn : 7.185969352722168\n",
            "Eval_MaxReturn : -39.35665512084961\n",
            "Eval_MinReturn : -56.57368850708008\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -50.01234817504883\n",
            "Train_StdReturn : 31.447946548461914\n",
            "Train_MaxReturn : 21.41268539428711\n",
            "Train_MinReturn : -137.06936645507812\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 241200\n",
            "TimeSinceStart : 179.08251404762268\n",
            "Training Loss : -0.06147836521267891\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 24 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -33.526954650878906\n",
            "Eval_StdReturn : 18.25554084777832\n",
            "Eval_MaxReturn : -14.963579177856445\n",
            "Eval_MinReturn : -58.34723663330078\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -46.1358642578125\n",
            "Train_StdReturn : 27.856599807739258\n",
            "Train_MaxReturn : -0.5082318782806396\n",
            "Train_MinReturn : -137.92181396484375\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 251250\n",
            "TimeSinceStart : 186.1994023323059\n",
            "Training Loss : -0.05492188781499863\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 25 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -30.66405487060547\n",
            "Eval_StdReturn : 4.142661094665527\n",
            "Eval_MaxReturn : -27.124319076538086\n",
            "Eval_MinReturn : -36.476837158203125\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -43.89330291748047\n",
            "Train_StdReturn : 28.24858283996582\n",
            "Train_MaxReturn : 27.77940559387207\n",
            "Train_MinReturn : -113.80770111083984\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 261300\n",
            "TimeSinceStart : 193.48010993003845\n",
            "Training Loss : -0.06418877094984055\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 26 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -36.33864974975586\n",
            "Eval_StdReturn : 1.6401822566986084\n",
            "Eval_MaxReturn : -34.175086975097656\n",
            "Eval_MinReturn : -38.144683837890625\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -39.57756423950195\n",
            "Train_StdReturn : 28.080982208251953\n",
            "Train_MaxReturn : 50.38961410522461\n",
            "Train_MinReturn : -106.28343200683594\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 271350\n",
            "TimeSinceStart : 200.6259162425995\n",
            "Training Loss : -0.06789585947990417\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 27 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -42.021236419677734\n",
            "Eval_StdReturn : 41.10491943359375\n",
            "Eval_MaxReturn : 2.079909324645996\n",
            "Eval_MinReturn : -96.87025451660156\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -39.379920959472656\n",
            "Train_StdReturn : 24.190080642700195\n",
            "Train_MaxReturn : 23.424596786499023\n",
            "Train_MinReturn : -97.22990417480469\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 281400\n",
            "TimeSinceStart : 207.83453559875488\n",
            "Training Loss : -0.01655152067542076\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 28 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -27.357030868530273\n",
            "Eval_StdReturn : 5.489522457122803\n",
            "Eval_MaxReturn : -20.264236450195312\n",
            "Eval_MinReturn : -33.6368293762207\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -36.92445373535156\n",
            "Train_StdReturn : 27.074804306030273\n",
            "Train_MaxReturn : 45.192474365234375\n",
            "Train_MinReturn : -117.21786499023438\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 291450\n",
            "TimeSinceStart : 215.76257991790771\n",
            "Training Loss : -0.03275672346353531\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 29 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -64.53546142578125\n",
            "Eval_StdReturn : 44.162086486816406\n",
            "Eval_MaxReturn : -30.223636627197266\n",
            "Eval_MinReturn : -126.88494873046875\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -34.91654586791992\n",
            "Train_StdReturn : 27.478796005249023\n",
            "Train_MaxReturn : 7.684571743011475\n",
            "Train_MinReturn : -112.6932144165039\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 301500\n",
            "TimeSinceStart : 223.25514388084412\n",
            "Training Loss : -0.04652835801243782\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 30 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -31.69481086730957\n",
            "Eval_StdReturn : 19.207895278930664\n",
            "Eval_MaxReturn : -8.699180603027344\n",
            "Eval_MinReturn : -55.71522903442383\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -37.45535659790039\n",
            "Train_StdReturn : 30.192045211791992\n",
            "Train_MaxReturn : 34.1473388671875\n",
            "Train_MinReturn : -114.9894790649414\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 311550\n",
            "TimeSinceStart : 230.54030060768127\n",
            "Training Loss : -0.050616536289453506\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 31 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -30.791898727416992\n",
            "Eval_StdReturn : 36.77488708496094\n",
            "Eval_MaxReturn : 7.282934665679932\n",
            "Eval_MinReturn : -80.51023864746094\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -39.7354850769043\n",
            "Train_StdReturn : 30.782577514648438\n",
            "Train_MaxReturn : 24.276214599609375\n",
            "Train_MinReturn : -110.94743347167969\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 321600\n",
            "TimeSinceStart : 238.0338213443756\n",
            "Training Loss : -0.017686640843749046\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 32 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -46.41915512084961\n",
            "Eval_StdReturn : 8.457576751708984\n",
            "Eval_MaxReturn : -34.80574035644531\n",
            "Eval_MinReturn : -54.704246520996094\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -35.61078643798828\n",
            "Train_StdReturn : 27.980770111083984\n",
            "Train_MaxReturn : 24.511110305786133\n",
            "Train_MinReturn : -124.09954071044922\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 331650\n",
            "TimeSinceStart : 245.53611540794373\n",
            "Training Loss : 0.012630658224225044\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 33 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -56.17471694946289\n",
            "Eval_StdReturn : 16.690412521362305\n",
            "Eval_MaxReturn : -35.7821044921875\n",
            "Eval_MinReturn : -76.66474914550781\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -43.029869079589844\n",
            "Train_StdReturn : 29.124446868896484\n",
            "Train_MaxReturn : 32.50754165649414\n",
            "Train_MinReturn : -139.13148498535156\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 341700\n",
            "TimeSinceStart : 253.50809860229492\n",
            "Training Loss : -0.020234325900673866\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 34 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -20.541051864624023\n",
            "Eval_StdReturn : 12.397655487060547\n",
            "Eval_MaxReturn : -3.024139404296875\n",
            "Eval_MinReturn : -29.948448181152344\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -36.568790435791016\n",
            "Train_StdReturn : 23.277040481567383\n",
            "Train_MaxReturn : 17.098100662231445\n",
            "Train_MinReturn : -97.29420471191406\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 351750\n",
            "TimeSinceStart : 261.0802516937256\n",
            "Training Loss : -0.06911256909370422\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 35 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -24.95261573791504\n",
            "Eval_StdReturn : 16.060407638549805\n",
            "Eval_MaxReturn : -9.906609535217285\n",
            "Eval_MinReturn : -47.21055221557617\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -35.46187973022461\n",
            "Train_StdReturn : 29.310199737548828\n",
            "Train_MaxReturn : 21.93579864501953\n",
            "Train_MinReturn : -124.67863464355469\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 361800\n",
            "TimeSinceStart : 268.55468463897705\n",
            "Training Loss : -0.027642367407679558\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 36 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -11.930347442626953\n",
            "Eval_StdReturn : 5.4766364097595215\n",
            "Eval_MaxReturn : -7.626018047332764\n",
            "Eval_MinReturn : -19.658790588378906\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -30.056400299072266\n",
            "Train_StdReturn : 21.893470764160156\n",
            "Train_MaxReturn : 28.503843307495117\n",
            "Train_MinReturn : -101.28390502929688\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 371850\n",
            "TimeSinceStart : 275.78793835639954\n",
            "Training Loss : -0.0343816764652729\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 37 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -41.93422317504883\n",
            "Eval_StdReturn : 9.802714347839355\n",
            "Eval_MaxReturn : -29.459117889404297\n",
            "Eval_MinReturn : -53.40805435180664\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -37.084354400634766\n",
            "Train_StdReturn : 30.439971923828125\n",
            "Train_MaxReturn : 25.120820999145508\n",
            "Train_MinReturn : -119.51376342773438\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 381900\n",
            "TimeSinceStart : 283.0462782382965\n",
            "Training Loss : -0.04793935641646385\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 38 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -36.6727180480957\n",
            "Eval_StdReturn : 13.79903793334961\n",
            "Eval_MaxReturn : -17.821815490722656\n",
            "Eval_MinReturn : -50.468841552734375\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -37.70531463623047\n",
            "Train_StdReturn : 25.074825286865234\n",
            "Train_MaxReturn : 10.282522201538086\n",
            "Train_MinReturn : -103.58655548095703\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 391950\n",
            "TimeSinceStart : 290.7346749305725\n",
            "Training Loss : -0.02814190834760666\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 39 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -45.660858154296875\n",
            "Eval_StdReturn : 18.240238189697266\n",
            "Eval_MaxReturn : -28.31324005126953\n",
            "Eval_MinReturn : -70.86810302734375\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -30.088916778564453\n",
            "Train_StdReturn : 30.039052963256836\n",
            "Train_MaxReturn : 59.039215087890625\n",
            "Train_MinReturn : -137.68228149414062\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 402000\n",
            "TimeSinceStart : 298.59682416915894\n",
            "Training Loss : -0.03033297322690487\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 40 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -57.76887893676758\n",
            "Eval_StdReturn : 39.046932220458984\n",
            "Eval_MaxReturn : -19.491539001464844\n",
            "Eval_MinReturn : -111.37678527832031\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -36.34149169921875\n",
            "Train_StdReturn : 23.470394134521484\n",
            "Train_MaxReturn : 25.204442977905273\n",
            "Train_MinReturn : -99.43579864501953\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 412050\n",
            "TimeSinceStart : 305.9921727180481\n",
            "Training Loss : -0.04626305773854256\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 41 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -51.31557846069336\n",
            "Eval_StdReturn : 32.2132568359375\n",
            "Eval_MaxReturn : -24.990158081054688\n",
            "Eval_MinReturn : -96.67720031738281\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -28.34330177307129\n",
            "Train_StdReturn : 19.523204803466797\n",
            "Train_MaxReturn : 27.127830505371094\n",
            "Train_MinReturn : -86.19715881347656\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 422100\n",
            "TimeSinceStart : 313.48272728919983\n",
            "Training Loss : -0.059715911746025085\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 42 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -14.999080657958984\n",
            "Eval_StdReturn : 5.479330062866211\n",
            "Eval_MaxReturn : -7.90364933013916\n",
            "Eval_MinReturn : -21.244152069091797\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -32.82013702392578\n",
            "Train_StdReturn : 19.19075584411621\n",
            "Train_MaxReturn : 7.766933917999268\n",
            "Train_MinReturn : -81.01818084716797\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 432150\n",
            "TimeSinceStart : 321.14128947257996\n",
            "Training Loss : -0.033743295818567276\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 43 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -26.226518630981445\n",
            "Eval_StdReturn : 13.256617546081543\n",
            "Eval_MaxReturn : -8.340723037719727\n",
            "Eval_MinReturn : -40.03568649291992\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -24.186500549316406\n",
            "Train_StdReturn : 25.995498657226562\n",
            "Train_MaxReturn : 29.54875946044922\n",
            "Train_MinReturn : -89.5625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 442200\n",
            "TimeSinceStart : 328.29039001464844\n",
            "Training Loss : -0.037400953471660614\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 44 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -21.558610916137695\n",
            "Eval_StdReturn : 15.745951652526855\n",
            "Eval_MaxReturn : -4.416288375854492\n",
            "Eval_MinReturn : -42.43863296508789\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -28.226768493652344\n",
            "Train_StdReturn : 23.13726234436035\n",
            "Train_MaxReturn : 23.284835815429688\n",
            "Train_MinReturn : -80.7106704711914\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 452250\n",
            "TimeSinceStart : 335.81764674186707\n",
            "Training Loss : -0.013815845362842083\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 45 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -44.26918411254883\n",
            "Eval_StdReturn : 7.563469409942627\n",
            "Eval_MaxReturn : -34.0380973815918\n",
            "Eval_MinReturn : -52.08708572387695\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -31.44495964050293\n",
            "Train_StdReturn : 16.61350440979004\n",
            "Train_MaxReturn : 11.557021141052246\n",
            "Train_MinReturn : -62.10780715942383\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 462300\n",
            "TimeSinceStart : 343.07670521736145\n",
            "Training Loss : -0.03495718538761139\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 46 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -32.62031555175781\n",
            "Eval_StdReturn : 12.261667251586914\n",
            "Eval_MaxReturn : -20.571197509765625\n",
            "Eval_MinReturn : -49.444725036621094\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -32.22139358520508\n",
            "Train_StdReturn : 26.95395278930664\n",
            "Train_MaxReturn : 51.450286865234375\n",
            "Train_MinReturn : -95.23153686523438\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 472350\n",
            "TimeSinceStart : 350.6594412326813\n",
            "Training Loss : 0.008451620116829872\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 47 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -20.696401596069336\n",
            "Eval_StdReturn : 4.727893829345703\n",
            "Eval_MaxReturn : -14.880793571472168\n",
            "Eval_MinReturn : -26.461389541625977\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -32.0102653503418\n",
            "Train_StdReturn : 27.27041244506836\n",
            "Train_MaxReturn : 60.0940055847168\n",
            "Train_MinReturn : -84.42296600341797\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 482400\n",
            "TimeSinceStart : 358.2438826560974\n",
            "Training Loss : -0.03877098113298416\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 48 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -9.731154441833496\n",
            "Eval_StdReturn : 8.942306518554688\n",
            "Eval_MaxReturn : 2.6340599060058594\n",
            "Eval_MinReturn : -18.21014404296875\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -33.4046630859375\n",
            "Train_StdReturn : 23.336063385009766\n",
            "Train_MaxReturn : 23.214900970458984\n",
            "Train_MinReturn : -97.47478485107422\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 492450\n",
            "TimeSinceStart : 366.05295276641846\n",
            "Training Loss : -0.014789586886763573\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 49 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -19.16978645324707\n",
            "Eval_StdReturn : 13.334660530090332\n",
            "Eval_MaxReturn : -4.667518615722656\n",
            "Eval_MinReturn : -36.860408782958984\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -37.651519775390625\n",
            "Train_StdReturn : 26.07206916809082\n",
            "Train_MaxReturn : 31.248027801513672\n",
            "Train_MinReturn : -100.03544616699219\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 502500\n",
            "TimeSinceStart : 373.6749165058136\n",
            "Training Loss : -0.05353674292564392\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 50 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -31.348012924194336\n",
            "Eval_StdReturn : 24.180906295776367\n",
            "Eval_MaxReturn : -11.91819953918457\n",
            "Eval_MinReturn : -65.43372344970703\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -33.66318130493164\n",
            "Train_StdReturn : 23.54723358154297\n",
            "Train_MaxReturn : 19.652122497558594\n",
            "Train_MinReturn : -100.33727264404297\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 512550\n",
            "TimeSinceStart : 381.0822913646698\n",
            "Training Loss : -0.01617124304175377\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 51 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -24.127660751342773\n",
            "Eval_StdReturn : 4.138010025024414\n",
            "Eval_MaxReturn : -18.380062103271484\n",
            "Eval_MinReturn : -27.954631805419922\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -34.791568756103516\n",
            "Train_StdReturn : 22.602006912231445\n",
            "Train_MaxReturn : 16.383695602416992\n",
            "Train_MinReturn : -87.05934143066406\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 522600\n",
            "TimeSinceStart : 388.8779857158661\n",
            "Training Loss : -0.013086550869047642\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 52 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -33.70547866821289\n",
            "Eval_StdReturn : 1.051289677619934\n",
            "Eval_MaxReturn : -32.56536865234375\n",
            "Eval_MinReturn : -35.1019287109375\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -31.170883178710938\n",
            "Train_StdReturn : 20.861299514770508\n",
            "Train_MaxReturn : 13.13011646270752\n",
            "Train_MinReturn : -86.10306549072266\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 532650\n",
            "TimeSinceStart : 396.37247800827026\n",
            "Training Loss : -0.03019201010465622\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 53 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -45.43714904785156\n",
            "Eval_StdReturn : 12.96387004852295\n",
            "Eval_MaxReturn : -28.550697326660156\n",
            "Eval_MinReturn : -60.06331253051758\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -34.88277053833008\n",
            "Train_StdReturn : 23.76237678527832\n",
            "Train_MaxReturn : 17.999996185302734\n",
            "Train_MinReturn : -93.5427017211914\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 542700\n",
            "TimeSinceStart : 403.6620571613312\n",
            "Training Loss : -0.021670954301953316\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 54 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -21.679906845092773\n",
            "Eval_StdReturn : 21.86734962463379\n",
            "Eval_MaxReturn : 6.014862060546875\n",
            "Eval_MinReturn : -47.44456100463867\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -32.29979705810547\n",
            "Train_StdReturn : 21.189090728759766\n",
            "Train_MaxReturn : 21.449817657470703\n",
            "Train_MinReturn : -73.44862365722656\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 552750\n",
            "TimeSinceStart : 411.33130979537964\n",
            "Training Loss : -0.010895121842622757\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 55 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -20.16681480407715\n",
            "Eval_StdReturn : 4.192378997802734\n",
            "Eval_MaxReturn : -14.556195259094238\n",
            "Eval_MinReturn : -24.63187599182129\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -27.441307067871094\n",
            "Train_StdReturn : 17.743234634399414\n",
            "Train_MaxReturn : 13.786996841430664\n",
            "Train_MinReturn : -95.9254150390625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 562800\n",
            "TimeSinceStart : 419.06753754615784\n",
            "Training Loss : -0.04349180683493614\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 56 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -28.049575805664062\n",
            "Eval_StdReturn : 9.565950393676758\n",
            "Eval_MaxReturn : -14.521794319152832\n",
            "Eval_MinReturn : -34.91575622558594\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -28.601858139038086\n",
            "Train_StdReturn : 22.793785095214844\n",
            "Train_MaxReturn : 22.72299575805664\n",
            "Train_MinReturn : -124.43180847167969\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 572850\n",
            "TimeSinceStart : 427.31911396980286\n",
            "Training Loss : -0.02981681004166603\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 57 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -21.95979881286621\n",
            "Eval_StdReturn : 12.492473602294922\n",
            "Eval_MaxReturn : -4.7751312255859375\n",
            "Eval_MinReturn : -34.102943420410156\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -27.811992645263672\n",
            "Train_StdReturn : 19.1901912689209\n",
            "Train_MaxReturn : 9.055929183959961\n",
            "Train_MinReturn : -73.95285034179688\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 582900\n",
            "TimeSinceStart : 435.4371838569641\n",
            "Training Loss : -0.036986444145441055\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 58 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -28.0767879486084\n",
            "Eval_StdReturn : 11.535806655883789\n",
            "Eval_MaxReturn : -13.841294288635254\n",
            "Eval_MinReturn : -42.09564208984375\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -24.466552734375\n",
            "Train_StdReturn : 16.689817428588867\n",
            "Train_MaxReturn : 15.659196853637695\n",
            "Train_MinReturn : -65.08290100097656\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 592950\n",
            "TimeSinceStart : 443.4506425857544\n",
            "Training Loss : -0.007714090868830681\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 59 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -37.08580017089844\n",
            "Eval_StdReturn : 5.06208610534668\n",
            "Eval_MaxReturn : -30.012907028198242\n",
            "Eval_MinReturn : -41.58021545410156\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -26.677148818969727\n",
            "Train_StdReturn : 14.963082313537598\n",
            "Train_MaxReturn : 1.422856330871582\n",
            "Train_MinReturn : -61.40673828125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 603000\n",
            "TimeSinceStart : 451.3414137363434\n",
            "Training Loss : -0.03342980146408081\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 60 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -17.148414611816406\n",
            "Eval_StdReturn : 22.628873825073242\n",
            "Eval_MaxReturn : 12.30172061920166\n",
            "Eval_MinReturn : -42.71857452392578\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -20.5814208984375\n",
            "Train_StdReturn : 18.52580451965332\n",
            "Train_MaxReturn : 14.824309349060059\n",
            "Train_MinReturn : -76.65821838378906\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 613050\n",
            "TimeSinceStart : 459.58522605895996\n",
            "Training Loss : -0.05944975093007088\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 61 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -19.97486686706543\n",
            "Eval_StdReturn : 14.939492225646973\n",
            "Eval_MaxReturn : -8.586874008178711\n",
            "Eval_MinReturn : -41.08047866821289\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -27.46631622314453\n",
            "Train_StdReturn : 20.878095626831055\n",
            "Train_MaxReturn : 9.686193466186523\n",
            "Train_MinReturn : -102.71978759765625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 623100\n",
            "TimeSinceStart : 467.564569234848\n",
            "Training Loss : -0.04016253724694252\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 62 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -44.0275764465332\n",
            "Eval_StdReturn : 44.61497497558594\n",
            "Eval_MaxReturn : -11.924269676208496\n",
            "Eval_MinReturn : -107.11940002441406\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -27.50286865234375\n",
            "Train_StdReturn : 21.433460235595703\n",
            "Train_MaxReturn : 4.163193225860596\n",
            "Train_MinReturn : -136.939453125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 633150\n",
            "TimeSinceStart : 474.99200344085693\n",
            "Training Loss : -0.03856414929032326\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 63 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -27.305984497070312\n",
            "Eval_StdReturn : 0.9784289598464966\n",
            "Eval_MaxReturn : -25.92337989807129\n",
            "Eval_MinReturn : -28.04511070251465\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -19.753267288208008\n",
            "Train_StdReturn : 19.726022720336914\n",
            "Train_MaxReturn : 13.029607772827148\n",
            "Train_MinReturn : -78.62786865234375\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 643200\n",
            "TimeSinceStart : 482.67228412628174\n",
            "Training Loss : -0.048033662140369415\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 64 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -12.660228729248047\n",
            "Eval_StdReturn : 16.54005241394043\n",
            "Eval_MaxReturn : 9.042386054992676\n",
            "Eval_MinReturn : -31.0684814453125\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -24.38022232055664\n",
            "Train_StdReturn : 27.529611587524414\n",
            "Train_MaxReturn : 17.808141708374023\n",
            "Train_MinReturn : -118.41563415527344\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 653250\n",
            "TimeSinceStart : 490.2410714626312\n",
            "Training Loss : -0.03885294124484062\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 65 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -24.98095703125\n",
            "Eval_StdReturn : 15.510518074035645\n",
            "Eval_MaxReturn : -4.1476149559021\n",
            "Eval_MinReturn : -41.34263610839844\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -23.27425765991211\n",
            "Train_StdReturn : 24.662494659423828\n",
            "Train_MaxReturn : 39.189598083496094\n",
            "Train_MinReturn : -98.89349365234375\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 663300\n",
            "TimeSinceStart : 497.8813199996948\n",
            "Training Loss : -0.033063601702451706\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 66 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -37.35308074951172\n",
            "Eval_StdReturn : 28.1568546295166\n",
            "Eval_MaxReturn : -5.1784443855285645\n",
            "Eval_MinReturn : -73.758056640625\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -22.486421585083008\n",
            "Train_StdReturn : 22.75667381286621\n",
            "Train_MaxReturn : 31.74740219116211\n",
            "Train_MinReturn : -102.4991455078125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 673350\n",
            "TimeSinceStart : 505.53392910957336\n",
            "Training Loss : -0.050740841776132584\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 67 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -5.584917068481445\n",
            "Eval_StdReturn : 5.186030864715576\n",
            "Eval_MaxReturn : 1.6477445363998413\n",
            "Eval_MinReturn : -10.254255294799805\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -20.67158317565918\n",
            "Train_StdReturn : 21.85667610168457\n",
            "Train_MaxReturn : 27.828916549682617\n",
            "Train_MinReturn : -95.65662384033203\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 683400\n",
            "TimeSinceStart : 513.282653093338\n",
            "Training Loss : -0.0314718633890152\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 68 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -34.20427322387695\n",
            "Eval_StdReturn : 28.64461326599121\n",
            "Eval_MaxReturn : 1.1040496826171875\n",
            "Eval_MinReturn : -69.05618286132812\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -19.02943992614746\n",
            "Train_StdReturn : 18.729812622070312\n",
            "Train_MaxReturn : 15.525405883789062\n",
            "Train_MinReturn : -60.65300750732422\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 693450\n",
            "TimeSinceStart : 520.7742924690247\n",
            "Training Loss : -0.046204034239053726\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 69 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -24.537160873413086\n",
            "Eval_StdReturn : 17.339466094970703\n",
            "Eval_MaxReturn : -11.877270698547363\n",
            "Eval_MinReturn : -49.05449295043945\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -17.916196823120117\n",
            "Train_StdReturn : 20.29941749572754\n",
            "Train_MaxReturn : 21.924915313720703\n",
            "Train_MinReturn : -83.86917114257812\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 703500\n",
            "TimeSinceStart : 528.3799531459808\n",
            "Training Loss : -0.04277754947543144\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 70 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -35.88190841674805\n",
            "Eval_StdReturn : 33.080650329589844\n",
            "Eval_MaxReturn : -3.0589704513549805\n",
            "Eval_MinReturn : -81.16352081298828\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -16.766529083251953\n",
            "Train_StdReturn : 24.46271324157715\n",
            "Train_MaxReturn : 32.03465270996094\n",
            "Train_MinReturn : -94.11984252929688\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 713550\n",
            "TimeSinceStart : 536.181964635849\n",
            "Training Loss : -0.027633123099803925\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 71 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -35.4776725769043\n",
            "Eval_StdReturn : 28.754730224609375\n",
            "Eval_MaxReturn : -6.114169120788574\n",
            "Eval_MinReturn : -74.52313232421875\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -16.25881004333496\n",
            "Train_StdReturn : 19.761289596557617\n",
            "Train_MaxReturn : 35.762046813964844\n",
            "Train_MinReturn : -58.4201545715332\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 723600\n",
            "TimeSinceStart : 544.139812707901\n",
            "Training Loss : -0.037045352160930634\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 72 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -18.334138870239258\n",
            "Eval_StdReturn : 15.037542343139648\n",
            "Eval_MaxReturn : -3.9262380599975586\n",
            "Eval_MinReturn : -39.08433532714844\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -22.382490158081055\n",
            "Train_StdReturn : 23.218273162841797\n",
            "Train_MaxReturn : 26.891742706298828\n",
            "Train_MinReturn : -120.1958236694336\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 733650\n",
            "TimeSinceStart : 552.4154255390167\n",
            "Training Loss : -0.008373464457690716\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 73 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -31.36203956604004\n",
            "Eval_StdReturn : 24.35719108581543\n",
            "Eval_MaxReturn : 2.3485164642333984\n",
            "Eval_MinReturn : -54.349849700927734\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -20.93682098388672\n",
            "Train_StdReturn : 22.57417869567871\n",
            "Train_MaxReturn : 24.244348526000977\n",
            "Train_MinReturn : -110.69111633300781\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 743700\n",
            "TimeSinceStart : 560.2551209926605\n",
            "Training Loss : -0.040427155792713165\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 74 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -12.297383308410645\n",
            "Eval_StdReturn : 23.297101974487305\n",
            "Eval_MaxReturn : 12.520493507385254\n",
            "Eval_MinReturn : -43.47297286987305\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -17.39945411682129\n",
            "Train_StdReturn : 21.95612907409668\n",
            "Train_MaxReturn : 36.56507110595703\n",
            "Train_MinReturn : -83.02025604248047\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 753750\n",
            "TimeSinceStart : 567.431040763855\n",
            "Training Loss : -0.005094698630273342\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 75 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -0.7495346069335938\n",
            "Eval_StdReturn : 18.856443405151367\n",
            "Eval_MaxReturn : 19.8426513671875\n",
            "Eval_MinReturn : -25.719398498535156\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -22.14500617980957\n",
            "Train_StdReturn : 20.117870330810547\n",
            "Train_MaxReturn : 30.453630447387695\n",
            "Train_MinReturn : -70.71803283691406\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 763800\n",
            "TimeSinceStart : 574.8512496948242\n",
            "Training Loss : -0.010865554213523865\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 76 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -29.20203399658203\n",
            "Eval_StdReturn : 11.158382415771484\n",
            "Eval_MaxReturn : -20.910310745239258\n",
            "Eval_MinReturn : -44.97543716430664\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -19.340801239013672\n",
            "Train_StdReturn : 20.67096710205078\n",
            "Train_MaxReturn : 38.72269058227539\n",
            "Train_MinReturn : -72.3145523071289\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 773850\n",
            "TimeSinceStart : 582.5044965744019\n",
            "Training Loss : 0.005599371623247862\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 77 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -3.652557373046875\n",
            "Eval_StdReturn : 6.951887130737305\n",
            "Eval_MaxReturn : 1.41023588180542\n",
            "Eval_MinReturn : -13.482528686523438\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -16.271678924560547\n",
            "Train_StdReturn : 20.68346405029297\n",
            "Train_MaxReturn : 19.642337799072266\n",
            "Train_MinReturn : -80.39312744140625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 783900\n",
            "TimeSinceStart : 590.0265274047852\n",
            "Training Loss : -0.040125586092472076\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 78 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -5.640449523925781\n",
            "Eval_StdReturn : 11.851191520690918\n",
            "Eval_MaxReturn : 7.590394020080566\n",
            "Eval_MinReturn : -21.165679931640625\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -19.896108627319336\n",
            "Train_StdReturn : 22.03519630432129\n",
            "Train_MaxReturn : 26.693037033081055\n",
            "Train_MinReturn : -94.13116455078125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 793950\n",
            "TimeSinceStart : 597.7516837120056\n",
            "Training Loss : -0.006699917372316122\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 79 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -14.39647388458252\n",
            "Eval_StdReturn : 22.434955596923828\n",
            "Eval_MaxReturn : 4.954217910766602\n",
            "Eval_MinReturn : -45.846893310546875\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -16.86739158630371\n",
            "Train_StdReturn : 19.734512329101562\n",
            "Train_MaxReturn : 28.513378143310547\n",
            "Train_MinReturn : -67.24026489257812\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 804000\n",
            "TimeSinceStart : 605.1757416725159\n",
            "Training Loss : -0.03048519603908062\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 80 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -14.942886352539062\n",
            "Eval_StdReturn : 17.841394424438477\n",
            "Eval_MaxReturn : 6.073475360870361\n",
            "Eval_MinReturn : -37.542694091796875\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -19.62127685546875\n",
            "Train_StdReturn : 22.790319442749023\n",
            "Train_MaxReturn : 30.204421997070312\n",
            "Train_MinReturn : -129.37118530273438\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 814050\n",
            "TimeSinceStart : 612.934513092041\n",
            "Training Loss : -0.021865131333470345\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 81 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -11.579628944396973\n",
            "Eval_StdReturn : 7.990265369415283\n",
            "Eval_MaxReturn : -5.911015510559082\n",
            "Eval_MinReturn : -22.87955093383789\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -16.176603317260742\n",
            "Train_StdReturn : 22.407075881958008\n",
            "Train_MaxReturn : 31.836593627929688\n",
            "Train_MinReturn : -111.90624237060547\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 824100\n",
            "TimeSinceStart : 620.565153837204\n",
            "Training Loss : -0.03303215280175209\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 82 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -3.64208722114563\n",
            "Eval_StdReturn : 3.147167444229126\n",
            "Eval_MaxReturn : -0.5201644897460938\n",
            "Eval_MinReturn : -7.950263977050781\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -17.046457290649414\n",
            "Train_StdReturn : 21.695899963378906\n",
            "Train_MaxReturn : 22.390605926513672\n",
            "Train_MinReturn : -111.96733093261719\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 834150\n",
            "TimeSinceStart : 628.3291654586792\n",
            "Training Loss : -0.023923462256789207\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 83 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -18.45659828186035\n",
            "Eval_StdReturn : 13.19734001159668\n",
            "Eval_MaxReturn : -7.760556221008301\n",
            "Eval_MinReturn : -37.05039978027344\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -16.592714309692383\n",
            "Train_StdReturn : 21.17463493347168\n",
            "Train_MaxReturn : 41.78585433959961\n",
            "Train_MinReturn : -115.6683349609375\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 844200\n",
            "TimeSinceStart : 636.2312252521515\n",
            "Training Loss : 0.013134146109223366\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 84 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -20.023569107055664\n",
            "Eval_StdReturn : 14.770709991455078\n",
            "Eval_MaxReturn : 0.8349294662475586\n",
            "Eval_MinReturn : -31.429092407226562\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -17.24136734008789\n",
            "Train_StdReturn : 18.453828811645508\n",
            "Train_MaxReturn : 29.136821746826172\n",
            "Train_MinReturn : -66.70156860351562\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 854250\n",
            "TimeSinceStart : 643.9182152748108\n",
            "Training Loss : -0.012293336912989616\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 85 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -20.773576736450195\n",
            "Eval_StdReturn : 11.234368324279785\n",
            "Eval_MaxReturn : -5.844727516174316\n",
            "Eval_MinReturn : -32.94582748413086\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -14.940580368041992\n",
            "Train_StdReturn : 18.1958065032959\n",
            "Train_MaxReturn : 26.24339485168457\n",
            "Train_MinReturn : -64.82828521728516\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 864300\n",
            "TimeSinceStart : 651.7294480800629\n",
            "Training Loss : -0.05032402649521828\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 86 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -11.899612426757812\n",
            "Eval_StdReturn : 19.358612060546875\n",
            "Eval_MaxReturn : 10.187566757202148\n",
            "Eval_MinReturn : -36.952171325683594\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -14.288300514221191\n",
            "Train_StdReturn : 20.323074340820312\n",
            "Train_MaxReturn : 42.89344024658203\n",
            "Train_MinReturn : -72.64051818847656\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 874350\n",
            "TimeSinceStart : 659.7181267738342\n",
            "Training Loss : -0.016677437350153923\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 87 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -23.795217514038086\n",
            "Eval_StdReturn : 8.336487770080566\n",
            "Eval_MaxReturn : -12.088375091552734\n",
            "Eval_MinReturn : -30.8560791015625\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -23.287443161010742\n",
            "Train_StdReturn : 17.218490600585938\n",
            "Train_MaxReturn : 14.502554893493652\n",
            "Train_MinReturn : -69.44229888916016\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 884400\n",
            "TimeSinceStart : 667.336989402771\n",
            "Training Loss : -0.006453912239521742\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 88 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -18.584211349487305\n",
            "Eval_StdReturn : 8.638728141784668\n",
            "Eval_MaxReturn : -6.372485160827637\n",
            "Eval_MinReturn : -25.001089096069336\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -22.92733383178711\n",
            "Train_StdReturn : 22.951745986938477\n",
            "Train_MaxReturn : 24.41609001159668\n",
            "Train_MinReturn : -116.06077575683594\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 894450\n",
            "TimeSinceStart : 675.1304912567139\n",
            "Training Loss : -0.04116763547062874\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 89 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -19.22208595275879\n",
            "Eval_StdReturn : 5.153407573699951\n",
            "Eval_MaxReturn : -13.982723236083984\n",
            "Eval_MinReturn : -26.229047775268555\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -12.814505577087402\n",
            "Train_StdReturn : 20.47303581237793\n",
            "Train_MaxReturn : 35.24252700805664\n",
            "Train_MinReturn : -63.56843185424805\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 904500\n",
            "TimeSinceStart : 683.36869764328\n",
            "Training Loss : -0.01639265939593315\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 90 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 5.513980865478516\n",
            "Eval_StdReturn : 1.5391476154327393\n",
            "Eval_MaxReturn : 7.488954067230225\n",
            "Eval_MinReturn : 3.733983039855957\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -13.857853889465332\n",
            "Train_StdReturn : 18.83753776550293\n",
            "Train_MaxReturn : 20.24117660522461\n",
            "Train_MinReturn : -62.73337936401367\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 914550\n",
            "TimeSinceStart : 690.6040208339691\n",
            "Training Loss : -0.04277174919843674\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 91 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -14.967013359069824\n",
            "Eval_StdReturn : 9.507633209228516\n",
            "Eval_MaxReturn : -1.6926015615463257\n",
            "Eval_MinReturn : -23.457626342773438\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -11.442777633666992\n",
            "Train_StdReturn : 14.828344345092773\n",
            "Train_MaxReturn : 17.407833099365234\n",
            "Train_MinReturn : -48.2364387512207\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 924600\n",
            "TimeSinceStart : 698.3831658363342\n",
            "Training Loss : -0.02285258285701275\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 92 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 4.313583850860596\n",
            "Eval_StdReturn : 17.02334213256836\n",
            "Eval_MaxReturn : 25.224565505981445\n",
            "Eval_MinReturn : -16.47338104248047\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -8.784614562988281\n",
            "Train_StdReturn : 16.198867797851562\n",
            "Train_MaxReturn : 34.40529251098633\n",
            "Train_MinReturn : -59.658233642578125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 934650\n",
            "TimeSinceStart : 706.3142104148865\n",
            "Training Loss : -0.005778055638074875\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 93 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 5.090554714202881\n",
            "Eval_StdReturn : 12.004871368408203\n",
            "Eval_MaxReturn : 15.948543548583984\n",
            "Eval_MinReturn : -11.641247749328613\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -8.28574275970459\n",
            "Train_StdReturn : 17.403514862060547\n",
            "Train_MaxReturn : 27.46332550048828\n",
            "Train_MinReturn : -47.12754440307617\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 944700\n",
            "TimeSinceStart : 714.3065814971924\n",
            "Training Loss : -0.012626664713025093\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 94 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 2.547621488571167\n",
            "Eval_StdReturn : 18.142057418823242\n",
            "Eval_MaxReturn : 18.782451629638672\n",
            "Eval_MinReturn : -22.775142669677734\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -12.756007194519043\n",
            "Train_StdReturn : 15.004058837890625\n",
            "Train_MaxReturn : 12.774393081665039\n",
            "Train_MinReturn : -48.99833679199219\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 954750\n",
            "TimeSinceStart : 722.3003985881805\n",
            "Training Loss : -0.015176607295870781\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 95 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -1.28633451461792\n",
            "Eval_StdReturn : 14.683025360107422\n",
            "Eval_MaxReturn : 17.801671981811523\n",
            "Eval_MinReturn : -17.910085678100586\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -11.031437873840332\n",
            "Train_StdReturn : 16.07148551940918\n",
            "Train_MaxReturn : 24.123367309570312\n",
            "Train_MinReturn : -45.03299331665039\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 964800\n",
            "TimeSinceStart : 729.8197865486145\n",
            "Training Loss : -0.02086203172802925\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 96 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -28.883010864257812\n",
            "Eval_StdReturn : 5.60391902923584\n",
            "Eval_MaxReturn : -23.922149658203125\n",
            "Eval_MinReturn : -36.71584701538086\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -14.600335121154785\n",
            "Train_StdReturn : 17.49837303161621\n",
            "Train_MaxReturn : 14.546815872192383\n",
            "Train_MinReturn : -49.61805725097656\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 974850\n",
            "TimeSinceStart : 737.4035496711731\n",
            "Training Loss : -0.0196745116263628\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 97 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -10.847569465637207\n",
            "Eval_StdReturn : 8.720322608947754\n",
            "Eval_MaxReturn : -0.7071895599365234\n",
            "Eval_MinReturn : -21.99604606628418\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -13.653060913085938\n",
            "Train_StdReturn : 15.937344551086426\n",
            "Train_MaxReturn : 19.916759490966797\n",
            "Train_MinReturn : -57.907596588134766\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 984900\n",
            "TimeSinceStart : 744.8526494503021\n",
            "Training Loss : -0.021024495363235474\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 98 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -9.390774726867676\n",
            "Eval_StdReturn : 12.830928802490234\n",
            "Eval_MaxReturn : 5.716266632080078\n",
            "Eval_MinReturn : -25.649585723876953\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -15.756281852722168\n",
            "Train_StdReturn : 17.259483337402344\n",
            "Train_MaxReturn : 21.995834350585938\n",
            "Train_MinReturn : -52.41570281982422\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 994950\n",
            "TimeSinceStart : 752.5306777954102\n",
            "Training Loss : -0.0428185909986496\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 99 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -11.815180778503418\n",
            "Eval_StdReturn : 6.149016380310059\n",
            "Eval_MaxReturn : -6.484121322631836\n",
            "Eval_MinReturn : -20.430538177490234\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -13.115885734558105\n",
            "Train_StdReturn : 18.612714767456055\n",
            "Train_MaxReturn : 19.36231231689453\n",
            "Train_MinReturn : -62.78219223022461\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1005000\n",
            "TimeSinceStart : 760.2857611179352\n",
            "Training Loss : -0.007966065779328346\n",
            "Initial_DataCollection_AverageReturn : -87.19107055664062\n",
            "Done logging...\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python cs285/scripts/run_hw2.py --env_name HalfCheetah-v2 --ep_len 150 \\\n",
        "--discount 0.95 -n 100 -l 2 -s 32 -b 10000 -lr 0.01 -rtg --nn_baseline \\\n",
        "--exp_name q4_search_b10000_lr01_rtg_nnbaseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OndS8iGu8UcK",
        "outputId": "6d839a2a-6648-4d88-f1e3-9df50c1b3189"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "########################\n",
            "logging outputs to  /content/gdrive/MyDrive/cs285_f2021/DRL_policy_grads/cs285/scripts/../../data/q4_search_b10000_lr02_rtg_nnbaseline_HalfCheetah-v2_06-02-2022_20-12-03\n",
            "########################\n",
            "Using GPU id 0\n",
            "Sequential(\n",
            "  (0): Linear(in_features=17, out_features=32, bias=True)\n",
            "  (1): Tanh()\n",
            "  (2): Linear(in_features=32, out_features=32, bias=True)\n",
            "  (3): Tanh()\n",
            "  (4): Linear(in_features=32, out_features=6, bias=True)\n",
            "  (5): Identity()\n",
            ")\n",
            "Sequential(\n",
            "  (0): Linear(in_features=17, out_features=32, bias=True)\n",
            "  (1): Tanh()\n",
            "  (2): Linear(in_features=32, out_features=32, bias=True)\n",
            "  (3): Tanh()\n",
            "  (4): Linear(in_features=32, out_features=1, bias=True)\n",
            "  (5): Identity()\n",
            ")\n",
            "\n",
            "\n",
            "********** Iteration 0 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -78.0953369140625\n",
            "Eval_StdReturn : 26.605802536010742\n",
            "Eval_MaxReturn : -51.398067474365234\n",
            "Eval_MinReturn : -114.4057846069336\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -91.45280456542969\n",
            "Train_StdReturn : 37.519203186035156\n",
            "Train_MaxReturn : -6.333817481994629\n",
            "Train_MinReturn : -156.469482421875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 10050\n",
            "TimeSinceStart : 20.23796844482422\n",
            "Training Loss : -0.07528405636548996\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 1 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -81.27442169189453\n",
            "Eval_StdReturn : 23.552284240722656\n",
            "Eval_MaxReturn : -47.978336334228516\n",
            "Eval_MinReturn : -98.6925048828125\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -88.62810516357422\n",
            "Train_StdReturn : 37.205657958984375\n",
            "Train_MaxReturn : -8.512678146362305\n",
            "Train_MinReturn : -193.53240966796875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 20100\n",
            "TimeSinceStart : 31.272613525390625\n",
            "Training Loss : -0.08075446635484695\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 2 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -61.738773345947266\n",
            "Eval_StdReturn : 6.462076663970947\n",
            "Eval_MaxReturn : -52.692447662353516\n",
            "Eval_MinReturn : -67.38471984863281\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -81.32544708251953\n",
            "Train_StdReturn : 28.709157943725586\n",
            "Train_MaxReturn : -12.719941139221191\n",
            "Train_MinReturn : -139.62075805664062\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 30150\n",
            "TimeSinceStart : 42.432509422302246\n",
            "Training Loss : -0.04709623381495476\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 3 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -53.23807907104492\n",
            "Eval_StdReturn : 14.58165168762207\n",
            "Eval_MaxReturn : -33.60938262939453\n",
            "Eval_MinReturn : -68.52714538574219\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -75.5998306274414\n",
            "Train_StdReturn : 28.010478973388672\n",
            "Train_MaxReturn : 0.9586400985717773\n",
            "Train_MinReturn : -161.6666259765625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 40200\n",
            "TimeSinceStart : 53.6005380153656\n",
            "Training Loss : -0.10289183259010315\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 4 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -97.78775787353516\n",
            "Eval_StdReturn : 36.522621154785156\n",
            "Eval_MaxReturn : -67.61048889160156\n",
            "Eval_MinReturn : -149.17861938476562\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -67.34664916992188\n",
            "Train_StdReturn : 32.31553649902344\n",
            "Train_MaxReturn : 35.54236602783203\n",
            "Train_MinReturn : -150.0932159423828\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 50250\n",
            "TimeSinceStart : 64.77054858207703\n",
            "Training Loss : -0.08268485963344574\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 5 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -65.22343444824219\n",
            "Eval_StdReturn : 25.677091598510742\n",
            "Eval_MaxReturn : -29.280397415161133\n",
            "Eval_MinReturn : -87.67189025878906\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -72.94721984863281\n",
            "Train_StdReturn : 34.22236251831055\n",
            "Train_MaxReturn : -17.469362258911133\n",
            "Train_MinReturn : -208.49591064453125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 60300\n",
            "TimeSinceStart : 75.79197955131531\n",
            "Training Loss : -0.08386094868183136\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 6 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -40.4088134765625\n",
            "Eval_StdReturn : 15.435336112976074\n",
            "Eval_MaxReturn : -23.396379470825195\n",
            "Eval_MinReturn : -60.76016616821289\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -63.4967041015625\n",
            "Train_StdReturn : 22.91878890991211\n",
            "Train_MaxReturn : -13.924394607543945\n",
            "Train_MinReturn : -131.59971618652344\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 70350\n",
            "TimeSinceStart : 86.74195265769958\n",
            "Training Loss : -0.09682513028383255\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 7 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -67.3059310913086\n",
            "Eval_StdReturn : 52.40900421142578\n",
            "Eval_MaxReturn : -29.34845733642578\n",
            "Eval_MinReturn : -141.4161376953125\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -62.997928619384766\n",
            "Train_StdReturn : 31.800737380981445\n",
            "Train_MaxReturn : 8.477426528930664\n",
            "Train_MinReturn : -144.22640991210938\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 80400\n",
            "TimeSinceStart : 97.74979662895203\n",
            "Training Loss : -0.0737566351890564\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 8 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -34.839046478271484\n",
            "Eval_StdReturn : 26.844078063964844\n",
            "Eval_MaxReturn : -14.138219833374023\n",
            "Eval_MinReturn : -72.74873352050781\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -57.9719123840332\n",
            "Train_StdReturn : 26.150135040283203\n",
            "Train_MaxReturn : -4.196369171142578\n",
            "Train_MinReturn : -133.94949340820312\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 90450\n",
            "TimeSinceStart : 110.68275809288025\n",
            "Training Loss : -0.060237254947423935\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 9 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -56.5870361328125\n",
            "Eval_StdReturn : 8.990346908569336\n",
            "Eval_MaxReturn : -43.876708984375\n",
            "Eval_MinReturn : -63.21642303466797\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -51.49692916870117\n",
            "Train_StdReturn : 25.461275100708008\n",
            "Train_MaxReturn : -5.908590316772461\n",
            "Train_MinReturn : -115.6551513671875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 100500\n",
            "TimeSinceStart : 121.8251485824585\n",
            "Training Loss : -0.07252278923988342\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 10 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -84.65128326416016\n",
            "Eval_StdReturn : 14.863945007324219\n",
            "Eval_MaxReturn : -71.5571060180664\n",
            "Eval_MinReturn : -105.43959045410156\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -39.06351852416992\n",
            "Train_StdReturn : 21.254240036010742\n",
            "Train_MaxReturn : 4.306232452392578\n",
            "Train_MinReturn : -94.30241394042969\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 110550\n",
            "TimeSinceStart : 132.83321166038513\n",
            "Training Loss : -0.05144632235169411\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 11 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -34.74967575073242\n",
            "Eval_StdReturn : 24.748455047607422\n",
            "Eval_MaxReturn : -9.269547462463379\n",
            "Eval_MinReturn : -68.26956939697266\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -44.74598693847656\n",
            "Train_StdReturn : 32.92257308959961\n",
            "Train_MaxReturn : 22.429874420166016\n",
            "Train_MinReturn : -139.0640411376953\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 120600\n",
            "TimeSinceStart : 143.89659810066223\n",
            "Training Loss : -0.035758476704359055\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 12 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -12.948051452636719\n",
            "Eval_StdReturn : 24.00102424621582\n",
            "Eval_MaxReturn : 19.609054565429688\n",
            "Eval_MinReturn : -37.53923797607422\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -44.664306640625\n",
            "Train_StdReturn : 32.66089630126953\n",
            "Train_MaxReturn : 30.748706817626953\n",
            "Train_MinReturn : -136.3263397216797\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 130650\n",
            "TimeSinceStart : 155.05418634414673\n",
            "Training Loss : -0.07653665542602539\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 13 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -36.741153717041016\n",
            "Eval_StdReturn : 23.07277488708496\n",
            "Eval_MaxReturn : -4.120388984680176\n",
            "Eval_MinReturn : -53.71763610839844\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -33.301177978515625\n",
            "Train_StdReturn : 31.29511833190918\n",
            "Train_MaxReturn : 40.04124450683594\n",
            "Train_MinReturn : -104.627685546875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 140700\n",
            "TimeSinceStart : 166.27605056762695\n",
            "Training Loss : -0.06733665615320206\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 14 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -51.770111083984375\n",
            "Eval_StdReturn : 50.11213302612305\n",
            "Eval_MaxReturn : 15.321791648864746\n",
            "Eval_MinReturn : -105.08589172363281\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -33.546749114990234\n",
            "Train_StdReturn : 36.61195373535156\n",
            "Train_MaxReturn : 91.10465240478516\n",
            "Train_MinReturn : -158.52374267578125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 150750\n",
            "TimeSinceStart : 177.3571379184723\n",
            "Training Loss : -0.05699387192726135\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 15 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 0.8435983657836914\n",
            "Eval_StdReturn : 8.761451721191406\n",
            "Eval_MaxReturn : 10.11125659942627\n",
            "Eval_MinReturn : -10.912550926208496\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -32.92929458618164\n",
            "Train_StdReturn : 32.53069305419922\n",
            "Train_MaxReturn : 55.184200286865234\n",
            "Train_MinReturn : -92.99629211425781\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 160800\n",
            "TimeSinceStart : 188.43834710121155\n",
            "Training Loss : -0.021098366007208824\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 16 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -27.023962020874023\n",
            "Eval_StdReturn : 5.303735733032227\n",
            "Eval_MaxReturn : -21.504085540771484\n",
            "Eval_MinReturn : -34.18192672729492\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -34.59318161010742\n",
            "Train_StdReturn : 27.209335327148438\n",
            "Train_MaxReturn : 17.904335021972656\n",
            "Train_MinReturn : -93.02001190185547\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 170850\n",
            "TimeSinceStart : 199.5023069381714\n",
            "Training Loss : -0.046223923563957214\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 17 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -20.4101505279541\n",
            "Eval_StdReturn : 16.062191009521484\n",
            "Eval_MaxReturn : 0.08690261840820312\n",
            "Eval_MinReturn : -39.13771438598633\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -31.525867462158203\n",
            "Train_StdReturn : 31.169544219970703\n",
            "Train_MaxReturn : 31.714885711669922\n",
            "Train_MinReturn : -111.36450958251953\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 180900\n",
            "TimeSinceStart : 210.58841800689697\n",
            "Training Loss : -0.05471402406692505\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 18 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -56.08793258666992\n",
            "Eval_StdReturn : 18.46204376220703\n",
            "Eval_MaxReturn : -36.66497039794922\n",
            "Eval_MinReturn : -80.91007232666016\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -24.923612594604492\n",
            "Train_StdReturn : 25.445812225341797\n",
            "Train_MaxReturn : 30.960098266601562\n",
            "Train_MinReturn : -71.20906829833984\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 190950\n",
            "TimeSinceStart : 222.043550491333\n",
            "Training Loss : -0.06094317510724068\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 19 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 9.749712944030762\n",
            "Eval_StdReturn : 2.65262508392334\n",
            "Eval_MaxReturn : 13.381632804870605\n",
            "Eval_MinReturn : 7.120427131652832\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -24.2009220123291\n",
            "Train_StdReturn : 27.391834259033203\n",
            "Train_MaxReturn : 30.34668731689453\n",
            "Train_MinReturn : -72.7135238647461\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 201000\n",
            "TimeSinceStart : 233.2002785205841\n",
            "Training Loss : -0.05143279209733009\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 20 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -19.067750930786133\n",
            "Eval_StdReturn : 9.290806770324707\n",
            "Eval_MaxReturn : -8.339115142822266\n",
            "Eval_MinReturn : -31.00100326538086\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -24.898277282714844\n",
            "Train_StdReturn : 25.511802673339844\n",
            "Train_MaxReturn : 43.02288818359375\n",
            "Train_MinReturn : -86.81848907470703\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 211050\n",
            "TimeSinceStart : 244.42581605911255\n",
            "Training Loss : -0.02042613923549652\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 21 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -24.746797561645508\n",
            "Eval_StdReturn : 9.618659019470215\n",
            "Eval_MaxReturn : -16.1901798248291\n",
            "Eval_MinReturn : -38.182952880859375\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -30.34505844116211\n",
            "Train_StdReturn : 28.09517478942871\n",
            "Train_MaxReturn : 23.459064483642578\n",
            "Train_MinReturn : -127.04837799072266\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 221100\n",
            "TimeSinceStart : 255.69528818130493\n",
            "Training Loss : -0.05583299323916435\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 22 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 2.7594330310821533\n",
            "Eval_StdReturn : 35.25409698486328\n",
            "Eval_MaxReturn : 52.5338134765625\n",
            "Eval_MinReturn : -24.609773635864258\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -30.14522361755371\n",
            "Train_StdReturn : 26.831050872802734\n",
            "Train_MaxReturn : 12.690093040466309\n",
            "Train_MinReturn : -136.07923889160156\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 231150\n",
            "TimeSinceStart : 266.89827609062195\n",
            "Training Loss : -0.024050863459706306\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 23 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -35.23917770385742\n",
            "Eval_StdReturn : 18.91042137145996\n",
            "Eval_MaxReturn : -11.842580795288086\n",
            "Eval_MinReturn : -58.156009674072266\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -27.89823341369629\n",
            "Train_StdReturn : 27.689809799194336\n",
            "Train_MaxReturn : 26.02855682373047\n",
            "Train_MinReturn : -105.81134033203125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 241200\n",
            "TimeSinceStart : 278.0845811367035\n",
            "Training Loss : -0.0524296909570694\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 24 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -23.894132614135742\n",
            "Eval_StdReturn : 8.715547561645508\n",
            "Eval_MaxReturn : -11.7484769821167\n",
            "Eval_MinReturn : -31.784496307373047\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -21.884057998657227\n",
            "Train_StdReturn : 27.318126678466797\n",
            "Train_MaxReturn : 52.77586364746094\n",
            "Train_MinReturn : -97.38976287841797\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 251250\n",
            "TimeSinceStart : 289.3436052799225\n",
            "Training Loss : -0.05038880929350853\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 25 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -33.9619140625\n",
            "Eval_StdReturn : 11.293774604797363\n",
            "Eval_MaxReturn : -20.74852180480957\n",
            "Eval_MinReturn : -48.338985443115234\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -24.406963348388672\n",
            "Train_StdReturn : 25.214643478393555\n",
            "Train_MaxReturn : 41.27394104003906\n",
            "Train_MinReturn : -80.59273529052734\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 261300\n",
            "TimeSinceStart : 300.35853338241577\n",
            "Training Loss : -0.03659193217754364\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 26 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -26.00550079345703\n",
            "Eval_StdReturn : 53.61207962036133\n",
            "Eval_MaxReturn : 32.38019943237305\n",
            "Eval_MinReturn : -97.08767700195312\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -19.272031784057617\n",
            "Train_StdReturn : 28.718046188354492\n",
            "Train_MaxReturn : 51.42741012573242\n",
            "Train_MinReturn : -105.36460876464844\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 271350\n",
            "TimeSinceStart : 311.4446427822113\n",
            "Training Loss : -0.050580788403749466\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 27 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -2.2434756755828857\n",
            "Eval_StdReturn : 14.688420295715332\n",
            "Eval_MaxReturn : 18.494953155517578\n",
            "Eval_MinReturn : -13.643587112426758\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -20.95646858215332\n",
            "Train_StdReturn : 25.67888641357422\n",
            "Train_MaxReturn : 37.92168426513672\n",
            "Train_MinReturn : -80.01229858398438\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 281400\n",
            "TimeSinceStart : 322.53621196746826\n",
            "Training Loss : -0.04014010354876518\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 28 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -17.16828727722168\n",
            "Eval_StdReturn : 24.272218704223633\n",
            "Eval_MaxReturn : 5.865022659301758\n",
            "Eval_MinReturn : -50.72605895996094\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -16.505916595458984\n",
            "Train_StdReturn : 31.624414443969727\n",
            "Train_MaxReturn : 66.79191589355469\n",
            "Train_MinReturn : -122.49562072753906\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 291450\n",
            "TimeSinceStart : 333.7708089351654\n",
            "Training Loss : 0.027949601411819458\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 29 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -28.08420753479004\n",
            "Eval_StdReturn : 1.6340376138687134\n",
            "Eval_MaxReturn : -25.843412399291992\n",
            "Eval_MinReturn : -29.69373321533203\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -24.614795684814453\n",
            "Train_StdReturn : 29.94569206237793\n",
            "Train_MaxReturn : 42.25920867919922\n",
            "Train_MinReturn : -99.59552001953125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 301500\n",
            "TimeSinceStart : 344.94423818588257\n",
            "Training Loss : -0.05277393013238907\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 30 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -25.044466018676758\n",
            "Eval_StdReturn : 54.3127326965332\n",
            "Eval_MaxReturn : 41.893463134765625\n",
            "Eval_MinReturn : -91.136962890625\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -28.016342163085938\n",
            "Train_StdReturn : 31.761886596679688\n",
            "Train_MaxReturn : 35.20486068725586\n",
            "Train_MinReturn : -90.19214630126953\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 311550\n",
            "TimeSinceStart : 356.07996368408203\n",
            "Training Loss : -0.0050665223971009254\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 31 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -42.02983474731445\n",
            "Eval_StdReturn : 24.378665924072266\n",
            "Eval_MaxReturn : -8.96200180053711\n",
            "Eval_MinReturn : -67.01170349121094\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -27.181320190429688\n",
            "Train_StdReturn : 37.013309478759766\n",
            "Train_MaxReturn : 64.74192810058594\n",
            "Train_MinReturn : -138.8251953125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 321600\n",
            "TimeSinceStart : 367.13584661483765\n",
            "Training Loss : -0.021795053035020828\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 32 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -72.47614288330078\n",
            "Eval_StdReturn : 47.226043701171875\n",
            "Eval_MaxReturn : -9.594097137451172\n",
            "Eval_MinReturn : -123.40652465820312\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -36.859500885009766\n",
            "Train_StdReturn : 38.405120849609375\n",
            "Train_MaxReturn : 35.308963775634766\n",
            "Train_MinReturn : -153.61448669433594\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 331650\n",
            "TimeSinceStart : 378.255774974823\n",
            "Training Loss : -0.0008048502495512366\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 33 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -26.309349060058594\n",
            "Eval_StdReturn : 16.105159759521484\n",
            "Eval_MaxReturn : -11.765796661376953\n",
            "Eval_MinReturn : -48.760982513427734\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -38.238059997558594\n",
            "Train_StdReturn : 39.42856979370117\n",
            "Train_MaxReturn : 55.79258346557617\n",
            "Train_MinReturn : -164.4054412841797\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 341700\n",
            "TimeSinceStart : 389.44426131248474\n",
            "Training Loss : -0.0010069282725453377\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 34 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -31.822608947753906\n",
            "Eval_StdReturn : 65.17957305908203\n",
            "Eval_MaxReturn : 14.345954895019531\n",
            "Eval_MinReturn : -124.00039672851562\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -29.11702537536621\n",
            "Train_StdReturn : 37.463436126708984\n",
            "Train_MaxReturn : 50.263641357421875\n",
            "Train_MinReturn : -126.51178741455078\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 351750\n",
            "TimeSinceStart : 400.48067903518677\n",
            "Training Loss : -0.05968714877963066\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 35 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -57.9034423828125\n",
            "Eval_StdReturn : 5.733320236206055\n",
            "Eval_MaxReturn : -52.678707122802734\n",
            "Eval_MinReturn : -65.88545227050781\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -40.322689056396484\n",
            "Train_StdReturn : 35.54572677612305\n",
            "Train_MaxReturn : 63.98710632324219\n",
            "Train_MinReturn : -115.72160339355469\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 361800\n",
            "TimeSinceStart : 411.60169529914856\n",
            "Training Loss : 0.01732696406543255\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 36 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -36.3044548034668\n",
            "Eval_StdReturn : 33.49245071411133\n",
            "Eval_MaxReturn : 6.036064147949219\n",
            "Eval_MinReturn : -75.86157989501953\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -57.71211242675781\n",
            "Train_StdReturn : 44.51311111450195\n",
            "Train_MaxReturn : 32.7954216003418\n",
            "Train_MinReturn : -186.65042114257812\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 371850\n",
            "TimeSinceStart : 422.6266372203827\n",
            "Training Loss : -0.05183268338441849\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 37 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -90.6484375\n",
            "Eval_StdReturn : 26.933542251586914\n",
            "Eval_MaxReturn : -66.56852722167969\n",
            "Eval_MinReturn : -128.2469940185547\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -50.13414764404297\n",
            "Train_StdReturn : 42.94696044921875\n",
            "Train_MaxReturn : 87.98046875\n",
            "Train_MinReturn : -154.1542205810547\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 381900\n",
            "TimeSinceStart : 433.5591688156128\n",
            "Training Loss : -0.009700207971036434\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 38 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -31.519256591796875\n",
            "Eval_StdReturn : 50.135501861572266\n",
            "Eval_MaxReturn : 20.459732055664062\n",
            "Eval_MinReturn : -99.2698745727539\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -48.51337432861328\n",
            "Train_StdReturn : 32.634708404541016\n",
            "Train_MaxReturn : 63.658843994140625\n",
            "Train_MinReturn : -133.52029418945312\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 391950\n",
            "TimeSinceStart : 444.6228404045105\n",
            "Training Loss : -0.029113151133060455\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 39 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -41.92647933959961\n",
            "Eval_StdReturn : 28.169466018676758\n",
            "Eval_MaxReturn : -4.523290157318115\n",
            "Eval_MinReturn : -72.50364685058594\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -46.62159729003906\n",
            "Train_StdReturn : 25.272201538085938\n",
            "Train_MaxReturn : 5.489780426025391\n",
            "Train_MinReturn : -115.41931915283203\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 402000\n",
            "TimeSinceStart : 455.8456988334656\n",
            "Training Loss : -0.04152444005012512\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 40 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -37.196311950683594\n",
            "Eval_StdReturn : 15.640029907226562\n",
            "Eval_MaxReturn : -17.378437042236328\n",
            "Eval_MinReturn : -55.61140441894531\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -40.54651641845703\n",
            "Train_StdReturn : 28.20266342163086\n",
            "Train_MaxReturn : 37.1898307800293\n",
            "Train_MinReturn : -118.47508239746094\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 412050\n",
            "TimeSinceStart : 466.94528436660767\n",
            "Training Loss : -0.048181191086769104\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 41 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -44.228179931640625\n",
            "Eval_StdReturn : 6.283827781677246\n",
            "Eval_MaxReturn : -35.80674362182617\n",
            "Eval_MinReturn : -50.896400451660156\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -38.589508056640625\n",
            "Train_StdReturn : 26.52223014831543\n",
            "Train_MaxReturn : 41.26396560668945\n",
            "Train_MinReturn : -123.24881744384766\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 422100\n",
            "TimeSinceStart : 478.10941338539124\n",
            "Training Loss : -0.047640010714530945\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 42 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -29.683984756469727\n",
            "Eval_StdReturn : 2.5268115997314453\n",
            "Eval_MaxReturn : -26.514095306396484\n",
            "Eval_MinReturn : -32.69757080078125\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -28.449039459228516\n",
            "Train_StdReturn : 19.89272689819336\n",
            "Train_MaxReturn : 15.180234909057617\n",
            "Train_MinReturn : -76.47172546386719\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 432150\n",
            "TimeSinceStart : 489.2213382720947\n",
            "Training Loss : -0.023974645882844925\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 43 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -25.249486923217773\n",
            "Eval_StdReturn : 9.991554260253906\n",
            "Eval_MaxReturn : -16.29932403564453\n",
            "Eval_MinReturn : -39.193870544433594\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -27.834941864013672\n",
            "Train_StdReturn : 21.458044052124023\n",
            "Train_MaxReturn : 53.95446014404297\n",
            "Train_MinReturn : -64.07076263427734\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 442200\n",
            "TimeSinceStart : 500.325314283371\n",
            "Training Loss : -0.047655023634433746\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 44 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -8.564887046813965\n",
            "Eval_StdReturn : 14.016170501708984\n",
            "Eval_MaxReturn : 10.909760475158691\n",
            "Eval_MinReturn : -21.50113868713379\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -17.523921966552734\n",
            "Train_StdReturn : 18.615816116333008\n",
            "Train_MaxReturn : 16.78038215637207\n",
            "Train_MinReturn : -63.104732513427734\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 452250\n",
            "TimeSinceStart : 511.3839735984802\n",
            "Training Loss : -0.05251162499189377\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 45 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -11.458781242370605\n",
            "Eval_StdReturn : 18.266477584838867\n",
            "Eval_MaxReturn : 14.29776382446289\n",
            "Eval_MinReturn : -26.05362319946289\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -18.42096519470215\n",
            "Train_StdReturn : 17.62428092956543\n",
            "Train_MaxReturn : 20.389936447143555\n",
            "Train_MinReturn : -66.54910278320312\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 462300\n",
            "TimeSinceStart : 522.441784620285\n",
            "Training Loss : -0.014640421606600285\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 46 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -35.70499801635742\n",
            "Eval_StdReturn : 4.942077159881592\n",
            "Eval_MaxReturn : -29.206226348876953\n",
            "Eval_MinReturn : -41.181640625\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -14.321734428405762\n",
            "Train_StdReturn : 16.550193786621094\n",
            "Train_MaxReturn : 21.029438018798828\n",
            "Train_MinReturn : -50.35493469238281\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 472350\n",
            "TimeSinceStart : 533.6506130695343\n",
            "Training Loss : -0.01920950785279274\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 47 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -22.963134765625\n",
            "Eval_StdReturn : 4.6266608238220215\n",
            "Eval_MaxReturn : -17.26793098449707\n",
            "Eval_MinReturn : -28.600444793701172\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -18.87811851501465\n",
            "Train_StdReturn : 16.46139144897461\n",
            "Train_MaxReturn : 15.929901123046875\n",
            "Train_MinReturn : -55.89917755126953\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 482400\n",
            "TimeSinceStart : 544.6949520111084\n",
            "Training Loss : -0.03420773521065712\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 48 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -12.563682556152344\n",
            "Eval_StdReturn : 5.412530422210693\n",
            "Eval_MaxReturn : -4.947383880615234\n",
            "Eval_MinReturn : -17.033058166503906\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -14.545085906982422\n",
            "Train_StdReturn : 18.985790252685547\n",
            "Train_MaxReturn : 28.800518035888672\n",
            "Train_MinReturn : -51.11668395996094\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 492450\n",
            "TimeSinceStart : 555.752717256546\n",
            "Training Loss : -0.022796891629695892\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 49 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -30.17576026916504\n",
            "Eval_StdReturn : 7.076114177703857\n",
            "Eval_MaxReturn : -20.208614349365234\n",
            "Eval_MinReturn : -35.933349609375\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -24.624109268188477\n",
            "Train_StdReturn : 16.45486068725586\n",
            "Train_MaxReturn : 32.38134765625\n",
            "Train_MinReturn : -57.86070251464844\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 502500\n",
            "TimeSinceStart : 566.9183502197266\n",
            "Training Loss : -0.01022180262953043\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 50 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -26.947710037231445\n",
            "Eval_StdReturn : 12.769608497619629\n",
            "Eval_MaxReturn : -8.888921737670898\n",
            "Eval_MinReturn : -36.04425811767578\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -24.784578323364258\n",
            "Train_StdReturn : 19.469120025634766\n",
            "Train_MaxReturn : 53.289817810058594\n",
            "Train_MinReturn : -71.31005859375\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 512550\n",
            "TimeSinceStart : 577.8866131305695\n",
            "Training Loss : -0.034286659210920334\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 51 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -32.4510612487793\n",
            "Eval_StdReturn : 6.074599742889404\n",
            "Eval_MaxReturn : -27.743715286254883\n",
            "Eval_MinReturn : -41.028221130371094\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -34.41456604003906\n",
            "Train_StdReturn : 24.622486114501953\n",
            "Train_MaxReturn : 75.00112915039062\n",
            "Train_MinReturn : -83.92259216308594\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 522600\n",
            "TimeSinceStart : 589.1754927635193\n",
            "Training Loss : 0.006754791364073753\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 52 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -58.78126525878906\n",
            "Eval_StdReturn : 16.140867233276367\n",
            "Eval_MaxReturn : -44.93777084350586\n",
            "Eval_MinReturn : -81.421142578125\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -27.623245239257812\n",
            "Train_StdReturn : 24.235803604125977\n",
            "Train_MaxReturn : 35.154197692871094\n",
            "Train_MinReturn : -107.368896484375\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 532650\n",
            "TimeSinceStart : 600.3369791507721\n",
            "Training Loss : -0.03634835407137871\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 53 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -27.782350540161133\n",
            "Eval_StdReturn : 17.874597549438477\n",
            "Eval_MaxReturn : -5.022650718688965\n",
            "Eval_MinReturn : -48.68842315673828\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -33.40414810180664\n",
            "Train_StdReturn : 19.213706970214844\n",
            "Train_MaxReturn : 12.478353500366211\n",
            "Train_MinReturn : -104.53077697753906\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 542700\n",
            "TimeSinceStart : 611.5254485607147\n",
            "Training Loss : 0.010971206240355968\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 54 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -11.816548347473145\n",
            "Eval_StdReturn : 18.695314407348633\n",
            "Eval_MaxReturn : 9.52048110961914\n",
            "Eval_MinReturn : -36.00617599487305\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -28.907495498657227\n",
            "Train_StdReturn : 23.03073501586914\n",
            "Train_MaxReturn : 16.477928161621094\n",
            "Train_MinReturn : -88.51390075683594\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 552750\n",
            "TimeSinceStart : 622.6752464771271\n",
            "Training Loss : 0.004046479240059853\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 55 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -48.48054504394531\n",
            "Eval_StdReturn : 19.510881423950195\n",
            "Eval_MaxReturn : -22.085895538330078\n",
            "Eval_MinReturn : -68.64231872558594\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -25.22366714477539\n",
            "Train_StdReturn : 25.712491989135742\n",
            "Train_MaxReturn : 33.46897888183594\n",
            "Train_MinReturn : -92.65229797363281\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 562800\n",
            "TimeSinceStart : 633.8645315170288\n",
            "Training Loss : -0.03233284503221512\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 56 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -16.68244171142578\n",
            "Eval_StdReturn : 19.91960906982422\n",
            "Eval_MaxReturn : 7.491406440734863\n",
            "Eval_MinReturn : -41.2955436706543\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -28.23223876953125\n",
            "Train_StdReturn : 29.729652404785156\n",
            "Train_MaxReturn : 49.326805114746094\n",
            "Train_MinReturn : -95.58843994140625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 572850\n",
            "TimeSinceStart : 644.9807188510895\n",
            "Training Loss : -0.056189510971307755\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 57 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -18.787260055541992\n",
            "Eval_StdReturn : 36.13517761230469\n",
            "Eval_MaxReturn : 13.959653854370117\n",
            "Eval_MinReturn : -69.13653564453125\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -22.504369735717773\n",
            "Train_StdReturn : 28.127649307250977\n",
            "Train_MaxReturn : 43.84170913696289\n",
            "Train_MinReturn : -107.01167297363281\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 582900\n",
            "TimeSinceStart : 656.0634832382202\n",
            "Training Loss : -0.0021947878412902355\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 58 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -16.230989456176758\n",
            "Eval_StdReturn : 8.721809387207031\n",
            "Eval_MaxReturn : -6.833194732666016\n",
            "Eval_MinReturn : -27.84841537475586\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -18.42168426513672\n",
            "Train_StdReturn : 25.792224884033203\n",
            "Train_MaxReturn : 47.04539489746094\n",
            "Train_MinReturn : -84.86930084228516\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 592950\n",
            "TimeSinceStart : 667.2854769229889\n",
            "Training Loss : -0.03640379756689072\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 59 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -4.560936450958252\n",
            "Eval_StdReturn : 23.12461280822754\n",
            "Eval_MaxReturn : 18.424175262451172\n",
            "Eval_MinReturn : -36.20008087158203\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -17.169986724853516\n",
            "Train_StdReturn : 25.710317611694336\n",
            "Train_MaxReturn : 55.5563850402832\n",
            "Train_MinReturn : -99.3829116821289\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 603000\n",
            "TimeSinceStart : 678.5181624889374\n",
            "Training Loss : -0.03327656164765358\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 60 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 27.6883544921875\n",
            "Eval_StdReturn : 10.672443389892578\n",
            "Eval_MaxReturn : 41.85105514526367\n",
            "Eval_MinReturn : 16.088706970214844\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -10.158048629760742\n",
            "Train_StdReturn : 25.37727165222168\n",
            "Train_MaxReturn : 31.29081153869629\n",
            "Train_MinReturn : -83.45193481445312\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 613050\n",
            "TimeSinceStart : 689.6387934684753\n",
            "Training Loss : -0.05352501571178436\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 61 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 31.264963150024414\n",
            "Eval_StdReturn : 4.5730061531066895\n",
            "Eval_MaxReturn : 35.630615234375\n",
            "Eval_MinReturn : 24.95001983642578\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 2.0379979610443115\n",
            "Train_StdReturn : 23.495620727539062\n",
            "Train_MaxReturn : 50.984886169433594\n",
            "Train_MinReturn : -63.20201873779297\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 623100\n",
            "TimeSinceStart : 700.6972613334656\n",
            "Training Loss : -0.04898441210389137\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 62 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -37.82686996459961\n",
            "Eval_StdReturn : 35.994110107421875\n",
            "Eval_MaxReturn : -7.709648132324219\n",
            "Eval_MinReturn : -88.42530059814453\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 9.743934631347656\n",
            "Train_StdReturn : 17.071014404296875\n",
            "Train_MaxReturn : 51.325218200683594\n",
            "Train_MinReturn : -36.02259826660156\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 633150\n",
            "TimeSinceStart : 711.8803310394287\n",
            "Training Loss : -0.08350034803152084\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 63 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 9.534440040588379\n",
            "Eval_StdReturn : 4.851065158843994\n",
            "Eval_MaxReturn : 15.291171073913574\n",
            "Eval_MinReturn : 3.4243130683898926\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 9.762028694152832\n",
            "Train_StdReturn : 25.76329231262207\n",
            "Train_MaxReturn : 58.638885498046875\n",
            "Train_MinReturn : -95.4287109375\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 643200\n",
            "TimeSinceStart : 723.0252861976624\n",
            "Training Loss : -0.041602060198783875\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 64 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 0.8595851063728333\n",
            "Eval_StdReturn : 17.140975952148438\n",
            "Eval_MaxReturn : 14.545025825500488\n",
            "Eval_MinReturn : -23.310890197753906\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 12.352094650268555\n",
            "Train_StdReturn : 23.02461051940918\n",
            "Train_MaxReturn : 65.68006134033203\n",
            "Train_MinReturn : -41.8098030090332\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 653250\n",
            "TimeSinceStart : 734.1805150508881\n",
            "Training Loss : -0.03549438714981079\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 65 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 17.11271095275879\n",
            "Eval_StdReturn : 4.497000217437744\n",
            "Eval_MaxReturn : 21.121028900146484\n",
            "Eval_MinReturn : 10.832507133483887\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 17.09126853942871\n",
            "Train_StdReturn : 18.384876251220703\n",
            "Train_MaxReturn : 57.715965270996094\n",
            "Train_MinReturn : -56.64976501464844\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 663300\n",
            "TimeSinceStart : 745.3344910144806\n",
            "Training Loss : -0.04781011864542961\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 66 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 8.766825675964355\n",
            "Eval_StdReturn : 12.757760047912598\n",
            "Eval_MaxReturn : 22.001766204833984\n",
            "Eval_MinReturn : -8.469868659973145\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 17.854310989379883\n",
            "Train_StdReturn : 18.381975173950195\n",
            "Train_MaxReturn : 62.20734786987305\n",
            "Train_MinReturn : -31.311595916748047\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 673350\n",
            "TimeSinceStart : 756.3954665660858\n",
            "Training Loss : -0.06721188873052597\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 67 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 20.8686466217041\n",
            "Eval_StdReturn : 19.943525314331055\n",
            "Eval_MaxReturn : 38.444705963134766\n",
            "Eval_MinReturn : -7.022470951080322\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 14.48493766784668\n",
            "Train_StdReturn : 17.440996170043945\n",
            "Train_MaxReturn : 46.06922149658203\n",
            "Train_MinReturn : -26.0294189453125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 683400\n",
            "TimeSinceStart : 767.5676848888397\n",
            "Training Loss : -0.05289841070771217\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 68 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -1.9339890480041504\n",
            "Eval_StdReturn : 5.931347370147705\n",
            "Eval_MaxReturn : 6.445528984069824\n",
            "Eval_MinReturn : -6.454017639160156\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 0.8909478187561035\n",
            "Train_StdReturn : 26.392274856567383\n",
            "Train_MaxReturn : 45.52516174316406\n",
            "Train_MinReturn : -67.46246337890625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 693450\n",
            "TimeSinceStart : 778.7714433670044\n",
            "Training Loss : -0.0651274099946022\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 69 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 14.942614555358887\n",
            "Eval_StdReturn : 16.954065322875977\n",
            "Eval_MaxReturn : 32.53044128417969\n",
            "Eval_MinReturn : -7.963768005371094\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 8.409119606018066\n",
            "Train_StdReturn : 23.336212158203125\n",
            "Train_MaxReturn : 50.88416290283203\n",
            "Train_MinReturn : -52.685264587402344\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 703500\n",
            "TimeSinceStart : 790.0167889595032\n",
            "Training Loss : -0.05363253504037857\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 70 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 6.451605319976807\n",
            "Eval_StdReturn : 24.084150314331055\n",
            "Eval_MaxReturn : 24.721927642822266\n",
            "Eval_MinReturn : -27.577648162841797\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 8.516579627990723\n",
            "Train_StdReturn : 20.496370315551758\n",
            "Train_MaxReturn : 62.72526931762695\n",
            "Train_MinReturn : -55.668609619140625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 713550\n",
            "TimeSinceStart : 801.1146619319916\n",
            "Training Loss : -0.03768761828541756\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 71 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 4.40990686416626\n",
            "Eval_StdReturn : 17.599029541015625\n",
            "Eval_MaxReturn : 23.946792602539062\n",
            "Eval_MinReturn : -18.712238311767578\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 16.492172241210938\n",
            "Train_StdReturn : 21.696855545043945\n",
            "Train_MaxReturn : 58.80235290527344\n",
            "Train_MinReturn : -56.09307098388672\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 723600\n",
            "TimeSinceStart : 812.204981803894\n",
            "Training Loss : -0.04917600378394127\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 72 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 5.727844715118408\n",
            "Eval_StdReturn : 4.390729904174805\n",
            "Eval_MaxReturn : 10.675760269165039\n",
            "Eval_MinReturn : 0.004830837249755859\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 11.517590522766113\n",
            "Train_StdReturn : 25.007396697998047\n",
            "Train_MaxReturn : 50.31984329223633\n",
            "Train_MinReturn : -70.96871948242188\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 733650\n",
            "TimeSinceStart : 823.301577091217\n",
            "Training Loss : -0.06958511471748352\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 73 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 19.38457489013672\n",
            "Eval_StdReturn : 20.268959045410156\n",
            "Eval_MaxReturn : 45.59693145751953\n",
            "Eval_MinReturn : -3.768012523651123\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 20.985111236572266\n",
            "Train_StdReturn : 26.601858139038086\n",
            "Train_MaxReturn : 64.96978759765625\n",
            "Train_MinReturn : -59.326114654541016\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 743700\n",
            "TimeSinceStart : 834.4809648990631\n",
            "Training Loss : -0.03297791630029678\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 74 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 38.19845199584961\n",
            "Eval_StdReturn : 13.329225540161133\n",
            "Eval_MaxReturn : 56.999053955078125\n",
            "Eval_MinReturn : 27.612674713134766\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 22.52975845336914\n",
            "Train_StdReturn : 23.387474060058594\n",
            "Train_MaxReturn : 68.10792541503906\n",
            "Train_MinReturn : -45.40675354003906\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 753750\n",
            "TimeSinceStart : 845.6927216053009\n",
            "Training Loss : -0.03808373957872391\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 75 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 51.04294204711914\n",
            "Eval_StdReturn : 19.916099548339844\n",
            "Eval_MaxReturn : 78.39999389648438\n",
            "Eval_MinReturn : 31.561796188354492\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 18.71721076965332\n",
            "Train_StdReturn : 29.648706436157227\n",
            "Train_MaxReturn : 62.694374084472656\n",
            "Train_MinReturn : -104.16778564453125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 763800\n",
            "TimeSinceStart : 856.8212594985962\n",
            "Training Loss : -0.050643760710954666\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 76 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 16.233362197875977\n",
            "Eval_StdReturn : 27.757293701171875\n",
            "Eval_MaxReturn : 54.83851623535156\n",
            "Eval_MinReturn : -9.22815990447998\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 24.08989906311035\n",
            "Train_StdReturn : 35.11530303955078\n",
            "Train_MaxReturn : 79.63604736328125\n",
            "Train_MinReturn : -93.04925537109375\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 773850\n",
            "TimeSinceStart : 867.8684170246124\n",
            "Training Loss : -0.043329060077667236\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 77 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 4.407354831695557\n",
            "Eval_StdReturn : 26.65469741821289\n",
            "Eval_MaxReturn : 28.285511016845703\n",
            "Eval_MinReturn : -32.792057037353516\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 23.053077697753906\n",
            "Train_StdReturn : 31.65818977355957\n",
            "Train_MaxReturn : 70.78081512451172\n",
            "Train_MinReturn : -75.41960906982422\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 783900\n",
            "TimeSinceStart : 879.0067496299744\n",
            "Training Loss : 0.0021101280581206083\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 78 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1.488627314567566\n",
            "Eval_StdReturn : 10.32330322265625\n",
            "Eval_MaxReturn : 10.340398788452148\n",
            "Eval_MinReturn : -12.9916353225708\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 5.92548942565918\n",
            "Train_StdReturn : 40.267269134521484\n",
            "Train_MaxReturn : 89.40461730957031\n",
            "Train_MinReturn : -127.4573974609375\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 793950\n",
            "TimeSinceStart : 890.0653636455536\n",
            "Training Loss : 0.0010005150688812137\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 79 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -26.949548721313477\n",
            "Eval_StdReturn : 39.4413948059082\n",
            "Eval_MaxReturn : 18.301807403564453\n",
            "Eval_MinReturn : -77.81830596923828\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 3.5272960662841797\n",
            "Train_StdReturn : 25.116483688354492\n",
            "Train_MaxReturn : 78.39635467529297\n",
            "Train_MinReturn : -53.006038665771484\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 804000\n",
            "TimeSinceStart : 901.0465812683105\n",
            "Training Loss : -0.017598440870642662\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 80 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 28.60312843322754\n",
            "Eval_StdReturn : 16.826196670532227\n",
            "Eval_MaxReturn : 47.505592346191406\n",
            "Eval_MinReturn : 6.633749008178711\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 3.7865304946899414\n",
            "Train_StdReturn : 26.088991165161133\n",
            "Train_MaxReturn : 59.52497100830078\n",
            "Train_MinReturn : -80.66553497314453\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 814050\n",
            "TimeSinceStart : 912.1149106025696\n",
            "Training Loss : -0.021296685561537743\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 81 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 14.26758861541748\n",
            "Eval_StdReturn : 10.640534400939941\n",
            "Eval_MaxReturn : 28.996973037719727\n",
            "Eval_MinReturn : 4.235428333282471\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 17.364652633666992\n",
            "Train_StdReturn : 27.3007869720459\n",
            "Train_MaxReturn : 84.15890502929688\n",
            "Train_MinReturn : -102.22561645507812\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 824100\n",
            "TimeSinceStart : 923.0842080116272\n",
            "Training Loss : -0.045752525329589844\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 82 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -15.988720893859863\n",
            "Eval_StdReturn : 3.8089706897735596\n",
            "Eval_MaxReturn : -10.614118576049805\n",
            "Eval_MinReturn : -18.988479614257812\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 12.846456527709961\n",
            "Train_StdReturn : 25.464599609375\n",
            "Train_MaxReturn : 63.5644645690918\n",
            "Train_MinReturn : -90.38296508789062\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 834150\n",
            "TimeSinceStart : 934.0965220928192\n",
            "Training Loss : -0.025186030194163322\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 83 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -8.731874465942383\n",
            "Eval_StdReturn : 5.918713092803955\n",
            "Eval_MaxReturn : -0.36383914947509766\n",
            "Eval_MinReturn : -13.085399627685547\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -3.076566696166992\n",
            "Train_StdReturn : 20.899778366088867\n",
            "Train_MaxReturn : 39.75572967529297\n",
            "Train_MinReturn : -73.87462615966797\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 844200\n",
            "TimeSinceStart : 945.5098536014557\n",
            "Training Loss : -0.01770774833858013\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 84 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 4.625128269195557\n",
            "Eval_StdReturn : 2.9024877548217773\n",
            "Eval_MaxReturn : 8.650976181030273\n",
            "Eval_MinReturn : 1.9186162948608398\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -7.0466766357421875\n",
            "Train_StdReturn : 20.69804573059082\n",
            "Train_MaxReturn : 26.796222686767578\n",
            "Train_MinReturn : -100.56014251708984\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 854250\n",
            "TimeSinceStart : 956.5019080638885\n",
            "Training Loss : 0.008394964039325714\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 85 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 17.04654312133789\n",
            "Eval_StdReturn : 34.26314926147461\n",
            "Eval_MaxReturn : 45.56340789794922\n",
            "Eval_MinReturn : -31.138816833496094\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 2.0825014114379883\n",
            "Train_StdReturn : 21.24170684814453\n",
            "Train_MaxReturn : 49.92109680175781\n",
            "Train_MinReturn : -55.342071533203125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 864300\n",
            "TimeSinceStart : 967.5218839645386\n",
            "Training Loss : -0.017722075805068016\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 86 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -29.389253616333008\n",
            "Eval_StdReturn : 97.35145568847656\n",
            "Eval_MaxReturn : 55.94622802734375\n",
            "Eval_MinReturn : -165.62167358398438\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 25.56581687927246\n",
            "Train_StdReturn : 19.7253360748291\n",
            "Train_MaxReturn : 83.69100189208984\n",
            "Train_MinReturn : -17.620189666748047\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 874350\n",
            "TimeSinceStart : 978.5839700698853\n",
            "Training Loss : -0.020736293867230415\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 87 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 12.351188659667969\n",
            "Eval_StdReturn : 21.842315673828125\n",
            "Eval_MaxReturn : 43.07673645019531\n",
            "Eval_MinReturn : -5.7657928466796875\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 29.833847045898438\n",
            "Train_StdReturn : 23.561498641967773\n",
            "Train_MaxReturn : 72.47482299804688\n",
            "Train_MinReturn : -47.575531005859375\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 884400\n",
            "TimeSinceStart : 989.5375142097473\n",
            "Training Loss : -0.03937350586056709\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 88 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -8.839520454406738\n",
            "Eval_StdReturn : 33.63737487792969\n",
            "Eval_MaxReturn : 23.32803726196289\n",
            "Eval_MinReturn : -55.273677825927734\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 11.35563850402832\n",
            "Train_StdReturn : 22.192819595336914\n",
            "Train_MaxReturn : 46.352508544921875\n",
            "Train_MinReturn : -68.88825988769531\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 894450\n",
            "TimeSinceStart : 1000.5120804309845\n",
            "Training Loss : -0.023073643445968628\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 89 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -25.69000244140625\n",
            "Eval_StdReturn : 16.513038635253906\n",
            "Eval_MaxReturn : -10.364004135131836\n",
            "Eval_MinReturn : -48.61262130737305\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -9.444725036621094\n",
            "Train_StdReturn : 25.695392608642578\n",
            "Train_MaxReturn : 39.46565628051758\n",
            "Train_MinReturn : -81.79853820800781\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 904500\n",
            "TimeSinceStart : 1011.5134227275848\n",
            "Training Loss : 0.015138911083340645\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 90 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -14.571927070617676\n",
            "Eval_StdReturn : 13.560079574584961\n",
            "Eval_MaxReturn : -1.1444997787475586\n",
            "Eval_MinReturn : -33.14278030395508\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -16.832550048828125\n",
            "Train_StdReturn : 27.304697036743164\n",
            "Train_MaxReturn : 35.968143463134766\n",
            "Train_MinReturn : -92.08616638183594\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 914550\n",
            "TimeSinceStart : 1022.5623209476471\n",
            "Training Loss : 0.014444033615291119\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 91 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -22.7560977935791\n",
            "Eval_StdReturn : 9.588648796081543\n",
            "Eval_MaxReturn : -9.901660919189453\n",
            "Eval_MinReturn : -32.9230842590332\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -11.216233253479004\n",
            "Train_StdReturn : 22.944093704223633\n",
            "Train_MaxReturn : 41.06428146362305\n",
            "Train_MinReturn : -65.9984130859375\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 924600\n",
            "TimeSinceStart : 1033.6142790317535\n",
            "Training Loss : -0.008542119525372982\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 92 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -0.8334267735481262\n",
            "Eval_StdReturn : 27.571134567260742\n",
            "Eval_MaxReturn : 36.31441116333008\n",
            "Eval_MinReturn : -29.667932510375977\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -15.185940742492676\n",
            "Train_StdReturn : 29.816085815429688\n",
            "Train_MaxReturn : 34.87241744995117\n",
            "Train_MinReturn : -138.44879150390625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 934650\n",
            "TimeSinceStart : 1044.8033323287964\n",
            "Training Loss : 0.0029376388993114233\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 93 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 29.485002517700195\n",
            "Eval_StdReturn : 26.3365478515625\n",
            "Eval_MaxReturn : 50.24763870239258\n",
            "Eval_MinReturn : -7.675135612487793\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -2.5654711723327637\n",
            "Train_StdReturn : 30.439773559570312\n",
            "Train_MaxReturn : 52.70716857910156\n",
            "Train_MinReturn : -142.71762084960938\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 944700\n",
            "TimeSinceStart : 1056.16192984581\n",
            "Training Loss : -0.01570229046046734\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 94 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 47.10187911987305\n",
            "Eval_StdReturn : 21.85109519958496\n",
            "Eval_MaxReturn : 67.63101196289062\n",
            "Eval_MinReturn : 16.834270477294922\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 7.3975911140441895\n",
            "Train_StdReturn : 31.008520126342773\n",
            "Train_MaxReturn : 57.05105209350586\n",
            "Train_MinReturn : -108.16145324707031\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 954750\n",
            "TimeSinceStart : 1067.3429181575775\n",
            "Training Loss : -0.01952105015516281\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 95 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 27.973344802856445\n",
            "Eval_StdReturn : 19.52885627746582\n",
            "Eval_MaxReturn : 42.540184020996094\n",
            "Eval_MinReturn : 0.36949825286865234\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 22.363731384277344\n",
            "Train_StdReturn : 29.530445098876953\n",
            "Train_MaxReturn : 77.52198028564453\n",
            "Train_MinReturn : -116.07320404052734\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 964800\n",
            "TimeSinceStart : 1078.417855978012\n",
            "Training Loss : 0.034952495247125626\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 96 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -7.126771450042725\n",
            "Eval_StdReturn : 9.232276916503906\n",
            "Eval_MaxReturn : 0.4849834442138672\n",
            "Eval_MinReturn : -20.119503021240234\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 10.95670223236084\n",
            "Train_StdReturn : 33.20752716064453\n",
            "Train_MaxReturn : 71.10226440429688\n",
            "Train_MinReturn : -128.09092712402344\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 974850\n",
            "TimeSinceStart : 1089.6230075359344\n",
            "Training Loss : -0.0021203604992479086\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 97 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -41.33743667602539\n",
            "Eval_StdReturn : 35.20651626586914\n",
            "Eval_MaxReturn : 1.454345703125\n",
            "Eval_MinReturn : -84.7763671875\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -10.840757369995117\n",
            "Train_StdReturn : 42.20708465576172\n",
            "Train_MaxReturn : 65.77643585205078\n",
            "Train_MinReturn : -173.44915771484375\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 984900\n",
            "TimeSinceStart : 1100.6846146583557\n",
            "Training Loss : -0.008295334875583649\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 98 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -54.69490432739258\n",
            "Eval_StdReturn : 42.35758590698242\n",
            "Eval_MaxReturn : -0.8079385757446289\n",
            "Eval_MinReturn : -104.29658508300781\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -24.330530166625977\n",
            "Train_StdReturn : 40.22613525390625\n",
            "Train_MaxReturn : 48.593910217285156\n",
            "Train_MinReturn : -194.07650756835938\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 994950\n",
            "TimeSinceStart : 1111.6348276138306\n",
            "Training Loss : 0.006181764416396618\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 99 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([10050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -109.0546646118164\n",
            "Eval_StdReturn : 74.7516098022461\n",
            "Eval_MaxReturn : -29.392148971557617\n",
            "Eval_MinReturn : -209.0699462890625\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -25.913450241088867\n",
            "Train_StdReturn : 34.40302658081055\n",
            "Train_MaxReturn : 42.03974533081055\n",
            "Train_MinReturn : -141.88621520996094\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1005000\n",
            "TimeSinceStart : 1122.9804933071136\n",
            "Training Loss : -0.032675690948963165\n",
            "Initial_DataCollection_AverageReturn : -91.45280456542969\n",
            "Done logging...\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python cs285/scripts/run_hw2.py --env_name HalfCheetah-v2 --ep_len 150 \\\n",
        "--discount 0.95 -n 100 -l 2 -s 32 -b 10000 -lr 0.02 -rtg --nn_baseline \\\n",
        "--exp_name q4_search_b10000_lr02_rtg_nnbaseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JPf-aE6a8WYn",
        "outputId": "95a98e51-c122-4e70-f2e1-4bccfbb4d6aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "########################\n",
            "logging outputs to  /content/gdrive/My Drive/cs285_f2021/DRL_policy_grads/cs285/scripts/../../data/q4_search_b30000_lr005_rtg_nnbaseline_HalfCheetah-v2_06-02-2022_20-30-53\n",
            "########################\n",
            "Using GPU id 0\n",
            "Sequential(\n",
            "  (0): Linear(in_features=17, out_features=32, bias=True)\n",
            "  (1): Tanh()\n",
            "  (2): Linear(in_features=32, out_features=32, bias=True)\n",
            "  (3): Tanh()\n",
            "  (4): Linear(in_features=32, out_features=6, bias=True)\n",
            "  (5): Identity()\n",
            ")\n",
            "Sequential(\n",
            "  (0): Linear(in_features=17, out_features=32, bias=True)\n",
            "  (1): Tanh()\n",
            "  (2): Linear(in_features=32, out_features=32, bias=True)\n",
            "  (3): Tanh()\n",
            "  (4): Linear(in_features=32, out_features=1, bias=True)\n",
            "  (5): Identity()\n",
            ")\n",
            "\n",
            "\n",
            "********** Iteration 0 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -81.3231430053711\n",
            "Eval_StdReturn : 36.331729888916016\n",
            "Eval_MaxReturn : -29.948469161987305\n",
            "Eval_MinReturn : -107.69869232177734\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -88.9120864868164\n",
            "Train_StdReturn : 35.07945251464844\n",
            "Train_MaxReturn : -6.333817481994629\n",
            "Train_MinReturn : -178.995361328125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 30000\n",
            "TimeSinceStart : 32.116459131240845\n",
            "Training Loss : -0.06758902221918106\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 1 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -108.61202239990234\n",
            "Eval_StdReturn : 31.34300422668457\n",
            "Eval_MaxReturn : -67.73735809326172\n",
            "Eval_MinReturn : -143.89935302734375\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -90.91838836669922\n",
            "Train_StdReturn : 37.78673553466797\n",
            "Train_MaxReturn : 20.640451431274414\n",
            "Train_MinReturn : -181.68765258789062\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 60000\n",
            "TimeSinceStart : 64.82395792007446\n",
            "Training Loss : -0.05114525556564331\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 2 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -73.59027099609375\n",
            "Eval_StdReturn : 23.91965675354004\n",
            "Eval_MaxReturn : -40.942787170410156\n",
            "Eval_MinReturn : -97.58418273925781\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -86.62187194824219\n",
            "Train_StdReturn : 35.74869918823242\n",
            "Train_MaxReturn : 10.355575561523438\n",
            "Train_MinReturn : -182.58660888671875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 90000\n",
            "TimeSinceStart : 97.1771399974823\n",
            "Training Loss : -0.08284498006105423\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 3 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -79.94806671142578\n",
            "Eval_StdReturn : 17.829313278198242\n",
            "Eval_MaxReturn : -59.93935012817383\n",
            "Eval_MinReturn : -103.24020385742188\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -80.57307434082031\n",
            "Train_StdReturn : 35.64052963256836\n",
            "Train_MaxReturn : 5.879401206970215\n",
            "Train_MinReturn : -202.63128662109375\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 120000\n",
            "TimeSinceStart : 129.26306247711182\n",
            "Training Loss : -0.08533937484025955\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 4 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -35.796024322509766\n",
            "Eval_StdReturn : 14.788041114807129\n",
            "Eval_MaxReturn : -19.30455207824707\n",
            "Eval_MinReturn : -55.179656982421875\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -75.13842010498047\n",
            "Train_StdReturn : 34.39692687988281\n",
            "Train_MaxReturn : 16.599802017211914\n",
            "Train_MinReturn : -183.75811767578125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 150000\n",
            "TimeSinceStart : 161.71103525161743\n",
            "Training Loss : -0.06683959811925888\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 5 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -62.454803466796875\n",
            "Eval_StdReturn : 8.238333702087402\n",
            "Eval_MaxReturn : -51.92424011230469\n",
            "Eval_MinReturn : -72.0369873046875\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -74.4006576538086\n",
            "Train_StdReturn : 35.935394287109375\n",
            "Train_MaxReturn : 33.4384880065918\n",
            "Train_MinReturn : -177.52133178710938\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 180000\n",
            "TimeSinceStart : 193.98179078102112\n",
            "Training Loss : -0.07656335830688477\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 6 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -79.24217987060547\n",
            "Eval_StdReturn : 24.968812942504883\n",
            "Eval_MaxReturn : -45.9653205871582\n",
            "Eval_MinReturn : -106.11048889160156\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -73.98538208007812\n",
            "Train_StdReturn : 30.530338287353516\n",
            "Train_MaxReturn : 6.971553325653076\n",
            "Train_MinReturn : -156.41969299316406\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 210000\n",
            "TimeSinceStart : 225.9666178226471\n",
            "Training Loss : -0.08150935918092728\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 7 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -89.69781494140625\n",
            "Eval_StdReturn : 42.8001708984375\n",
            "Eval_MaxReturn : -29.36712074279785\n",
            "Eval_MinReturn : -124.09848022460938\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -73.58514404296875\n",
            "Train_StdReturn : 32.03032684326172\n",
            "Train_MaxReturn : 15.1431303024292\n",
            "Train_MinReturn : -197.14013671875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 240000\n",
            "TimeSinceStart : 258.03436946868896\n",
            "Training Loss : -0.07635679095983505\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 8 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -94.9461898803711\n",
            "Eval_StdReturn : 14.240702629089355\n",
            "Eval_MaxReturn : -75.41273498535156\n",
            "Eval_MinReturn : -108.95906066894531\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -71.2062759399414\n",
            "Train_StdReturn : 31.992033004760742\n",
            "Train_MaxReturn : 6.950368881225586\n",
            "Train_MinReturn : -196.90045166015625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 270000\n",
            "TimeSinceStart : 290.4245104789734\n",
            "Training Loss : -0.07308049499988556\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 9 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -75.74323272705078\n",
            "Eval_StdReturn : 3.2256574630737305\n",
            "Eval_MaxReturn : -72.51359558105469\n",
            "Eval_MinReturn : -80.14810180664062\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -69.52224731445312\n",
            "Train_StdReturn : 30.02729034423828\n",
            "Train_MaxReturn : 16.453628540039062\n",
            "Train_MinReturn : -217.4141082763672\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 300000\n",
            "TimeSinceStart : 322.4447956085205\n",
            "Training Loss : -0.06864674389362335\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 10 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -70.87083435058594\n",
            "Eval_StdReturn : 25.404024124145508\n",
            "Eval_MaxReturn : -36.25642013549805\n",
            "Eval_MinReturn : -96.51041412353516\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -71.24982452392578\n",
            "Train_StdReturn : 29.526166915893555\n",
            "Train_MaxReturn : 21.8138484954834\n",
            "Train_MinReturn : -156.18695068359375\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 330000\n",
            "TimeSinceStart : 354.6785068511963\n",
            "Training Loss : -0.10339516401290894\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 11 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -60.32059860229492\n",
            "Eval_StdReturn : 25.964370727539062\n",
            "Eval_MaxReturn : -33.08726501464844\n",
            "Eval_MinReturn : -95.26757049560547\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -71.01065063476562\n",
            "Train_StdReturn : 32.91365432739258\n",
            "Train_MaxReturn : 12.119301795959473\n",
            "Train_MinReturn : -180.12542724609375\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 360000\n",
            "TimeSinceStart : 386.8514244556427\n",
            "Training Loss : -0.08151155710220337\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 12 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -71.5597152709961\n",
            "Eval_StdReturn : 19.08493995666504\n",
            "Eval_MaxReturn : -49.117557525634766\n",
            "Eval_MinReturn : -95.76596069335938\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -65.9819564819336\n",
            "Train_StdReturn : 26.393569946289062\n",
            "Train_MaxReturn : 0.39870500564575195\n",
            "Train_MinReturn : -141.03726196289062\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 390000\n",
            "TimeSinceStart : 418.93375539779663\n",
            "Training Loss : -0.09264954179525375\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 13 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -100.0134048461914\n",
            "Eval_StdReturn : 34.27641677856445\n",
            "Eval_MaxReturn : -56.238555908203125\n",
            "Eval_MinReturn : -139.93222045898438\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -69.08891296386719\n",
            "Train_StdReturn : 28.975040435791016\n",
            "Train_MaxReturn : -1.4218559265136719\n",
            "Train_MinReturn : -189.70953369140625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 420000\n",
            "TimeSinceStart : 451.26113295555115\n",
            "Training Loss : -0.08103348314762115\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 14 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -67.34942626953125\n",
            "Eval_StdReturn : 9.966350555419922\n",
            "Eval_MaxReturn : -55.91472244262695\n",
            "Eval_MinReturn : -80.20315551757812\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -64.53559875488281\n",
            "Train_StdReturn : 31.70827865600586\n",
            "Train_MaxReturn : 11.085997581481934\n",
            "Train_MinReturn : -183.48526000976562\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 450000\n",
            "TimeSinceStart : 483.39533138275146\n",
            "Training Loss : -0.07025062292814255\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 15 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -49.48137283325195\n",
            "Eval_StdReturn : 16.2159423828125\n",
            "Eval_MaxReturn : -36.748477935791016\n",
            "Eval_MinReturn : -72.3656997680664\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -64.6400375366211\n",
            "Train_StdReturn : 28.963781356811523\n",
            "Train_MaxReturn : -8.294854164123535\n",
            "Train_MinReturn : -168.50729370117188\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 480000\n",
            "TimeSinceStart : 515.4860391616821\n",
            "Training Loss : -0.08949455618858337\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 16 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -106.26158905029297\n",
            "Eval_StdReturn : 40.88507080078125\n",
            "Eval_MaxReturn : -48.72374725341797\n",
            "Eval_MinReturn : -139.97332763671875\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -63.729854583740234\n",
            "Train_StdReturn : 27.463134765625\n",
            "Train_MaxReturn : -8.842010498046875\n",
            "Train_MinReturn : -159.69407653808594\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 510000\n",
            "TimeSinceStart : 547.9826486110687\n",
            "Training Loss : -0.08000499755144119\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 17 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -69.87938690185547\n",
            "Eval_StdReturn : 43.514373779296875\n",
            "Eval_MaxReturn : -29.44915199279785\n",
            "Eval_MinReturn : -130.2728271484375\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -63.218502044677734\n",
            "Train_StdReturn : 25.67212677001953\n",
            "Train_MaxReturn : 11.87900161743164\n",
            "Train_MinReturn : -147.377197265625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 540000\n",
            "TimeSinceStart : 580.7965838909149\n",
            "Training Loss : -0.08086956292390823\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 18 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -46.48129653930664\n",
            "Eval_StdReturn : 6.47277307510376\n",
            "Eval_MaxReturn : -40.73896789550781\n",
            "Eval_MinReturn : -55.52614974975586\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -62.72787094116211\n",
            "Train_StdReturn : 27.287254333496094\n",
            "Train_MaxReturn : -0.8492171764373779\n",
            "Train_MinReturn : -155.24468994140625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 570000\n",
            "TimeSinceStart : 613.3864467144012\n",
            "Training Loss : -0.0706307590007782\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 19 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -42.46055221557617\n",
            "Eval_StdReturn : 21.571643829345703\n",
            "Eval_MaxReturn : -19.29850196838379\n",
            "Eval_MinReturn : -71.23585510253906\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -59.24446105957031\n",
            "Train_StdReturn : 26.700336456298828\n",
            "Train_MaxReturn : -0.02259349822998047\n",
            "Train_MinReturn : -145.15895080566406\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 600000\n",
            "TimeSinceStart : 646.5723655223846\n",
            "Training Loss : -0.06951683759689331\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 20 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -54.93484878540039\n",
            "Eval_StdReturn : 12.80453109741211\n",
            "Eval_MaxReturn : -37.01315689086914\n",
            "Eval_MinReturn : -66.14151763916016\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -56.705379486083984\n",
            "Train_StdReturn : 26.645816802978516\n",
            "Train_MaxReturn : 6.546379089355469\n",
            "Train_MinReturn : -176.94674682617188\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 630000\n",
            "TimeSinceStart : 679.3371450901031\n",
            "Training Loss : -0.08647724986076355\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 21 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -66.2531967163086\n",
            "Eval_StdReturn : 32.01264572143555\n",
            "Eval_MaxReturn : -39.50049591064453\n",
            "Eval_MinReturn : -111.2591781616211\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -54.0710563659668\n",
            "Train_StdReturn : 25.17299461364746\n",
            "Train_MaxReturn : 6.236152648925781\n",
            "Train_MinReturn : -126.75359344482422\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 660000\n",
            "TimeSinceStart : 711.7767324447632\n",
            "Training Loss : -0.058227360248565674\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 22 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -37.915016174316406\n",
            "Eval_StdReturn : 23.58979606628418\n",
            "Eval_MaxReturn : -7.648187637329102\n",
            "Eval_MinReturn : -65.1998519897461\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -50.0152587890625\n",
            "Train_StdReturn : 24.91451644897461\n",
            "Train_MaxReturn : 25.457412719726562\n",
            "Train_MinReturn : -121.65365600585938\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 690000\n",
            "TimeSinceStart : 744.0939683914185\n",
            "Training Loss : -0.06517504900693893\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 23 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -52.22624588012695\n",
            "Eval_StdReturn : 2.6026039123535156\n",
            "Eval_MaxReturn : -48.54657745361328\n",
            "Eval_MinReturn : -54.13908767700195\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -54.95280456542969\n",
            "Train_StdReturn : 28.60791015625\n",
            "Train_MaxReturn : 32.43783950805664\n",
            "Train_MinReturn : -160.2530975341797\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 720000\n",
            "TimeSinceStart : 776.4066727161407\n",
            "Training Loss : -0.08785850554704666\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 24 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -55.90374755859375\n",
            "Eval_StdReturn : 48.328121185302734\n",
            "Eval_MaxReturn : -20.31070899963379\n",
            "Eval_MinReturn : -124.23008728027344\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -55.34934616088867\n",
            "Train_StdReturn : 28.055166244506836\n",
            "Train_MaxReturn : 10.730493545532227\n",
            "Train_MinReturn : -165.31675720214844\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 750000\n",
            "TimeSinceStart : 808.9489676952362\n",
            "Training Loss : -0.056213296949863434\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 25 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -36.78901290893555\n",
            "Eval_StdReturn : 27.563274383544922\n",
            "Eval_MaxReturn : 1.4455822706222534\n",
            "Eval_MinReturn : -62.478065490722656\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -54.058780670166016\n",
            "Train_StdReturn : 27.393951416015625\n",
            "Train_MaxReturn : 29.146875381469727\n",
            "Train_MinReturn : -144.25772094726562\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 780000\n",
            "TimeSinceStart : 841.3733241558075\n",
            "Training Loss : -0.07392466068267822\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 26 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -46.0417366027832\n",
            "Eval_StdReturn : 14.756620407104492\n",
            "Eval_MaxReturn : -25.21350860595703\n",
            "Eval_MinReturn : -57.5851936340332\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -51.308448791503906\n",
            "Train_StdReturn : 25.749122619628906\n",
            "Train_MaxReturn : 16.226543426513672\n",
            "Train_MinReturn : -171.16323852539062\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 810000\n",
            "TimeSinceStart : 873.5736064910889\n",
            "Training Loss : -0.052773308008909225\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 27 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -50.81901550292969\n",
            "Eval_StdReturn : 31.2539005279541\n",
            "Eval_MaxReturn : -15.534509658813477\n",
            "Eval_MinReturn : -91.51473236083984\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -47.6855583190918\n",
            "Train_StdReturn : 26.83652114868164\n",
            "Train_MaxReturn : 30.82079315185547\n",
            "Train_MinReturn : -132.69908142089844\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 840000\n",
            "TimeSinceStart : 906.0716683864594\n",
            "Training Loss : -0.07428624480962753\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 28 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -89.82624053955078\n",
            "Eval_StdReturn : 14.957232475280762\n",
            "Eval_MaxReturn : -74.18630981445312\n",
            "Eval_MinReturn : -109.9800033569336\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -50.472068786621094\n",
            "Train_StdReturn : 29.686500549316406\n",
            "Train_MaxReturn : 18.361454010009766\n",
            "Train_MinReturn : -139.83941650390625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 870000\n",
            "TimeSinceStart : 938.1713507175446\n",
            "Training Loss : -0.061381176114082336\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 29 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -37.57773208618164\n",
            "Eval_StdReturn : 31.238786697387695\n",
            "Eval_MaxReturn : 3.7609100341796875\n",
            "Eval_MinReturn : -71.74261474609375\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -51.419822692871094\n",
            "Train_StdReturn : 28.242868423461914\n",
            "Train_MaxReturn : 24.51930046081543\n",
            "Train_MinReturn : -139.03109741210938\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 900000\n",
            "TimeSinceStart : 970.5745785236359\n",
            "Training Loss : -0.06575165688991547\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 30 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -48.08365249633789\n",
            "Eval_StdReturn : 13.140790939331055\n",
            "Eval_MaxReturn : -34.89888000488281\n",
            "Eval_MinReturn : -66.01808166503906\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -50.16566467285156\n",
            "Train_StdReturn : 29.62040901184082\n",
            "Train_MaxReturn : 23.895410537719727\n",
            "Train_MinReturn : -178.4850311279297\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 930000\n",
            "TimeSinceStart : 1003.113879442215\n",
            "Training Loss : -0.05443582311272621\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 31 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -33.58652877807617\n",
            "Eval_StdReturn : 5.630666255950928\n",
            "Eval_MaxReturn : -26.45174217224121\n",
            "Eval_MinReturn : -40.21622848510742\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -48.911094665527344\n",
            "Train_StdReturn : 28.86964988708496\n",
            "Train_MaxReturn : 6.09957218170166\n",
            "Train_MinReturn : -147.6329803466797\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 960000\n",
            "TimeSinceStart : 1035.7128908634186\n",
            "Training Loss : -0.0581594742834568\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 32 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -32.855648040771484\n",
            "Eval_StdReturn : 16.866764068603516\n",
            "Eval_MaxReturn : -14.322967529296875\n",
            "Eval_MinReturn : -55.12723159790039\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -51.39501953125\n",
            "Train_StdReturn : 28.91340446472168\n",
            "Train_MaxReturn : 5.029623031616211\n",
            "Train_MinReturn : -154.86724853515625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 990000\n",
            "TimeSinceStart : 1068.3037133216858\n",
            "Training Loss : -0.05427910387516022\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 33 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -9.359338760375977\n",
            "Eval_StdReturn : 24.790237426757812\n",
            "Eval_MaxReturn : 24.967058181762695\n",
            "Eval_MinReturn : -32.69567108154297\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -44.682498931884766\n",
            "Train_StdReturn : 26.2082576751709\n",
            "Train_MaxReturn : 33.040733337402344\n",
            "Train_MinReturn : -131.15821838378906\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1020000\n",
            "TimeSinceStart : 1100.8495404720306\n",
            "Training Loss : -0.05626773461699486\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 34 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -50.42618942260742\n",
            "Eval_StdReturn : 13.876422882080078\n",
            "Eval_MaxReturn : -35.33690643310547\n",
            "Eval_MinReturn : -68.83673095703125\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -46.315975189208984\n",
            "Train_StdReturn : 27.24526023864746\n",
            "Train_MaxReturn : 31.775270462036133\n",
            "Train_MinReturn : -149.62754821777344\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1050000\n",
            "TimeSinceStart : 1132.904007434845\n",
            "Training Loss : -0.06791426986455917\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 35 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -9.423224449157715\n",
            "Eval_StdReturn : 38.36880111694336\n",
            "Eval_MaxReturn : 44.69525146484375\n",
            "Eval_MinReturn : -39.89426803588867\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -45.36125564575195\n",
            "Train_StdReturn : 26.156635284423828\n",
            "Train_MaxReturn : 27.187255859375\n",
            "Train_MinReturn : -135.69677734375\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1080000\n",
            "TimeSinceStart : 1165.114957332611\n",
            "Training Loss : -0.041283104568719864\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 36 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -34.74966049194336\n",
            "Eval_StdReturn : 6.280740261077881\n",
            "Eval_MaxReturn : -26.383787155151367\n",
            "Eval_MinReturn : -41.51729965209961\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -44.7819938659668\n",
            "Train_StdReturn : 27.252147674560547\n",
            "Train_MaxReturn : 20.965543746948242\n",
            "Train_MinReturn : -143.51756286621094\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1110000\n",
            "TimeSinceStart : 1197.3297173976898\n",
            "Training Loss : -0.07117397338151932\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 37 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -31.186294555664062\n",
            "Eval_StdReturn : 4.627635955810547\n",
            "Eval_MaxReturn : -24.650400161743164\n",
            "Eval_MinReturn : -34.74420928955078\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -45.09708023071289\n",
            "Train_StdReturn : 26.847129821777344\n",
            "Train_MaxReturn : 30.26274299621582\n",
            "Train_MinReturn : -118.77933502197266\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1140000\n",
            "TimeSinceStart : 1229.7332916259766\n",
            "Training Loss : -0.054894085973501205\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 38 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -45.648929595947266\n",
            "Eval_StdReturn : 3.214548349380493\n",
            "Eval_MaxReturn : -41.116825103759766\n",
            "Eval_MinReturn : -48.22319793701172\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -43.146270751953125\n",
            "Train_StdReturn : 25.90528106689453\n",
            "Train_MaxReturn : 50.770835876464844\n",
            "Train_MinReturn : -162.05355834960938\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1170000\n",
            "TimeSinceStart : 1261.8977267742157\n",
            "Training Loss : -0.053787149488925934\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 39 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -70.88410186767578\n",
            "Eval_StdReturn : 28.469478607177734\n",
            "Eval_MaxReturn : -30.66921615600586\n",
            "Eval_MinReturn : -92.67652130126953\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -44.106021881103516\n",
            "Train_StdReturn : 25.53500747680664\n",
            "Train_MaxReturn : 12.29031753540039\n",
            "Train_MinReturn : -110.6584701538086\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1200000\n",
            "TimeSinceStart : 1294.193974494934\n",
            "Training Loss : -0.06200139969587326\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 40 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -49.7652587890625\n",
            "Eval_StdReturn : 5.131698131561279\n",
            "Eval_MaxReturn : -46.047645568847656\n",
            "Eval_MinReturn : -57.0218391418457\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -44.562355041503906\n",
            "Train_StdReturn : 25.83555030822754\n",
            "Train_MaxReturn : 34.72577667236328\n",
            "Train_MinReturn : -133.4598388671875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1230000\n",
            "TimeSinceStart : 1326.670496225357\n",
            "Training Loss : -0.049983032047748566\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 41 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -52.65494918823242\n",
            "Eval_StdReturn : 26.480398178100586\n",
            "Eval_MaxReturn : -16.839065551757812\n",
            "Eval_MinReturn : -80.03570556640625\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -42.43474197387695\n",
            "Train_StdReturn : 29.618850708007812\n",
            "Train_MaxReturn : 45.50904083251953\n",
            "Train_MinReturn : -148.15499877929688\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1260000\n",
            "TimeSinceStart : 1358.8422524929047\n",
            "Training Loss : -0.05598389729857445\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 42 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -26.058263778686523\n",
            "Eval_StdReturn : 1.6888649463653564\n",
            "Eval_MaxReturn : -23.779617309570312\n",
            "Eval_MinReturn : -27.817445755004883\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -45.80262756347656\n",
            "Train_StdReturn : 28.663969039916992\n",
            "Train_MaxReturn : 37.415374755859375\n",
            "Train_MinReturn : -151.7803955078125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1290000\n",
            "TimeSinceStart : 1391.023256778717\n",
            "Training Loss : -0.038832902908325195\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 43 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -42.10761642456055\n",
            "Eval_StdReturn : 13.285968780517578\n",
            "Eval_MaxReturn : -23.84624671936035\n",
            "Eval_MinReturn : -55.068077087402344\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -42.6013298034668\n",
            "Train_StdReturn : 27.95537567138672\n",
            "Train_MaxReturn : 35.19585037231445\n",
            "Train_MinReturn : -164.1836700439453\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1320000\n",
            "TimeSinceStart : 1423.4872934818268\n",
            "Training Loss : -0.0470396988093853\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 44 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -48.47955322265625\n",
            "Eval_StdReturn : 24.512136459350586\n",
            "Eval_MaxReturn : -13.880948066711426\n",
            "Eval_MinReturn : -67.64154052734375\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -43.678253173828125\n",
            "Train_StdReturn : 27.812847137451172\n",
            "Train_MaxReturn : 36.510398864746094\n",
            "Train_MinReturn : -150.20745849609375\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1350000\n",
            "TimeSinceStart : 1455.979418516159\n",
            "Training Loss : -0.07139351963996887\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 45 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -42.06962203979492\n",
            "Eval_StdReturn : 13.571605682373047\n",
            "Eval_MaxReturn : -30.718507766723633\n",
            "Eval_MinReturn : -61.14842224121094\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -39.49330520629883\n",
            "Train_StdReturn : 26.597606658935547\n",
            "Train_MaxReturn : 52.25386047363281\n",
            "Train_MinReturn : -114.5219955444336\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1380000\n",
            "TimeSinceStart : 1488.3791289329529\n",
            "Training Loss : -0.035558611154556274\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 46 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -45.59891128540039\n",
            "Eval_StdReturn : 9.813644409179688\n",
            "Eval_MaxReturn : -37.97718811035156\n",
            "Eval_MinReturn : -59.454345703125\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -39.460269927978516\n",
            "Train_StdReturn : 24.10382080078125\n",
            "Train_MaxReturn : 44.39947509765625\n",
            "Train_MinReturn : -124.7857666015625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1410000\n",
            "TimeSinceStart : 1520.6345999240875\n",
            "Training Loss : -0.05296189710497856\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 47 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -61.20179748535156\n",
            "Eval_StdReturn : 27.921648025512695\n",
            "Eval_MaxReturn : -26.53561019897461\n",
            "Eval_MinReturn : -94.90924072265625\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -37.233036041259766\n",
            "Train_StdReturn : 25.801132202148438\n",
            "Train_MaxReturn : 64.49333190917969\n",
            "Train_MinReturn : -107.83106231689453\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1440000\n",
            "TimeSinceStart : 1552.9326961040497\n",
            "Training Loss : -0.04715766757726669\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 48 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -30.874242782592773\n",
            "Eval_StdReturn : 9.34605598449707\n",
            "Eval_MaxReturn : -22.21109962463379\n",
            "Eval_MinReturn : -43.85078811645508\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -41.504764556884766\n",
            "Train_StdReturn : 24.81100082397461\n",
            "Train_MaxReturn : 10.505369186401367\n",
            "Train_MinReturn : -138.68728637695312\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1470000\n",
            "TimeSinceStart : 1585.2918133735657\n",
            "Training Loss : -0.054849445819854736\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 49 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -27.940797805786133\n",
            "Eval_StdReturn : 12.36475944519043\n",
            "Eval_MaxReturn : -11.097697257995605\n",
            "Eval_MinReturn : -40.432159423828125\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -39.365211486816406\n",
            "Train_StdReturn : 22.55261993408203\n",
            "Train_MaxReturn : 27.04448890686035\n",
            "Train_MinReturn : -138.20120239257812\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1500000\n",
            "TimeSinceStart : 1617.7198796272278\n",
            "Training Loss : -0.05720413476228714\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 50 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -37.7896728515625\n",
            "Eval_StdReturn : 12.567155838012695\n",
            "Eval_MaxReturn : -21.54034423828125\n",
            "Eval_MinReturn : -52.148887634277344\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -35.602272033691406\n",
            "Train_StdReturn : 20.520776748657227\n",
            "Train_MaxReturn : 20.062885284423828\n",
            "Train_MinReturn : -109.90390014648438\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1530000\n",
            "TimeSinceStart : 1650.050637960434\n",
            "Training Loss : -0.06181754544377327\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 51 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -52.17494583129883\n",
            "Eval_StdReturn : 24.166473388671875\n",
            "Eval_MaxReturn : -21.135433197021484\n",
            "Eval_MinReturn : -80.08175659179688\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -38.30521011352539\n",
            "Train_StdReturn : 20.73880386352539\n",
            "Train_MaxReturn : 4.060576438903809\n",
            "Train_MinReturn : -94.26143646240234\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1560000\n",
            "TimeSinceStart : 1682.5153787136078\n",
            "Training Loss : -0.0528239831328392\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 52 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -47.87955093383789\n",
            "Eval_StdReturn : 23.164669036865234\n",
            "Eval_MaxReturn : -20.733234405517578\n",
            "Eval_MinReturn : -77.3338623046875\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -33.14283752441406\n",
            "Train_StdReturn : 21.35049819946289\n",
            "Train_MaxReturn : 13.722770690917969\n",
            "Train_MinReturn : -102.01081848144531\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1590000\n",
            "TimeSinceStart : 1714.7639224529266\n",
            "Training Loss : -0.060769498348236084\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 53 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -44.23246765136719\n",
            "Eval_StdReturn : 11.126030921936035\n",
            "Eval_MaxReturn : -28.600704193115234\n",
            "Eval_MinReturn : -53.603614807128906\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -32.164493560791016\n",
            "Train_StdReturn : 19.016368865966797\n",
            "Train_MaxReturn : 19.559377670288086\n",
            "Train_MinReturn : -114.45271301269531\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1620000\n",
            "TimeSinceStart : 1746.9990289211273\n",
            "Training Loss : -0.06475528329610825\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 54 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -31.61830711364746\n",
            "Eval_StdReturn : 26.959152221679688\n",
            "Eval_MaxReturn : -10.075479507446289\n",
            "Eval_MinReturn : -69.63166809082031\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -32.793739318847656\n",
            "Train_StdReturn : 21.08262062072754\n",
            "Train_MaxReturn : 26.86998176574707\n",
            "Train_MinReturn : -117.51924896240234\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1650000\n",
            "TimeSinceStart : 1779.3267195224762\n",
            "Training Loss : -0.06170877441763878\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 55 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -68.21764373779297\n",
            "Eval_StdReturn : 33.349796295166016\n",
            "Eval_MaxReturn : -32.77123260498047\n",
            "Eval_MinReturn : -112.88481140136719\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -34.88798522949219\n",
            "Train_StdReturn : 21.34296989440918\n",
            "Train_MaxReturn : 12.80286979675293\n",
            "Train_MinReturn : -109.09602355957031\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1680000\n",
            "TimeSinceStart : 1811.6493744850159\n",
            "Training Loss : -0.05921384319663048\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 56 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -41.50760269165039\n",
            "Eval_StdReturn : 4.563826084136963\n",
            "Eval_MaxReturn : -38.075172424316406\n",
            "Eval_MinReturn : -47.957374572753906\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -32.37607955932617\n",
            "Train_StdReturn : 24.182586669921875\n",
            "Train_MaxReturn : 64.357177734375\n",
            "Train_MinReturn : -124.43247985839844\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1710000\n",
            "TimeSinceStart : 1844.0824432373047\n",
            "Training Loss : -0.0394388847053051\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 57 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -43.03470230102539\n",
            "Eval_StdReturn : 23.276758193969727\n",
            "Eval_MaxReturn : -16.03619384765625\n",
            "Eval_MinReturn : -72.84412384033203\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -34.1934928894043\n",
            "Train_StdReturn : 20.960540771484375\n",
            "Train_MaxReturn : 9.054163932800293\n",
            "Train_MinReturn : -120.47216033935547\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1740000\n",
            "TimeSinceStart : 1876.2906250953674\n",
            "Training Loss : -0.04930907487869263\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 58 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -34.72354507446289\n",
            "Eval_StdReturn : 25.679683685302734\n",
            "Eval_MaxReturn : -7.152726173400879\n",
            "Eval_MinReturn : -68.97982788085938\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -33.366153717041016\n",
            "Train_StdReturn : 19.286802291870117\n",
            "Train_MaxReturn : 16.2670841217041\n",
            "Train_MinReturn : -121.04888916015625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1770000\n",
            "TimeSinceStart : 1908.550992488861\n",
            "Training Loss : -0.0619928352534771\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 59 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -34.13374710083008\n",
            "Eval_StdReturn : 8.577401161193848\n",
            "Eval_MaxReturn : -22.17978858947754\n",
            "Eval_MinReturn : -41.89534378051758\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -30.940528869628906\n",
            "Train_StdReturn : 20.24859046936035\n",
            "Train_MaxReturn : 23.509471893310547\n",
            "Train_MinReturn : -86.33660888671875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1800000\n",
            "TimeSinceStart : 1940.800153017044\n",
            "Training Loss : -0.059426236897706985\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 60 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -44.2027473449707\n",
            "Eval_StdReturn : 23.627498626708984\n",
            "Eval_MaxReturn : -22.428768157958984\n",
            "Eval_MinReturn : -77.03987121582031\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -32.23879623413086\n",
            "Train_StdReturn : 21.519733428955078\n",
            "Train_MaxReturn : 30.806541442871094\n",
            "Train_MinReturn : -116.26953125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1830000\n",
            "TimeSinceStart : 1972.8599245548248\n",
            "Training Loss : -0.05386603996157646\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 61 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -22.8630428314209\n",
            "Eval_StdReturn : 8.772757530212402\n",
            "Eval_MaxReturn : -15.180198669433594\n",
            "Eval_MinReturn : -35.14083480834961\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -29.616199493408203\n",
            "Train_StdReturn : 20.989131927490234\n",
            "Train_MaxReturn : 26.475629806518555\n",
            "Train_MinReturn : -117.68112182617188\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1860000\n",
            "TimeSinceStart : 2005.1087291240692\n",
            "Training Loss : -0.030780663713812828\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 62 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -24.37812042236328\n",
            "Eval_StdReturn : 10.85155963897705\n",
            "Eval_MaxReturn : -11.902031898498535\n",
            "Eval_MinReturn : -38.3553466796875\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -32.35170364379883\n",
            "Train_StdReturn : 17.790416717529297\n",
            "Train_MaxReturn : 12.287818908691406\n",
            "Train_MinReturn : -92.83263397216797\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1890000\n",
            "TimeSinceStart : 2037.066244840622\n",
            "Training Loss : -0.050909411162137985\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 63 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -35.780677795410156\n",
            "Eval_StdReturn : 4.178699970245361\n",
            "Eval_MaxReturn : -30.685325622558594\n",
            "Eval_MinReturn : -40.92071533203125\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -28.164278030395508\n",
            "Train_StdReturn : 19.48851776123047\n",
            "Train_MaxReturn : 27.76055145263672\n",
            "Train_MinReturn : -70.69334411621094\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1920000\n",
            "TimeSinceStart : 2069.238092660904\n",
            "Training Loss : -0.051937468349933624\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 64 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -35.86972427368164\n",
            "Eval_StdReturn : 2.6403796672821045\n",
            "Eval_MaxReturn : -33.39842224121094\n",
            "Eval_MinReturn : -39.52960968017578\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -29.871244430541992\n",
            "Train_StdReturn : 19.21665382385254\n",
            "Train_MaxReturn : 16.709712982177734\n",
            "Train_MinReturn : -95.97654724121094\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1950000\n",
            "TimeSinceStart : 2101.517115354538\n",
            "Training Loss : -0.04420340061187744\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 65 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -18.657461166381836\n",
            "Eval_StdReturn : 22.034944534301758\n",
            "Eval_MaxReturn : 9.527917861938477\n",
            "Eval_MinReturn : -44.2608642578125\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -31.214895248413086\n",
            "Train_StdReturn : 19.70743751525879\n",
            "Train_MaxReturn : 41.11768341064453\n",
            "Train_MinReturn : -119.04180908203125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1980000\n",
            "TimeSinceStart : 2133.937713623047\n",
            "Training Loss : -0.031185775995254517\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 66 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -38.75252151489258\n",
            "Eval_StdReturn : 4.186142444610596\n",
            "Eval_MaxReturn : -33.99726486206055\n",
            "Eval_MinReturn : -44.18405532836914\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -33.16242980957031\n",
            "Train_StdReturn : 19.602890014648438\n",
            "Train_MaxReturn : 25.595043182373047\n",
            "Train_MinReturn : -139.71295166015625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2010000\n",
            "TimeSinceStart : 2166.0685369968414\n",
            "Training Loss : -0.056230321526527405\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 67 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -26.163427352905273\n",
            "Eval_StdReturn : 2.0149247646331787\n",
            "Eval_MaxReturn : -23.32080841064453\n",
            "Eval_MinReturn : -27.756546020507812\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -29.514955520629883\n",
            "Train_StdReturn : 19.850526809692383\n",
            "Train_MaxReturn : 23.866729736328125\n",
            "Train_MinReturn : -126.32852172851562\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2040000\n",
            "TimeSinceStart : 2198.321521282196\n",
            "Training Loss : -0.05395089462399483\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 68 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -17.117328643798828\n",
            "Eval_StdReturn : 11.75113582611084\n",
            "Eval_MaxReturn : -6.231678009033203\n",
            "Eval_MinReturn : -33.43492889404297\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -29.365785598754883\n",
            "Train_StdReturn : 20.628841400146484\n",
            "Train_MaxReturn : 16.637773513793945\n",
            "Train_MinReturn : -101.29838562011719\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2070000\n",
            "TimeSinceStart : 2230.395966529846\n",
            "Training Loss : -0.02693401835858822\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 69 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -27.208694458007812\n",
            "Eval_StdReturn : 4.286838531494141\n",
            "Eval_MaxReturn : -23.191844940185547\n",
            "Eval_MinReturn : -33.14957046508789\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -28.7950496673584\n",
            "Train_StdReturn : 16.984460830688477\n",
            "Train_MaxReturn : 12.433719635009766\n",
            "Train_MinReturn : -90.89435577392578\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2100000\n",
            "TimeSinceStart : 2262.478320121765\n",
            "Training Loss : -0.06286655366420746\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 70 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -28.851125717163086\n",
            "Eval_StdReturn : 16.063480377197266\n",
            "Eval_MaxReturn : -7.615011215209961\n",
            "Eval_MinReturn : -46.456581115722656\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -26.06359100341797\n",
            "Train_StdReturn : 16.866043090820312\n",
            "Train_MaxReturn : 21.85500144958496\n",
            "Train_MinReturn : -81.24942016601562\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2130000\n",
            "TimeSinceStart : 2294.4677217006683\n",
            "Training Loss : -0.05400434508919716\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 71 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -40.0113639831543\n",
            "Eval_StdReturn : 12.287107467651367\n",
            "Eval_MaxReturn : -28.045427322387695\n",
            "Eval_MinReturn : -56.906333923339844\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -26.530492782592773\n",
            "Train_StdReturn : 17.550281524658203\n",
            "Train_MaxReturn : 32.68999481201172\n",
            "Train_MinReturn : -76.53675842285156\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2160000\n",
            "TimeSinceStart : 2326.5572578907013\n",
            "Training Loss : -0.05466494336724281\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 72 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -12.044459342956543\n",
            "Eval_StdReturn : 12.216514587402344\n",
            "Eval_MaxReturn : 3.8935298919677734\n",
            "Eval_MinReturn : -25.78841781616211\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -25.788339614868164\n",
            "Train_StdReturn : 16.917522430419922\n",
            "Train_MaxReturn : 27.698680877685547\n",
            "Train_MinReturn : -75.0564193725586\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2190000\n",
            "TimeSinceStart : 2358.8211789131165\n",
            "Training Loss : -0.016858691349625587\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 73 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -6.390399932861328\n",
            "Eval_StdReturn : 8.233407974243164\n",
            "Eval_MaxReturn : 4.855605602264404\n",
            "Eval_MinReturn : -14.626644134521484\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -26.03512191772461\n",
            "Train_StdReturn : 18.317607879638672\n",
            "Train_MaxReturn : 12.452938079833984\n",
            "Train_MinReturn : -122.43077850341797\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2220000\n",
            "TimeSinceStart : 2391.0929815769196\n",
            "Training Loss : -0.03656186908483505\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 74 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -23.533248901367188\n",
            "Eval_StdReturn : 11.970501899719238\n",
            "Eval_MaxReturn : -11.96176528930664\n",
            "Eval_MinReturn : -40.02015686035156\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -23.67316436767578\n",
            "Train_StdReturn : 18.05136489868164\n",
            "Train_MaxReturn : 28.096698760986328\n",
            "Train_MinReturn : -85.23944091796875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2250000\n",
            "TimeSinceStart : 2423.0089149475098\n",
            "Training Loss : -0.049908529967069626\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 75 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -40.003849029541016\n",
            "Eval_StdReturn : 10.705147743225098\n",
            "Eval_MaxReturn : -27.167404174804688\n",
            "Eval_MinReturn : -53.37329864501953\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -25.648897171020508\n",
            "Train_StdReturn : 16.540693283081055\n",
            "Train_MaxReturn : 12.383942604064941\n",
            "Train_MinReturn : -76.88135528564453\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2280000\n",
            "TimeSinceStart : 2455.5219235420227\n",
            "Training Loss : -0.039337337017059326\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 76 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -30.633615493774414\n",
            "Eval_StdReturn : 9.697677612304688\n",
            "Eval_MaxReturn : -17.147056579589844\n",
            "Eval_MinReturn : -39.53374099731445\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -24.656763076782227\n",
            "Train_StdReturn : 17.104095458984375\n",
            "Train_MaxReturn : 14.015409469604492\n",
            "Train_MinReturn : -111.25733947753906\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2310000\n",
            "TimeSinceStart : 2487.631212949753\n",
            "Training Loss : -0.041129838675260544\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 77 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -33.548828125\n",
            "Eval_StdReturn : 12.252164840698242\n",
            "Eval_MaxReturn : -17.350414276123047\n",
            "Eval_MinReturn : -46.97549819946289\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -23.77865219116211\n",
            "Train_StdReturn : 18.4538516998291\n",
            "Train_MaxReturn : 25.122089385986328\n",
            "Train_MinReturn : -69.9338607788086\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2340000\n",
            "TimeSinceStart : 2519.8301680088043\n",
            "Training Loss : -0.04327545687556267\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 78 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -25.069320678710938\n",
            "Eval_StdReturn : 14.637032508850098\n",
            "Eval_MaxReturn : -5.492898941040039\n",
            "Eval_MinReturn : -40.68306350708008\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -24.201662063598633\n",
            "Train_StdReturn : 16.102731704711914\n",
            "Train_MaxReturn : 17.923870086669922\n",
            "Train_MinReturn : -74.03336334228516\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2370000\n",
            "TimeSinceStart : 2552.118970155716\n",
            "Training Loss : -0.04116187244653702\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 79 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -28.950721740722656\n",
            "Eval_StdReturn : 4.281577110290527\n",
            "Eval_MaxReturn : -23.620685577392578\n",
            "Eval_MinReturn : -34.10388946533203\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -21.225305557250977\n",
            "Train_StdReturn : 14.652899742126465\n",
            "Train_MaxReturn : 19.811222076416016\n",
            "Train_MinReturn : -66.22343444824219\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2400000\n",
            "TimeSinceStart : 2584.477400302887\n",
            "Training Loss : -0.039981503039598465\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 80 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -29.901784896850586\n",
            "Eval_StdReturn : 8.372970581054688\n",
            "Eval_MaxReturn : -19.599342346191406\n",
            "Eval_MinReturn : -40.10817337036133\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -23.66303253173828\n",
            "Train_StdReturn : 16.49152374267578\n",
            "Train_MaxReturn : 24.32189178466797\n",
            "Train_MinReturn : -72.32170104980469\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2430000\n",
            "TimeSinceStart : 2616.756827354431\n",
            "Training Loss : -0.05187351629137993\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 81 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -31.722360610961914\n",
            "Eval_StdReturn : 22.590511322021484\n",
            "Eval_MaxReturn : -14.128819465637207\n",
            "Eval_MinReturn : -63.61344528198242\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -25.09853744506836\n",
            "Train_StdReturn : 14.636468887329102\n",
            "Train_MaxReturn : 15.284497261047363\n",
            "Train_MinReturn : -69.45852661132812\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2460000\n",
            "TimeSinceStart : 2648.7742602825165\n",
            "Training Loss : -0.04976659268140793\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 82 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -16.490755081176758\n",
            "Eval_StdReturn : 5.433669090270996\n",
            "Eval_MaxReturn : -9.072746276855469\n",
            "Eval_MinReturn : -21.936710357666016\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -25.070938110351562\n",
            "Train_StdReturn : 16.736440658569336\n",
            "Train_MaxReturn : 20.842037200927734\n",
            "Train_MinReturn : -84.11363220214844\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2490000\n",
            "TimeSinceStart : 2680.78294301033\n",
            "Training Loss : -0.037869758903980255\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 83 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -21.288393020629883\n",
            "Eval_StdReturn : 14.76359748840332\n",
            "Eval_MaxReturn : -3.7115025520324707\n",
            "Eval_MinReturn : -39.83570098876953\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -23.373027801513672\n",
            "Train_StdReturn : 14.973440170288086\n",
            "Train_MaxReturn : 20.6972599029541\n",
            "Train_MinReturn : -70.09005737304688\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2520000\n",
            "TimeSinceStart : 2712.951481103897\n",
            "Training Loss : -0.041148096323013306\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 84 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -14.092354774475098\n",
            "Eval_StdReturn : 19.612733840942383\n",
            "Eval_MaxReturn : 13.172268867492676\n",
            "Eval_MinReturn : -32.137054443359375\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -23.34107208251953\n",
            "Train_StdReturn : 15.983850479125977\n",
            "Train_MaxReturn : 23.072446823120117\n",
            "Train_MinReturn : -68.99227142333984\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2550000\n",
            "TimeSinceStart : 2745.037373304367\n",
            "Training Loss : -0.04881764203310013\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 85 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -41.91438293457031\n",
            "Eval_StdReturn : 13.272773742675781\n",
            "Eval_MaxReturn : -25.923931121826172\n",
            "Eval_MinReturn : -58.42306137084961\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -22.035112380981445\n",
            "Train_StdReturn : 16.973888397216797\n",
            "Train_MaxReturn : 22.845542907714844\n",
            "Train_MinReturn : -133.12496948242188\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2580000\n",
            "TimeSinceStart : 2777.2758162021637\n",
            "Training Loss : -0.05824645981192589\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 86 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -1.868112564086914\n",
            "Eval_StdReturn : 13.65103816986084\n",
            "Eval_MaxReturn : 17.297094345092773\n",
            "Eval_MinReturn : -13.462533950805664\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -20.94011878967285\n",
            "Train_StdReturn : 14.984028816223145\n",
            "Train_MaxReturn : 24.273035049438477\n",
            "Train_MinReturn : -57.928428649902344\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2610000\n",
            "TimeSinceStart : 2809.3307299613953\n",
            "Training Loss : -0.0629514828324318\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 87 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -24.932077407836914\n",
            "Eval_StdReturn : 6.097817897796631\n",
            "Eval_MaxReturn : -18.814579010009766\n",
            "Eval_MinReturn : -33.25459289550781\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -20.32994842529297\n",
            "Train_StdReturn : 14.97131633758545\n",
            "Train_MaxReturn : 20.574987411499023\n",
            "Train_MinReturn : -62.225624084472656\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2640000\n",
            "TimeSinceStart : 2841.37038564682\n",
            "Training Loss : -0.06086024269461632\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 88 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -24.0939884185791\n",
            "Eval_StdReturn : 5.788777828216553\n",
            "Eval_MaxReturn : -17.993328094482422\n",
            "Eval_MinReturn : -31.87204360961914\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -19.915328979492188\n",
            "Train_StdReturn : 17.999380111694336\n",
            "Train_MaxReturn : 32.73219299316406\n",
            "Train_MinReturn : -138.3671875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2670000\n",
            "TimeSinceStart : 2873.4884247779846\n",
            "Training Loss : -0.05697185918688774\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 89 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -11.2135009765625\n",
            "Eval_StdReturn : 3.567298650741577\n",
            "Eval_MaxReturn : -8.414794921875\n",
            "Eval_MinReturn : -16.247941970825195\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -17.803932189941406\n",
            "Train_StdReturn : 17.706132888793945\n",
            "Train_MaxReturn : 28.395755767822266\n",
            "Train_MinReturn : -79.22726440429688\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2700000\n",
            "TimeSinceStart : 2905.8203480243683\n",
            "Training Loss : -0.04501790553331375\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 90 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -11.734179496765137\n",
            "Eval_StdReturn : 14.393547058105469\n",
            "Eval_MaxReturn : 8.40357780456543\n",
            "Eval_MinReturn : -24.374902725219727\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -17.643953323364258\n",
            "Train_StdReturn : 13.961050987243652\n",
            "Train_MaxReturn : 25.639095306396484\n",
            "Train_MinReturn : -62.423946380615234\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2730000\n",
            "TimeSinceStart : 2937.9597277641296\n",
            "Training Loss : -0.04568386822938919\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 91 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -18.39064598083496\n",
            "Eval_StdReturn : 7.639133453369141\n",
            "Eval_MaxReturn : -10.24036693572998\n",
            "Eval_MinReturn : -28.606979370117188\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -17.085325241088867\n",
            "Train_StdReturn : 15.151636123657227\n",
            "Train_MaxReturn : 22.969242095947266\n",
            "Train_MinReturn : -72.25138092041016\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2760000\n",
            "TimeSinceStart : 2970.032336950302\n",
            "Training Loss : -0.04547424241900444\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 92 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -8.609875679016113\n",
            "Eval_StdReturn : 8.070380210876465\n",
            "Eval_MaxReturn : 0.9002819061279297\n",
            "Eval_MinReturn : -18.82977294921875\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -16.422605514526367\n",
            "Train_StdReturn : 16.852338790893555\n",
            "Train_MaxReturn : 27.673721313476562\n",
            "Train_MinReturn : -71.09626770019531\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2790000\n",
            "TimeSinceStart : 3001.8982412815094\n",
            "Training Loss : -0.043143369257450104\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 93 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -8.9192533493042\n",
            "Eval_StdReturn : 12.031325340270996\n",
            "Eval_MaxReturn : 7.320281028747559\n",
            "Eval_MinReturn : -21.436443328857422\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -15.15464973449707\n",
            "Train_StdReturn : 14.939228057861328\n",
            "Train_MaxReturn : 16.09984588623047\n",
            "Train_MinReturn : -53.362640380859375\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2820000\n",
            "TimeSinceStart : 3033.7912063598633\n",
            "Training Loss : -0.04764353111386299\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 94 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -26.673072814941406\n",
            "Eval_StdReturn : 11.861123085021973\n",
            "Eval_MaxReturn : -10.728175163269043\n",
            "Eval_MinReturn : -39.15657043457031\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -14.532878875732422\n",
            "Train_StdReturn : 17.012508392333984\n",
            "Train_MaxReturn : 33.509395599365234\n",
            "Train_MinReturn : -114.03517150878906\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2850000\n",
            "TimeSinceStart : 3066.1086192131042\n",
            "Training Loss : -0.01291996706277132\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 95 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -35.75993347167969\n",
            "Eval_StdReturn : 9.737934112548828\n",
            "Eval_MaxReturn : -23.69394302368164\n",
            "Eval_MinReturn : -47.541839599609375\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -12.907958984375\n",
            "Train_StdReturn : 17.60641098022461\n",
            "Train_MaxReturn : 34.11298370361328\n",
            "Train_MinReturn : -78.88111877441406\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2880000\n",
            "TimeSinceStart : 3098.2643938064575\n",
            "Training Loss : -0.032895527780056\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 96 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -8.029623985290527\n",
            "Eval_StdReturn : 15.883976936340332\n",
            "Eval_MaxReturn : 14.302404403686523\n",
            "Eval_MinReturn : -21.29599380493164\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -13.128087043762207\n",
            "Train_StdReturn : 16.029237747192383\n",
            "Train_MaxReturn : 53.78661346435547\n",
            "Train_MinReturn : -50.27519607543945\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2910000\n",
            "TimeSinceStart : 3130.301926136017\n",
            "Training Loss : -0.03364258632063866\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 97 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -4.497760772705078\n",
            "Eval_StdReturn : 7.668114185333252\n",
            "Eval_MaxReturn : 4.857079029083252\n",
            "Eval_MinReturn : -13.925464630126953\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -13.264315605163574\n",
            "Train_StdReturn : 15.667978286743164\n",
            "Train_MaxReturn : 36.5831298828125\n",
            "Train_MinReturn : -63.79435729980469\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2940000\n",
            "TimeSinceStart : 3162.236277103424\n",
            "Training Loss : -0.03150949999690056\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 98 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -15.825728416442871\n",
            "Eval_StdReturn : 8.687774658203125\n",
            "Eval_MaxReturn : -4.202512741088867\n",
            "Eval_MinReturn : -25.085784912109375\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -11.919831275939941\n",
            "Train_StdReturn : 16.584239959716797\n",
            "Train_MaxReturn : 36.24510192871094\n",
            "Train_MinReturn : -55.266441345214844\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2970000\n",
            "TimeSinceStart : 3194.13495016098\n",
            "Training Loss : -0.028959590941667557\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 99 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -18.663400650024414\n",
            "Eval_StdReturn : 2.671022415161133\n",
            "Eval_MaxReturn : -15.342000961303711\n",
            "Eval_MinReturn : -21.882230758666992\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -12.07284164428711\n",
            "Train_StdReturn : 17.189708709716797\n",
            "Train_MaxReturn : 46.533477783203125\n",
            "Train_MinReturn : -59.055763244628906\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3000000\n",
            "TimeSinceStart : 3226.0138845443726\n",
            "Training Loss : -0.037359412759542465\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python cs285/scripts/run_hw2.py --env_name HalfCheetah-v2 --ep_len 150 \\\n",
        "--discount 0.95 -n 100 -l 2 -s 32 -b 30000 -lr 0.005 -rtg --nn_baseline \\\n",
        "--exp_name q4_search_b30000_lr005_rtg_nnbaseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJvcIWYs8Zm2",
        "outputId": "0f493cca-5eb2-4d6f-d7ed-bb07d5001d1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "########################\n",
            "logging outputs to  /content/gdrive/My Drive/cs285_f2021/DRL_policy_grads/cs285/scripts/../../data/q4_search_b30000_lr01_rtg_nnbaseline_HalfCheetah-v2_06-02-2022_21-24-42\n",
            "########################\n",
            "Using GPU id 0\n",
            "Sequential(\n",
            "  (0): Linear(in_features=17, out_features=32, bias=True)\n",
            "  (1): Tanh()\n",
            "  (2): Linear(in_features=32, out_features=32, bias=True)\n",
            "  (3): Tanh()\n",
            "  (4): Linear(in_features=32, out_features=6, bias=True)\n",
            "  (5): Identity()\n",
            ")\n",
            "Sequential(\n",
            "  (0): Linear(in_features=17, out_features=32, bias=True)\n",
            "  (1): Tanh()\n",
            "  (2): Linear(in_features=32, out_features=32, bias=True)\n",
            "  (3): Tanh()\n",
            "  (4): Linear(in_features=32, out_features=1, bias=True)\n",
            "  (5): Identity()\n",
            ")\n",
            "\n",
            "\n",
            "********** Iteration 0 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -71.840087890625\n",
            "Eval_StdReturn : 29.49768829345703\n",
            "Eval_MaxReturn : -30.48509407043457\n",
            "Eval_MinReturn : -97.26033782958984\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -88.9120864868164\n",
            "Train_StdReturn : 35.07945251464844\n",
            "Train_MaxReturn : -6.333817481994629\n",
            "Train_MinReturn : -178.995361328125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 30000\n",
            "TimeSinceStart : 31.11048173904419\n",
            "Training Loss : -0.06758902221918106\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 1 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -99.93710327148438\n",
            "Eval_StdReturn : 25.317813873291016\n",
            "Eval_MaxReturn : -64.28250122070312\n",
            "Eval_MinReturn : -120.60157775878906\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -87.9639663696289\n",
            "Train_StdReturn : 37.3625373840332\n",
            "Train_MaxReturn : -13.684986114501953\n",
            "Train_MinReturn : -206.39581298828125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 60000\n",
            "TimeSinceStart : 62.65178823471069\n",
            "Training Loss : -0.06166200339794159\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 2 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -62.70283889770508\n",
            "Eval_StdReturn : 21.996639251708984\n",
            "Eval_MaxReturn : -37.424400329589844\n",
            "Eval_MinReturn : -91.04328918457031\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -79.99874877929688\n",
            "Train_StdReturn : 37.20126724243164\n",
            "Train_MaxReturn : 0.21604424715042114\n",
            "Train_MinReturn : -229.98159790039062\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 90000\n",
            "TimeSinceStart : 94.13660287857056\n",
            "Training Loss : -0.09518499672412872\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 3 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -89.7917709350586\n",
            "Eval_StdReturn : 19.51515007019043\n",
            "Eval_MaxReturn : -73.44541931152344\n",
            "Eval_MinReturn : -117.22264862060547\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -77.21912384033203\n",
            "Train_StdReturn : 33.273738861083984\n",
            "Train_MaxReturn : 5.159814834594727\n",
            "Train_MinReturn : -175.60931396484375\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 120000\n",
            "TimeSinceStart : 125.58206248283386\n",
            "Training Loss : -0.0929010882973671\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 4 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -61.75249099731445\n",
            "Eval_StdReturn : 25.442781448364258\n",
            "Eval_MaxReturn : -25.816614151000977\n",
            "Eval_MinReturn : -81.28955841064453\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -70.53323364257812\n",
            "Train_StdReturn : 28.857065200805664\n",
            "Train_MaxReturn : -6.232480049133301\n",
            "Train_MinReturn : -210.02737426757812\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 150000\n",
            "TimeSinceStart : 157.21972131729126\n",
            "Training Loss : -0.07832253724336624\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 5 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -44.57876968383789\n",
            "Eval_StdReturn : 10.12761402130127\n",
            "Eval_MaxReturn : -31.318241119384766\n",
            "Eval_MinReturn : -55.89642333984375\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -69.18583679199219\n",
            "Train_StdReturn : 29.35750389099121\n",
            "Train_MaxReturn : 12.894773483276367\n",
            "Train_MinReturn : -174.54873657226562\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 180000\n",
            "TimeSinceStart : 188.812481880188\n",
            "Training Loss : -0.08758094161748886\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 6 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -83.12728881835938\n",
            "Eval_StdReturn : 34.186397552490234\n",
            "Eval_MaxReturn : -48.724239349365234\n",
            "Eval_MinReturn : -129.74627685546875\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -69.45671844482422\n",
            "Train_StdReturn : 26.748231887817383\n",
            "Train_MaxReturn : -4.110065460205078\n",
            "Train_MinReturn : -166.22720336914062\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 210000\n",
            "TimeSinceStart : 220.4565873146057\n",
            "Training Loss : -0.09858480095863342\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 7 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -39.111881256103516\n",
            "Eval_StdReturn : 25.57724952697754\n",
            "Eval_MaxReturn : -8.899568557739258\n",
            "Eval_MinReturn : -71.44318389892578\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -66.2159423828125\n",
            "Train_StdReturn : 25.316089630126953\n",
            "Train_MaxReturn : -2.4291763305664062\n",
            "Train_MinReturn : -150.78916931152344\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 240000\n",
            "TimeSinceStart : 251.9572982788086\n",
            "Training Loss : -0.07542271912097931\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 8 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -55.08673095703125\n",
            "Eval_StdReturn : 19.783313751220703\n",
            "Eval_MaxReturn : -40.946319580078125\n",
            "Eval_MinReturn : -83.06401062011719\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -66.21441650390625\n",
            "Train_StdReturn : 26.308521270751953\n",
            "Train_MaxReturn : 13.558371543884277\n",
            "Train_MinReturn : -138.6091766357422\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 270000\n",
            "TimeSinceStart : 283.68919944763184\n",
            "Training Loss : -0.08104803413152695\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 9 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -78.1580581665039\n",
            "Eval_StdReturn : 27.207347869873047\n",
            "Eval_MaxReturn : -44.87865447998047\n",
            "Eval_MinReturn : -111.52261352539062\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -63.34135818481445\n",
            "Train_StdReturn : 29.09065818786621\n",
            "Train_MaxReturn : 13.919363021850586\n",
            "Train_MinReturn : -169.12286376953125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 300000\n",
            "TimeSinceStart : 315.4126160144806\n",
            "Training Loss : -0.09410113841295242\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 10 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -39.60307693481445\n",
            "Eval_StdReturn : 26.049983978271484\n",
            "Eval_MaxReturn : -14.250585556030273\n",
            "Eval_MinReturn : -75.42755889892578\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -64.2982406616211\n",
            "Train_StdReturn : 30.598342895507812\n",
            "Train_MaxReturn : 36.614173889160156\n",
            "Train_MinReturn : -172.55416870117188\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 330000\n",
            "TimeSinceStart : 347.1199355125427\n",
            "Training Loss : -0.08317095786333084\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 11 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -33.42715072631836\n",
            "Eval_StdReturn : 7.266073226928711\n",
            "Eval_MaxReturn : -23.409639358520508\n",
            "Eval_MinReturn : -40.418540954589844\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -62.091575622558594\n",
            "Train_StdReturn : 29.363136291503906\n",
            "Train_MaxReturn : 7.956714630126953\n",
            "Train_MinReturn : -151.9524688720703\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 360000\n",
            "TimeSinceStart : 379.01680755615234\n",
            "Training Loss : -0.07136229425668716\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 12 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -55.92311096191406\n",
            "Eval_StdReturn : 7.1225433349609375\n",
            "Eval_MaxReturn : -48.216217041015625\n",
            "Eval_MinReturn : -65.39338684082031\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -56.332637786865234\n",
            "Train_StdReturn : 32.02369689941406\n",
            "Train_MaxReturn : 28.048276901245117\n",
            "Train_MinReturn : -200.63458251953125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 390000\n",
            "TimeSinceStart : 411.04918241500854\n",
            "Training Loss : -0.06789084523916245\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 13 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -30.385839462280273\n",
            "Eval_StdReturn : 4.346083164215088\n",
            "Eval_MaxReturn : -25.591829299926758\n",
            "Eval_MinReturn : -36.11387252807617\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -57.167518615722656\n",
            "Train_StdReturn : 31.572696685791016\n",
            "Train_MaxReturn : 28.008577346801758\n",
            "Train_MinReturn : -174.05007934570312\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 420000\n",
            "TimeSinceStart : 442.8705794811249\n",
            "Training Loss : -0.07296213507652283\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 14 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -33.05131149291992\n",
            "Eval_StdReturn : 11.658034324645996\n",
            "Eval_MaxReturn : -17.91541290283203\n",
            "Eval_MinReturn : -46.27992248535156\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -53.836002349853516\n",
            "Train_StdReturn : 28.942296981811523\n",
            "Train_MaxReturn : 47.17028045654297\n",
            "Train_MinReturn : -144.01226806640625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 450000\n",
            "TimeSinceStart : 474.6948070526123\n",
            "Training Loss : -0.08982998132705688\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 15 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -46.13151931762695\n",
            "Eval_StdReturn : 6.420859336853027\n",
            "Eval_MaxReturn : -37.460487365722656\n",
            "Eval_MinReturn : -52.801780700683594\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -51.15012741088867\n",
            "Train_StdReturn : 29.85271644592285\n",
            "Train_MaxReturn : 43.92221450805664\n",
            "Train_MinReturn : -166.72853088378906\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 480000\n",
            "TimeSinceStart : 506.619460105896\n",
            "Training Loss : -0.06569036841392517\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 16 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -43.78351974487305\n",
            "Eval_StdReturn : 3.612029552459717\n",
            "Eval_MaxReturn : -38.67536544799805\n",
            "Eval_MinReturn : -46.352622985839844\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -50.302127838134766\n",
            "Train_StdReturn : 24.832998275756836\n",
            "Train_MaxReturn : 20.591400146484375\n",
            "Train_MinReturn : -147.77682495117188\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 510000\n",
            "TimeSinceStart : 538.5821645259857\n",
            "Training Loss : -0.062271468341350555\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 17 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -45.659366607666016\n",
            "Eval_StdReturn : 15.621196746826172\n",
            "Eval_MaxReturn : -32.668609619140625\n",
            "Eval_MinReturn : -67.62933349609375\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -46.9480094909668\n",
            "Train_StdReturn : 23.499282836914062\n",
            "Train_MaxReturn : 6.9944658279418945\n",
            "Train_MinReturn : -140.35720825195312\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 540000\n",
            "TimeSinceStart : 570.135568857193\n",
            "Training Loss : -0.08518876135349274\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 18 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -22.5116024017334\n",
            "Eval_StdReturn : 18.27001190185547\n",
            "Eval_MaxReturn : 0.08551979064941406\n",
            "Eval_MinReturn : -44.659934997558594\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -45.66334915161133\n",
            "Train_StdReturn : 21.124330520629883\n",
            "Train_MaxReturn : 21.249183654785156\n",
            "Train_MinReturn : -101.20133972167969\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 570000\n",
            "TimeSinceStart : 601.973058462143\n",
            "Training Loss : -0.05412713438272476\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 19 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -33.12199401855469\n",
            "Eval_StdReturn : 12.963068962097168\n",
            "Eval_MaxReturn : -16.35342025756836\n",
            "Eval_MinReturn : -47.92289733886719\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -43.69621658325195\n",
            "Train_StdReturn : 25.48773193359375\n",
            "Train_MaxReturn : 15.941349983215332\n",
            "Train_MinReturn : -124.05856323242188\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 600000\n",
            "TimeSinceStart : 633.6364126205444\n",
            "Training Loss : -0.06694310903549194\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 20 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -8.479585647583008\n",
            "Eval_StdReturn : 18.576946258544922\n",
            "Eval_MaxReturn : 10.673007011413574\n",
            "Eval_MinReturn : -33.6295166015625\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -44.35396957397461\n",
            "Train_StdReturn : 23.41731071472168\n",
            "Train_MaxReturn : 23.784584045410156\n",
            "Train_MinReturn : -128.18045043945312\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 630000\n",
            "TimeSinceStart : 665.4738101959229\n",
            "Training Loss : -0.07206139713525772\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 21 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -33.5555305480957\n",
            "Eval_StdReturn : 15.44378662109375\n",
            "Eval_MaxReturn : -15.50338077545166\n",
            "Eval_MinReturn : -53.22846984863281\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -40.055625915527344\n",
            "Train_StdReturn : 23.39215087890625\n",
            "Train_MaxReturn : 17.956371307373047\n",
            "Train_MinReturn : -113.82203674316406\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 660000\n",
            "TimeSinceStart : 697.3132321834564\n",
            "Training Loss : -0.07119069993495941\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 22 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -47.944122314453125\n",
            "Eval_StdReturn : 22.917741775512695\n",
            "Eval_MaxReturn : -31.645954132080078\n",
            "Eval_MinReturn : -80.35452270507812\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -39.34484100341797\n",
            "Train_StdReturn : 22.900394439697266\n",
            "Train_MaxReturn : 18.309770584106445\n",
            "Train_MinReturn : -117.04989624023438\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 690000\n",
            "TimeSinceStart : 729.2695744037628\n",
            "Training Loss : -0.050262078642845154\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 23 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -26.835298538208008\n",
            "Eval_StdReturn : 17.147296905517578\n",
            "Eval_MaxReturn : -8.073653221130371\n",
            "Eval_MinReturn : -49.52195358276367\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -40.5035285949707\n",
            "Train_StdReturn : 25.50558090209961\n",
            "Train_MaxReturn : 21.854656219482422\n",
            "Train_MinReturn : -126.41375732421875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 720000\n",
            "TimeSinceStart : 761.3795258998871\n",
            "Training Loss : -0.04833761602640152\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 24 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -69.10665130615234\n",
            "Eval_StdReturn : 22.204195022583008\n",
            "Eval_MaxReturn : -41.94120788574219\n",
            "Eval_MinReturn : -96.33006286621094\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -39.2896614074707\n",
            "Train_StdReturn : 27.304969787597656\n",
            "Train_MaxReturn : 52.422462463378906\n",
            "Train_MinReturn : -130.02267456054688\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 750000\n",
            "TimeSinceStart : 793.2850072383881\n",
            "Training Loss : -0.041314803063869476\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 25 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -46.561248779296875\n",
            "Eval_StdReturn : 1.783345103263855\n",
            "Eval_MaxReturn : -44.07636260986328\n",
            "Eval_MinReturn : -48.17717361450195\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -35.565834045410156\n",
            "Train_StdReturn : 26.988750457763672\n",
            "Train_MaxReturn : 88.952880859375\n",
            "Train_MinReturn : -119.36248779296875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 780000\n",
            "TimeSinceStart : 825.0834534168243\n",
            "Training Loss : -0.04860769957304001\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 26 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -15.466236114501953\n",
            "Eval_StdReturn : 9.936274528503418\n",
            "Eval_MaxReturn : -1.5694084167480469\n",
            "Eval_MinReturn : -24.218238830566406\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -39.468406677246094\n",
            "Train_StdReturn : 23.603471755981445\n",
            "Train_MaxReturn : 38.55030059814453\n",
            "Train_MinReturn : -109.70637512207031\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 810000\n",
            "TimeSinceStart : 857.088054895401\n",
            "Training Loss : -0.030949337407946587\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 27 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -23.24052619934082\n",
            "Eval_StdReturn : 18.984905242919922\n",
            "Eval_MaxReturn : 3.266016960144043\n",
            "Eval_MinReturn : -40.194114685058594\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -36.57876968383789\n",
            "Train_StdReturn : 22.936853408813477\n",
            "Train_MaxReturn : 23.941303253173828\n",
            "Train_MinReturn : -113.03273010253906\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 840000\n",
            "TimeSinceStart : 888.9025182723999\n",
            "Training Loss : -0.053894028067588806\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 28 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -50.055419921875\n",
            "Eval_StdReturn : 28.7984676361084\n",
            "Eval_MaxReturn : -17.702260971069336\n",
            "Eval_MinReturn : -87.65587615966797\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -41.979164123535156\n",
            "Train_StdReturn : 23.218900680541992\n",
            "Train_MaxReturn : 17.647785186767578\n",
            "Train_MinReturn : -99.58700561523438\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 870000\n",
            "TimeSinceStart : 921.1034648418427\n",
            "Training Loss : -0.039422787725925446\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 29 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -33.61235427856445\n",
            "Eval_StdReturn : 15.66612434387207\n",
            "Eval_MaxReturn : -13.030577659606934\n",
            "Eval_MinReturn : -51.00493621826172\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -39.81026077270508\n",
            "Train_StdReturn : 27.889894485473633\n",
            "Train_MaxReturn : 43.670494079589844\n",
            "Train_MinReturn : -158.5948486328125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 900000\n",
            "TimeSinceStart : 953.0369398593903\n",
            "Training Loss : -0.041699301451444626\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 30 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -69.31769561767578\n",
            "Eval_StdReturn : 33.3589973449707\n",
            "Eval_MaxReturn : -29.767900466918945\n",
            "Eval_MinReturn : -111.36576080322266\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -31.724611282348633\n",
            "Train_StdReturn : 22.890308380126953\n",
            "Train_MaxReturn : 38.208892822265625\n",
            "Train_MinReturn : -81.08905029296875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 930000\n",
            "TimeSinceStart : 984.8942775726318\n",
            "Training Loss : -0.03473823145031929\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 31 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -25.993886947631836\n",
            "Eval_StdReturn : 10.358986854553223\n",
            "Eval_MaxReturn : -11.344098091125488\n",
            "Eval_MinReturn : -33.344947814941406\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -31.666706085205078\n",
            "Train_StdReturn : 22.820194244384766\n",
            "Train_MaxReturn : 22.692771911621094\n",
            "Train_MinReturn : -88.47593688964844\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 960000\n",
            "TimeSinceStart : 1016.8076918125153\n",
            "Training Loss : -0.038372527807950974\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 32 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -31.747474670410156\n",
            "Eval_StdReturn : 28.095935821533203\n",
            "Eval_MaxReturn : 7.849370956420898\n",
            "Eval_MinReturn : -54.39891815185547\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -31.812480926513672\n",
            "Train_StdReturn : 22.705881118774414\n",
            "Train_MaxReturn : 40.812171936035156\n",
            "Train_MinReturn : -107.64337158203125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 990000\n",
            "TimeSinceStart : 1048.6526808738708\n",
            "Training Loss : -0.05261066183447838\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 33 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -21.753694534301758\n",
            "Eval_StdReturn : 14.397577285766602\n",
            "Eval_MaxReturn : -1.4124813079833984\n",
            "Eval_MinReturn : -32.70636749267578\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -30.402803421020508\n",
            "Train_StdReturn : 24.21625328063965\n",
            "Train_MaxReturn : 32.08973693847656\n",
            "Train_MinReturn : -109.02371978759766\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1020000\n",
            "TimeSinceStart : 1080.85085272789\n",
            "Training Loss : -0.032795216888189316\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 34 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -32.01609420776367\n",
            "Eval_StdReturn : 17.031801223754883\n",
            "Eval_MaxReturn : -8.17618179321289\n",
            "Eval_MinReturn : -46.913841247558594\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -32.50791931152344\n",
            "Train_StdReturn : 26.028850555419922\n",
            "Train_MaxReturn : 47.513614654541016\n",
            "Train_MinReturn : -131.48211669921875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1050000\n",
            "TimeSinceStart : 1112.7933852672577\n",
            "Training Loss : -0.05354078859090805\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 35 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -45.41939163208008\n",
            "Eval_StdReturn : 7.512137413024902\n",
            "Eval_MaxReturn : -34.8062629699707\n",
            "Eval_MinReturn : -51.13755798339844\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -29.413612365722656\n",
            "Train_StdReturn : 24.25815773010254\n",
            "Train_MaxReturn : 16.097410202026367\n",
            "Train_MinReturn : -147.57559204101562\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1080000\n",
            "TimeSinceStart : 1144.771693944931\n",
            "Training Loss : -0.04044567793607712\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 36 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -11.27145767211914\n",
            "Eval_StdReturn : 8.75100326538086\n",
            "Eval_MaxReturn : 0.2837486267089844\n",
            "Eval_MinReturn : -20.88676643371582\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -26.59732437133789\n",
            "Train_StdReturn : 24.58056640625\n",
            "Train_MaxReturn : 41.93130874633789\n",
            "Train_MinReturn : -118.52381134033203\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1110000\n",
            "TimeSinceStart : 1176.674106836319\n",
            "Training Loss : -0.04412811994552612\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 37 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -34.82168197631836\n",
            "Eval_StdReturn : 13.183798789978027\n",
            "Eval_MaxReturn : -19.604585647583008\n",
            "Eval_MinReturn : -51.760223388671875\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -29.427261352539062\n",
            "Train_StdReturn : 21.625234603881836\n",
            "Train_MaxReturn : 20.17945671081543\n",
            "Train_MinReturn : -123.36639404296875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1140000\n",
            "TimeSinceStart : 1208.73499417305\n",
            "Training Loss : -0.0581546276807785\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 38 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -18.994821548461914\n",
            "Eval_StdReturn : 14.961795806884766\n",
            "Eval_MaxReturn : 1.8666086196899414\n",
            "Eval_MinReturn : -32.488792419433594\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -25.921215057373047\n",
            "Train_StdReturn : 20.94095802307129\n",
            "Train_MaxReturn : 35.049095153808594\n",
            "Train_MinReturn : -87.03507995605469\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1170000\n",
            "TimeSinceStart : 1240.9173414707184\n",
            "Training Loss : -0.03729904815554619\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 39 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -32.775753021240234\n",
            "Eval_StdReturn : 30.2694091796875\n",
            "Eval_MaxReturn : 2.27135968208313\n",
            "Eval_MinReturn : -71.58617401123047\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -25.452482223510742\n",
            "Train_StdReturn : 20.218944549560547\n",
            "Train_MaxReturn : 26.59134292602539\n",
            "Train_MinReturn : -98.06102752685547\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1200000\n",
            "TimeSinceStart : 1273.029559135437\n",
            "Training Loss : -0.045296795666217804\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 40 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -21.298608779907227\n",
            "Eval_StdReturn : 5.432298183441162\n",
            "Eval_MaxReturn : -13.745068550109863\n",
            "Eval_MinReturn : -26.28898048400879\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -24.388486862182617\n",
            "Train_StdReturn : 19.26906967163086\n",
            "Train_MaxReturn : 26.34041976928711\n",
            "Train_MinReturn : -98.003173828125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1230000\n",
            "TimeSinceStart : 1305.2872850894928\n",
            "Training Loss : -0.04202510789036751\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 41 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -25.959203720092773\n",
            "Eval_StdReturn : 31.882356643676758\n",
            "Eval_MaxReturn : 16.247325897216797\n",
            "Eval_MinReturn : -60.79868698120117\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -21.717514038085938\n",
            "Train_StdReturn : 18.010986328125\n",
            "Train_MaxReturn : 24.235183715820312\n",
            "Train_MinReturn : -85.81277465820312\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1260000\n",
            "TimeSinceStart : 1337.543463230133\n",
            "Training Loss : -0.05261923745274544\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 42 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -18.72502326965332\n",
            "Eval_StdReturn : 8.960307121276855\n",
            "Eval_MaxReturn : -8.898187637329102\n",
            "Eval_MinReturn : -30.56705093383789\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -23.0978946685791\n",
            "Train_StdReturn : 17.32929229736328\n",
            "Train_MaxReturn : 24.187353134155273\n",
            "Train_MinReturn : -99.96456909179688\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1290000\n",
            "TimeSinceStart : 1369.8855051994324\n",
            "Training Loss : -0.02526203915476799\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 43 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -9.71141529083252\n",
            "Eval_StdReturn : 2.2275729179382324\n",
            "Eval_MaxReturn : -6.637988090515137\n",
            "Eval_MinReturn : -11.847007751464844\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -18.507041931152344\n",
            "Train_StdReturn : 16.58144760131836\n",
            "Train_MaxReturn : 27.486888885498047\n",
            "Train_MinReturn : -76.56695556640625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1320000\n",
            "TimeSinceStart : 1402.069284915924\n",
            "Training Loss : -0.03874039649963379\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 44 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -32.07889938354492\n",
            "Eval_StdReturn : 17.691736221313477\n",
            "Eval_MaxReturn : -17.90256118774414\n",
            "Eval_MinReturn : -57.02119827270508\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -17.936941146850586\n",
            "Train_StdReturn : 16.20574378967285\n",
            "Train_MaxReturn : 45.07992172241211\n",
            "Train_MinReturn : -59.20586395263672\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1350000\n",
            "TimeSinceStart : 1434.1336648464203\n",
            "Training Loss : -0.03963657096028328\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 45 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -15.721351623535156\n",
            "Eval_StdReturn : 5.160275459289551\n",
            "Eval_MaxReturn : -10.08758544921875\n",
            "Eval_MinReturn : -22.555469512939453\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -17.92523765563965\n",
            "Train_StdReturn : 15.869979858398438\n",
            "Train_MaxReturn : 38.559783935546875\n",
            "Train_MinReturn : -69.90147399902344\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1380000\n",
            "TimeSinceStart : 1466.377162694931\n",
            "Training Loss : -0.022522347047924995\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 46 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -11.33031177520752\n",
            "Eval_StdReturn : 11.847113609313965\n",
            "Eval_MaxReturn : 4.703768730163574\n",
            "Eval_MinReturn : -23.555957794189453\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -17.921709060668945\n",
            "Train_StdReturn : 15.178613662719727\n",
            "Train_MaxReturn : 32.404815673828125\n",
            "Train_MinReturn : -64.27157592773438\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1410000\n",
            "TimeSinceStart : 1498.518394947052\n",
            "Training Loss : -0.02485397644340992\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 47 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -8.50903034210205\n",
            "Eval_StdReturn : 8.140669822692871\n",
            "Eval_MaxReturn : 2.9957690238952637\n",
            "Eval_MinReturn : -14.629472732543945\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -18.465253829956055\n",
            "Train_StdReturn : 15.92920207977295\n",
            "Train_MaxReturn : 22.862621307373047\n",
            "Train_MinReturn : -76.69049072265625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1440000\n",
            "TimeSinceStart : 1530.7288777828217\n",
            "Training Loss : -0.04664941504597664\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 48 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -20.36273765563965\n",
            "Eval_StdReturn : 13.508962631225586\n",
            "Eval_MaxReturn : -4.998828887939453\n",
            "Eval_MinReturn : -37.87834930419922\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -21.854991912841797\n",
            "Train_StdReturn : 13.055818557739258\n",
            "Train_MaxReturn : 13.303939819335938\n",
            "Train_MinReturn : -61.84485626220703\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1470000\n",
            "TimeSinceStart : 1562.7672894001007\n",
            "Training Loss : -0.031853675842285156\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 49 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -13.30490779876709\n",
            "Eval_StdReturn : 12.324234962463379\n",
            "Eval_MaxReturn : 0.12915992736816406\n",
            "Eval_MinReturn : -29.638307571411133\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -22.363706588745117\n",
            "Train_StdReturn : 14.343896865844727\n",
            "Train_MaxReturn : 20.921974182128906\n",
            "Train_MinReturn : -60.08715057373047\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1500000\n",
            "TimeSinceStart : 1595.026214838028\n",
            "Training Loss : -0.048206087201833725\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 50 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -21.82029151916504\n",
            "Eval_StdReturn : 6.232516288757324\n",
            "Eval_MaxReturn : -14.224310874938965\n",
            "Eval_MinReturn : -29.490257263183594\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -22.49441909790039\n",
            "Train_StdReturn : 13.337234497070312\n",
            "Train_MaxReturn : 12.820760726928711\n",
            "Train_MinReturn : -65.27284240722656\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1530000\n",
            "TimeSinceStart : 1627.0037479400635\n",
            "Training Loss : -0.03951254487037659\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 51 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -13.51522159576416\n",
            "Eval_StdReturn : 13.35736083984375\n",
            "Eval_MaxReturn : 4.349384307861328\n",
            "Eval_MinReturn : -27.764530181884766\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -20.853809356689453\n",
            "Train_StdReturn : 14.723793029785156\n",
            "Train_MaxReturn : 11.123392105102539\n",
            "Train_MinReturn : -74.09249877929688\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1560000\n",
            "TimeSinceStart : 1659.077577829361\n",
            "Training Loss : -0.02026410773396492\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 52 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 0.6048221588134766\n",
            "Eval_StdReturn : 19.09183120727539\n",
            "Eval_MaxReturn : 27.410369873046875\n",
            "Eval_MinReturn : -15.598670959472656\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -19.86675262451172\n",
            "Train_StdReturn : 14.29843521118164\n",
            "Train_MaxReturn : 28.997425079345703\n",
            "Train_MinReturn : -60.52046203613281\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1590000\n",
            "TimeSinceStart : 1691.314153432846\n",
            "Training Loss : -0.03683064505457878\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 53 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -20.938570022583008\n",
            "Eval_StdReturn : 6.485198497772217\n",
            "Eval_MaxReturn : -13.219752311706543\n",
            "Eval_MinReturn : -29.08768653869629\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -19.919641494750977\n",
            "Train_StdReturn : 13.86056137084961\n",
            "Train_MaxReturn : 16.05524444580078\n",
            "Train_MinReturn : -59.397605895996094\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1620000\n",
            "TimeSinceStart : 1723.672636270523\n",
            "Training Loss : -0.024895520880818367\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 54 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -25.776166915893555\n",
            "Eval_StdReturn : 15.802809715270996\n",
            "Eval_MaxReturn : -3.487623929977417\n",
            "Eval_MinReturn : -38.33778381347656\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -16.963611602783203\n",
            "Train_StdReturn : 12.83781623840332\n",
            "Train_MaxReturn : 24.187408447265625\n",
            "Train_MinReturn : -57.38492202758789\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1650000\n",
            "TimeSinceStart : 1755.6809005737305\n",
            "Training Loss : -0.04671772941946983\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 55 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -24.849899291992188\n",
            "Eval_StdReturn : 8.95709228515625\n",
            "Eval_MaxReturn : -14.60751724243164\n",
            "Eval_MinReturn : -36.4258918762207\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -17.702247619628906\n",
            "Train_StdReturn : 14.615997314453125\n",
            "Train_MaxReturn : 32.32526779174805\n",
            "Train_MinReturn : -54.81512451171875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1680000\n",
            "TimeSinceStart : 1787.9843859672546\n",
            "Training Loss : -0.047330792993307114\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 56 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -24.257108688354492\n",
            "Eval_StdReturn : 8.22043514251709\n",
            "Eval_MaxReturn : -12.727750778198242\n",
            "Eval_MinReturn : -31.31360626220703\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -15.413522720336914\n",
            "Train_StdReturn : 15.231728553771973\n",
            "Train_MaxReturn : 19.748119354248047\n",
            "Train_MinReturn : -70.07656860351562\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1710000\n",
            "TimeSinceStart : 1820.2333476543427\n",
            "Training Loss : -0.016500944271683693\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 57 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -9.632929801940918\n",
            "Eval_StdReturn : 6.240921974182129\n",
            "Eval_MaxReturn : -2.759733200073242\n",
            "Eval_MinReturn : -17.864633560180664\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -16.10996437072754\n",
            "Train_StdReturn : 14.54572582244873\n",
            "Train_MaxReturn : 26.996356964111328\n",
            "Train_MinReturn : -62.95963668823242\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1740000\n",
            "TimeSinceStart : 1852.3986642360687\n",
            "Training Loss : -0.019360575824975967\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 58 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -5.063172817230225\n",
            "Eval_StdReturn : 5.536141395568848\n",
            "Eval_MaxReturn : 1.6846582889556885\n",
            "Eval_MinReturn : -11.875601768493652\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -13.013667106628418\n",
            "Train_StdReturn : 12.968474388122559\n",
            "Train_MaxReturn : 23.63860321044922\n",
            "Train_MinReturn : -46.25602722167969\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1770000\n",
            "TimeSinceStart : 1884.6148042678833\n",
            "Training Loss : -0.02355150505900383\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 59 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -14.066741943359375\n",
            "Eval_StdReturn : 7.967234134674072\n",
            "Eval_MaxReturn : -5.617685317993164\n",
            "Eval_MinReturn : -24.746912002563477\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -11.29858684539795\n",
            "Train_StdReturn : 14.36864948272705\n",
            "Train_MaxReturn : 20.800804138183594\n",
            "Train_MinReturn : -52.71199417114258\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1800000\n",
            "TimeSinceStart : 1916.66446185112\n",
            "Training Loss : -0.034342944622039795\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 60 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -9.392763137817383\n",
            "Eval_StdReturn : 3.52008318901062\n",
            "Eval_MaxReturn : -4.810567855834961\n",
            "Eval_MinReturn : -13.36882209777832\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -10.23135757446289\n",
            "Train_StdReturn : 15.30788516998291\n",
            "Train_MaxReturn : 52.48036575317383\n",
            "Train_MinReturn : -64.96739196777344\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1830000\n",
            "TimeSinceStart : 1948.8607459068298\n",
            "Training Loss : -0.02562655135989189\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 61 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -10.656820297241211\n",
            "Eval_StdReturn : 9.905205726623535\n",
            "Eval_MaxReturn : 2.735074996948242\n",
            "Eval_MinReturn : -20.91120719909668\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -9.205138206481934\n",
            "Train_StdReturn : 15.606499671936035\n",
            "Train_MaxReturn : 30.719242095947266\n",
            "Train_MinReturn : -47.794921875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1860000\n",
            "TimeSinceStart : 1980.796862602234\n",
            "Training Loss : -0.022325964644551277\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 62 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -6.448047161102295\n",
            "Eval_StdReturn : 2.2643444538116455\n",
            "Eval_MaxReturn : -3.917901039123535\n",
            "Eval_MinReturn : -9.413018226623535\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -8.272762298583984\n",
            "Train_StdReturn : 16.763538360595703\n",
            "Train_MaxReturn : 33.26032638549805\n",
            "Train_MinReturn : -63.869571685791016\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1890000\n",
            "TimeSinceStart : 2012.6169776916504\n",
            "Training Loss : -0.02789180912077427\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 63 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -15.844813346862793\n",
            "Eval_StdReturn : 13.29865550994873\n",
            "Eval_MaxReturn : -5.550158500671387\n",
            "Eval_MinReturn : -34.62285614013672\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -8.471217155456543\n",
            "Train_StdReturn : 17.487213134765625\n",
            "Train_MaxReturn : 47.823204040527344\n",
            "Train_MinReturn : -78.51898193359375\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1920000\n",
            "TimeSinceStart : 2044.557383298874\n",
            "Training Loss : -0.01904529705643654\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 64 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -24.554651260375977\n",
            "Eval_StdReturn : 24.354433059692383\n",
            "Eval_MaxReturn : -6.868964195251465\n",
            "Eval_MinReturn : -58.99280548095703\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -8.167620658874512\n",
            "Train_StdReturn : 14.451314926147461\n",
            "Train_MaxReturn : 29.78877830505371\n",
            "Train_MinReturn : -52.017887115478516\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1950000\n",
            "TimeSinceStart : 2076.748797416687\n",
            "Training Loss : -0.01067525427788496\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 65 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -4.414713382720947\n",
            "Eval_StdReturn : 4.189093112945557\n",
            "Eval_MaxReturn : 1.3768870830535889\n",
            "Eval_MinReturn : -8.390226364135742\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -9.68269157409668\n",
            "Train_StdReturn : 17.278554916381836\n",
            "Train_MaxReturn : 34.98421859741211\n",
            "Train_MinReturn : -65.07231140136719\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1980000\n",
            "TimeSinceStart : 2108.6466858386993\n",
            "Training Loss : -0.01913483440876007\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 66 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -7.62184476852417\n",
            "Eval_StdReturn : 3.957379102706909\n",
            "Eval_MaxReturn : -2.0946712493896484\n",
            "Eval_MinReturn : -11.146376609802246\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -12.397758483886719\n",
            "Train_StdReturn : 16.086111068725586\n",
            "Train_MaxReturn : 23.007539749145508\n",
            "Train_MinReturn : -97.68858337402344\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2010000\n",
            "TimeSinceStart : 2140.3425002098083\n",
            "Training Loss : -0.01223727222532034\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 67 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -0.42159080505371094\n",
            "Eval_StdReturn : 5.604056358337402\n",
            "Eval_MaxReturn : 5.178123474121094\n",
            "Eval_MinReturn : -8.078460693359375\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -11.584268569946289\n",
            "Train_StdReturn : 15.984607696533203\n",
            "Train_MaxReturn : 42.15821075439453\n",
            "Train_MinReturn : -72.31135559082031\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2040000\n",
            "TimeSinceStart : 2171.9670112133026\n",
            "Training Loss : -0.012183024547994137\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 68 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -12.656753540039062\n",
            "Eval_StdReturn : 11.897401809692383\n",
            "Eval_MaxReturn : 3.933103561401367\n",
            "Eval_MinReturn : -23.38165283203125\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -7.701693058013916\n",
            "Train_StdReturn : 14.884432792663574\n",
            "Train_MaxReturn : 26.137733459472656\n",
            "Train_MinReturn : -57.599266052246094\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2070000\n",
            "TimeSinceStart : 2203.54679274559\n",
            "Training Loss : 0.0020614522509276867\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 69 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -16.669876098632812\n",
            "Eval_StdReturn : 7.868978500366211\n",
            "Eval_MaxReturn : -6.54847526550293\n",
            "Eval_MinReturn : -25.736717224121094\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -5.4567108154296875\n",
            "Train_StdReturn : 13.712348937988281\n",
            "Train_MaxReturn : 36.01106262207031\n",
            "Train_MinReturn : -55.98556900024414\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2100000\n",
            "TimeSinceStart : 2235.289354801178\n",
            "Training Loss : -0.04429414123296738\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 70 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 6.967775344848633\n",
            "Eval_StdReturn : 10.088085174560547\n",
            "Eval_MaxReturn : 21.196910858154297\n",
            "Eval_MinReturn : -1.0428853034973145\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -2.59120512008667\n",
            "Train_StdReturn : 14.935872077941895\n",
            "Train_MaxReturn : 29.843538284301758\n",
            "Train_MinReturn : -46.928436279296875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2130000\n",
            "TimeSinceStart : 2267.1390433311462\n",
            "Training Loss : -0.020113196223974228\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 71 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 7.20012903213501\n",
            "Eval_StdReturn : 21.042675018310547\n",
            "Eval_MaxReturn : 34.875831604003906\n",
            "Eval_MinReturn : -16.11046600341797\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -1.9807549715042114\n",
            "Train_StdReturn : 16.28907012939453\n",
            "Train_MaxReturn : 36.51561737060547\n",
            "Train_MinReturn : -53.91514587402344\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2160000\n",
            "TimeSinceStart : 2298.800225496292\n",
            "Training Loss : -0.019190657883882523\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 72 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 5.949602127075195\n",
            "Eval_StdReturn : 17.32178497314453\n",
            "Eval_MaxReturn : 18.276643753051758\n",
            "Eval_MinReturn : -18.546932220458984\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -2.9190824031829834\n",
            "Train_StdReturn : 15.434290885925293\n",
            "Train_MaxReturn : 35.523170471191406\n",
            "Train_MinReturn : -60.7762565612793\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2190000\n",
            "TimeSinceStart : 2330.8641154766083\n",
            "Training Loss : -0.006397936958819628\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 73 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -0.3086468279361725\n",
            "Eval_StdReturn : 4.073263645172119\n",
            "Eval_MaxReturn : 4.192080497741699\n",
            "Eval_MinReturn : -5.672658920288086\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 1.652815818786621\n",
            "Train_StdReturn : 14.062971115112305\n",
            "Train_MaxReturn : 31.136960983276367\n",
            "Train_MinReturn : -59.516700744628906\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2220000\n",
            "TimeSinceStart : 2362.873260974884\n",
            "Training Loss : -0.009111816063523293\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 74 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -0.2062627524137497\n",
            "Eval_StdReturn : 4.297474384307861\n",
            "Eval_MaxReturn : 4.978831768035889\n",
            "Eval_MinReturn : -5.544447898864746\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -1.6681201457977295\n",
            "Train_StdReturn : 15.200345993041992\n",
            "Train_MaxReturn : 35.819339752197266\n",
            "Train_MinReturn : -72.40667724609375\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2250000\n",
            "TimeSinceStart : 2395.0605504512787\n",
            "Training Loss : -0.018019596114754677\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 75 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 2.422074556350708\n",
            "Eval_StdReturn : 8.240336418151855\n",
            "Eval_MaxReturn : 11.299201965332031\n",
            "Eval_MinReturn : -8.555004119873047\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -1.8316071033477783\n",
            "Train_StdReturn : 15.545284271240234\n",
            "Train_MaxReturn : 31.337064743041992\n",
            "Train_MinReturn : -57.39393615722656\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2280000\n",
            "TimeSinceStart : 2427.1779506206512\n",
            "Training Loss : -0.00734226917847991\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 76 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 7.974981307983398\n",
            "Eval_StdReturn : 10.215826988220215\n",
            "Eval_MaxReturn : 17.483652114868164\n",
            "Eval_MinReturn : -6.1992034912109375\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -0.16473206877708435\n",
            "Train_StdReturn : 13.969701766967773\n",
            "Train_MaxReturn : 26.758108139038086\n",
            "Train_MinReturn : -43.73138427734375\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2310000\n",
            "TimeSinceStart : 2459.1304371356964\n",
            "Training Loss : -0.013869612477719784\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 77 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -4.40183687210083\n",
            "Eval_StdReturn : 17.841699600219727\n",
            "Eval_MaxReturn : 18.988332748413086\n",
            "Eval_MinReturn : -24.29230499267578\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -0.2555573284626007\n",
            "Train_StdReturn : 14.88893985748291\n",
            "Train_MaxReturn : 33.24589920043945\n",
            "Train_MinReturn : -43.41899108886719\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2340000\n",
            "TimeSinceStart : 2491.2352681159973\n",
            "Training Loss : -0.013051962479948997\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 78 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -13.622169494628906\n",
            "Eval_StdReturn : 15.008757591247559\n",
            "Eval_MaxReturn : 1.0031452178955078\n",
            "Eval_MinReturn : -34.256587982177734\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -1.487715721130371\n",
            "Train_StdReturn : 15.605270385742188\n",
            "Train_MaxReturn : 27.792831420898438\n",
            "Train_MinReturn : -56.3759651184082\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2370000\n",
            "TimeSinceStart : 2523.261040210724\n",
            "Training Loss : -0.0065457927994430065\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 79 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -2.8303744792938232\n",
            "Eval_StdReturn : 15.153440475463867\n",
            "Eval_MaxReturn : 18.398780822753906\n",
            "Eval_MinReturn : -15.981164932250977\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -1.277349591255188\n",
            "Train_StdReturn : 15.681428909301758\n",
            "Train_MaxReturn : 57.567508697509766\n",
            "Train_MinReturn : -55.661529541015625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2400000\n",
            "TimeSinceStart : 2555.1957428455353\n",
            "Training Loss : 0.0011919657699763775\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 80 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -1.5507227182388306\n",
            "Eval_StdReturn : 10.962857246398926\n",
            "Eval_MaxReturn : 13.941469192504883\n",
            "Eval_MinReturn : -9.816762924194336\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -3.324411630630493\n",
            "Train_StdReturn : 14.22518253326416\n",
            "Train_MaxReturn : 40.74953079223633\n",
            "Train_MinReturn : -49.42013168334961\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2430000\n",
            "TimeSinceStart : 2587.157051086426\n",
            "Training Loss : -0.020551562309265137\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 81 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -8.567191123962402\n",
            "Eval_StdReturn : 18.87596321105957\n",
            "Eval_MaxReturn : 17.613704681396484\n",
            "Eval_MinReturn : -26.17133140563965\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -8.697820663452148\n",
            "Train_StdReturn : 14.776360511779785\n",
            "Train_MaxReturn : 33.554908752441406\n",
            "Train_MinReturn : -51.01219177246094\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2460000\n",
            "TimeSinceStart : 2619.113021373749\n",
            "Training Loss : -0.00045523681910708547\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 82 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -9.990328788757324\n",
            "Eval_StdReturn : 14.521228790283203\n",
            "Eval_MaxReturn : 9.895611763000488\n",
            "Eval_MinReturn : -24.373027801513672\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -8.214816093444824\n",
            "Train_StdReturn : 15.186067581176758\n",
            "Train_MaxReturn : 39.52991485595703\n",
            "Train_MinReturn : -50.416507720947266\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2490000\n",
            "TimeSinceStart : 2651.2093727588654\n",
            "Training Loss : -0.0014628825010731816\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 83 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -10.315842628479004\n",
            "Eval_StdReturn : 4.412896156311035\n",
            "Eval_MaxReturn : -4.986063003540039\n",
            "Eval_MinReturn : -15.7924165725708\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -13.66039752960205\n",
            "Train_StdReturn : 16.798383712768555\n",
            "Train_MaxReturn : 26.062397003173828\n",
            "Train_MinReturn : -53.11262130737305\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2520000\n",
            "TimeSinceStart : 2683.060345888138\n",
            "Training Loss : -0.010078251361846924\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 84 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -29.05279541015625\n",
            "Eval_StdReturn : 20.93939781188965\n",
            "Eval_MaxReturn : -8.49566650390625\n",
            "Eval_MinReturn : -57.79052734375\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -17.46001434326172\n",
            "Train_StdReturn : 19.34222412109375\n",
            "Train_MaxReturn : 29.140316009521484\n",
            "Train_MinReturn : -92.96939086914062\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2550000\n",
            "TimeSinceStart : 2714.9491527080536\n",
            "Training Loss : -0.010343428701162338\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 85 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -0.6509749293327332\n",
            "Eval_StdReturn : 6.178463459014893\n",
            "Eval_MaxReturn : 7.116084575653076\n",
            "Eval_MinReturn : -8.000728607177734\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -15.243376731872559\n",
            "Train_StdReturn : 14.541025161743164\n",
            "Train_MaxReturn : 28.528331756591797\n",
            "Train_MinReturn : -53.35356903076172\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2580000\n",
            "TimeSinceStart : 2746.878171443939\n",
            "Training Loss : -0.023712914437055588\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 86 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -8.817891120910645\n",
            "Eval_StdReturn : 32.728477478027344\n",
            "Eval_MaxReturn : 20.004730224609375\n",
            "Eval_MinReturn : -54.592750549316406\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -14.313843727111816\n",
            "Train_StdReturn : 18.125858306884766\n",
            "Train_MaxReturn : 31.2386417388916\n",
            "Train_MinReturn : -69.36107635498047\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2610000\n",
            "TimeSinceStart : 2778.4438664913177\n",
            "Training Loss : -0.020654834806919098\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 87 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -26.00600242614746\n",
            "Eval_StdReturn : 16.498260498046875\n",
            "Eval_MaxReturn : -8.111199378967285\n",
            "Eval_MinReturn : -47.91954803466797\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -13.815781593322754\n",
            "Train_StdReturn : 20.11983871459961\n",
            "Train_MaxReturn : 31.956674575805664\n",
            "Train_MinReturn : -81.43766784667969\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2640000\n",
            "TimeSinceStart : 2810.369246482849\n",
            "Training Loss : -0.019746899604797363\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 88 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 6.549570560455322\n",
            "Eval_StdReturn : 14.84677791595459\n",
            "Eval_MaxReturn : 25.631103515625\n",
            "Eval_MinReturn : -10.578128814697266\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -8.324714660644531\n",
            "Train_StdReturn : 17.44217872619629\n",
            "Train_MaxReturn : 33.61224365234375\n",
            "Train_MinReturn : -94.6043701171875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2670000\n",
            "TimeSinceStart : 2842.2629537582397\n",
            "Training Loss : -0.03286653384566307\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 89 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -8.991621971130371\n",
            "Eval_StdReturn : 5.529959678649902\n",
            "Eval_MaxReturn : -1.2494115829467773\n",
            "Eval_MinReturn : -13.818924903869629\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -4.311158657073975\n",
            "Train_StdReturn : 18.299524307250977\n",
            "Train_MaxReturn : 36.18251037597656\n",
            "Train_MinReturn : -66.54224395751953\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2700000\n",
            "TimeSinceStart : 2873.912308692932\n",
            "Training Loss : -0.012059456668794155\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 90 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -2.209836483001709\n",
            "Eval_StdReturn : 2.7608935832977295\n",
            "Eval_MaxReturn : 0.4909224510192871\n",
            "Eval_MinReturn : -6.002187728881836\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -0.5959203839302063\n",
            "Train_StdReturn : 15.564225196838379\n",
            "Train_MaxReturn : 29.151647567749023\n",
            "Train_MinReturn : -44.782814025878906\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2730000\n",
            "TimeSinceStart : 2905.6456310749054\n",
            "Training Loss : -0.015233435668051243\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 91 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 9.765731811523438\n",
            "Eval_StdReturn : 12.148966789245605\n",
            "Eval_MaxReturn : 24.623044967651367\n",
            "Eval_MinReturn : -5.135626316070557\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 0.14607185125350952\n",
            "Train_StdReturn : 14.775477409362793\n",
            "Train_MaxReturn : 37.792091369628906\n",
            "Train_MinReturn : -42.14896774291992\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2760000\n",
            "TimeSinceStart : 2937.534076690674\n",
            "Training Loss : -0.015476253814995289\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 92 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 10.42109203338623\n",
            "Eval_StdReturn : 7.894355297088623\n",
            "Eval_MaxReturn : 16.233386993408203\n",
            "Eval_MinReturn : -0.7400054931640625\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -1.3076672554016113\n",
            "Train_StdReturn : 16.121183395385742\n",
            "Train_MaxReturn : 32.3352165222168\n",
            "Train_MinReturn : -51.92347717285156\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2790000\n",
            "TimeSinceStart : 2969.4059269428253\n",
            "Training Loss : -0.03083210438489914\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 93 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -10.159786224365234\n",
            "Eval_StdReturn : 20.303604125976562\n",
            "Eval_MaxReturn : 16.841358184814453\n",
            "Eval_MinReturn : -32.11956787109375\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 0.9339454770088196\n",
            "Train_StdReturn : 15.161334037780762\n",
            "Train_MaxReturn : 37.64912414550781\n",
            "Train_MinReturn : -52.50410842895508\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2820000\n",
            "TimeSinceStart : 3001.3541312217712\n",
            "Training Loss : -0.021437976509332657\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 94 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 8.885171890258789\n",
            "Eval_StdReturn : 2.110930919647217\n",
            "Eval_MaxReturn : 11.804759979248047\n",
            "Eval_MinReturn : 6.885889053344727\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 1.130339503288269\n",
            "Train_StdReturn : 14.993030548095703\n",
            "Train_MaxReturn : 32.242042541503906\n",
            "Train_MinReturn : -44.38100814819336\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2850000\n",
            "TimeSinceStart : 3033.2785465717316\n",
            "Training Loss : 0.007323966361582279\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 95 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -20.40082359313965\n",
            "Eval_StdReturn : 12.638522148132324\n",
            "Eval_MaxReturn : -10.035928726196289\n",
            "Eval_MinReturn : -38.19378662109375\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 0.7648176550865173\n",
            "Train_StdReturn : 17.669618606567383\n",
            "Train_MaxReturn : 50.69610595703125\n",
            "Train_MinReturn : -50.039920806884766\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2880000\n",
            "TimeSinceStart : 3064.9872579574585\n",
            "Training Loss : 0.0016565348487347364\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 96 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -6.288820266723633\n",
            "Eval_StdReturn : 9.61744499206543\n",
            "Eval_MaxReturn : 1.9703459739685059\n",
            "Eval_MinReturn : -19.776954650878906\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 1.8133355379104614\n",
            "Train_StdReturn : 15.50454330444336\n",
            "Train_MaxReturn : 45.81118392944336\n",
            "Train_MinReturn : -67.46365356445312\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2910000\n",
            "TimeSinceStart : 3096.962578058243\n",
            "Training Loss : -0.007483667228370905\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 97 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1.3793219327926636\n",
            "Eval_StdReturn : 2.7221052646636963\n",
            "Eval_MaxReturn : 5.220564365386963\n",
            "Eval_MinReturn : -0.7613630294799805\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -0.5393126010894775\n",
            "Train_StdReturn : 17.023212432861328\n",
            "Train_MaxReturn : 36.85090637207031\n",
            "Train_MinReturn : -73.50904846191406\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2940000\n",
            "TimeSinceStart : 3128.7101354599\n",
            "Training Loss : -0.004962845705449581\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 98 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -3.498128890991211\n",
            "Eval_StdReturn : 7.711090087890625\n",
            "Eval_MaxReturn : 6.804666519165039\n",
            "Eval_MinReturn : -11.744791984558105\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -1.1445046663284302\n",
            "Train_StdReturn : 15.986398696899414\n",
            "Train_MaxReturn : 32.279632568359375\n",
            "Train_MinReturn : -59.534156799316406\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2970000\n",
            "TimeSinceStart : 3160.513864517212\n",
            "Training Loss : -0.022823713719844818\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 99 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 3.166355848312378\n",
            "Eval_StdReturn : 22.12918472290039\n",
            "Eval_MaxReturn : 33.950279235839844\n",
            "Eval_MinReturn : -17.10554313659668\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 0.24799127876758575\n",
            "Train_StdReturn : 16.089170455932617\n",
            "Train_MaxReturn : 40.47189712524414\n",
            "Train_MinReturn : -59.189022064208984\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3000000\n",
            "TimeSinceStart : 3192.1408977508545\n",
            "Training Loss : -0.004587174393236637\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python cs285/scripts/run_hw2.py --env_name HalfCheetah-v2 --ep_len 150 \\\n",
        "--discount 0.95 -n 100 -l 2 -s 32 -b 30000 -lr 0.01 -rtg --nn_baseline \\\n",
        "--exp_name q4_search_b30000_lr01_rtg_nnbaseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-IJ-aw58bbs",
        "outputId": "88d0fc40-37fe-4e37-a647-d168d86398e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "########################\n",
            "logging outputs to  /content/gdrive/My Drive/cs285_f2021/DRL_policy_grads/cs285/scripts/../../data/q4_search_b30000_lr02_rtg_nnbaseline_HalfCheetah-v2_06-02-2022_22-17-58\n",
            "########################\n",
            "Using GPU id 0\n",
            "Sequential(\n",
            "  (0): Linear(in_features=17, out_features=32, bias=True)\n",
            "  (1): Tanh()\n",
            "  (2): Linear(in_features=32, out_features=32, bias=True)\n",
            "  (3): Tanh()\n",
            "  (4): Linear(in_features=32, out_features=6, bias=True)\n",
            "  (5): Identity()\n",
            ")\n",
            "Sequential(\n",
            "  (0): Linear(in_features=17, out_features=32, bias=True)\n",
            "  (1): Tanh()\n",
            "  (2): Linear(in_features=32, out_features=32, bias=True)\n",
            "  (3): Tanh()\n",
            "  (4): Linear(in_features=32, out_features=1, bias=True)\n",
            "  (5): Identity()\n",
            ")\n",
            "\n",
            "\n",
            "********** Iteration 0 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -93.4373550415039\n",
            "Eval_StdReturn : 34.35115051269531\n",
            "Eval_MaxReturn : -47.01206970214844\n",
            "Eval_MinReturn : -129.04039001464844\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -88.9120864868164\n",
            "Train_StdReturn : 35.07945251464844\n",
            "Train_MaxReturn : -6.333817481994629\n",
            "Train_MinReturn : -178.995361328125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 30000\n",
            "TimeSinceStart : 31.155485153198242\n",
            "Training Loss : -0.06758902221918106\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 1 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -83.07010650634766\n",
            "Eval_StdReturn : 36.57284164428711\n",
            "Eval_MaxReturn : -41.02839660644531\n",
            "Eval_MinReturn : -130.1817626953125\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -80.6435546875\n",
            "Train_StdReturn : 35.75518798828125\n",
            "Train_MaxReturn : 10.577484130859375\n",
            "Train_MinReturn : -175.43136596679688\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 60000\n",
            "TimeSinceStart : 62.68729901313782\n",
            "Training Loss : -0.08144355565309525\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 2 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -51.8096809387207\n",
            "Eval_StdReturn : 17.048023223876953\n",
            "Eval_MaxReturn : -28.759042739868164\n",
            "Eval_MinReturn : -69.45494842529297\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -77.39508056640625\n",
            "Train_StdReturn : 29.505109786987305\n",
            "Train_MaxReturn : -17.54793930053711\n",
            "Train_MinReturn : -190.35324096679688\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 90000\n",
            "TimeSinceStart : 94.24292182922363\n",
            "Training Loss : -0.09067592769861221\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 3 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -79.22750854492188\n",
            "Eval_StdReturn : 3.718528985977173\n",
            "Eval_MaxReturn : -73.9967269897461\n",
            "Eval_MinReturn : -82.31234741210938\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -73.836669921875\n",
            "Train_StdReturn : 31.15610694885254\n",
            "Train_MaxReturn : 10.92647647857666\n",
            "Train_MinReturn : -212.06680297851562\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 120000\n",
            "TimeSinceStart : 125.92988276481628\n",
            "Training Loss : -0.08552814275026321\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 4 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -71.96859741210938\n",
            "Eval_StdReturn : 10.137181282043457\n",
            "Eval_MaxReturn : -62.63388442993164\n",
            "Eval_MinReturn : -86.05885314941406\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -71.54999542236328\n",
            "Train_StdReturn : 27.476594924926758\n",
            "Train_MaxReturn : 2.4678430557250977\n",
            "Train_MinReturn : -149.6499786376953\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 150000\n",
            "TimeSinceStart : 157.59718322753906\n",
            "Training Loss : -0.07499097287654877\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 5 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -59.877071380615234\n",
            "Eval_StdReturn : 11.422466278076172\n",
            "Eval_MaxReturn : -44.79346466064453\n",
            "Eval_MinReturn : -72.42613983154297\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -60.25579071044922\n",
            "Train_StdReturn : 28.208778381347656\n",
            "Train_MaxReturn : 21.241771697998047\n",
            "Train_MinReturn : -155.8509979248047\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 180000\n",
            "TimeSinceStart : 189.3579180240631\n",
            "Training Loss : -0.07611676305532455\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 6 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -47.9213752746582\n",
            "Eval_StdReturn : 31.222055435180664\n",
            "Eval_MaxReturn : -5.448026657104492\n",
            "Eval_MinReturn : -79.60964965820312\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -60.358787536621094\n",
            "Train_StdReturn : 28.776575088500977\n",
            "Train_MaxReturn : 11.941574096679688\n",
            "Train_MinReturn : -193.3141632080078\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 210000\n",
            "TimeSinceStart : 220.94616842269897\n",
            "Training Loss : -0.05684638023376465\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 7 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -46.26456069946289\n",
            "Eval_StdReturn : 27.433820724487305\n",
            "Eval_MaxReturn : -21.625720977783203\n",
            "Eval_MinReturn : -84.53812408447266\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -58.36003112792969\n",
            "Train_StdReturn : 29.750097274780273\n",
            "Train_MaxReturn : 15.987857818603516\n",
            "Train_MinReturn : -182.52923583984375\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 240000\n",
            "TimeSinceStart : 252.80366230010986\n",
            "Training Loss : -0.07451451569795609\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 8 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -58.49601364135742\n",
            "Eval_StdReturn : 4.970093727111816\n",
            "Eval_MaxReturn : -51.53114700317383\n",
            "Eval_MinReturn : -62.797447204589844\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -55.642433166503906\n",
            "Train_StdReturn : 30.78017234802246\n",
            "Train_MaxReturn : 39.86238479614258\n",
            "Train_MinReturn : -231.82144165039062\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 270000\n",
            "TimeSinceStart : 284.6142020225525\n",
            "Training Loss : -0.07628227770328522\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 9 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -29.948156356811523\n",
            "Eval_StdReturn : 16.229703903198242\n",
            "Eval_MaxReturn : -7.165874481201172\n",
            "Eval_MinReturn : -43.75398254394531\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -52.99407196044922\n",
            "Train_StdReturn : 31.557510375976562\n",
            "Train_MaxReturn : 29.041728973388672\n",
            "Train_MinReturn : -187.72531127929688\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 300000\n",
            "TimeSinceStart : 316.57416129112244\n",
            "Training Loss : -0.07863594591617584\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 10 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -32.437591552734375\n",
            "Eval_StdReturn : 19.650148391723633\n",
            "Eval_MaxReturn : -4.8008012771606445\n",
            "Eval_MinReturn : -48.77555847167969\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -48.263275146484375\n",
            "Train_StdReturn : 21.65090560913086\n",
            "Train_MaxReturn : 4.457286357879639\n",
            "Train_MinReturn : -119.16072082519531\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 330000\n",
            "TimeSinceStart : 348.38751125335693\n",
            "Training Loss : -0.08026115596294403\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 11 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -34.3000602722168\n",
            "Eval_StdReturn : 1.4228349924087524\n",
            "Eval_MaxReturn : -33.16537857055664\n",
            "Eval_MinReturn : -36.3065185546875\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -41.800655364990234\n",
            "Train_StdReturn : 24.921781539916992\n",
            "Train_MaxReturn : 19.743934631347656\n",
            "Train_MinReturn : -138.17214965820312\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 360000\n",
            "TimeSinceStart : 380.3057703971863\n",
            "Training Loss : -0.06743042171001434\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 12 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -15.76179027557373\n",
            "Eval_StdReturn : 14.08842945098877\n",
            "Eval_MaxReturn : -3.852964162826538\n",
            "Eval_MinReturn : -35.549522399902344\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -39.683406829833984\n",
            "Train_StdReturn : 23.725130081176758\n",
            "Train_MaxReturn : 32.791934967041016\n",
            "Train_MinReturn : -118.68359375\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 390000\n",
            "TimeSinceStart : 412.02152371406555\n",
            "Training Loss : -0.09057561308145523\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 13 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -26.75543785095215\n",
            "Eval_StdReturn : 7.965871334075928\n",
            "Eval_MaxReturn : -19.49217987060547\n",
            "Eval_MinReturn : -37.84471130371094\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -32.794044494628906\n",
            "Train_StdReturn : 23.575239181518555\n",
            "Train_MaxReturn : 50.377445220947266\n",
            "Train_MinReturn : -102.01753234863281\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 420000\n",
            "TimeSinceStart : 443.83388662338257\n",
            "Training Loss : -0.07158823311328888\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 14 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([30000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -53.30638122558594\n",
            "Eval_StdReturn : 18.17672348022461\n",
            "Eval_MaxReturn : -29.371448516845703\n",
            "Eval_MinReturn : -73.39352416992188\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -31.648452758789062\n",
            "Train_StdReturn : 26.295730590820312\n",
            "Train_MaxReturn : 49.57083511352539\n",
            "Train_MinReturn : -152.0272216796875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 450000\n",
            "TimeSinceStart : 475.47576785087585\n",
            "Training Loss : -0.059040267020463943\n",
            "Initial_DataCollection_AverageReturn : -88.9120864868164\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 15 ************\n",
            "\n",
            "Collecting data to be used for training...\n"
          ]
        }
      ],
      "source": [
        "!python cs285/scripts/run_hw2.py --env_name HalfCheetah-v2 --ep_len 150 \\\n",
        "--discount 0.95 -n 100 -l 2 -s 32 -b 30000 -lr 0.02 -rtg --nn_baseline \\\n",
        "--exp_name q4_search_b30000_lr02_rtg_nnbaseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imA3uAZl8f2X"
      },
      "outputs": [],
      "source": [
        "!python cs285/scripts/run_hw2.py --env_name HalfCheetah-v2 --ep_len 150 \\\n",
        "--discount 0.95 -n 100 -l 2 -s 32 -b 50000 -lr 0.005 -rtg --nn_baseline \\\n",
        "--exp_name q4_search_b50000_lr005_rtg_nnbaseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mmhsNWDv8fnZ"
      },
      "outputs": [],
      "source": [
        "!python cs285/scripts/run_hw2.py --env_name HalfCheetah-v2 --ep_len 150 \\\n",
        "--discount 0.95 -n 100 -l 2 -s 32 -b 50000 -lr 0.01 -rtg --nn_baseline \\\n",
        "--exp_name q4_search_b50000_lr01_rtg_nnbaseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j9liUxOv8fjT"
      },
      "outputs": [],
      "source": [
        "!python cs285/scripts/run_hw2.py --env_name HalfCheetah-v2 --ep_len 150 \\\n",
        "--discount 0.95 -n 100 -l 2 -s 32 -b 50000 -lr 0.02 -rtg --nn_baseline \\\n",
        "--exp_name q4_search_b50000_lr02_rtg_nnbaseline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJxO8TAC8pwp"
      },
      "source": [
        "##Plots"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_q4_search = read_data('search','HalfCheetah-v2',4)\n",
        "data_q4_search"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "VjwRCmwc0V5R",
        "outputId": "427586e4-977b-4ade-f24f-536838a8f087"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-6f4817cb-8d82-4f1f-80aa-79f2e6999135\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Iteration</th>\n",
              "      <th>Config</th>\n",
              "      <th>Train_EnvstepsSoFar</th>\n",
              "      <th>Eval_AverageReturn</th>\n",
              "      <th>Eval_AverageReturn_Smooth</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>search_b10000_lr005_rtg_nnbaseline</td>\n",
              "      <td>10050.0</td>\n",
              "      <td>-87.088509</td>\n",
              "      <td>-87.088509</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>search_b10000_lr005_rtg_nnbaseline</td>\n",
              "      <td>20100.0</td>\n",
              "      <td>-68.322739</td>\n",
              "      <td>-73.684387</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>search_b10000_lr005_rtg_nnbaseline</td>\n",
              "      <td>30150.0</td>\n",
              "      <td>-56.560104</td>\n",
              "      <td>-62.707283</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>search_b10000_lr005_rtg_nnbaseline</td>\n",
              "      <td>40200.0</td>\n",
              "      <td>-41.102299</td>\n",
              "      <td>-49.403721</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>search_b10000_lr005_rtg_nnbaseline</td>\n",
              "      <td>50250.0</td>\n",
              "      <td>-83.027802</td>\n",
              "      <td>-69.786893</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>912</th>\n",
              "      <td>95</td>\n",
              "      <td>search_b50000_lr01_rtg_nnbaseline</td>\n",
              "      <td>4809600.0</td>\n",
              "      <td>93.424339</td>\n",
              "      <td>84.305945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>913</th>\n",
              "      <td>96</td>\n",
              "      <td>search_b50000_lr01_rtg_nnbaseline</td>\n",
              "      <td>4859700.0</td>\n",
              "      <td>80.227043</td>\n",
              "      <td>81.858604</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>914</th>\n",
              "      <td>97</td>\n",
              "      <td>search_b50000_lr01_rtg_nnbaseline</td>\n",
              "      <td>4909800.0</td>\n",
              "      <td>90.360054</td>\n",
              "      <td>86.959474</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>915</th>\n",
              "      <td>98</td>\n",
              "      <td>search_b50000_lr01_rtg_nnbaseline</td>\n",
              "      <td>4959900.0</td>\n",
              "      <td>87.281410</td>\n",
              "      <td>87.152636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>916</th>\n",
              "      <td>99</td>\n",
              "      <td>search_b50000_lr01_rtg_nnbaseline</td>\n",
              "      <td>5010000.0</td>\n",
              "      <td>76.420937</td>\n",
              "      <td>80.713616</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>917 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6f4817cb-8d82-4f1f-80aa-79f2e6999135')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6f4817cb-8d82-4f1f-80aa-79f2e6999135 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6f4817cb-8d82-4f1f-80aa-79f2e6999135');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     Iteration  ... Eval_AverageReturn_Smooth\n",
              "0            0  ...                -87.088509\n",
              "1            1  ...                -73.684387\n",
              "2            2  ...                -62.707283\n",
              "3            3  ...                -49.403721\n",
              "4            4  ...                -69.786893\n",
              "..         ...  ...                       ...\n",
              "912         95  ...                 84.305945\n",
              "913         96  ...                 81.858604\n",
              "914         97  ...                 86.959474\n",
              "915         98  ...                 87.152636\n",
              "916         99  ...                 80.713616\n",
              "\n",
              "[917 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "poac9s0K8u_J",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "b0457738-97d9-4ab1-ec1a-267e16bb5964"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fa4a011f790>"
            ]
          },
          "metadata": {},
          "execution_count": 90
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkgAAADNCAYAAABD/I/tAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydeVxV1fr/32c+zCCIoIgiiImKmlPOmeR1aqS62rW0LE0rzW8OgCZqkVp5ra5XTMukbvdWDonm9eeQ5lBqDjmAKAKigIADyCCcef/+4HoUOMBREVHW+/XyVSz2XutZa2/2fvaz1no+MkmSJAQCgUAgEAgEVuT32gCBQCAQCASC+oZwkAQCgUAgEAgqIBwkgUAgEAgEggoIB0kgEAgEAoGgAsJBEggEAoFAIKiA8l4bcCccPnz4XpsgEAgE9x1dunS51yYIBPWe+9pBgtv/Q09KSqJt27a1bE39piH2GRpmvxtin6Fh9vtW+yw+LAUC+xBTbAKBQCAQCAQVEA6SQCAQCAQCQQWEgyQQCAQCgUBQAeEgCQQCgaDB8dRTT9V4TGZmJhMnTqwDa2rGHnvrOwcOHCAmJqZW60pMTGTVqlW1UmdF7FqknZKSwqpVq8jJycFisZT73cqVK++KYQKBQCAQ1Efi4+NZvHgxsbGxtG3bFkmSiIyMpLS0FJPJxIcffohKpSIiIgKZTIZCoWDhwoXk5+cze/Zs1Go1np6eREdHk5KSwvz589FqtbRv354JEybYbcfmzZtZu3YtkiQxevRo+vXrR1xcHPv27cNoNDJlyhTc3d0ZMWIEoaGhAIwaNYpevXpVW++RI0c4fvw4Y8aMuZNhqhPatWtHu3bt7krddjlIU6ZMoXv37gwePBiFQnHHjUqSRFxcHLGxsWzbto3t27fz9ddf07x5cwDmzp2LJEmVbiSBQCBo6OQkmLiaaeahwZp7bYoVqVQHBuOdVaJWIXPQ2vzV3r17+f7779FqtQQFBSGXyzl9+jRGo5GJEyfy0EMPMXPmTEwmE5cuXWL+/Pmkp6ezfPlyvLy8mDdvHlFRURiNRpycnIiJiUGSJBYvXkxCQgKPPvooL730ks22c3JymDNnDqmpqUyaNIlu3bqhUql45JFHrMfs2rULLy8vpk6dSnx8PD/88ANOTk707NmTkSNHsnTpUrZu3UpCQgIvvvgi/fr1Y+bMmRw9epSVK1cSFRVFYGAgY8eOJTc3lyZNmlQ5TH/729/w9/dnxIgRrFixgtWrV2MwGHjppZcIDQ1l+/btfPvtt2RnZzN79myio6MJDQ1l6dKl1Q7/unXr2LlzJ35+fpw7d468vDz69OlDXFwcJpOJxo0bk5KSYrOeAwcOsGLFCkJDQzlx4gTTp08nLy+vUhnAqVOniI6OJjU1lblz5+Lh4UFUVBSurq4YjUYWLVpEfHw8u3btQpIk+vXrR3h4ODExMRQXF1NaWsqMGTPKtb19+3bCwsIqtRcQEEBUVBQqlQq9Xk90dDQuLi7VjsPN2OUgGQwG3nvvPbsrrYmCggKCg4MJDg62loWHh5fzVhcuXFjpRurUqVOt2SAQCAT3I9nHTTg3qT+rIySzBf37y0BnuLOKtGo0709Cpqjct127dhEeHs6AAQM4ePAgy5cvZ8WKFVy8eJEPPviA+fPn06dPH4YMGcLq1avZuXMnAQEBaLVaFi5cSHx8PB06dGDMmDFs3bqVgoICSkpKeOWVV9BoNLz88stVOkglJSXMmTOHjIwMPvzwQ7p168bQoUPZvXu39ZjTp09bUy2EhITw66+/4uLiwrPPPmstO3ToEMnJybz66qvWsqSkJNLT0wkMDAQgODiY06dPV+sg5ebm8s9//hODwYCHhwcKhQIHBwcAzp49S0BAAAC+vr7k5OQAkJaWZo1wTZs2jWbNmtms29fXlxkzZrBu3ToKCwvRarVcvnyZ2NhYtmzZQkpKSpV2OTs7M2nSJDZt2sTOnTvp2LGjzTK1Ws3cuXPZv38///nPfxg5ciRvvPEGnTp1YurUqaSnp7Nt2zbeeecdgoODSU5O5ujRo+j1eubPn8/Ro0eJi4tjwIABNdqQnJxMUFAQ48aNY9OmTaxfv77K62wLuxykPn361Gp+EXd3d3r16kVsbKy1bMeOHZw4cQJXV1ciIyNt3ki2HKSkpKTbskGn0932ufcrDbHP0DD73RD7DA9+vyWzjCvpzZD5XSIpSQ/c+z7LFHI0771ROxEkG84RwLhx44iNjeXLL7+kf//+ZGZmEhERAYBcLkepVHLs2DEOHTpEZmYmPXv2BMpe+FAWBWrZsiUAgwYNAsDJyQl3d3egLAhQFf7+/gD4+Phw+fJlm8fIZDIkSSr3M2B3WcW6qsPR0RF3d3cuXbpk17ne3t58/vnnBAcHc+jQIT777DM++ugjm3U3bdq03M8XL160jmFQUFC1djVu3BgAjUaDXq+vsqzieGo0Gr7++ms2bdrEmTNn0Ov1TJ8+nS+++ILMzExee+01iouLSUxMJCIiArPZjJubm102ZGVlsWfPHtLS0tDpdISEhFTbh4pU6yC98sor1gs/atQoAgMDcXZ2LndMbaxB6t+/Pz179sTX15elS5eyYcMGoOYbCbhtp00klGs4NMR+N8Q+w4Pf78spJnKVekJ7ByBXlD0T60OiSJmDFqqYHqsNzp8/z8yZMwEYMmQIbdq0YcGCBZhMJi5cuMCePXtQKpVERETw1Vdf3bDrf++N69NGULZ+qEePHna3nZ2dDZRFbry9vW0e07ZtW/bt28fw4cNJTEykQ4cOODg4cPLkSTp37kxCQgIdOnQAyq6Xt7c3CQkJjBo1iqCgIFJSUggKCiI5OZmxY8dWa8/1Pnl5eZGfn4/JZMJgMKBUKmnVqhVnz54FICsri+bNm3PhwgXy8/OBsgiL0VizI3v9vd+oUSOrU5iWlmbHaNVMxfGMi4tj0KBB9OvXj/HjxyNJknWatLS0lLFjxzJjxgy6dOlCVFQUxcXFXLt2jfT09Brb8vPzIywsjNGjR5OXl1ej81mRah2kJ5980ub/1zanT5+2epVOTk4YjUZr1OjmG0kgEAgaMldSzTQKUFido4ZCRkYGy5cvx93dnSFDhqDVapk+fToFBQU8//zzBAcHs2LFCqKjo/Hz82Pz5s34+flZzw8LCyMyMpJJkyah0WgYPny43W1rtVpiYmJISUnhzTffJDc3l7lz53Ly5EmysrIYOHAgo0ePZvPmzbz99tvI5XJiYmJQKBRERESwf/9+nJ2dmThxIg8//DCzZs1i9erV+Pv7065dO9566y1iYmJQqVT07dsXLy8vu+ySyWRMmDCB8ePHA2VrhV1dXRk8eDDjxo1DkiSmTZuGl5cXH330Ed999x3Xrl2zRt6qIzAwkJkzZ9K5c2fUarV1jdCtOhi20Ol0fPDBB5w5c4bo6GjOnDnDl19+yY4dOwgMDCQuLs76X41Gw9ChQ+nYsSMbNmwgMjKSK1eu2L2QPSwsjFmzZlnPi4qKwsPDw25bZdLNYZoqWLVqlc3V7AsXLiy3WMpeTp48yZIlSzh8+DAdO3YkNDSUI0eO4OzsjCRJLFiwgNLSUmbNmoVSqcTf39+6wOtmDh8+LKRGboGG2GdomP1uiH2Guuu3oUQiZYeBh4ao69RZ+X1pCf6PqPB7WGUtu50IktBiE9jLb7/9Ru/evTly5Ajr169n3rx599qkOqPaCFJycjKnTp1i5cqVeHl5lZvyKiws5Pvvv78tBykkJKTGFfVOTk4sW7bslusWCASCu83lMyYuHDXRKECBT7u6kbQsybNQkifhFXjnO4kFlfnqq6+s03DXef75561TY3XFL7/8wq5du8qVdevWjSeeeKJW6rdYLMyZM6dS+fTp0ystoQHYuXMnq1evpqSkhGnTprFo0SIKCgrKHfP6669bd6E/SFT7l63T6Th8+DCFhYX88MMP5X6nUqmYNm3aXTVOIBAI6iP56RZkCsj4w1hnDtKVVDNOXjK0bvVnB9uDRE1rf+qKgQMHMnDgwLtWv1wuv6Uo0KxZs8r9/O6779a2SfWWav+yQ0NDCQ0NpW3btowYMaKubBIIBIJ6iyRJ5KWbCeynIvVXIwVZZtya3f2ozpVUM55BInokENQVdn36PPXUUyxbtozffvuNK1eu4OnpyYABAxg1ahRqtfpu2ygQCAT1htJ8CX2RhG+oksIcCxl/GHF75vYdF7NJQi4HmbzqtUxmU5lT5t/j7u0UEwgE5bHLQZo3bx6FhYWMGTMGNzc3rl69ypo1a8jIyBAZrgUCQYMi72zZVJfGRY5/NxWH/6WjdZgFjcutT30VX7Tw5390qBwgeJCGRi1tO1pXz5mRycC9uZheEwjqCrv+2o4dO8aSJUsYOHAgXbt2JSwsjCVLlnDgwIG7bZ9AIBDUK/LPmfH4nyPj1lyOs7eczMOmW64n76yZg3GleAYq8Gip4M9/6zi+Voe+yFLp2MspZW3KlQ1re//dRIjV3n1q0+brddna0X63sMtBkiSpUqZRk+nWHwgCgUBwP3N9/dH1SI9MJqN5dyWZR4wU5ZrLHXs1w8zR73WUXq3s8OQkmPjzPzpa9lTRdpiaNoM0PDLOAV2BRPK28s9aSZLITTLj3VasP6ovxMfH8+ijj1ozmEuSREREBJMnT+bNN9+0SplMmjSJyZMn83//938YjUYuXrzIG2+8waRJk5g7dy5QJgY/duxY3nzzzXLqEvawefNmXnvtNcaOHWuVPjlx4gTPP/+83Qr3JpPpvlp4XVUW8LuBXVNsgwYNYuTIkTzzzDO4urpy9epVNmzYwODBg++2fQKBQFBvuHZJwlgC7v43nBWfdkry0sz88aUO31Al/j1UnD9gJPu4CbkaLp0249/jxreoJEmc3qqn9UA1/j1u5DNy8pITNEDN0R90mHQSSm1ZtOhqhgVjqUTj4LrZLXc7mHVFWEy6O6pDrtSi0NoWEhVitTeoTqy2X79+5OTk8Pzzz1NSUlJlHdelWjw9PQkODubPP/9k+/bt5Ofn88svvxAYGMjevXuJj4+3ef6wYcMYNGgQ58+fp1+/fjz11FM2y0pKSpg3bx7nzp0jPDycoUOHVrpOeXl5fPbZZ7i5ueHi4sKsWbNYv349O3bsQCaTMWLECKt0DJRFkuLj4222t3z58kr3xZ1g11/cddG4Xbt2kZeXh5eXF6+//rpwkAQCQYMiL92McxM5ascbU11yhYz2T2tp3s1M8jYD+5eX4uorp9urWnISTeSdM5dzhIpzLRhLwDe08uPXo6UclaOM3CQTzTqXnZN70oRnKwUqbf2cXpMsJs6sGIbFcO2O6pGrnWjz5g5k8srjIsRqb1CdWK1er+fxxx9n3bp1NY53cXEx//rXv8jMzCQxMZGwsDCeeeYZVq9eTUFBAWvWrKny3IKCAt5++22uXLlCZGQkTz31lM2yvLw8IiIisFgsvPTSS/Tv37/SddLpdPTp04dRo0Zx5swZzGYz3377LWvWrMFgMDBu3LhyDlJVNjzyyCMcPHiw3H3x+eef1zgO1WGXgySTyRg2bBgdO3YkLy8PT0/PKtWABQKBoL5yNcOMXAmuvrc3XVU2vWZ7ZYJbMwVdR2u5dlnCyVOGTC7DUCxx4U89kkWy7lLLS7fg6itH5WBbqNS3g5Ls42UOkmSRuHjKTOuB9Xe3sEyupPXrm2olgmTLOQIhVnsz1YnV3grXx6YiSqUST0/PaiU5PD09kcvl5URobZX5+PhYd7qbTCab1+n5558nNjaWv/3tb/Tv3x93d3cuX75MZGRktfZXbC87O7vSfXGn2OUgJSQk8O6773L16lVcXFwoKCjAx8eHxYsX16jwKxAIBPWF1F8NqBxkhD5XtYMkSRIWIyjU5V9UkkXi6jkzfp01VZ4rk8lwbnzjPHd/BWYDFOVYcG1a1mbe2TI9tarwDVWS/puRknwL+kIJU6lE4+D6vf5IoXVBge3psdpAiNXeoDqxWo2m6nuzqnpkMhkWS9k6OYvFgiRJ5OfnWwVu74RLly5hNBqxWCyo1Wqb1yk9PZ0JEybg5OTE2LFjefbZZ/Hz82PBggWA/SK5vr6+BAUFlbsv7hS7HKT333+fd9991+p5A/z888/MmTOHf/3rX3dshEAgENyMxSSRe9KETwdltV/UFrNktxaaZJEozLbUOFWV/puRrCMmHnnDAeVNTtLVDAtmQ/n1RzWh1Mhw8ZWTd86Ma1MFFrNE/vnyU24VcfKU49pMTs4JE4ZrEp6BCpSa+jm9VlcIsdrK2BKrBYiMjOTUqVOYTCbOnDlDTExMtfV4enpy/vx51qxZw7PPPsukSZPw8/Oz247qaNSoEZ988glnz55l9OjRNq+Tt7c3ixcvxsvLi2bNmuHl5cUzzzzDlClTMBgM9OnTh1atWtXYVpMmTQgJCSl3X1yP/t0udonVDh06lP/+9792l9cVQqz21miIfYaG2e/7vc/n9hk584uBXhMdcGxkO1RuNkr8vrSU1mFqq9xHdf0uvmRh/xelAPR9xwGNc+V6zUaJvf8owWyA5t1U1qkti1nij690uDWT03aY/V/pACk7DBTlWug8Ukv+OTN//ltH/6mOKFRVOz0Zh4yc32/EbITgx9X4tK/6W1aI1Qpqi4MHD9KxY0cARowYYddapgcZuyJIWq2Wo0eP0qlTJ2vZsWPH0GpFVleBQFC7GEslzv5WtiakMNtSpYN0KdmMvkgiZYcB7zY15wgqzDLj4CHDpJMovGChcXDlenNOmJDJZYQ+p+bYj3p8Oyhx9paT/psRY6l0W2uBPFrIyThkxGIuSxHg1lxerXME0CRESfJWAzIZeLWu39NrDwoPqljtrfQrKyuLL774ArVazWuvvcbatWs5duxYuWMef/xx+vbte1u23G/Y5SDNmDGDCRMm4Ovri6urK/n5+Vy5coVPP/30btsnEAgaGGf3GtC6ydE2l1GUY8Gnne3jso+baNpJyeUUM5lHTPh3r3raCqDgggW3ZnKMpfzPQSr/e0mSOP+HkeZdlXgFKfFua+LUZj1tBqs5u9dIxxc01q33t4J7cwUWExRlW8g7a7bL4VE7ymjcRgESDX56ra54UMVqb6VfTz/9NE8//XS5svDw8Fqz5X7DLgepR48e/PLLLxw7doz8/Hw8PT0JDQ21bi0UCASC2qA030LGIROdXtBQ+D+Hwhb6YgtX0sx0f1WLq6+c1F0Gmnas/nFWeMGCb0clxmtlEaSKXEk1U3pVotnDZY5WcJia32NLOfKdDp/2ZU7T7aBQy3BtKudSspnCLAvBj9sXhQoZfmtTeQKBoHaxax+cxWLh+PHjXLp0CYPBQHZ2Nlu2bGH9+vV32z6BQNCASP3VgEcLBZ6BSlx85RTmWLC1TDInoUwPzcVHTtNOSlRaGef2G6us12yUKM614Na0bAF0wQVzpXrP7zfStKPSmuNI4yKn9UA1CpXMbqemKhq1VJBxyIhCDa6+9m0/VmpkInokENxD7PokGj9+PMnJybRo0QKF4kZ4WCaTVQrHCQQCwe1QlGsm56SZHmPL1ja6+igw66Ekryyv0M1kHzfh+78dbjIFBA5Qc3KjnsaP23Y+inIsIAeXJnKMOjDpoDRfwrGR7H+/N5OXbuGhoeWjNn5dVDTtrEQuvzNHxaOlgrN7jTRuo7DmQxIIBPUbuxyk1NRUtm3bZk34JBAIBLXN+QMmGgcrcPEp+whTO8nQuskoyrbg5HnD8SnKNVN80YJP+xvOjPdDClJ2yNDl2J72L7hgwaWJHLlShsYZtK4yCi/cWAB+bp+RxsEKmwvC79Q5AnDzkyNXYNVwEwgE9R+7Yr2dO3cmJyfnbtsiEAgaKPpiCzmJlRdau/rKKcwuvw4p+7iJRgFytK43Hl8ymQwnTznma7a/+QqzzLg2vXH89Wk2gJI8CzknzbTsXf0i7ztBoZTR8QWNTXkRwb3BHqX5zMxMJk6cWAfW1Iw99tYnanPsrtd18eJFPv7441qp0x7s+mt9/vnnee655/D398fR0bHc77755pu7YphAIGg4ZB424eQlx92//Debq6+cy6k3HCSLWSInwUzrsMrRbK27jGsXq3CQLlho1f/GOa5N5Vw6XVZv+u9GGrWU49bs7kZ3PAMfXOfIYCjCdIdSI0qlFrX67mXjrk3i4+NZvHgxsbGxtG3bFkmSiIyMpLS0FJPJxIcffohKpSIiIgKZTIZCoWDhwoXk5+cze/Zs1Go1np6eREdHk5KSwvz589FqtbRv354JEybYbcfmzZtZu3YtkiQxevRo+vXrx8KFCzl37hzFxcVMmjSJrl27VltHbm4uX331FVFRUXc6LHcdb29vpk2bVmft2fUXGxkZSXh4OG3atKkVfRNJkoiLiyM2NpZt27ZZU4/XdCMJBIIHD7NJIuuIkaDH1JWyZrv4Kjj7m9GqZZZ9woQkSXg/VNmZcXCXY06vXG64JlF6VSoXQXJrqiBtl5HSfAvZx010flHkdLtdLBYT69cMw2gsvqN6VCpnnhuxA7kNPba9e/fy/fffo9VqCQoKQi6XV1Jtr6gSn56ezvLly/Hy8mLevHlERUVhNBpxcnIiJiYGSZJYvHgxCQkJPProo1WK1ebk5DBnzhxSU1OZNGkS3bp1Q6VS8cgjj1iP2bVrF15eXkydOpX4+Hh++OEHnJyc6NmzJyNHjmTp0qVs3bqVhIQEXnzxRfr168fMmTM5evQoK1euJCoqisDAQMaOHUtubm61YrV/+9vf8Pf3Z8SIEaxYsYLVq1djMBh46aWX6NSpE40bN2bGjBkkJiYSFxdn00E6cOCAdWxcXV3Zv38/hw4dYv/+/aSmptK6dWt++eUX1q5dW+nczMxMpk6dSq9evTh16hQvvfQSzZs3t1lWcexCQ0OZPn06Dg4O5OXl8emnn3LkyJFy1/aNN95g+fLl5a6vs7Ozte0PP/yQqKioSu317NmTmJgYiouLKS0tZcaMGVXqzdmLXQ6Ss7MzM2bMuKOGbqagoIDg4GCCg8sSkfz000923Ug3J6oUCAQPBrkJJgBrNuybcfWVYzaULdR2bATnfjfSoofKZqJFrZvM5hRb4QUzSi3WBdkALj5yLCZI3KjHtakcjxZ3/uHXUJHLlTz93KZaiSDZco6gzAEJDw9nwIABHDx4kOXLl5dTbZ8/f34llfiAgAC0Wi0LFy4kPj6eDh06MGbMGLZu3UpBQQElJSW88soraDQaXn755SodpJKSEubMmUNGRgYffvgh3bp1Y+jQoezevdt6zOnTp63ZzENCQvj1119xcXHh2WeftZYdOnSI5ORkXn31VWtZUlIS6enpBAYGAhAcHMzp06erdZByc3P55z//icFgwMPDA4VCYU25o9ForPXv3r2b3r17V1nP9bE5cOAAAKGhoSxYsIA1a9aQkJDAli1bqjzXbDYzadIkjh49yk8//cTrr79us6zi2M2ZM4fnnnuOvn37snjxYg4fPszu3but1zY5OZnc3FwOHjxY7vpOnz69RhscHBzQ6/XMnz+fo0ePEhcXZxWuvV3scpBefvllVqxYQVhYWKUptuouZFW4u7vTq1cvYmNjgbKby54byZaDlJSUdMvtA+h0uts+936lIfYZGma/75c+SxJc3OODg38Jp8+ct3mMwsmXU4cvgwxKixpxzeU8SUmVt/4b8lWYS304mZiE7CZ/p/CkGwpXNadOla9f6erD1fNqPHtf5NSpO3u530vqw7VWq13u6vTYuHHjiI2N5csvv6R///6VVNttqcTDDcX6nJwcWrZsCWDVFHVycsLd3R0Ag8FQZdvX9bx8fHy4fPmyzWNkMlm5tBHXI6H2llWsqzocHR1xd3fn0qVLNn8vSRL/+Mc/cHFxqXbdUsXoyvUchwCtW7eu1obGjRsDZQ6ZXq+vsqzi2Gk0Gmum8KSkJDp06FDu2oaHh9OqVatK19ceG7KyskhMTCQiIgKz2Yybm1u1fbAHuxyk9957D4BFixaVK5fJZLX2h3k7NxJw23pT97tW1e3QEPsMDbPf9b3PkkUiL91C9gkT5mITnf7ijsa5mc1jTUk61DiQn26hRXcFQaEP2TzOUCJxaUcJLX3blNuN9udRHZ6t5QS1LS++KaXqKcqx0OnRljW+lOozt6PFdr9x/vx5Zs6cCcCQIUNo06ZNOdV2WyrxcOO94efnZ5XbiI+Pp0ePHna3nZ2dDZRFbry9vW0e07ZtW/bt28fw4cNJTEykQ4cOODg4cPLkSTp37kxCQoJV2iMpKQlvb28SEhIYNWoUQUFBpKSkEBQURHJyco2Zr6/3ycvLi/z8fEwmEwaDAaVSiUajYf78+TzyyCMMGDDArnquO3dubm7k5+cDZTvXa4OKY7d+/XratGnDyJEjmTdvXln2+puu7YgRI1iyZAlBQUHlrq89+Pn50aVLF6KioiguLubatWt3bL9dDtKpU6fuuKHqCAkJsetGEggE9z+5J02c3mrApJNoHKyg80gtGueqHRQXXzln9xiRLODfveq1QioHkCkt6ArKpuOuU3zJYjPLdtAANRazdF87Rw2FjIwMli9fjru7O0OGDEGr1ZZTbbelEu/n52c9PywsjMjISCZNmoRGo2H48OF2t63VaomJiSElJYU333yT3Nxc5s6dy8mTJ8nKymLgwIGMHj2azZs38/bbbyOXy4mJiUGhUBAREcH+/ftxdnZm4sSJPPzww8yaNYvVq1fj7+9Pu3bteOutt4iJiUGlUtG3b1+8vLxqNooyx2bChAmMHz8egClTppCSksLGjRvJyMhg9erVBAQE1LiouXnz5uzdu5fevXvTtWtXpk6dSosWLWrl76Li2Mnlcj7++GNOnz6Nl5cX33zzDeHh4dZr26tXL5o0aUJISEi56/vQQ7Y/im6mY8eObNiwgcjISK5cucKECRNua4brZmSSrTS1N3Hs2DFCQ0Otg/Xjjz+SnJxM9+7draHKW+XkyZMsWbKEw4cP07FjR5544gm2b9+OxWLB2dmZmJgY8vLymDVrFkqlEn9/f5tzkHeiSl3fv7DvBg2xz9Aw+30v+ixJEic3GCgtsBD4qBoP/8oLpjMOGkneZiDoMTXNOivtyhSdl27myL90NO+upM2g6uU3fv08n7GbNdMAACAASURBVNZ9nWnWuWzLvkkv8evHJTwy3gHnxg/mOqPbiSDd7nNT8GDz22+/0bt3b3Jzc4mKiioXjWuIVBtBWr16NX//+9/ZuHEjXl5eLF26lO+++44nn3ySJUuWkJ+fz1//+tdbbjQkJISlS5eWK6uoVOzl5cWyZctuuW6BQHBvSNlh5HKqicbBSo78S0ejAAV+XZQ4uMvRupVJgZz73UiHcA3ebezf8u7qK8fNT06LR2rOU6R0NKMruPHNd+2SBZm8/AJtgcAWt6J6fze5vkbnZrp161bpHWkvixYtoqCgoFzZ66+/TvPmzSsdm5iYyHfffYfZbGb8+PH1ZkzuFdU+pb755hu+//57vLy8kCSJf//737z33nsMHjyYy5cv88orr9yWgyQQCB4sMg4ZyThopMsoLW5+Clr2UpG2x8jJn/UYS8qOUWig84taPFrcWr4hpUZGtzH2CWMrnEyUXr0hRFt8yYKjpwy54v51kCRJApMECpmQKbmL3Irq/d1k4MCBDBw4sNbqe/fdd+0+dty4ceV+7t69e63ZcT9SrYNkNBpp0aIFULYOqaCggEcffRQoi/BUt/JfIBA0DC6dMZG81UCHZzW4+ZU5P46N5LR/SgNoMBskSgskVNoyAdi7icLRhO7qjQhS8SXLfTm1JhksGFZlYT5WBEYJJJC3ckAzpQUyrZArEQjqArvj3Hv27KFz585otSKhmkAgKENfbOHkBj2BA1R4P2T7caJQy3BuXDeRD6WTiWvp5afY3G2shapPmBOKwAzyDs7I5DKkYhP6JeeRrpnRTPQHRzkyuQz911nov8hE86Y/MqWIJAkEd5tqHaT27duzaNEiQkNDWbVqFVOmTLH+bv369dbokkAgaHhIksSp/xpwamzf+qC6QOFoQl8kYTFLyBUyii9J+HWpvxEkSW9BvyIT9BZkjVQo+3pg+v0qMicF2hkByJxvPKI1k1qgX5CG4V8XUI9uKnbfCQR3mWqfHDNnziQrK4vPPvuMp59+mueffx6AX3/9lYULFzJ16tQ6MVIgENQ/chLMXDlrJuQJTb15WSudyvTVdAUSxlIJQ7GEUz2eYjP/UYBMJcfh4zYoH/PEtK8AeXMtmv9rWc45ApA3UqGZ3ALzn4WYtl65RxY/OAix2rpn3bp1rFq1qlbr+vXXX/nvf/9bK3VWpNoIkoeHB3//+98rlXfv3p0dO3ZY05tDWfKtB+ECCgSCmtEXWTi9RU/rgWocPeqPAyJTWVCoofRqmXMkU4CDR/1w3ioiSRLGnXko+3kgc1GiCvNEFeZZ7TnyZlo077REyhPrP+8Vubm5REdHo1QqKSoq4v3338fLy+u2hWkPHjzIsmXLUCgUDB482KoqYQ9xcXHs27cPo9HIlClTaN++PR999BGZmZnodDree+89Lly4wMyZM63SXpMmTaoxr9DGjRtxcHAgLCzsjsaqLri+LvpucFvy0hXlRgC++OIL4SAJBA2AwmwzpzYbcGkix69L/VKol8nAwV2GrsCCZAEnTznyerrzy5JainRBh3KS/y2dpwhwgAD7dvXVFdeMRejNdybXolFocVLZliupT2K13t7eRERE0LJlS2JjYzl69ChFRUW3LUy7ePFili1bhrOzMy+88ALDhw9HrVZXOU5PP/00AQEBvPbaa2zfvp1vv/2W7OxsZs+ezfTp08nJyeHzzz/n0KFDrFixgmHDhjFgwABrtuqq+Mc//sH58+cJDg5m8+bNeHh40KlTJ+bMmUOjRo1QKBQolUqb9axbt449e/YQEBDAsWPHWLhwIbt3765UBvD777+TlpbGuXPnWLRoEUVFRSxYsAAnJyc8PDx47733+OKLL0hJSaGkpIS//vWv9OrVi6ioKFQqFXq9vpx4/bp16ygsLMTV1bVSe2q1mlmzZuHm5oYkSURHR6NS2b8coNaebjXkmxQIBPc5pfkWUnYayE0y49NeSeuB6noztXYzWjc5pVclTHqpzhaH14RUYsacWIwi2BGZ2/+SWO7MQ/GwKzL3+rF+63YxW0yM2zaMElPxHdXjqHTmm8E7UNgQrK1PYrWxsbFcuXKF0aNHA7BixQo++OCD2xamLS4uxtXVFYCmTZuSkZFhPcYW2dnZrF27luPHjxMQEACU6arl5ORw+vRpa3QoJCSEjz76iGHDhnHkyBGmTZuGXC4nKiqqSp2y9u3bM3r0aHQ6HW3btiU1NRUfHx9mzZrFypUrrdIhtmjatCmTJk1i+fLl/PHHH1WW+fj4MG/ePNauXcvPP/9Mp06dmD59OoGBgbz44ovodDp+/fVXPv/8c9zc3MjKymLLli0EBQUxbtw4Nm3axPr163FycqrRhszMTP7yl78wbNgwli9fzp49e3jssceq7ENFas1Bqo8PSoFAUHv8+R8dGlcZPV7T4tKk/u4Mux5B0hdJNAqoWzsls4T5QAGYJdDKQQ7mI0WY/ywEuQzUMjSvNkPu74D5cCGa/7v/N7oo5EqWP76pViJItpwjqH9itZ6ensTFxbFq1Sp+/PFHoPaEaWt6lzZp0gSFQlHluRXbDAkJYdGiRbRs2ZL4+HhWrVrF5MmTbdbdtGnTcj9fvHjROoZBQUHVOkjXxWPVajU6na7KspvHMy0tDbVazcqVK3F0dCQ3NxeDwcDMmTOJiYmhsLCQyZMnk5WVxZ49e0hLS0On0xESEmLTQarYXmZmJkeOHGHPnj0UFRVVqaVXFfUrPi4QCOolJXkWSvIkHh6lRetaf9Yc2ULrLqcw20RpvoXm3esuOiOVmtEvz8SSXloWFdKZkQwSirZOaN72Rx7shGnzZfRLziNrpkXmo0beuvJyhfsRJ5VLldNjtUF9EqtdvXo1bm5uDBo0iEaNGpGVlWW3nqgtYVo3NzcKCgpwcXEhJyfHZobrm7nep1atWnH27FkAsrKyaN68OQ899BDbtm0DsIrmpqeno1SWveqdnJwwGo011i2TybBYLDRq1IiTJ08CkJaWZveYVUfF8VyyZAnvvvsurVq1Yv/+/UiShE6n49NPP7Wu93ryyScJCwtj9OjR5OXlIZPJ2LlzZ41t+fn50a9fP8LCwsjNzcXZ2fmWbBUOkkAgqJG8s2acvGT13jkCcHCTUXzRgtlAnSWJtFw2oP/HeVDK0M4ORO5h2zFTDW+MvI0jhq8voHqysYi820l9EqsNDAwkMjKSn3/+mZKSEuv6mdsVpn3nnXeYMmUKCoWCMWPG2L1GxtXVlcGDBzNu3DgkSWLatGkEBgbSokULJk6ciMViYe7cuUiSxKxZs3B0dESn0/H+++/XWHdwcDBffPEFn3zyCWfPnmX27NlYLBab649vlZycHD744APS0tL4+OOPAViwYAH+/v507tyZVatWUVxczLfffgvAM888w4ABA5g1a5ZViDYqKsqutl544QXmzJnD9u3bKSws5IMPPrAZeaqKGsVq7WXIkCFs3ry5NqqyGyFWe2s0xD5Dw+x3bff52GodWlcZbf5SvVjsvSYpKYlmHsH88aUOuRIGTHesNXkOySJhSS1BKrGAzoJUYkK6aMRyUY8lpRRFsCPqsc3qPNO1EKsV3C30ej3Hjx+nW7dubNy4kQsXLjB+/Ph7bVadUWsRpGeeeaa2qhIIBPUIi0UiP91M+6frt3N0HQe3sqiRk5e8Vp0jQ9yFsrxFTgrQyJE5yJE1ViP306Ls4Y6iq6vQSruPqS/CrGvXruXYsWPlyh5//HH69u1bK/Xn5eXx6aeflitTqVS89957lY5VqVT8+9//5vvvv6e4uJh58+Yxe/bsSsdNnz79lqev7gfscpAOHTpEbGwsFy5cwGKxlPvdli1bgMoidwKB4MGg8IIFsxHcb1Fk9l6h1JYJ49ZWgkhJkjCuzsF8vAjte62QNxVySw8i9UWsNjw8nPDw8LtWf6NGjZg3b55dx8rlchYvXlyuzN5zHwTscpAiIiIYOXIkISEhKBT3x0NSIBDUDnlpZtz85CjV90d0RCaT4eghx8W7dhwk08+XMO25iubdlsI5EggaEHY5SGq1ut541wKBoG7JO2vGM/D++jDq8KwGtfOdO3TmhCKM/72MZnKLsgSNAoGgwWDXJ1ZYWJhdW+oEAsGDhUkvUZBpqfN8QneKY6PaiXiZDhWi6OqK4iH7d74IBIIHA7scpD/++IPJkyfTq1cv/vKXv5T7JxAI7n8kSaL0qoXLqSYyDxvRFZatNcw/Z0ahAVff+r+9314kScKcfA39ikz0S85jOnAVSW+pfJxFwny8CEXHu5ffR3DvEGK1d5faHLvrdV28eNGaGqAusGuK7f/+7//uth0CgeAeYSyV2L+8FH2RhFIDKkcZydsMNO+mQl9clo36QdidJRUYMR0sxLQnHynXgKKLK7JGKgw/5MC32aiGN0Y12Mt6vOVsKZSYUYQ8eLtzBLdPfRer3bt3LzExMbz77rt2ic3m5uby1Vdf2Z1b6F7i7e3NtGnT6qw9uxyk3bt3M3Xq1Ltti0AguAfkJpmQyaHvOw6oncocoSspZlJ2Gim+aOGhoVULZ94PmBOLMW65jOXUNWRN1Ch7uaPs7YHMtezxp/qrD+bfr2L4dzbK3u7IXMrKzceLkAc7IXO8v6YX7wVFBj06c9UZmu1Bq1DhoradSkKI1d6gOrHaFStWUFRUxJAhQ6od6wMHDljHxtXVlf3793Po0CH2799PamoqrVu35pdffmHt2rWVzs3MzGTq1Kn06tWLU6dO8dJLL9G8eXObZRXHLjQ0lOnTp+Pg4GBNN3DkyJFy1/aNN95g+fLl5a7v9RQCmZmZfPjhh0RFRVVqr2fPnsTExFBcXExpaSkzZsywyqTcLnY5SAkJCWRkZNSYAv1OWLduHV9//bW1jTlz5lTyvgUCQe2Tc8KET3slGucb02herZV4BinIO2vB3f/+nV6zZOnQ//M8yj4eqJ9rgqy5tlL2aplChqKPO7LtVzDtykc1vEzPyXysCGUfjzq193zRNbQKOd6O98+CcJPFwhNbvuaaqWo9M3twUqrZPmwcSnnl+02I1d6gOrFaKEvanJKSUuN4Xx+bAwcOABAaGsqCBQtYs2YNCQkJ1hQ+tjCbzUyaNImjR4/y008/8frrr9ssqzh2c+bM4bnnnqNv374sXryYw4cPs3v3buu1TU5OJjc3l4MHD5a7vtOnT6/RBgcHB/R6PfPnz+fo0aPExcVZ9fpuF7scJBcXF5566ilatmxpFfe7zsqVK+/IgJsJDw9nzJgxACxcuLCS992pU6dK5yQlJd1WWzqd7rbPvV9piH2GhtlvW32+dtaJolNuNB6Qg0JbtubGdE3B1YxmqB/KJCnJZLOui2fuurm1xs39lhklfP4tYWgNVzpfhWtX4VTV5zq3k3DbfpGUlpdQXAO/LIl0p1xMSRfryHr4OD2by0YTc1o1w0Fhn2N6r+9vpVzOxr+8UisRJFvOEQix2pupTqz2VqgYXcnPz8fT0xOA1q1bV3vudVFYjUaDXq+vsqzi2Gk0Gn755Rd27dpFUlISHTp0KHdtw8PDadWqVaXra48NWVlZJCYmEhERgdlsxs3N7ZbHpCJ2OUiPPfYYjz322B03VhM7duzgxIkTuLq6kpKSUsn7tuUg3a6cgpCfaDg0xH7f3GdJkkj/zciFY0a0LjIU2S1pO7RsKiNtjwFXXzOhPap/IN4v3Nxvw7cXMCuv4TahFd52yH9IgRZK9yXTutgHqdSMyTef1j2D7rbJ5chOyaLULLGxxER09452nXM7UiO1jYtagwt3L9O6EKu9QXVitbfCzcK0kiTh5uZGfn4+AKmpqbdUV1VUHLv169fTpk0bRo4cybx585Akqdy1HTFiBEuWLCEoKKjc9bUHPz8/unTpQlRUFMXFxVy7du2O7bfLQaoLGZH+/fvTs2dPfH19Wbp0KatXr67R+xYIBJWRLBLGAhVFOWYkIPuYiQvHTHQeoUWuhMPf6PDvrsLRU0ZOggm/LnWneF9XmA4XYPr9KtrIALu10WRqOcp+Hpi2XwFnJYrQul2cfUWnJ19v4JNeXZh54E+6nfNkaAu/mk9sAAix2srYEqs1Go1MnjyZtLQ0du/ezfHjx2vcZNW8eXP27t1L79696dq1K1OnTqVFixa18s6tOHZyuZyPP/6Y06dP4+XlxTfffEN4eLj12vbq1YsmTZoQEhJS7vo+9NBDNbbVsWNHNmzYYBW0nTBhAk2aNLkj++0Sq23Xrl2Vg5WQkHBHBlzn999/x9/fHz8/P+Li4liyZAmffPIJ/fv3JzIyklGjRtGuXbty5wix2lujIfYZGl6/Mw8bObX5xpSB2llGp79qcPUtcxSOrdEhmSGgr4pDX+voM9kRTS0kVawPJCUl0cY3CF10CqonvFGFed7S+ZarRnQRyWABzdSWKILrLv/RH7mXidh3mO1PDWLD2Qw+O5bEtIfbkVVcwqmrhQS7uTKuXetKz2IhViuoLX777Td69+5Nbm4uUVFR5aJxDRG7Ikhbt24t93NBQQHx8fG1+tJp1KgRs2fPxtnZGUmSWL9+Pe+//34571sgENRM9gkTLg8V0O1ZX66/S29+qbZ+TM2+ZaUYSyQatVLUG+eooOAshw8u4tHHPkUut09H23SgAEUbR2Tu//vqlspEZeX+Digfa3TLNsjdVSi6uGFOLEYe6HjL598JKQWFBLq6IJfJeCqgOYl5V1ly/BTB7q4EurnwQ0o6Tiolo9q0qlO7GgoPqljtokWLKCgoKFf2+uuv25ySS0xM5LvvvsNsNjN+/Ph6Myb3CrsiSFXx3HPPsWbNmtq055YQEaRboyH2GRpWv0vyLfz+z1K8B10gtHvV64pOb9GTcdBE+6c1+LS3zxm52xz4/X1SzvzEowM/o5lfzS8Dc1oJ+vlnkXmq0LzTArmPhowfT+K5R4Z2TiByz9tLT2C5YkC6oEfRoW4TRM47eAyNQs6Mh22/fH7Pvsi03w/z4SOd6d/Mx1ouIkgCwd3htvfvXt+OJxAI6g85CSZcm8pRudjekXadgL5qmj2spHGb+pHjR68v4GzaZlxdW5KW+rNd5xg3XkLRzRV5a0d0C85iOliAx68S6r/63LZzBCD3VNe5cwSQWlBEoGvV7fby9WZyx7ZE/3GMU/kFVR4nEAhqB7s+HSuuQbJYLMjlct5+++27ZphAILg1JEmyLrquaf+G2lFm3clWH0hL2YCjkzfdHolk5/a30esL0WhcqzzenFaC5WQx2rlByLzVGNflYlieiS4AnHq7V3lefcVksXC2sJggt6r7DPBCUEsuXCvhp7TzRHZpGNMcAsG94rbWICkUCjw8PKrN9ikQCOqWomwLpXkSTUKUpGXca2vsx2Ixk3zqR9qEvEgTny44OHhyPn0rrds8V+U5xo2XUPRwQ+5T5uSpn/NBEexEhikDr/tgx+v5c7/g6NgEr8btAcgoLsFgsRDoVnPk6p2OIdzBygiBQGAndk2xzZgxg2bNmln/+fj4oNFo6Nev3922TyAQ2El2gqleLbq2lwtZe9Hp8mgVOByZTE5A4PBqp9nMqWXRI9WwxuXKFaEuWBzqf9/NZgP79kaz5b+jObh/AUZDMakFRTRx0OKitm+Lt0h7IhDcfap1kNavX88rr7xCYmIir776arl/L7zwQpUZLgUCQd1isUjkJpruyYJrySLdUUQj+dQPBAQOR60ui560ChzG5UvHKSw4Z/N448//ix41qT9ThFVhslgqlV3M/RMJCwMHxZKbe5iN68M5kZNGkB3RI0Ht8dRTT9V4TG0q0t8p9thbnzhw4AAxMTG1WldiYiKrVq2qlTrtodqn6dChQ2nZsiVvvfUWTzzxRPkTlUqxE0IgqCdcTjZjNoB3HS+6liQJ/T/OI2+uRf3srSdlK8w/y+VzCXR57oYYtourP429O5GW+jOdHn6z3PHWtUfz6jbD9e1wzWjk+f+3izndO9G9iZe1/ELWXnx8uuPj250hw//N7l/fZVPOObq0fPgeWiuwl9zcXKKjo1EqlRQVFfH+++/j5eVFREQEMpkMhULBwoULyc/Pr6QnmpKSwvz589FqtbRv354JEyZw8OBBli1bhkKhYPDgwVZNN3uIi4tj3759GI1GpkyZYhXtLSkpobCwkOjoaFq1qj4txJEjRzh+/LhV5qs+065duzpN+VOtg6RWq+nUqRPx8fF4enqSk5NDXl4eISEhdWWfQCCogbx0M4nxelr0UqFQ1+3UiyXpGpaEYixnS1E90RiZynZUWSoyYblkQNHqRm4hyWihZFkaQ9L/gWOPxnDT2uqAwGEkHP+K0E5vIJffcPqMGy+h6H5/RI+2ZWSTpzfwQ0p6OQcpK3MvbUP+BoBCocLffyCZx0r5aw0LtOszRQYjOrP5jurQKhRVTjHu3bu3nOK7XC4vp/Z+3TEwmUxcunSJ+fPnk56eblWsnzdvHlFRURiNRpycnIiJiUGSJBYvXkxCQgKPPvpolWK1FRXpvb29iYiIoGXLlsTGxnL06FGKioro2bMnI0eOZOnSpWzdupWEhIRKeqIrV64kKiqKwMBAxo4dS25uLosXL2bZsmU4OzvzwgsvMHz48GrX9z799NMEBATw2muvsX37dr799luys7OZPXs27733Hj169ODZZ59l69atbNy4kcmTJ1eqY926dezcudMqwZKXl0efPn2Ii4vDZDLRuHFjUlJSWLp0aaVzDxw4wIoVKwgNDeXEiRNMnz6dvLy8SmUAp06dIjo6mtTUVObOnYuHhwdRUVG4urpiNBpZtGgR8fHx7Nq1C0mS6NevH+Hh4cTExFBcXExpaSkzZswo1/b27dsJCwur1F5AQABRUVGoVCr0ej3R0dG4uNxZVNaueHxpaSnh4eGcP38ejUbD3r17mT59OkOGDGHAgAF3ZIBAILh9rqSZOfajjpa9VAT0sf1ysVhMdidevBUkScL400WU/T0wHSrEfLQIZTfbApGG77IxHy5E0cMN9Qs+oADdknMosuXoHilBsTQD9dhmKLuWnd+i5SCOHPw7F7J+w6952VpH89lSLIn3R/QIYMPZDPo1bcLeC7lkXyvF18mBosLzFBWeo2mz3tbjnLwepoATNFPp7qG1t4/JYuHp/+7kmqn61BI14aRUsuXJMJuCtbt27bIqvh88eJDly5eXU3ufP38+ffr0YciQIaxevZqdO3cSEBBgVayPj4+nQ4cOjBkzhq1bt1JQUEBJSQmvvPIKGo2Gl19+uUoHqaIifWxsLFeuXGH06NEArFixgg8++MAa+QkJCeHQoUMkJydX0hNNT08nMDAQgODgYE6fPk1xcTGurmXOcdOmTcnIyLAeY4vs7GzWrl3L8ePHCQgIAMqEZ3NycvD397cKxO7du7daSRVfX19mzJjBunXrKCwsRKvVcvnyZWJjY9myZQspKSlVnuvs7MykSZPYtGkTO3fupGPHjjbL1Go1c+fOZf/+/fznP/9h5MiRvPHGG3Tq1ImpU6eSnp7Otm3beOeddwgODiY5OZmjR4+i1+uZP38+R48eJS4uzqafUbG95ORkgoKCGDduHJs2bWL9+vVVXlN7seupOXXqVMaOHcvQoUMZMmQIAG+//TZvv/22cJAEgnuAJElknzBxapOBgH4qAnrb/uI8f+4XDv/xCU8/999aX9hrPlqE5YIOzdv+oJJh2pNv00GyZOgwHylE/bofph1XKH3vDDInJQZ1Eb93/TvD/7YGKfAahi8zodSCsq8HarULrQKf4HTSf6wOkvHni2XRI5/6Hz1KLSgiKb+AtY905opOz/qz55nQvg1ZWb/h7hGEXNsYiyQhl8nINTshx4yqOBG4/7JkK+Vy1g8dUCsRJFvOEVBO8b1///6V1N6VSiXHjh3j0KFDZGZm0rNnT+CGYn1OTg4tW7YEYNCgQQA4OTnh7l4WtjQYDFRFRUV6AE9PT+Li4li1ahU//vgjgE3t0Jr0RO0tu5kmTZqgUCiqPM5gMDB//nx69OhB9+7dq6ynadOm5X6+ePGidbyCgqr/CGncuGyDhEajQa/XV1lWcew0Gg1ff/01mzZt4syZM+j1eqZPn84XX3xBZmYmr732GsXFxSQmJhIREYHZbMbNzfZHV8X2srKy2LNnD2lpaeh0ulqZ6bLLQcrLy2Po0KHAjYvXvHlzjEbjHRsgEAhujYIsM8lbDRRfshA8SF2l2KzFYubYn/+kpCQXvS4frcOtS29UhWSRMMZfRBnmicxVibKPB7q5qVguGZA3Lu+sGTdcRPGwK8rubii6umLem48lQ8cRj8/w8+qPQqGBfhrQKjB8nYXlXCmqF3wIbvtXfl7/HAVX03Ap8MVyoizv0f3AxrMZdPX2pKmTI8+28mfJiVO8FtKaC5l7UXk/yrObf8XPyZHILh1ILSjCR6nncu5xgls/UXPl9RAXtQoX7p7o8c2K70OGDKFNmzbl1N737NmDUqkkIiKinH7Y9ffV9akkgPj4eHr06GF32xUV6VevXo2bmxuDBg2iUaNGZGVlERISwsmTJ+ncuTMJCQlWKY6kpCS8vb1JSEhg1KhRBAUFkZKSQlBQEMnJyYwdOxY3NzcKCgpwcXEhJyfHpgTIzVzvU6tWrTh79iwAWVlZNG/eHEmSmDlzJi+99BKhoaF29U8mkyFJEo0aNbI6gGlpaXaPT3VUHLu4uDgGDRpEv379GD9+PJIkWadES0tLGTt2LDNmzKBLly5ERUVRXFzMtWvXSE9Pr7EtPz8/wsLCGD16NHl5ebXyQWiXg+Tq6sq+ffusXjnA8ePHcXSsW60igaAhI1kkkrcbyDxowrejktDntdVu6U8/uxldaR5yuZqCgrO16iCZDxYg5RlRDSpbWyNvpkXe0gHT71dRP+VtPc5yrhTzsSK0c8qmDGRyGcp+jSgqzODCT7/zcK8bSuPK7m7Im6jRL8/E/GEaLq/54efZn9Q/4gk59SyKrq7Ifet/9MhgNrP5fBZTO5ctJh3YuWXy3gAAIABJREFU3JfPjiWx4/x5snJOssnwJKGeHmgUCl7evpemTo4EujiQm3MISZLEFn4bZGRkWBXfhwwZglarLaf2HhwczIoVK4iOjsbPz4/Nmzfj5+dnPT8sLIzIyEgmTZqERqOpduqpIhUV6QMDA4mMjOTnn3+mpKSEBQsW4OTkREREBPv378fZ2ZmJEyfy8MMPM2vWrHJ6om+99RYxMTGoVCr69u2Ll5cX77zzDlOmTEGhUDBmzBhUKvscTVdXVwYPHsy4ceOQJIlp06axe/duDh8+zLVrZaliu3btap3mq4rAwEBmzpxJ586dUavV1jVCtXEf6nQ6PvjgA86cOUN0dDRnzpzhyy+/ZMeOHQQGBhIXF2f9r0ajYejQoXTs2JENGzYQGRnJlStXmDBhgl1thYWFMWvWLOt5UVFReHh43JH9dmmxHT58mIkTJ+Lj48P58+cJDAzk0qVLfP7553Ts2PGODLgThBbbrdEQ+wwPRr9NeomEn/QU5VoIfU6DW7Pqd6udTDzBmdMzCQx6inPpWwl+6AVaB4ffkQ0Wixm5XIGkM6Obk4qyr0e5XESm3XkYf76EdkEwMnnZw1X3+TlkDgo0r/uVq+vokX+Qm3OEvwz9ulI7ks6M4V/ZmA/cJKehlaGNbIW8qbZaG+vDtf4lM5uFhxPYOPwxNIqy6/TZsSSOZJ+juPAcHl7tWdL/EbQKBb9nX+STo4mMCPDGeOAlnnwmHhfX6iMIFRFabILa4rfffqN3794cOXKE9evXM2/evHtt0j3FrghSly5d2LFjB4cOHaKoqAhvb286duyIRlP/v+YEgvuR/PNm/j975x0YRZ3+/9ds382m914JCQlJSAJIr0oXUECxe9jOXg48RYoo6qnYCzbsig2lSO+EEhICIUAK6b2X3c1m+/z+iAZjQvE8/Xn3zeu/zE5mnpmdnXnP83k+z7u9wYFcIyBTwNndncPZg29VoXK5eP+xpqY0rBYD/WPn09JccN6eQpdKh7GBbVtuZUDcTYRljwa5gOwKz27rSIe4Yvm6Dtv+FiS+CsQGC45TPYuqHQ4rRYUbSRrUfQr/zwgqKYoFgYgzvBEFke27FxAaO4kBAf8ds2c3llQwKTSgSxwBzI4I4cuzJXjJPXlxxGBUP3023N+Hdf6dGbcNuSHU1Wb+ZoHUx3+Gv4pz/XfffUd2dna3ZZdffjmjRl3cwPnXOBwOli9f3mP5okWL0Gq1PZbv2bOHb775BqPRyMKFC1m1ahVtbd19/26//faLDgP+r3BRgWQwGCgtLSUiIoIxY8Z0+2zv3r2MHTv2j4qtjz7+T+Kwi+SsMyNTgMMGlg4Rz3ApcTOVyJQXT3vb7VZqq74nbuAtyOUaXFzDaG7K/bfjsdlM7Nv9MA67lbL9Wwg6FofykbAeU/oFlRTZMFesn9eAUgIqCbLJXj2KqstLd2G3mQgNu+K8+xQEAeGnqfwRiTM4c/oTYgbORyK5+PBDR0cj9XVZ+Ph22pb8mXxfXE5GfRP3JsR0Wx6s1TCZXUzuPw43Ze8F9b5+g6mtzSAqevafEWofv2LBggX/v0MA4Oqrr+bqq39ftvdnJBLJb8oCPfHEE93+fuSRR/4jcfy3ckGBtG/fPh5++GHUajU2m401a9Z0TVd87rnnKCoqIi0t7c+KtY8+/k9Qd8aOaBcZersGqfy31wFUlO3C4bAQHTMXABfXMEqLt/RYT7SLCNILb18UHRw+uAyrtZ0p075Et+QYbbF1+Eefa9bW3l6LRJCi1ngjv84f+Xz/riG2X9NhbCDz6PPEJyxAJldf0vFERM3g9KmPyMp8hdQhC8+7XkHeN5zJ+YysoxUIgpT+sfNJGfzwedf/TyKKIh/mFvJRXhFPDU3qYTpr0FfSr30PCaGPnmcL4OuXyrGMVX11SH308RfhggLp1Vdf5YMPPiApKYlt27bx7LPPEhAQwN69e/nb3/7G6tWr/6w4++jjfxJTmwOFs4DkF4KiIsNK4CB5r+LIurcZDDbk0316fPYztTXpuLglIpN1ChBX1zAMhirsdnPnjDHAUW/GtKwISaQG2TBXpMkuCGopZlMrW368AZlMjbt7NCIitTVHmTz1Y2T77GgcvuxwX8g0cwpKpSstzQXs3H4nNquRyH6zGBB/M1ptQK9xiaLI4YPLcXOPImbADZd8juRyJ8aMW8X2LQtwd+9HZL9ZPdax261kZb6Et+9kUie9QkN9NjnZ75Kc+tAliY3Skm0Y9BXEJ9x2yXH9jM3h4JXsXDaXVfHyyMGk+PTMWtXVHcPZJQSN0/m/N1+/VEwdjeh0pbi6hv/mOProo4//LBcsZmhvbycpKQmASZMmkZubi5+fHzt27ODOO+9Erb60N8A++uijJ/X5Ng6+1UHe5nM9WNqq7OhrHASl9Hx3Ee0itk0NWDc14Gg4f9+WutpMnJ3P1es4u4QCInpdRdcye6YOwVeBJEyF9Yd6OhYV4Kgxk33ibRQKF2Ji56NQOGMxtzFm2CoU66RYNzSgvjkUpbsbZ0591CWOQsOuYOyE12hrLWLDulkcOrCEhvrsHv5sBXlf0diQw7CRK7p1x74UPL3iGDr8CY4eeZbGhpM9Pm9tKcDhsOHnPxNX13CCg8fSYWyguenMRbdtsejJPPo8+Xlf94i51WxhZ0VNr55qAMVtem7fc5i9VbW8NWZoN3Gks5j4MD+DVnMHdbUZ+PqlXjAOtdoTV7dI6moyLxpzH3308cdzwQySVNr9Jubt7c1DDz30hwbURx//F6jJsXFmo5mQoXIqMqy4BkoIHCSn4qgVn1gpKtee7y6O0wZEkwNJhAbrpgaUtwb2WMdgqMZgqCI08tysJrlcg0bji66tFDf3zoJp2zEdssvckE/2QrzKF8vbFbR/VUShxzomTn4PH5/OFyN7rgHLW9U4NCZUiyOQBKtI9LqHtH3/pOjsekJDL2fw0EcRBAn+AUOpr8siP3ctO7bejptbBP6BI5DJlIginD71IcNGLMfJye+i58chipTpWwh3OdeaICJyOq3NZ9m35x9Mv/JrlKpz3iQN9dm4e0Qj+SlDplS54euXSnnZTjy9LuzddDrnQ2QyNe2GavT6ClxcOpvb2RwOHjucxfHGZkKdnbhnYAyj/H1wANXtRnZW1LAmt5CJQf68Mmowrr+wh9hdVcjz2XtptXTQaGonsvYYIXGLMNlEVLJzGa1ag501OR2MDlYwMkiBt08SjY05RDO3W4x17Xb0FpEo9z/fjPh/lZkzZ7J+/foLrlNZWckzzzzTq+XGn82lxPtX5+eu3f8J37eftxUWFobRaOzq1fif5Df92vrGxfvo4/chiiKVx2wUbLcQO01BQKIcrY+E3E1mFE4Cdbl2Um7sfSq77WAr0sEuyEa5Y/5XCY4pPQug62oz0WoDUSrPTb8XrQ5cXMNoaysFwNFgQSw3Ib2zcyaKIBGQzfbBtryN2Enzz4mj0g7Mr5V3zlab5sWjGcdxrpVzVcRAvH2TcXUJIWXIP7A6RBQ/vUv5+Cbj45tMh7GBI2e+Z11dLaU2OeV2JXKX+WiEIIJFB1Lh/MnrCkMrTx/fRVZjFQ8NHMV1UYO6PktKuY+ysh1UVu4nMurKruUNDdl4e3dvORISOoEzpz8hKfn+8967DIZq8s58zuhxL3Es4wUa6rK6BNKbOflUthv5ZvIYNpVWsuTIcTzVSppMZsx2B/4aNSsvG8TogHMmvVaHnaWZ2zlQU8wdsZfRz9WLhw9v4JoOWH0yAcmpFqZEKHHR1KAzerL+rAMvtYSj1RZS/Nzx8IwhP/er7t+7Q+TRvXrq2x18Mt0NL83FZzH28ceRnp7O4sWLiY6OBuD+++8nJCTkL2FWGx8fz/PPP09lZSUmk4klS5ZQXV3dI96YmJgLbnfjxo2o1WomTpz475+oP4k/cqLYBQVSQ0MDS5YsOe/fAE899dQfE1kfffwPUaZrR1OnpGS/FUOjg/jZSnxjO39+/gNltFXZyf7ajLOfBNegng9AUW/Dnq1H+Y8wpBEaJPFarBvqUd7RfbptXW1mt6Ec695mrD/U4z4zGp2uFAB7lg4hRIXE51zGo8qShtG3iP5F0zuHmTocWN6t6LT9mO3Lq9m5FLTqGODhxp17jxDpei0eFiUrt+yj1tjBVZEhLBwU37W9QpONlXUQ6NSfod5B3ObhT3W7jtdOpfF1cTZ3xAwl2SsIZ8U5gddsNrKlPI+3c48wzCeUpckTeeb4bhQSKXMiOrsCSyQyAoNGUV15sJtAaqw/yaDUB+n4hZ1ZUMg40tP/xYcnj1LUoUBnsaC3WpkSEsg1/TprfE4cex0f3xQ0Xqm0uY2hsvYEkf1msbOihm+Lynh9ZBIqYyEzQuOpbPblVIOVfw2XEOPh3G02ms0hIpMIvJ93lJPNNXw+/jpCnTub1MVoFOw134ErBq5VHeTrwniqbEGopDqWDXVjWKgLN25s5YvTHcwKjEHXVozN1tFVQ/Z1romWDgdhrlL+dcTA8+Oc/3Ivq3qLA/Pvs2JDKQNnRe/i769kVgswbty4rs7eAJ9//vlfwqx20aJF1NbW8tprr5GZmcl7773HtGnTesTbG6+//jrl5eVER0ezZcsW3N3dSUpKYvny5Xh4eCCVSpHJZL1uZ926dRw4cIDw8HCys7P517/+xf79+3ssAzh06BDFxcWUlZWxatUq9Hp9V7NNd3d3lixZwjvvvENhYSFGo5FrrrmG4cOH9zCi/eW+dTodLi4uPfanUCh44okncHV1RRRFli1bdsmNOOEiAulnM77z/f1HYzQae6jy33JwffRxKTSbzDSbzTjJ5JgLBdoKwDVQgkuAFNdAyb81k+yXFFe1s3ttGyFmF8IGy0m8pmcH7OjLFVgMIv4Jsl4ffrb0NgQvOZLIzoemYqYPpqeLcUw1IfgqEPV2UArU1WaSNOgeTBZw1JqxflMLailBOSkci3gXAPsxHZJBTpw88TbG9npstg7qajMZMPkm+MyGI7cd2/4WUEuRz/Vlf3UdXxeWsnrsZQz0dKe+w8Tm0kqsDgfTwgKRCgJL0k8wNTSIOA839tUUszhjK/MiErg3bgSSXxzP1JAY3s87yrJj22m3WQnVuuOn0VKsa6bB1I6HUsOy5IlMDOyHIAg4yRQsztiKXCJlZljnUFlA4AgOHXgCh8OKRCKnvb0Wo7EOb+8Eyitau/bV4lCzUXsfzUX1TI+Mop+rMw5R5LWTeUS5uhAqVFFetpMxUz7j3v3pFOuikWAnaV86pxvMzA6P59iZE7xR3kiBJJBUfwUOUUqTUYOb/7kH2NkWG3dtbWNMqJ3Ndcd5dcT0LnEEMMZWxHu2KVxp24S3m54KeyOpGiVZVhMum9bR0G8sd8TeyzNZDqZGRAACrS2FeHkPpNpg54OTRhYP1zLAU8ZNm1p5Or2UBD9j1/n4/43NITLn+1barRftOXxBnOQCP851R9bLDMi/klntLbfcQlZWFgsXLkQikfD444+Tn5//lzCrzc/P78oODRgwgOeff55p06b1iPd8/mbx8fHcfPPNmEwmYmNjKSoqws/PjyeeeII1a9Z0WYf0RkBAAPfffz/vvvsuR48ePe8yPz8/VqxYwXfffcemTZtISkpi0aJFREZGct1112Eymdi7dy+vvfYarq6uVFVVsW3bth5GtE5OTheNobKykkmTJjFt2jTeffddDhw4wPjx4897DL/mggLp3nvvveQN/RF8//33PVT5tGnTuq2Tm/vv9XcxmUz/9v/+t/J/8Zjh3HFbHSKtNhsmh4jJ4aDQaOa4vp1CoxkRkDoEHikeSp3KgGulAq8OJ9BYCZpYjyD9927+pnoltYc9cajtvBR4hOtd3LBX9PxhA8jjoNEOjbkgaxVxKMGhFkAU8d8l0h4joMvL61rfKwrEp4oQfqoftisdaKO80fVzw2E10fZ5IbYw0CXb8fvKA4fcTP6R0wSXwOmEAxSd+hJ3z6FIJEo8vSfjcEtEN1DE6a0yBAfU3CBQe+YUTxZXc7WPG7L6WnLrawEYCp1TPAydTeRGuml5+nAml3tKeLfmNNd696OjWcKtW/YQqVESrVERrVGhlkqYKvdmcuQYqi3tFHW00WwzkeAWQbFRoLTDhrzRRJ6+8zj9gUlu/Xk2s5iC8game/titztjs5nJzNiIs0sszU2HMcuDeCQtD6PNjk9VA1qplL0tOsKlKqaaPmawfAUCVhCgytOFxYcyuM70Dt5e43g6qwaLxcbjgW6sKywmt2oINoecLQUOlPYgPGVqZtoWMtr5SnaTzKcnLISbW/hZ971V5EKQSsLOUivOkhk0lJnI/anvlKN4C2UNIjKZhFM+LuyySBnn7sN8n2geLkojPXYBo0s34Kd7nlD1I6w60MFwVSBnzuzF00vKq0VuRGvBr72egtYOtCod2wpjcLdVk9uR2+36/v+FTCLw7Wy3/0gGqTdxBH8ts9oBAwawatUqwsLCWL9+PR999BHw1zCr/dlX7Zd/9xbvAw880Ou2L2ZgeyGB9LN5rEKhwGQynXfZL89ncXExCoWCNWvWoNFoqKurw2KxsHjxYlauXIlOp+OBBx7o1Yi2N4H06/1VVlaSlZXFgQMHuppc/xYuqQbJYrHwyiuvsH37dux2O3v27OH9999nwoQJXQr2j6A3Vf5rgfTv2gr8FSwJ/mz+asdcn2+jPtdG7DTlJWVpTHY7XxaUcF10eLcuxRcjNzeX/jExLNh9iNyWzge6VBCIdHVmbFgISwN8CXF2ouyYhapKB/5z7JzWtbKtvpIh6WG057hz5bU+SH/DsIYoipSn26g+aCHDp4KUCVoW2KN4KyefYTHRBDhp+L6onO+LyxkZ4MO9A2OQWjuzO7YDLTgKjaAQkI10Q9LfCUtTBS4z+xHodi6DKkY4cJR0IGilnDbrqduey7Djj6Ds709DdT0qkwzVY5F4O8kwni0krnAOPsFOCIE2GtlObNy1JA66u3vcwTZMK4qQz/MjOEXLc/vSSfT25MERqZTpW/DVaNHIeqb/H4uwMHfrXj6vr+feuOHUG9VsL61kXlQYea1tvFfdhFom5cURqcS4d769xgGjbHa+Lizl0/wivNUq/N1cWVXVyJujhxLi7MTRukZ255YR4KTku3oD42MGkOLjQ31NKnJZFbGxV/HVgZ18qvwbKlsHYQoJXu6+NHSYeDApjst9lPzw3XME+Ctwc4+iSm/n5gALJ3d/x07FVIYFj6CkpJppgYN5PteGn0TCLREVzE1NxdB8kh1bb+eqOdvIO5NKfv5rDEp9ia11IZg8okj2k3O22UZ2VhujI/PRt5Uy3G0GLxRYuCdFw1TVcfIL13Lc43WmRAh8X9dCsncgTw6/EplEymx0HG2o4LrRd1Gz6zkWzfPgjm0GPN1uJdcgcKTFTrNBiov7blY1yChoayDFJ4gQZwWtkkRiY7Vd1/dvtRr5T+OskOB8/lGh381fyay2tLQUmazz0enk5ITVav3LmNXGxMSwY8cOAE6fPs3AgQN7jfdi2xYEAYfDgYeHB2fOdM4E/aMMbN944w0eeeQRIiIiOHLkCKIoYjKZeOWVV6irq2PZsmVceeWVPYxo9+zZc9F9BQUFMXr0aCZOnEhdXV2v3cMvxCUJpMceewxnZ2def/11HnzwQQDCwsJYunQpn3766W/a4W/lYgq8j/NTn2ejqchO7LTfbwnTUGBD6y1B7f6fKRC1W0Xyt1qwmUXMehOJ16iQKS78/R6oruOd0wUopRKui474TftLq6mnVGdg3ZSxeKtVyCXdj8PhEGk4KhI+TE5YkDfD8IYBcMijCf0GDc+sP8PNE8Iw2e00dpiQCAJDfL26DR/9THuTg9wfzRjqHEjGG9lXW87C4PGopFIKWnU8eCADm0NELZMyOyKEb4vK0BXqeTjdDYkdZMPdUNwcgNhgwbq1EdvuZiQDtUjcug8vC0oJ0hgnDFYrj2/PocHbxEMja5mxVY6bERQPBCI4df7ElXNC8Fysx7HDgG2YSEtzAWPGvdQjdsFFhur5aOyILDmchcFq5aURqWwsO8OzJ3YT7erNq8OvxF3Z3ajaTalgeIAL28vMnG2Vcri2ijfHDO0SQzaHg1dP5nLX3iM8OSSR0QG+7Kqs5Y2cXAQEHk6K44qQAERRZEVGNnfvO8Jd8f158fhp/hYbxfXR4Vy5ZRMPpWXwzaRxBASNJCN/K++27+B4fThSiY5Rvmr2Vxdj0LXwj4SxJHp2vvn6+CZz8MDjDIhfwPIzQ6jTt3OFJJ0fldP5rKCMBdFD+CTHxqrxzlgLNyEXnVDLBnOyaBOBQSNRqdxJHHQ3u5paefHUAbxV43jvpIO3/bx5KbMZZ1UDu6qP8kZcCin9nbkswMLyND1nzGVEh82nRR/KHYN8GK+fRaybD7KfWhzMCB3AmvwM6uNH4LB2EGLM5ub4eLafTaDeYkAml3FbkoNQ98HUdui5oV8yY/0jsNhBb/l9w1n/bfyVzGq9vb154okn0Gg0mEwmnnrqKVxcXP4SZrWRkZGEhoZy991343A4ePLJJxFFsUe8FyM6Opp33nmHF198kZKSEpYuXYrD4fiPGNTX1tby9NNPU1xczAsvvADAc889R0hICIMGDeKjjz7CYDB0aYvZs2czbty4Hka0l8K8efNYvnw5O3fuRKfT8fTTT/eaeTofl2RWO2HCBHbt2gXA1KlT2bx5MwDTpk3jxx9/vOSd/VbWrl2L3W7n+uuv54033iA6OrorPQp9ZrUXwtjiIP29DuwWSL5ehUe4tNdjNpt1nD75AUkp95+3N42x2cGhtzoQBPAdICV0uBxn357rNhTYsFvAM0qKXHVhsVN8wEJNto2UG1UcX2tCrhJIulZ1QSuNxUeOc6qphQ6bnW+njMVFce5GUt1uxF+j7iaiRYdI/jYLHZpKXrPVkuztwX0JvX/nNTk28reZGXmfpkcMObuMlB6z8FLoUTqkNtwUCsx2O35Oam6NiWJCsD9SQcCmt9OwtomCOhXusQr6X6Hg8exj+GjUPJrcWcBcoW/jmh1bmRQcyuKUIcgkEtoONyJ+XMuuYCPya/yYEBqAk/zcu4ujrAOcZUg85FjsdhzQ5eUFsDLzJHktbcS0fMVm6VTei0vFKa+R0FndvctyX3iH0IKR5F65GaNzA6PGPt/ruRBFkWeO5XCkrpF3x17G+rKTfHI2k0cTx/FjeS4t5g5eHzELP43zuRhFkWt2fobR7IsoSnht9JAe3aQBviks5ZXsXMJdtFQZjNwaG8U1/cK6MoKiKGIXRZ7KPMm28mpujYnizvjoc+du224U9v44qWppsnYgAeJsaawYNx9/3wSOnspmj62Z70tPMdg7mBmhA4jXF1LddIz95bWsdywhlAzalEO5Z7CUZrON97Jk3JfixKxoFQX531KQu5YpMz5n3ddXMHT4UkJCJwBw276voOEIKteRHK8bg5vrcVrbkhjsuoVZ5Z/hj42waz9A6RnOwe0f80zdSIwSJwZpi3hp5ohez/Xf09YR7erNnJINyDTuaEc/wl37vqC1rYzPpj+Cu8q51//r9r32mdX28QdhNps5efIkgwcPZuPGjVRXV3PnnXf+/w7rT+OSMkgKhYLGxka8vLy6lv2c5vojmTlzZg9V3sfFcdg7nd89wqUonQWK9llwD+t96nhx4Xpyz3xKQNBI/PwH97pO5TErbiES+k1QUHrISvp7JvwTZfS/XIFMJSA6RM7uslCZaUOmFrBuEHEPkRA0WI5P/56XmFnvoOyQlQEzlKhcJaTcqCbrcxNZn5kYeLUStVvPLJXJbudQTT0rLxvEm6fy+TiviPt+8rvaUlbFioxs7k+IZX70uSHf4gNWqrJs2BWeVIeW8OKI3rNOoihSeshC8GB5rwItbqwaY5nAiuYROLlLkNgFRIVIntjEa5m5vJ2dzxhdEHOOCrh1mEmRS1AmedJic+JwbQNrJpx7OL6dewgXlZ49tSf4u24AbjuNyHc2I7s2gHa/Fr7JL+SlnFwmBPlxQ/9Iwl20SEI7C7NbzGYeOJBBi9nCY8nxhLmo2FlZyZayKl4fGs6ZXYeYO3ABiwpzeCLCh9BfHMOp5lpWR+vwdD6OUn+QBYOX8GtEUaSq3cg3hWXsqarlnoQwXj61h8yGSt4YMZtkr0AmBffnsaObuW3/N7w+fFZXn6IDtSXUdRj4eOyVOMuVeKl7v97mRoURpHXiYE09L48cjPcv1jOUpVOz/WkibvqCpYMTuSoihARP967Y3BtPk2IWyBK9abO6kqL4hHm+7dRU7MXHq9Nvylmq4NH4ccyJSOD70lM8d2wbDmsHA60GGjQP019Sw6IkN9aUqHnvhA2HqGBKpJxEPyMvnTxKh0lBidmbhsyv0AoSAoM6DUIrDa1kN9fxdEg/bLVfY/YcS17zIEYECtx+9is8R9xOR+0pyr67B//xj+J+6k1emxbPU5kFXBN9/rfuWaFxvHhyH7PDx/B11iZ27/ocD6WKq9q30dIyGatrCD6a3juT9/Gf5X/RrLY3mpubeeWVV7otk8vlPWao/7z8iy++YO3atRgMBlasWMHSpUt7rHc+89v/di4pg/TVV1/x+uuvM2XKFDZt2sTs2bO7umnPmTPnz4izV/oySL1TuNtCTY6N5FvstLaUkr82goQ5ShqsZ7sdsyiKbPzhKoztdURETmfIsJ5pS7tV5MCrRmKmKPGL6xQ7ulo7ZzZasBpF+k9SUHXChr7GQeI8JS4BEnTVDurz7JQfteIXL6P/FYpuwuPMJjPtjQ5Sb1Z1iWxrh8jpDWZaK+wMmKHsElaiKGK3wKGmelZkZLNlxkQy65t49NAxvpo0hrzWNp44cpxJIQHsqqjhk8tHEuqspanYzom1JhLnKdixoRmZq8Ccv3l3FTHWnrLT3uhArhawGkUqMqyMvF+DXN276DfpHFRn2xAdYLCYaWjuQFGjxdIuIsrt9K9pROkwsXR0E5EaESC9AAAgAElEQVRNUu4o8sDRYeeYn5lxV0QijdWS1VHDPWk/8Pnoazny7Ukuz/HC2VmN4pYApNGdaV+7KHK0rpHvisrIqG/kwcQBzAoPpslk5r4DR3FVyEnx9uTjvCKk0nZMNjk+GpEbPepQ1mwnaMRrPJV5mlaTif6eEtxVEmo69OS31jNII4Hm42Qp47knbhQ39ktGEAT0FivPZeVwrL6ZVosFjUzAJqnBgYlhPiHcPWB4t4aNNoedu/ecIF9fwJNDhjA2IJIF+74h3t2XhxJG/1vXrCg6KPn0BkwN+fiMfgCvwTeduwYt7VSse4DihjZWuL/JTdF15BY1kGMLZrrjH0T7eHLFlDXAud+1KIrUp71JXdZaykcuZF9JGYdN1yHRbmdEgBtPpkzhif16zHZYNd6Zv6d9h8VhJ0zrTknpDvIkgSz2NjFzVGch8Du5R0ivK+fNoRP44dtpOCe+xws5Abw1qBTJjvuIvmsbEpmKivWPYCg5iNvAWXSED+TosVcJGrGQE43p5DRmckfCP0n1PfegM9ttTN3yAUabFU9LG/MjE7k6cRIbN17NVpUBg8PEDTH3MFYRg62lDKnaDZnGA6VXJFKlc7djvlT6Mkh99HFpSJcvX778YivFx8eTkJBARUUFQUFBuLm5cffddzNmzJg/IcTzU1NT06Pq/lJpbGzsqnj/IxFFkZZSB1Kl8Luni/8au0XE2CTSWmmnudROU5GdulwbFRk2EuaqqGxcy5HDj+HlMZS2Ak8UwW14eXlRk2OjJM2KyZFPcfnnJA9+iLMF3xIz4HqEXzXwqz1lo6XMQew0RZcBqVIrISBJht0C+dtM2BxtpN7khLOPHEEQULlI8IyQ4h0tozLTSkWGDUEAQ4MDXZWD0oNWBl6tROVybl9SuYBvnBSJVCBvswVdjYOKDCsFOy2U7LdiOiUlyeSDrEVGoEpNoVXH1qoqvi0qY3FoDNf/KMPmr+DLpkomegaQ/aWJkBQpTt+VkCupx7cjELWbBKWzwOn1ZioyrEgVAoZaB/o6B8FD5HhG9GLv8ZNxqEwp4BwssN2ew4qaH9khySFwiJTJQ4MJyGvG2WDC9fFIJg0KJUfZwRPKEurUNkZL3XFK02Pb0IDbng6uLw3Dba+J6FZnVkcUILnRj4iIc52lJYJAsNaJK0IC8NOoeTn7DLktbXxaUIy/Rs2qEYPp5+7E1qrj2OzOBGtdGOhm4pPqBg5LIthcmUeEqwrBJqNQJ8HmkJHq7cMzQ65gmMoIRZ8yMmoC75aWUqRr5jKfUBYeOkaz2cx9CTGEu4mcactjeep4Hk8ax9SQWNyV3S2F6tpF3s1S4SYNZn3VRkoNzaTXV7By8GS08ovXu+U3n+TH4i8Z6D0YyU/Xmy5/B21nNuE1dAEtJ77FY9A8hJ+GfBuPvI+x9jQfhr5DjLeKR4YHM35ACNnFhRywzcS1vZTg9lKUTu40V59F2nicxiPvoT+7h/CrXyOu/1iy2/ojaz7Dg4p9vKu3MzEoinn93ZgUoeRUSy0f5B/l/dFzmBE6AM+6bRQZ2qjWxDAtLAGHKPJU1k7mRiaS4B2Gsb0GWvby4KSrkB57HaVXFELEUFRyJ5yjxoIgxXPo3/jy0EJ2qIxkN2Xg7xSMl9qXnWXfMyn0aqQ/HZtMIiHC2ZMJgVHMr9lHP7EDl8gRfFDyMSAyz30CX5Z8TEbpRgJqyrEV7KP5xDfYO1pxjuwUo7/1XvZ77pt99PF/iUsSSNXV1Tg7O5OQkEBqaiqxsbGoVCoMBgOCIFywqdUfyX+DQNLXOcj82ETZEStNxXbsZnAJlFzy8GT+NjN1Z+xI5QJqVwG7GaqzbZz50ULBdguVx2y0lDswtYhYjYAIIZd1Dm0V5H2NUulCo3ErkuoZINipO6ai+rgNtauEykNaXLQxxA+bwJnTa/D2SUDrHNRt/7lbLPjEyHqIB0EioPZt5XjpjZicf6CkbC1SqRI39+iuWialVsA/UYbFCPX5dtoq7bRWOghIlBOQ2LMQURAE3IKkeIZL6WgWcQ2WEJIqJ2iYjDfrTzEkwAOv/A5KzghElHujaVRyha83E7ZbENvtJDQq2akyozqqxdVdhry1GqHcTGKzAs9BavKyBKqzbSBA8nUqglPlBCTJKQ6swOTZTpC2u3VF2r5/Ulq8jYio6ZTomnno8AYO1pXyz6TxXBOZyIs5+wiuEIg6DsqFoeQr20ivL+OaqGiG+fuSq+5g0pX90Uz2YadfDe9qznD5jGTUg91RzvOnyKudt3LKsFn8OVZr53CVBYNVJMhZilQi0M/NhQlB/mwtqyJY68Qzlw3CKtq49+APuCsVfDxhGrNCA7BkP8UYdxdmDrqGRYljuSo8noF2O9cMSqBEZ2RneTNxHh708/Chvi6LaSMfZUJQDO/npvNjWRMGK7w5eiieahlLMjfz8MAxXBEU3VVM/GveOGZEZrXQbJEzNyqaPXWZTAjox7TQ82cx2i0OagwO1DIzyw7fTVZ9GmZ7B0k+wxDtVio3PYp74tV4pt5IU8YnyF38UHn3w6qrpWrzYk4nvsCOBjeeH+eCRi4gkUgYF+VF9unvSJfO54fmSAqzd+Nb8hlKXSFKj3D8L1+M2m8AOrODZw4buW+IG74n36bSOZjTRiMTg2MQBIEXT+4jRuPOdJkXgqszJxsyqGjP5Lg5hAQPf+o69KwrOcXS5IkopTKcXULIyniJkIBk9px4g+88Ovgo73UKWnIIcetPQNQVvJf5BLs6crk+5m4WDVnFsIAJJNZ586NhKyAS65nUdW5Cnd0Jc/ZAEG20HF/Ldq2e7KZMJjSZiK9uZnz4HIpcVXwvFqAddDXDJr+Me9SErntIn0Dqo48/hkuqQZoxYwYmkwnHLwwbBaHzJmW324mMjOS5554jPj7+Alv5v4mh1oHGQyD+KiWNZ+2c3WXBJUCCW/DFp6m3VtipzLTh3V9K9tcmZEqwWUChEQgcJCPuSiUadwHpeWZ/tTYXEDPgenyHp5D2xRb0p2fi2c/GsLucEBQ6zn66CB/9c2SuEfAL+Bvbco+wLcfMouR4krw80NXa0VU7GDi796xAafEWzrgmcsO4B3HU7SDn5HvU1WUycvRzXTdvqUyg3/iLC2ibw0Gz2YKPWoVrkBTXoHPn50htA/naZoZqIxBPN+DrLsMyzR//dne8ttSgkwgYJoXgtamcB7OD2BLUwrf2cl4+7MWWyZBsgqD9dQQNC0QIURM+Uo5E2hlfVmMVj6ZvxlWh5PsrbgZzC8cyVqE7U8TgqnvR1HvSvPMktXI9c6KCGXNjCq6KzrqZ14bNRPJsBTtDCvngxD7qrFac5Uq+KT7Js0OmsnxIEnbRwQ+lp3m1/jAPjh6Jc9i5BoJOjjg69GF8U1DPQE8vFFIJG4vaeSWjnamRSq6JVROkdeK98cOBzmzW4owdiCK8NGwGTjI5WZlvYrW2M23YI8gV3WsAwl20PDcshXVFZSxJP8E/BsUxe8YXAARKVaR6JbK9vIa7BvrhoVLy2NFdxLj5MC2kdxuC+oOrafMbzdZiX14q3kHegCS+LQ7giyk3oVWc/3puMNp5aJee0jY7fk51KBXJLBu2hJXp9xHgFMJgnYDdpMcj5XokcjXuSXNoyvwMl5gp1B98C5PfMD6oCuaOJE03mw2FXMXKq+YiU3hypMbGD7nTWVY/nelRKv6WoEGuEihptfFdgQlfJykjozyweqxm9rZ/8ViNiuPHv0MTNpz9NcV87AjHsvkbxNvHcqR0M7UqE2HSWl7JOUC0qxej/cNx+el7d3UNR+qfyCMZ9yB4OYi3wQCbN7Xmdhbuu4EAbSj1+lJu8Z/NldG3AmA/dhrJ51u5LiaZ923vMzZ4Ou4qr27nyTliNLsOLOf7gjVcUwd2lZSIW9chU6hZLIocq0/jw1Mvsat8A3cnLmGw3783nNlHH31cGpeUQXJ3dycsLIyXXnqJhQsXMnfuXBQKBXPmzOH555/HycmJN954g3nz5v0JIZ/jvyGDVH3ShkwhEDJYgXuolMazdmSqzkzJhRBFkdPrOwut42epCB4sp7zma0SPw4y4IRXPcCVKrdD1oP81druZrMyXiU9YgJt7P5p9tKxr3YZO9QmhwYnUlm+nzZTB+Otuxm6BpuMx1DaFgredNUVnSfT2wJghQ6kV8B4kYXdlLf5O6q7p8aIo8v3B1XzrmEiDycp1yZMICh7D8cxXUChd8fQa0Gtc52Nl5klezc5lXlQYsl9Nwf80vxhftYrRW+3YE1qRR/sj/FCLR6MRpQraZwXTUAXKIAV+xU3YrlYxP1uDJtiJQTdFUy9rwkvljvZ4Ex4pKmizIeps1NsN3H30B+ZGJFDV3kaHzYY94yP8sxKIz5+PZmAA30ZuY726nVh/f4alO6GJdUXi1Sn4vIvBKU3P23FbSdWf4fbGI1zt6kKxWySvnz6EIAi8kL2PvdVF3BV3GVeFDewSjhvOmnjtmJFHL5OTadhCpGc7y4fGMC9GjZdGytZiM2mVFiaHK7taCWytzOfLohOsHnU1nkoNZaXbOX7sNcaMX4WLa2i3c/bL6zvWw61TLB07Ra2xgw0lFTx//BTlehM3xvjzQUEaDkR+KD3Ny8N6TuEHsOpqqNywkDXNKfjJXJhfdIRoNwkb1aEIgoQUv95FdJXezn07dQQ6S7k7uZ6dZWkYTDeR1+jNjXGxvH/qSTyLThCdugBlQHKniAqMpD7tTQSZkoZjX/JOwGt4a1U8kKrp0VZBLndCKhEIdZUyKVKDp7majFY1q08Y+eJMB1/nmdGZRe5NcSLUVYZM40543FSOlmbwXcMJ9pUepr/amzn5TRjN+ZSWvcMPPjaud7+CU/o9VFjCyGtr5r74EYRo3RFFB43Gat4uXYOvsYNJVndSg64gzGcQtoLtDPEfgyiVEd+qZ864t5BI5TiqG7CuWYds+hgCi6xkuZRTZq9giP/YbsciSmW8XP0JozqcmTnuZfJLNhAeNQ2Vyh1BEAjQhjIp7GoUUiVWu5lItwE9vutLoS+D1Ecfl8YlZZA+/vjjbtP5/fz8eOihh5g9ezYzZ85kzpw5vP/++39YkP/NGOoceISfE0OuQRLaKu3AhXtdNBfbaatyED+z88EjVUCDfQ02u4m0/YWMGvsiUmnPbeS3tHGgpp5Ep3ZERNTO4azJLeT9MwXY1c5kOi5nw/YcJtb5URF9M/riUnSeVjZHVHNDtZrojIFMIJraMyIy0Ur7GB1LtuTSYDIzPSyIJ1I7PbGams6w3RJHnJeWgzX1VBmMBLqEMHTYExw+uBxJcyzlEieavQQsdjuRLs4M8fXqdWhxS1kVpacaeaTIlTPyCpLGhyAoO0WSXRTZV13LSlU/HM06qlwWETT+X2gGDcK6rRH5bF8CvRUEjgBRVGFuMTDsKzNimxXlinOiQT7XD9Fgx/pVLaLJASYHLiK86z6YgERfpuk9sG02ENR+A44gAeXCUN4xZ/PFWbhC8i0Js1cj1diwfF6DamkEgkyCYV0+FT4HmazKRunuQezYldTveYH7VU6kxE3n/bx0Jgf1Z0HMkK7sA8DWYjMvZbSzbISWcaFK+nvP5Pb93+Cnceb2mKFMiVAy1F/OTZta+TrPxPwBahpN7byYvY/74kYg1xeyfd8btDTnkzz4IXx8ky96HY4P8sdVoeD9M2fp7+7C1JBQavVOzI1R025t5d3cdG7w9iFU697r/7flbqHBfSiHSeaFog+RDIxGXt/I7WM1vHi0nRlRKtxV3YVtYYuNf+zWEe8tZ/EwJY8fXMqs/vHcGOvJoj16vspNYaJqBF+6HyA1aiqL9ug5WmPlxjgN02KmUr//VbaHraTKpOTD8Vqk5+my/Ev6aa3MSHUhq86GKEK0hxQXZfe4jtbtp9mxkxbJBFpwcG3TUcolJxE8ZNSIYSiltcwc8RTBJz9kcelelCThf/hVzjYW0a6v4r0g8LHDdbUS4m77ErlzZ3fegKBRpO17FB9dOYNSHkQmVyN2mLF+9D3SQbHIxg5Gmtifm96tYKlsE5PD5hHlfu5FIqN2H0aZwA2zv8NJ6YqTkz/Njbm4up6bmSmTyJkeMf+i56GPizNz5kzWr19/wXUqKyt55plneOutt/6kqM7PpcT7VyI9PZ2dO3de1APut2xr1qxZZGRkcMstt/z+AC+BSxJI7e3tpKWlMXLkyK5lGRkZtLV1diXevHkzSuXvb0b4v4YoiujrHIRedk7IuAVJyd9u6Sr+Pd//Fe61EpQiQ+XaeXM3GKowm1uZPO1TDux7lIP7/8mglAeprT1KTdVhvH2SiI27gU/yi8hqaOYDsxl3zcP8sOcoJrsdqbSeKJWMBoeZF854EJEfQqnBl9ekNVTZzCwdl4Ap7wWklkziBtzFusIKNpdX0d5i4ubYKAZ6dpqUjvL3YUygHz+e2kONNIzXLxvMkxkn+K6ojPsTYwmLmExrZjneHzrQKvS8cIUeg7PA6lMFxHu6ce/AGAZ4nKv1KdMbeD7rFM9VKXFtt+Hxo56OzfnIhrkhn+vL1yWZtJnaiTimQ+e6iwafEJyyv0M7c3gPo1ZBEFDM98e0vBD5dG8knueG9gSpgPK2zvqqhg4DyzK3o6x38LTbaCgyEyjV8k5UNi0+1Syd+xCv5BxgfdkZ3kyeQvWJNM7mf8fAK2/DntGGbUcT1lAb0goFulGnmDzjCzZvnE9hYzqx056h5ItbmBw+nLlTb+/x3RY023juiIHHLusURwBRLp68MHQa96atI68un7kxY0j1DuYfQ51YkWZgqL+MN/N2E6l1xafsE3ZVHiCq3yxGjX0ejab3zIEoOjCUpdOWuxmrrp7QOW+Q4uNJio8nte12Fu7WU9LWAQjM7yhG25rFkPJCSit34Dv6QTQBA3+xLZHW05vY5PkUqa1FeKp2sjfBG+WObMYH3sQ3LhIe3KljQaKGUUFyzHb4KMfI2lwTUyOUPDzEiS2lX9JmbuHmAQ/iJJfwwjhnHtjeTFrlHERPHbdv1+Hr5MLTo7W8mN5OkesdJHkr2GBK5ZWJznioL71BqSAIpPid+82dbTnNiYbDNJsaaOioIbv+CH+Le4jtNWpONZ1GEhpHUF44yodvZvOupaTow5AIUgYn3c6jgpXVpR/xtETB8JhU6kRfBHMd/4x7Cq2TT5c4AvDw6M+U6Z9TVLiBqH6zEB0i1i83g1KB7KpOV3TB3YXY6+9i1JbTvHt4Kc9N+bqrUH1D0WdcHnIVTkpXRLsdN70zjbt/ICxgAoL6r31/tZpEHL/Ti00iFy7aP+2vQHp6OosXLyY6urM/1/33309ISEgP39CWlhaWLl2KQqHA09OTZcuWUVhYyLPPPotKpSI+Pp6///3vZGRksHr1aqRSKZMnT+5yj7gUPv74Yw4fPozVauWhhx7qMu01Go3odDqWLVtGRMSFm+pmZWVx8uTJP010/B7i4uKIi/vzPAgvSSA99dRT/POf/8RqteLi4kJ7ezt2u73LUXfNmjXd3HX76MSsE7GZQOt77ubuGiTBYhAxtYmo3TpvBnZRZPnRE3iqlEwOCcS9VoOx0cGga89lHZoaT6Nx8sPTK46JV7zDjm23s+H7mTi7hODk5E9+7peERV/LwZoG/jUsmfaSz8hok+AbOgQnRQcfFpTycHAq7xSeJvRsP7hGS/h+K68cc0J5bwiCi4xy0xWkH1qBulYk0Qmco1y4PHEmrppOQXNnXDTPHjtFjJsT3zZomeIrw1cv4drAEFaeOc3tcf1QFJsJ3zOcb6JqGdfSyGMHAqi7phB13Dg+L9Nx2+5DJPt4kuTlQbyHG2/m5DHB1ZPYcjkrLlvNEe101oUOxXlDC/aKDtZFVjO0tQRpdTinR9XzmHYoC+oOsUBf3/VwajEbeTprFzf2SyHJJwD1M/3AtfPSrmxvo8bSTj+HA5lEwo7KAv51Yi/93Lx4bOpknNRamAAGQzUd6z9ji/wKOvZ/RYa+jVcbXYj54TDOU+ZzIusN4gbeivxaPywfVNGmLcHoWUPMjGc4Uqdi5Ohn2bntdnz8UvAZcTfV21YQ4ReHXHtOwFjtIisPGZgSoWRSRPcHXj+5lavbt1AgHcE/0n9EI9qJVsjw1I7nnp1G9LJybjJtwiiTMyL8OoKSbkWq7t1wsqEsm7S0jRRJoijW3ECzXc3oHcVcmRSGWibw6B4dMZ4y5saoeP1YO2GNG5k38e9ogpJpOLSa0rULCJrxHC79Ok0dTbWnOWb0I0Ppy9uF+zge2s7XVW8h6y9hS9qt3DXonxytCWdFmp4QFyl6q4gEeGGcM4P9FThEB5uL1zIzfD5O8s6p6VqFhIXi26xQzKZc9zyuqsO8OnEyGrmMGA8Zj+7V85bkdu5M1DDIt3um1J5bjMTfG8Ht/E0UHdX1CB6uNImtLD/8d0JdovDVBBHiHMWcfguI8UhkXLCFH0va2ZP3MTNDbkfiFkCWppi/56TgyM5HEhrAuIBrGRY6j8O6g+yp2ES1oZyVIz/Aw+mcOBdtNuzpOUhT45ArnYiJ7czwWLem4SipRPHgjQi/aGoqCfLjpsSHub/iIXbkfMakhJsoaDlFfksODyY/jSiKWL/ehmerB2UuhVjeXovijrkI2t/fxfiPwOEQSXvdiN38+7YjVcKYRzRIeskUpqWlsXbtWlQqFVFRUUgkEvLz87Fardx9991dwsBms9HQ0MCzzz5LaWkp7777Ll5eXqxYsYLHH38cq9WKk5MTK1euRBRFXn75ZU6dOsXYsWPPa1ZbW1vL8uXLKSoq4v777wdg3Lhx3TIjn3/+eQ/f0FOnTnHdddcxevRoFi9ezIkTJ1izZg2PP/44kZGRLFiwgLq6Ol5++WVWr16NVqtl3rx5TJ8+/YITn2bNmkV4eDi33XYbO3fu5NNPP6WmpoalS5eyZMkShg4dylVXXcX27dvZuHFjr75r69atY8+ePV0WLM3NzYwcOZKPP/4Ym82Gt7c3hYWFvWbO0tPTee+990hISCAnJ4dFixbR3NzcYxlAXl4ey5Yto6ioiCeffBJ3d3cef/xxXFxcsFqtrFq1ivXr17Nv3z5EUWT06NFcffXVrFy5EoPBQEdHB48++mi3fe/cuZOJEyf22F94eDiPP/44crkcs9nMsmXLcHa+eKPVC3FJAmnUqFHs37+fkpISdDodWq2W0NBQ6urqAPj2229/VxD/q+jrHcjVoHQ+94NXuXRONW+rcnQ1RNxdWcPBmnoiXJz56mwpD5QNJjJRhcLp3P81NZ7C06tTOWudA5l25VdYzDq0zoF0GBtY980k9pSeQSGRkOLjyZ4TZ5gWOIz42Chu2fsVV4bGoRSkLKlJ5qR7HV4p3kQPC8L8Vjmm50pQ3h9CQOAIgoLHoteXA6BoKSS9dR/jJ76JTK5mfnQ4aTV1LFl/mJll4Vxzwg/Tp4UMlsAKTy/yDSVEHbbyVaiOQTfGoDAUIn1fiXa9KznJi1g8cy3zo8PZVVHLicZmvigoxlut4upmKw3aNsIH+XO6QscP2mZu/2cEtasKWZEWglbrSXrgQdb6e+JjdeITr8tIOr6Oy0bfhclu45HDm6jr0HP/ofW8MvxKkr0CEUWRb4tPsurkfmyiA0VpOr5qLfUdBu6JG8E1kYnd6llOZ79PnGCmwFjJUYeF172H4HHgBAUqZ2JDL+f4sVfJz/0Sm8SIq4s33k2xCHMMrM5Ts7nIwJdXxpMw6G4O7n8MH98UpG4a2n+4Cz+fZEwN+VjbqtjebxV6Syj3Jvd80J0t+I5otZzA1vU85D6e9IYaqhUeKCnlmOTv+JkjCW4XiZSB1XCAguPf4j5wFp6pNyJ39gU6XdV/yG/ng0xXFJr5DA7z5CZfFWLBevY1+fHwLg+sDpgdreTBVCckAmw+Xsi3rnfzYv+JCML/Y++8o6uotj/+mVtzc5Ob3nsnHUISCCEUASkKgiCiiKgo6LNLU+BZQUQfCvaCKKKIIAgoIr2XQAihhJAe0nsvt8/vjzyCoUZF3+/5+KzFYmXWzDl7zpS75+yz91eCVfwjvFG3laF7XmKoZwwylS1lZ7byrd107qEUmbeJdS5GRjVYc0vhANZG5/D60clEWHXjhT7TyK7tgYVMyj2hKpSy9vFNqzpMTWsZ3jtW0Ig3muBBtJakYc7+kXfuvocTOhlfZbzJiSolie5DcLWS8tFQGw4W6xnk2/mHwlxWheGz70EQkIT4Ie0dhSQiEOFX69ZMGXkYlq9HkhTDh87rCbIN56WEDy+bsVXLFQzzvY21GUvI9NFirk7BhIke0aMwfLWpYz+JtZpb5k1jkPcdV5z5NW45gGn3UUzHzqB4eCyClSWmtHOYdh5BPm08EgdbLsU+PoF78ofyde7H9A4cwY+5X5PgdgvOlu4YtuzHfCYbr4emcurAQ7Qp2uCDb1E8Oh7B5o+98P8MJBKBvk9a3pAZpCs5RwB79+5l7NixDBw4kGPHjvHpp5/y2WefUVlZyfz581m4cCF9+/Zl+PDhrF27lt27d+Pn54eFhQWLFi1i48aNREZG8sADD7Bt2zYaGhpobW3lwQcfRKlUcv/991/VQWptbeXll1+mqKiI119/nQceeIDU1FRmzpyJRCJhzpw5V9QNzcrK4qGHHurYlpGRQUFBAQEBAUC7nEdmZibNzc1oNO1V593d3SkqKurY50qUlZWxbt06Tp061aGF6ubmRnl5Od7e3h1isAcOHLimpIqbmxuzZ89m/fr1NDY2YmFhQXV1NR999BFbt24lJyfnqsdaWVnx1FNPsXnzZnbv3k10dPQVtykUCl555RWOHDnCt99+yz333MOjjz5K9+7dmTFjBgUFBWzfvp1nnnmG4OBgsrKySEtLQ6fTsXDhQtLS0lixYgUDBw68rg1ZWVkEBgYydepUNm/ezIYNG656TbtKlxwkgKqqKurq6tqn2+vrKS0tZd68eezfv/8PGfB3prnCjJXz5Sn9tl7t6596lw0AACAASURBVJBcw2WYRJFlZ7Ppa6NlVmwk1fW25JwT+UmRQxzRHcfUVKfj4XUxa0WhsEahaH9ZqiydsLULZFtBHknufkgFgfq6LMIiJpNZX8XZugreiB9B8/EibFP1nBlt5MjJPSzvPx7lMz7ovyxFuygf5ePeJPR9paMPnbae7VsfYe/u6QwY9A5SqZLnvdywWm1FpU0LK71z2RxezO02QcQXu6FObWVbgIGqvlbEuXkCnphn6FEu0NAtZSTFdjsI6H8rgRHtLwOTKLYXbZx1mMPBtfxU5oLOlMGPBc7cHxLAP7oX8lSKgfgKbyyH1XKmSc6j3bw5X1rIa5VVfK1t5vW0vTQadKwaNJE1uSd5+tBG3ux1G7tKc/ilKJPX4oZiU9eG3NWRguZaujt44Gt9cZ2NobmK6vQN5GVvIFjqw8L+E8jfPA+n0wWsT3yG9XVqvipqJihkHCeOL8XeIQxTuA2y0jyKwp9i694W3KwkbC/Q8WDk/djY+FFddZoaQxtZlWmUVjcQ5T+GSpM3a/PdeMknGbViWKf7wWjUkp/7E7FxMzlx6HVqKo8ytmwY8lqo1RSw3vc5kiXPs0TzFQ93t2J0sBJt/gGqj35J/jf343vvlxQYnXjlQDP1LS2MMawlIXYwkVHtL1mdfTzuX43DvdftHK4uZbDvI0gl8egbShhX/jLzHT7meLmJWDcJKw+9ToVCx1oHCN61kMBh81lZ6IiFRsntJ9byatJe+rmOoFfJIRqVmxiRY00fr+7sKjnJ563PYyG34v6wp1HKLopK/3Tuc6IbzLh1u42Sn+fSnHcAbVUmdlF34uIRyDCgUjuWDTlf0cdtMIIgYCkXGOJ3eVjJlHyKvDAFsqQYrM9UYP3dj8j3uSG/ZwQSB1uU5TUYfjmK4OvBzsJNnJOdZOmANRfV1du0IJEgKNsdL2vBithqD3YHpaEsKyLGORHL2IGQEAdSCQgCujeXY047hzQu4rJn2ZxbhGlvCvIpd2Lccwz9u18ju30AhtVbkI0ehDTQ+6rvh6EjZ7N70xHe3f40aZIsXg99B8NPezHtS0ExbTxKf0+sTnpSFeeAzz4z+pU/onzi3qu2959EbiHAnxgemzp1Kh999BHLli2jf//+FBcX8/zz7UU8JRIJMpmMkydPkpKSQnFxMQkJCQAdSvTl5eX4+voCdMhVqdVqbG3bnVe9Xn/Vvn+tPl9dXU1YWBiLFy/G19eXjRs38uWXXwJX1g29npZoV7f9GhcXF6RS6VX30+v1LFy4kF69ehEfH3/Vdi5dqF9ZWdkxXoGBgde04UJSgFKpRKfTXXXbpWOnVCr54osv2Lx5M9nZ2eh0OmbNmsUnn3xCcXExDz/8MM3NzaSnp/P8889jMpmwsbnyTPml/ZWUlLB//37y8vLQarWEhf22RKEr0SUH6csvv2Tx4sU4OTlRVVWFnZ0dWq2Wu++++w8b8HemqcLcKbx2ARsPKeVnjADsKCqluk3L0PI32V5jQ6jtCnBScKCxAr3JhEIqxWw2UFuTcZny+q9xdOvDifMCC8JdaW0pR69vws4umJXZZ+jj4ourpTXVB0WkPawZd4sfK7d+wZHKQhJcfFBM8cCwoRLd4gIUUzyQxbbfkEoLWwYN+ZDtvzzM3t3TkUqUuOwMpkkTwtReZ3gwNJY5dmHMSt7Mbff25L7th1DLZayOvujISZwUWDzri823NahWadDuyEY+1AlZkh1SQaAxoxJNoxWf29XQ1zWQHwtaaGtr4/F9h2gQW9nW/X18y32R9Z6FcGwLB4re41bP20it0TJ++wokUiXL+9+FjcKCR0J7IQgCTx3aiLulhuX9xxNk40hGYwahju50d7z4QmgpSqHq8Ke0FqVS6mCF2sKJHnetRRCkmA3BNNikk2fthLbBwOJTWhaOfAhfv2GIJWcpy30d1eQZvHmojUkRKmyVAt9nankwUoWnV388vfpT22Zm9u5a6psqEXIraZUHMsy1EfcTr1IpycMp8bGOF1xhwXYkEjni8Q04iGqaVWoUZhuUr06m8uhSAoqLmVJ6kl3jovj4RCv7iw28ObAfvv6JFG2cyal1c5lv/RY9nYzcVnA/gcPnUmJsD8+aRTO7m46z0l+KY+1BhvkNZcHRp5gV9xZux7cR5O7MeH8Vbx9rZm7vInYZDvJSywMsl6xnVdtOBm7xY6fiTl5VneO9qP3YWbkwNWoOom8Fhm0HkOksUd55BwHHvqLk8Edk9x3MB2mv4G7lQ7BdBOXNhaTVpTHb6RZcb5mJbeRoSn6ei7G5Gu9xF6fvb/e/lx9zvyG9JpUIxytXedbrWvm0+jN2O2cjZq5ElIvQC+xMVrhs+QpXOz98ss3Q7xasEnqxcs8SJjtPxcnS7WIby9YjKGQoprVn3IpF5QwsD2Sxy0FUrWoejHiu/br8KnwnTYjGuP84ktjwzlp/Wh2Gb39G2j8WaXggkhBfDKs2Y/hyA9I+3ZEl9rjq8wogs7RkWtQcZmc/S3CzKz4fHsLs5Yp88h1IAtpDeB4efSmrOELg+BfRvf4p5vxiJH6e12z370hhYWFHSGv48OGEhITwxhtvYDQaKS0tZf/+/chkMp5//nk+//zzjuMuXK8LoSSAjRs30qtXry73fan6fEFBATJZ+0+nWq3GYDAQFhbG2bNn6dGjB2fOnOmQJ8nIyMDZ2ZkzZ85w3333ERgYSE5ODoGBgWRlZTFlyhRsbGxoaGjA2tqa8vJyvLy8rmrLr8/J39+f/Px8AEpKSvDy8movBTJ3LpMmTSIqKqpL53dBXcDe3p7q6moA8vLyujw+1+LSsVuxYgW33nor/fr1Y9q0aYii2BESbWtrY8qUKcyePZuePXsyZ84cmpubaWlpoaCg4Lp9eXp6MnjwYCZPnnzDpNC65CB9/fXX/Pzzz3h5eTF8+HC2bNnCDz/8QFtb2x824O9Mc4UZx8DLM81sPCVk7zSj15tZnpFDXzsDGq0CR6dIzidX4NnTAVOjyM7iMob7eFJfl4vJpMfe4eqF+CpVPRHFahwsTHx+9iBtqmBqRAW/FJ3jlZ63YspvQ5UH8ldccLBQcrtPGF9lHSfBxQdBIqC40wWJoxzdZ8WYUhqR3+mMxFmJytKJW279iH27Z+Bh7I1XdSKPJBzlo3530t3RHbMo4qRSc6Qyn39EhOBtrcbmkvi5xEeF/cw4tqyeSHfzI9ivNmIu1iK/25WKbdnkuLYxpFso06P7IzftYWdZPem1EuyFPcRIHPCesphV51JIcvUnUiNwsjYZmTKPNmMic6OG46G++IXxcLd4Qm2dCbdzwfaSCtC/pnz3YpT2vmh730l1zkb6psehT/8IwdIC6xZP6p2Pk1vdwkNCOV+3eLKrSGCAnZy8nYtwHTiDZeedsFIYmRyhotkg8t7xVs7VmAh1bH+kvk5vwyjKmBTjT3GFkYKCb5kQnIRr6AcU/vA0co0rdlHtU/LZWevwdOiOLv0wEaOX8MueaWgHBCFViuRU/EJc3AwkyzMZIamiz+0ePLm9kTl7m3hjgDVOwxfwz+/P4aLLYmLVamSe4VgHDoRz5wDYfn49K8++y93uYwg8vJmQIY/hrHLjjeRnGV8GI0ev5AF7S7bk6Xjj0DYGVgUROWkqT77XwuygdaTVdCfGMo0vda/grvFiVtxi5FIF2Hkh8QrFdPAEAI5x92Nqq0d5+Aeqeg7gXymzebv/t2w8thBvvZSet84DwMIpCL+JX2PSNiBTXQw92Vs40c9zOCsz3qWHUwK1uiraDC0E20US5RSPpcyKN/c9SaOmkrcSV+JjF0yjvp46XTUVLSWUZhyjNC+V7d4NrDAtQnpQRrjZm4EFnhDb3oe5oATxfAmiIGDKKUQa6I05v5hITTQ2yrPUaqs7yYBcQJbQHd3OZMTzpQi+Hh3bjRt2gUKObHh78oogkyG/bxTmnrlIQvwua+dKBIX1Z2rtFHzt3VHeNgRB07mWlbtnIvv3zMbczxJJTBjGXckopvzvOUhFRUV8+umn2NraMnz4cCwsLJg1axYNDQ3cddddBAcH89lnn/HSSy/h6enJli1b8PS8OE6DBw/mhRde4KmnnkKpVF4z9HQpFhYWLFiwgJycHB5//HGcnJyYN28elpaWaLVaXnvtNTQazWW6oTExMcybN4+1a9fi7e1NeHg4TzzxBAsWLEAul5OUlISjoyPPPPMMzz77LFKplAceeAC5/NoZzhfQaDQMGzaMqVOnIooiM2fOZN++fRw/fpyWlhYAYmNjO8J8VyMgIIC5c+fSo0cPFApFxxqhG+FgaLVa5s+fT3Z2Ni+99BLZ2dksW7aMXbt2ERAQwIoVKzr+VyqVjBgxgujoaDZt2sQLL7xATU0Njz32WJf6Gjx4MPPmzes4bs6cOdjZXTkrt6t0SYvtglMEMHToULZu3Qr859MO/z9rsZn0IrvfbCX+YQs0rp1rHplNInveakV/SxP/KjvFdNsUrMR6eoQv4Mgnehp9pnDM7wn0KFncN47szO/JPLeG2+9Yc9X+Xj16gtz87aicXclraqDNZESLFGcLNRuHPoh5YxVN6dU4zGtfx1Tc0sDYbV+xfMB4wu3a17DsLc3l4537+KgqCUWWDll/e+TDHRFs5YhmEd3reZQ46njC5zA/D3uo4wH6IvMY24oymV+xDdvQYTjEXDkMkJu9kdTjSxgV+z2mj6uReFnQllHPvxJO8/Kke5BLpBwq3cGS1I+oa7mNVnkev4yYjkqhYdjPn/NCj4EM8ggCoKUig6Xb7qPUzoY3+67A0vbKX10HivVQnU/f7iEd24yttWR9NARtwjiy8n4kMa8fbkMmINhYI9Y3IfFypTB3PfcV381y50KO5zez0i6c1w3/pF7lz3GPaWzK0fHJMBtCbAXEilpmpgk4qbRorD6jh8c45u5x5/UB1vR2b3cW9++djVyuplfCP6k7vpbKIx8Q+OA6mvR1/LxpAtEmd5xDRmDXGMH24gV4xd2JXKHmXMa3jBqzAePXP4NMiuLe26hqNfHEtkb8bKVYKSScqtAxp+5plE15BExeg8LWk4yMDPyDfHls5x2MDXqIEb53kfP5Hdh1H4+uKpudFTvY4KAnzCGGwd6j2ZJrx9ESC9apS7EffTvGrQf5V+lpNstH4GQ1mTtLfJjw4IfILC+unzLnFqH/ZA3KN55FkEjaw6W73qLq5Hcs87PAXu1Odkse97mNYXjvedd8XgBKmgtYmvoi1gob7JVOyJt0nDPnUdCYBUB3rT9PyiZhd+eoKx4v6g2cy8nGI8CNzLpTBBRbYLnxKMqX/4EglaL/YgPIZQgqJeaSChRPTsSwbB2CmxM/heSTXX+WWXFvXrFt/VcbQZCgmDSy/R46eALjhl0onrkPiYfLdc/t92I0avl+9S0MGLQEZ/zQ/+sLFDMeROJ2cfH/TS22m9woDh48SGJiIqmpqWzYsIFXX331P23Sf5QuzSB5eHjw6quvMnfuXNzc3Pjuu+8ICwujrq7uz7bvv5bmKjOCBKwcL4bYRFHkUHkVBU3NWFnbkHa6jiE93DEWpuASei9VWSIaNwG5hxs+zftY3daT7/POICvPwNUxnKLmFjRyOTbKzjM0RrOZA2XV9LMysam+jhmaCvytHfCImIKAgEwiQXu2Ba33xS8CT7UNgzwC+SorhUW9bqOstZFXUnfQam1gV9827tD6YfihkrYXspH20dDWfAp5mTurYk4TZ20DiEB7e7d5dePjs4c4V1dJaMYvV3WQfP1HcPrYEo6mTiPiuc+pW5KDWWFm/PCeyP8ta9HDOQGzeTZeii/JEMawp6IMe2UDBtFEootvR1tql1CmxC9gVsaLfLV+NLc5DcJt0PPILC+KqrYaRF7c34StzJbIUDM2/66HU52fytuOr+GSd5wnfGZgl1WKND4SQXrRkW0Q70JaZMRGeop+5XvYpprKdOEFDG0q4lvMvB7YSsCOo+jO5EBLG/3s/Vni04MAxR5+yPPDUmHCUaUA2uPgXpIIjmV/TNQOB1T1zSiDXSjf/TZljhocrf2Ql9djHzIW47++wXfwMHLzf8Fo0hIaPgmJRIa0dzSGZesQRw/CydKCpYM1PL69kSa9kU+G2uApfRt9QwkK24tfzZvzv0MuVXCrz50IEil20eOo3LcUhZ0Pd9+xikFKgR3nN/BF+tvUa41gWk1GiB+JgBAbzun1zvRwyeSB6tuJdArv5BwBCC4OYDQh1jQgOLUXM3QbNAuH2Ik8evJr5teuQSqRMih2xjWflQt4WPnyZr+vADCdycaw4QekcZNoHdOb4vKz+L13EIvnel/1eEEhB0FAo7QjzrU/op0e3feHMGedR3C0xXwmG8Vz9yNYq9Et+BRzeg7m/BLkiT0YE3RtXUlZUk/0H6xGHDUAU3ouxg07kd9/x5/qHAHIZBa4uMVSWnwQ17h4JGEBGHcfRXHvbdc/+Ca/ic8//7wjDHeBu+66qyNc9lexbt06Tp482WnbkCFDSEq6fHbzepjNZq5UC3rWrFlYWVldtn337t2sXbuW1tZWZs6cyeLFizvK+VzgkUceuW4Y8O9ClxykRYsW8dFHHyGVSnnuueeYOXMmdXV1V0wfvEk7TRVm1I4Ckn9n8rQYDLyWcork8mq8rNQkWkkJ1zkQ5dnKsdMFuLrFk7HfhEuYDE3oE2zbMgedIoq3Tx7DAgue9vZl3s6D9HN34cW46E59Ha+qQW8206hywM9QjkXjWex9puBm2b4YWmwxYT7fRlvfzlOmk4N7cv/u78hrrGH+iZ1EO7jhorImpaqYO+MjkXRTYzrbTMs3KSiqfGgMPcDetkYmFiVTULwF91tfRGnvg/TcT0S3lZESMRG/40upqC1mSc5p4pw8udOv/eUimgyUbXkJx2Yjey3NvHz0SxS9tcSqanjNuf2r3Who4+Sxt3HWi5QpmhlkJ2XpmQNE2buR5OqPhazz1LNLyDCmWctYmjqP2OYSDOufwnf8p0gU7T/kR0rblemtZWZe2NPEO4M1GE0is085kC91ocYiCLusU0ijQzo5RwDndda4ywupSXsXpcKeWe75pLt2Y2CADbbpGRjW/IIYEYh83K1IuvlRkfERxjMJDKyaxae28cS6reP5A8uZn/gZwUYvHDcUYYoyUtfPAVebW3D4rpmCtl/Iq5fh26rAsfdjnN3xPR4eVvgm3MGJ71eiUFgTEHgHAJJAbwQbK0zH05El9cTVSsonQ22o05qobNvPh9nLaTU0M1vzL7w1AbSZWlhf8AUPR8xsD4kBdtFjEU167GPuQaq0xgOYHP4M94Y+Tvba5fwsVrK62JfEUNjTpKLawpp3K3WoT5uRPtudSxGsLMHKErGiGpwuTmUrbDwI6zeb5zc50lxaiKyyEdwtLjv+WpiOpSMJ8cOUmY9qjZFgJzvMHq5IPJyvf/AF+5QKJOGBmE5kICjkSIK8OxwaaVJPDGu3gU6H5Fdhs6u25euB4OaIfsUmxKIy5JNGIY0M+k3n9Hvx8OhL5rnviIl7Ftmg3ujfX4U4rC+C/ZUXr97k9zFlypT/tAkAjB07lrFjx96QtiQSyW+aBZo3r/NM7/Tp02+IHf+tdKn6WlFRUcfARUVFsXXrVo4ePcrEiRP/VOP+m7mQwQaQ39jMQ7sOUdDYzPxePVgxOJExvTxwalYjbTyDpdoVmdGDpnIzTt2kzE0/yT7LBNyk1XS3C8bG2MBbBUqkgsDZ2noATJktmM+3rwHbX1pJTyd7DjcbiGhJoamxCFv74A5bTJktoJZiuKSmYIitM3HOnjx2YD0Vbc28FDOEeCcvUqqKO9KZa2q+oNzjNSQzLWh4cAxNEgtGjX8XudqRvJX3UL7rLSr2LuHOkN7sbmrmmGM0Ew9s4FhVET8UnAHAbGijaON02spOkd1zBpssk5CJKfS1O8fzg/8JQEtzGVs2T6Si5AhuTVE0ts6hr6EAd0sN+8vzudXzyj9GCW6DiHSKZ7OXNWazgaIfZyGaDADsPq8nyUvB44EN1GrNvHawmae319Jo1OGqnk2V1p5nLdZyNvjyDJa8ehMh7s4ETtmIJ+MJ0kQyLsIOB5UE09HTSJN6orj/DqTRIRyp2c/2om+IczPzmW08EcZ6Xk+axmDv0Sw7/SaGlNPIfX3w8OlPsSIbaY9QLG+9nSapAzKdDjusqT5WyqsWy/kxrhJLtTPePoMIi3wAubzd2RMkAtLeUZgOn+zIjKlsO8l7J+9lSeo8wh1iCLaL5IUDD3KqKpl9dT9hb+FMkufwjnOSKq1xSpiKVNk5VVzWZsT/eDMTYuw4WWkkvdrA8lNt3OWkQ33qLIKXKxJP1yuOv+Bsj1hRe9l2c2klwftqiZVFon9nJcadRxBNZkSdHnNVLWJD0xXbAxBb2jCfzUE2JAHF4/diPl+KafthpL26tuj010hjQjGfzsJ09AzSgRczemQD48FgRHB1QrC8vvMmCAKyfrGIhaXI7xuJNCr4usfcKNw9+9LYkE9zUwkSXw8EXw+M+1L+sv5vcpP/VbrkIN2IUuH/azRVmLF2kVLR2saUXQdxV1vyRkJPEt2dEQQBKxfwLqqmZLcCZ7sBVJ4zYe0qIVVXyJnaclYkDie+ZQuna+owiz5IJCLOVi0UNbfSlFyL7p0C9Gvb61ClVdcilWpxtLAiXGlEEKSd5AnMGc1IQ9VwhUV3DwTH0mTQsSB2GLZKFTGOHtTp28htqqXm+CpqT6zGa8wSLIIDOFxZSJidMw527niOXITHiPk0Zm3HMe5+BvcYhUqm4GNNFKPMtXycNJZz9VVUa1so3/km+oYSfCd8zvrKYjSSE4xXwZ1ncpA11QDtC5VlMkt8bW/nkPwVdMaBpBbrmB4WQ29nb3o7eyOKIm1tNZ3sFwSBqZHPk16XRsvAqehr8ind9hptBjOHSnRoKt6nuuA95navJLXcQFNjIQPMM0GejY+iDaVhCPMLXmFp6osYzIaOdvPqjfjbK1DYeiJ4uCAWt4+1WNuAOacQaWz7Wq7qtnLeT3uF+8OfYVyIC0YkTM47DE0t3NvtMSpaS9iVvwFpzzC8fQdTVLgbs9mIKTGUEpsGvFps0ZQH8b7jL9ipHDnW0v7D17f/IsIjHuh0rtK4CMTKWsTzZZyrPclrR54gyjGeT4Zs5oHwZ3mqxyuMDryf1448ycH6LdwX+gRS4fqiyKa0cwg21nhEeDHAW8E/9zVTozUzvq8bqFXXzMaSuDpirqjutE0URQzrdiDpEYri4XHIJ4/CuO84uhfeQffCEvQLl6FbuAxTxpUzZS7YI/h5IHGyQ/n4PUjjI5HG/Pa0XUmIH0ikCE52SIJ9O7YLahWyUQORJkRf/eBL24oNRznvUaTRIdff+QZiZeWOjY0/pSUHAZDfObhLs143uclN/hhdCrENHjyYRx55hP79+19Wk2DkyJF/imH/zYiiSHOlGf9+EjYUFOOiUvFyXHSntUN527PxbzYjPe1FVkUC+QoDvn3kvHQumbF+kfg7hdDXN5StZa3oJBrm94plYdov9C3zR9xWSkG0iM/JFhrr2shtaKLWUMuk4GjcK89TU30GqfRiX6azLciHOQLNl9ka6+TFjtumYilr399WqSLIxpEjBWnE7H0HrzsWY+ne/uV+uPI8CS4X9c00QbdgHTgA4d9SCYviR0D5GRS7XsPf8vn22Z/8NELObsb37s/I1DdSrjVxj9qKMLUL1v7eFP84G//7vqa4aC/eAWNZdDyIEF0JLi1mzjqPZ1TFPt5LfBiAnKz1HD2ykNHjfu4kseFs6U53p94cbzjBxLHvk/ftA2wzLgfjICLstTTWmTi9dyL3qUMR9CXkqETiXfujOVlKmuUQ3h4wkPnJTzH/yJPMinsLS5kVefUmxobIaTE0ofR0wXSmvWiaKfUsgqdLxyLZXwrW4mnty+1+7dWTlw/X4FOoxXQ6G01iD+52nMDqlhUkhb2Ah7obh40vU1F+nOqqU6isXYnW38PKoGMY5Epe6vUuT+4eS0lzAR5WvpddK0FjhSQikKyda3nN7XtG+E3gvtAnOhbLC4LAXcEP46r2Yn/2NuJc+mGuqsN07AwSf8/2MJ3scofJlJKOpGcYgiBwb5iKh7c08HCUCo2VAvH5h+EaMyyCiwPmlPRO28zHzyKWVqKY3L6YWhoRhMTPE3NJJYJGjWBjjenISQzL18OEEUh7dnZ8TCnpnVLqBXsb5BOG83sQZFLko29BcLC9LCtH1vu3zUhdmv7/V+LmkUB52VGCu41H4u4M7l0PNd7kJjf5fXRpBik1NRWtVsvWrVtZs2ZNx7+1a9f+2fb9V9JWL2LSg9pZ4KeCYpLcnTs5R/omPc579OyOqUKl1+MWWIx3LzklHmXkNdQwuSkEc5We7tGPcJtuNdOci+nn7sGXxgjmnnLim5haFoScpkauY+nqXUgEkWZjEyN9QgkxJxDV0KejL3ONHrFSjyRUfUVbq1pNfJiqx2huD9uIRhNxjp4czjuOlX8S1gH9aDE0MWXbKE5UF1Hfmkxa5RFM5vY6ThecI4AoBzcigpMQzUZaS9Lo4+LDnpxkLD27Y+kRzZKTq7CSahnlN5TK8hTcBr+ASdfE+f3vUF+fy3c5UWhFKfPUZYxzM1BgDufIuSOYzSZqqtM5lrwIEKiuzuB4uYHP95ZT1NhuR5xrf46W70UrhUJ3J/bV2dLLqZWkpJfxD3qakWM20M2nJ93UgZy10JNkN5A++ac4bbLESu7LG32/pNnQyLyDD7M5bzv1OpEPTt7PpC0DmGFYxHLlT5ytSsWUkt4xe2QwG9hxfiPDfMcjCAKCIBDsIEcS3Q1zWnua/eB8b2wkGtYUr0QmV+HumUhuzkbOnf2GiOiHyRztwy/GvTwTMx9Paz8CbEI5WrbnqvdW3kAXFtitpn9TOBODH7tiKm6Sx1DGuDyMWFGD/oNVmNNzMHy5Ad0/38OweguiyXTx/qisRTxf2nFO3RxkvDHAGy/s4wAAIABJREFUmglh7SUSBLXqmum+gosDYkVNR9hPbNNh+HEPsmGJnVLWBbUKabAPEldHBJUS2cB4ZHcNxbD6Z4x7UzqOv9SeG4E0LgKJ/393arytbQCNjeevv+NNuswdd9xx3X2Ki4v5xz+uXn/ur6Qr9v5/4kaO3YW2Kisreeutt25Im12hSzNIK1eu/LPt+FtRfLoSUdnCsRoj1Vodt1yyfiNrVSZY6vDqV8l2bS6D9sdiPd/MwtRklub3RvlzFVrLWlRTPRnT+wHs7brR8uUJrA5a8HPwCdKDfPnmlntpKirk1hKBZO9y7uuWgJVciT6zEVW6HvOIeiQOtpgzWhCcFEgcFVB1ua3vH29l53k9Q3yVRBrr0L/7DZFD/dhglGDft33mZk3mZ+hxRymVotNns+jYGtzU3kyNep5u9p1DFBK5BWrvXjTn7aeX7yBezDVjG/8gaZWHOdegZ5RfPK5u0SQfeoU2QyPuQ+aRsuUpSu1Gk9xow8u6hThMfg+Hxma6f5vPcfoxMG8zp9I+xjNgAhvKglh5KACduQHv5ga+LpYxIdySoV5RVLSWsOqn8QS5DqCwJYG7THuB9h9aa2tPevR8iu9P90fqrCCqUINgLeCqlnKgSM/IIEfmJ37G4uMvsCJ9MzJJJNNjn8TZ0o2M8mOcKF7NK4f/wdtNw3Dv0T5bdLR8DybRSB/3wZ3GQBodgn5XMmJdI5zMZsqoR3ktfyE12kpc1CrqMn9Cp7Yjs2orp8+lMCZwcsc4xrsO4Gj5XsYEPdDRnkk0kVK+jx/zVnG2JpXhXqO5b4sDxlU/I594O4L08u8ceU0j+m93Ign1R373MDCZMWefx/DdLwj7U5ENiGtv+3h6eyjL8eIi676eV9eBuhSJiwPoDVDfhGhpgWH1lnZnqG/MdY+VxUciqFUYVv6IuaQC+bhbr2jPTcDK2ovmpmJE0dzpo+Qmfz3/n8VqIyIiOHDgAAsWLGD69OkMHjz4um1UVFTw+eefM2fOnN89Jn8Vzs7OzJw58y/rr0sOkiiKrFq1iu3bt6PT6fj222/ZsGEDSUlJODg4/Nk2/kcRRZGqw59i1rfgOuC5Lh1TcrKNFovNfJciEOPYkyDbi2HJ5pImvI7DiQmWSKtS8I53oKxMT9pbhTxk8iUENRYv+mJKa0L37nm8RyVgOFuFKVeLfvh5DKZ8cmtUiCYDljF2BCU3cvfoICYEBCKaRcx5xaCQY0o+jTC8L8azTe3rj35FW3k65XvepqbvUvYU6pBKivnwRDmvlJZhp1HjeXgV2m6JFCodsG0u5Of81fg6PoenrQ3zwqbQkJbKd6rdzD34MAO9bueh8OlYyi/OFlgHJFGTshJfBIyCjEyVG8tPzUZPH+7w7YmVlTNWVp5UlKcQEDiKZls7TuuSGGDYRWhsQvuMhY0141yMvNI8mL0HJ2DrEMXyugdoMdcw3OoXHrCIRJGyh6MRsXxQ0IMfzpjQWIzEIlSB0nkm8uoGPDPfRxsf12GXriqHE8oWEozxCJsPIRsziH5KBfuL9YwMskAlUzOv17usPtvG7kI9vdzaU7/9bIK55ftm5is38W10DjOs28dzW8E6BnjdhlLaOQQleDgj2Ntg+O4XQCCq50heqHHmROVB0mpSKbAGJ6WUXlY+jAyYSKTjRRvjXfuzOvNj6nW12CrtEUWRRUenc6bmOIO8R/F49xdxU3th9q1D/8G3GL74Admdg5H8O6NJFEXMp7Nx23wIaUwYsrG3IkgEkEiQhgXAqAEYvt+GtHs30FhhSklHNujqqfPXRWMFFsp27bHkUyAIyB8cfVlW4NWQhgciPDMJw5cb0C/9GrFNi2xwwu+352+KtcYbk0lHW2sVluo/t7TA70FsNSHqzX+oDUEhQbC88n1zU6z2ItcSq/3ss89oampi+PBrh6STk5M7xkaj0XDkyBFSUlI4cuQIubm5BAUFsXPnTtatW3fZscXFxcyYMYM+ffpw7tw5Jk2ahJeX1xW3XTp2UVFRzJo1C5VKRW1tLUuWLCE1NbXTtX300Uf59NNPO13fCyUJiouLef3115kzZ85l/SUkJFwmcntBOuX30iUHaeHChRQWFnLfffd1TG/pdDrmzp3Lxx9//IcMgK575F2tMHojMO4/DqJInfIUNcdWIJoM2EXdidLe94r7p1XXsrWwlIfcAzE1OOMxxJdzRXBXw49gjgNpu+1F3+RS69pCYv9ebFybQkzvF/kg0p2X9tdTaKdGPTcQQSND4mmB4GWBflkRekkhbUPP4HrHdPrVVvDu7lRO7lhKSP+nQRTp3dD+gy2WVyG2SpD2SMKYnMwm/2wST4VROrKZHuLFG6Xq0Cc0lZzm7UNV+NllYxYrKKwP52nbfzI8eBjRybkEt/biWF4mpaYNhNolklLdyMMtZnRrP8LCbGLKHcMZnDSWN1NmsaVgLWODHsSUfR7Bxhorv0TKti/A0LiGbqGTef/0NzTrrHFRWRNs0752x8UtloryFDw9+1FkUJIvi2Jy/btYB37QYWfi0FDsvisjXfk4JcZBOFpKmNk9n8yT61DmqxAig4g/k0LAo5YsPbyHVOM0vsluwq+ylSRvFfbWAyj/5XUsbe7B2GSkrGA9WWqYkO+OfNpdSIN8SKow8OzORloNIpby9lBSfoMJf9vOL2qJpyv3Z0bzQtw2ztacwFbpwOnqYzwcOeuye0EQBCTRIZh2JSNNiEaQyejpkkhPl0QAWrV1WFpceYbERxOEo8qVlIp9DPYezc6ijZyuTmHpwDU4W16USpE42aF44h6M67ajf2MZ0n6xSHzcMW4/hFhZS2OkP67jbr0sPCaJCUNy5BSGTbuR9ekOjS3tztLvRBAEBBcHjD/uQRofiWzMoA6ds64icXVE8cwkDGu2Ip7N/UP2/F1RqRyRyixoair6f+cgiSaRtuezoO2POUioJKje6YYgvTyke1Os9iLXEquF9sLO1xKavcCFsUlOTgbaM9TfeOMNvv/+e86cOdNREPpKmEwmnnrqKdLS0vjhhx945JFHrrjt0rF7+eWXGTduHElJSbzzzjscP36cffv2dVzbrKwsKioqOHbsWKfrO2vW5e/ZS/tTqVSXidxe0Ov7vXTJQdqxYwc7duxAIpGwePFiAO6++25WrFjxhzr/NV3xyG+77fLiaBkZGb+rP61We9VjBaMRr5/30WCdQ73qOMROh/yfyd22BCF6GqIZzFopxpIsJNV7OBF8B59VNCEXwJQiEq3QcVRvh5W0GYfmk8xb/xOhblEknG7DLVfKuTFmTp3Yjk7XwPJz3uQqZLwbWk+xgwtPl2RDyb8NUYAQ/S5mmQGCnqX+3DlEUUQjETmZf4a8lnexcuxHRGotGXb1WJ8swE7bG/NBBaLYC+vvUrDWWfFhy4tY71jOcJuJiEcKIP8Qe73mUKc1oVIuYKTTHJbXevNo63h+Ejawy1+KY5uBXWePUGt9Gn3bCKz07ri36ikbHo9lXhnSkxnonWLppozh2Pn9hBl747FmF2YLBWUjE9nv0JdtyhCq6/wxmftjKTMQalvJuX9LYJhM7pQUf4fZvIYcRhBoqsDd3Z/c0gYovViYbKiyla/Mg4mSaHnEowpdk5TWlnLainKpGTkYh4pqig99Tx91Ibf4xfJO3gmKG+5nuH01Rl0MbeVvIilfQF6mhEO2zWgclMgGjSHL2AoZGchFsJA48v3RfOLs2wUW08vs6O2gJSOjqMMOG4UED4Mj8dYD+SDlNfxVofioQmgu1pHB5feRwkaBB1DkaIXuivdZ+VXvzUBlFLuyN6Oud2RZ4VuMcLyXmvMN1NBw+c5JEaj8nLE/ko5s7zEaw/1oGBBNqyBS/++xvhR5jwA81u+lrbAUo7cz+efzr2pLV7AMckfwd6Ul0APycn9/Q7GBSKJ8MP8Be671XP+3o5A7k5V5lNq6zjPC/+lzFqQCqjeCb8wM0hWcI7gpVvtrridW21UunV2pq6vriAgFBV27xtcfEavduXMne/fuJSMjg8jIyE7XduzYsfj7+192fbtiQ0lJSZdEbn8LXXKQFAoFbW1tqNXqjoui1WrpgkpJl+mKR34lB+n3yoVcqzy/8chJGpTF1CuO4tH/JRqDwjhv34L9tg9R+8wja5eqvZA0rpiERNYpU4nzVHCg+hz+dbHssisku1FLf29P1DWvcKzMhb5bdWiqJbzQXUmAnR8tusMUW03mYK0N77lWUH+2gFccAgkOcUYqaR9jk66ZzC2p+N2zHJVbRId93etaydeMx6ryBGrb8yRkemF7pxVCmj2iSg4vd2PryrcIPR+BNNKaN0d8w+dn/sUX5Qt53hyDLHAkm7X9iZK+T4tMzn32IfyQ2YbEvz9PHl9DRv+xrCo9SpkxCYl4O70d4kmtCuZ5Gxhva8Gk7kXIf9qFQ7duNFUM4r0TLxHs7oGhoQVzUxuHyzR8LZuLkyKHJCdvdpSfpdnsRGplDz6XKXgk2pIePo4U5H1Iffk2zvEGU2OcCItcfNm18PHR4/jhDm4L9kYZHoEohpCVbkGDvRb/vr0xW1jTfOwnfMIG0j1mEBvqljIuKIgBZf40JGfxbf9u5JqK0EuMtJpExviNJ+ySyrhDmpvZXiFnTJwGtVygPK2WPiEOhLpenLEUvX0Re/fgMQ8rHt85mkP1W3k65jVCPa9+/5l9/fDzdPnNLzKD4xgWHH2GLc0rCXWIZlKvf1y7jbAwxEH9wGjEUqnAlevLTxhqWhF2H8VqzGAcQq+t3H1d/kTJnt/Kny0h9J+kqjwQKyvDZef3e6RGbjSCpfSq4bEbwU2x2otcS6z2t/Dr7FdRFLGxselQx8jN/QMfOr/i0rHbsGEDISEh3HPPPbz66quIotjp2k6YMIH333+fwMDATte3K3h6el4mcvtH6ZKDdPvttzNhwgTGjh1Lc3Mz33zzDZs2bfrdq+qXLVvGgQMHOv6OjY3tskf+ZyOKIqZ9x2l0LcG2KRp1mwdf5XzFrqJN3O7ljec+E+cDCrjF/AXfI6Kq+gdTSz3YIl3FffYDcTBYcN6xgoo2iBTMnD6j4K3yEvybBN7uWYLEN4BGvTPbCkNoFWN4JtaSoB1ptIQ40maWkZddSVBI+xR6a1EKEqUaC5fOL78IBzt2FGux9RxMlIcZSaYlbR+mo6oN5ttb7fl5ZxV4/sii8maUk/pjYaFhRs83eH7bRFbUHcDN4Xs8WlqoUu9gQIUBQ+Y2ujv3YH92Hn36P0tUz3tJDClh6r51TAzsy7ozfjwUqSTcScaSY61s1Tnxpl5GcH0T3eyiaDY0UpR1FJWNHYtChnCuRMDGah7/GvQc/jaeZGzbRZOhgI8TI1h5RssT2xt4b4gd1hofTjfao5VaMzjkyunTlpYKRkXaYNpzFDEuHEGQYGt2ptGrvZAlkYHUnC4nuK3dEYlz6Udy+kbCDvqxaMBxFGprBiknEuQbglpmTbD95bIBj8WoeWp7Ay/saeK5eDVaE/hdEmIT1CoEP080wMRuj/N99uckuA265r0k8bpyccXrEebQA7lETm59BksHrunSvS9IJSDtemhLdmsfBGtLJN26Jqp6k/881hovmhqLrr/j35CbYrWXcyWxWoPBwNNPP01eXh779u3j1KlTPPfctdfOenl5ceDAARITE4mNjWXGjBn4+PjckN/cS8dOIpHw1ltvkZmZiaOjI1999RVjx47tuLZ9+vTBxcWFsLCwTte3W7frh92vJHLr4vLHwtFdEqsF2LBhA3v27KGpqQlnZ2cGDRrUpRXyXeH06dPIZDJCQ0PZsWMHaWlpeHp6YjKZmDhxIu+//z7BwcEdU6MX+DPEak3Z59F99i0Fbj/g6TYNixZbZvqvxkcTSN0ZObGlj7MoeA2vV23jVYdJDJHXEJMxlEN2JXTXVmFhsmfg47346suDDMq0wq3Zihq3ZjLCv+FleSBLipT0fOhe1m4cQVSfxYTahqCb/wmK2VOYtLWFcRY1jBnfXpivbMcbmNrq8By5qPN5V9bw7IFjSCUCb/SOIXJZJZyHButU7o0dgVlsJdI5i1dO76FWfhT7xAewixzN0XXP8Y6ymLLmz3lI+wPbnL5gTo4atVHNXk0o6+2fYuPd7p0ejI9PtLCnUM+K221RSgUMJpEZu5vwzDzLcwkapDFhPLHrTm6rj2Fzyz3o7e25PXMJ64L38MVtu6GyjuUb19BqNvJ432FIwgNZmtLKjgIdU01LWK/rToDPAP45wJ6rIba0oXvtY+T3j0IS7Evy+5MwBNiTNPJ9amsz2fLjvYxufhKLxN6cPLCGRR4/olHa4WUfzMzYNynIPn/dL+w6rZnHtjYgitBmFNk07ur2AOhNOhRS5TX3+SP8mLcKZ5UbvdwG/q7j/84zKdfi73zeOVnryTz3HbeN+q7T9ptitTe5UVwQq62oqGDOnDmdZuP+F+nSDNLbb7/N8OHDGT169J9iRFc98r8C0/7j6EKVNGllNPhYY/4xh2KnPJ7s/goFB53Z6nAGKc1843UP6qY2pqULbI3eS5/0sUiENrD9AL73ZvwpR9Z6tpAW58QrQ2D/9nI0VpFEmhVU/rQKUdQR7BWJad8p8HCi4vQndNOMI73YwGijCUEmpeX8ERziJnfY1qRvQCFREGpvg9Fsxmhun01SjFZSvnYRK90G4KJuwCR8SHrVC2TZbcO5HGoOLac6eTmatgYcXf5FlSyNE/7bucX5TrzDYyneNJP+sZP5PMuCvHoTAXbtt0VBg5HVGVreHGCN8t9rA+RSgZGBSpaU+fBkfjrSmDBC7buTUlxJmsSWVUkafhLqCa92RkzLxLDmF+6PCELibI9hxSYkkYH8w9ONmioZX1g+RJ3MkmdCr118T1CrkMZHYtx9FJlchm2rHVmGYgAqK1Kx0wQgPVmJofgXQpP6YSnZR4Rzbx7v/k9kkq59jdlZSFh8i4ZHtzbgb3v9x+LPdI4ARvpfWfD3Jv+7WFl70dRU1CEDdJMby99RrBb4TYKz6enpfPPNN5hMJqZNm/b/Zkz+U3TJQdJqtTz++OPI5XKGDx/eEQO+Ubi6urJs2bLLti9duvSG9dEVzDX1mNNzaEiqI79BT33tZpzVLkgFKepyf0ytOqoDcpDrSnDK7cX8LAssdGpkYTWkOyQTURtNgE6FaV8jWB/iK79B9PPS4eAYSo4ykDiNEuW4WylfNRuH4GBkchW61LMYuimpO7kOb19/tqriMKfnYPK1Ql9fhNr3Ygr268nPEOYQw6SwJ/G3scZkFlHLZRChoWZfE9vUkYSpV5Lg4UtGhYTP8ofxTveeKHbl0xoj4ZSFidPmUG5xXcnJljxm+r6FxtqPwEd+QqFxI7i6nuQyAwF2MloNIv9KbqGfl4J4986hm0RPBW9IZKSU6ugLhFiG8oGshkgNeGuknFHkM7LBF8M3m5HdMRBp35j2zK6oEAxrtyIeTGXOoN7MabXDosVMtPP1b0Np/1hMCz/DuO0Q9s7hNDUdxmBoobIiFWePOOSPjkfi4YygVvGhMR4L6bULHF4JD2spHw21QW+6cWvrbnKTG4W1xguTUUtbW3WnSvI3uTH8HcVq4bcJzk6dOrXT3/Hx8VfZ83+DLjlIc+bMYc6cOaSnp7Nz505mzpyJ0Whk+PDhPPnkk3+2jX8ZpgOpCL6enKv/EbnCktraszT62ONrdqfwsIlUhyzuc+2Ny7cROLeoqLdJRiN1YOiOIFL7V2Nh+xVu+0fR4PkD+Ta5iKbxlBmSaTE6UyBxYZghH4mXK9UerTiVOmAurkAsr6IxpAGFnQ9uJT9QaD+EhmP7EQQzCjsfFJr2TIOS5vOcqzuJVJBiOpvLgKp6jAo5osmMIJXwszAcT1MeZa1r6OX6JX0MJ5haFMQ2314Mm1KF+uuNbHZLor+Hjtn9H+VcbW88rdvXn1zoI95dQXKpASeVhA9PtGIhhZf6Wl02TiqZQF8nkZ3VDiTq9AQ3OFEjRnB3gEhlayllrcX0GPoqCqULEp+LmRISFweUT1ycGXnLLNJq6NrXsMTBFklUCOa0c9iOuwVJ7grqajOprEglvvccpD4XJVBUMsvfdf0BPK3/vIWmN7nJH8HS0hmpVElTY+FNB+kmN/kL+E0lWcPDw3n00UeZPn06fn5+fPLJJ3+WXX85YkMTHxaW8O7/tXfncVWX+QLHP2djP+z75oYoKEJquAsKpWmWZWaijjnVrdSariveSW00Hc1M7ZrO1DhTea28TdcwUwIrUytEaTIQMBckUJB9P4BnuX9YzEskxOJAcL7v18vXi3PO7zy/7/Ocn4cvz+9ZemsopZbRI9egUKjJdi5Ae/X3VBQYOepyloGfWVGiUTI76jOS+1VSMMTIuvBM7jzmyaATk1ENd8LZ1YcUhyj8DRdIrzjPexdO46DWYFv0BfprOkpMeXhUeXDtzQ8x9fKkKucI3uOW0NtFgw2NZObXUnP+OPY9hrP/XD3ZpXq+yP8YG6y5UJxOw9sf8juFikczLnLtjfcpuniVJPvBhOrfxMXKiT7OIVjlfsJcx1T++xsd95xy4OHwWaQ6BfDEeB9s1Xbc4TnypjYY5qMhrfAaL52oYXo/G96+1xmPn5mZcld/R44790R3qYD8SzaYTE542afzbXEKPvaBeAdH3JActUStVOBo3fZLUD0+Eqw0aEL74ewSxKWLiTTUl+PpdetVm4Xo6hQKJQ5af2qqLXOgthAdrU09SOXl5Rw5coRPP/2U1NRUwsLCmDBhAmvXrjV3fB3mWvLXfOLpTHmdgvkE4ek3Bk+3O3i3th8Tq8dyRtuAT/lY7L+v5Ku7r2ClSifRJgRnWytyrX/A5tke6FMr0TzkQcMLFaRGzmaiwxmSyot4IyuFqYH9MWTWkJW5B4VCiTbmXjacWUOISwCDipyw7zEMd105PVPPkunTA/ec1yga+QovnajFw1aBizqJ+3ND2NvzW0qWTCbQvT+mymoa//Ehuw5cJMjOjTqnbMI1QWC4RnXOlzww5X4eDnTlSrWBvGojVy/nEejo/rNtEOah5j/vtCMqwBp3u9YTl0g/azQKE1+dreRohS2+ThlcqsqgtP4q4R5tn0J7O5T+3livWYjCSoOra38uXjyAk1NvbH5m0UUhuhvtj+OQhBDm16Y/36Ojo0lMTGTcuHEkJyeza9cuHn74YVxdW5/p01UYSyu48N1ZylQq+hi+56DDNOq35NLj8ydQVT5EkE7FMfdEZuZX85W7DVWmWmJL6ig0WbHfWMrwokaUfaywftQPCq7yiUsfChpU3B8dxUMhozECo1WNeHoNJjPjTTy9Ithr8zlXPPV8RBpb/eo5WXQcbd9Y+hjOk+5sS61Cw9azvjzSA+yvlZFb9xgT71qMt50/5+vOAaBw0pI1/SEOufblKc9SvreuJ6RKT23uCRQKJfaBd2KtUtDLWc3YACsGOv38YmgAKqWCaf1sb5kcwfXB2lG2NSSUWHPc2ptRPtVklv2L70pOmi1BAlBYXR907eLaH4O+XnqPhEXRagOorsrv7DCEsAhtSpCOHz/OX//6V6ZNm9a0mNTu3bt56KGHzB1fh9AnfcWp3l446xvw12kZdS6MylwdqjprllzIRW9fgu01JcMLjFSMVfFVwzjuNgzDVlnDxfpqRlQpMOZeXxBrf3olW/1H8seRDrjYKJkcFsvv7cD79G58/Uah19ehc/Hnk9wPWNj/WRZdNDLKfyKbTi3jX2WphAd6crbBlf/zisdBBb/7eDehNS9jMA7mM2UfglwGcL7iDAANBhMbT9Uzvb8txshG1EoNPj+cozL7Exx6j0GhMu/WLHcFaviXlTsuhnpiQ/pyvuIMtY1VN+wtZi6ubtfXxZAESVgSB8cAqqt/6OwwhLAIbUqQtFoter2e5ORk5s+fz5QpU8jMzOSpp54yd3xmsTPza76vqwDAWFiC8dQZvnQFoyEYagbxuxwTm0P1HInOYVCxI+dVedx3qSeVdjUM8fkGJ4r4JmASo7z9UNJIsIsLpkuX+eBsPVurvXjeqYC7e12fBm6tUvMfY+diqCrA8ZoSA3Cg/Esm95qBR+4ZXAOHMyd8GaN9J/Dl5WQih4yiTunIcdNQ/niPD6p77iTDO52ZA4rZnlaLRjGG8xWZALyVrkNvhMcj7DhReISh3mNRoaQq+xMc+443ezuGD/DEs6GGCcpS+rqGYKW0JsglFHtN69P224OzS1+8fSLx9jVfb5UQvzWOPy4W2Z67GAghWnbLMUinT59m3759HD16lMjISFJSUjh58iSqNu7W/VtUWFfNuaoq7gf0SV/SGBrAmXobNHoPnrxQi/VoZ8r8c8k4589AV3seyjZgb1SiCs7js9TXiLo2kwMO09gZPo3LFU+SHNgH1x96sr2klpW5Rxj3yI2/tFW2TrgNnU3lNx9wLWIqxrJUpjpFUfT5YnzvXgnAMJ9oXvt2DQsjVtHH/irRPWzo567hWFANmnRrHhs0AL2hkb1ZkSgVXrzxbTV7zjSyaZwWK5WRk4Vf8OSg/8I+oJbavFM49Lp5EHZ7UznYsa3qa1yH9kOj1BDiGkGI2x1mPy+AWm1DzN2/fqNkIboSB20Aen0d9fVl2Nq6dXY4QnRrrfYgTZ06lb/85S9ERkZy8OBBNmzYgEql6tLJEcAo7558V1OCoaySwtzdfGh4D4PRlVm51VwzKbg0Qc320XcyusKZA/3OUOBcgpW/LQWT6qm3ucYsVy+KdCbOl1vx+9CZ7DOmsk3dh9/7NzKq6gcUPXxvOqfr4DgyTcUcyt/PbPsxXP3gGVwGPYg2+Pp2FREeI2g0NJBZ9i923e/LvMHXv/w++yGBMX4TUSs1LBhiz7v32WKjOUxSTh2T+lgT6WtFdtm36PR13OE5EucBU3AJfwilxrZD2tL/qQewGxUOwPLIzUzrO69DziuEJbKz80Kp1MhAbSE6QKsJko2NDQaDgYaGBozG6zs1d4cVXHubyqgyNJK+P+PKAAAQt0lEQVSW9D9U2eWS7hSCrULLyFId6YPr2fL9cfLOVKAxWHPYMZevQreheMad777bSdjQp/GZeR/je1qTcK6BMf73UKd/AgXlTMs5ibKHLwrNzR1zF+py2OPZwN2lCjxOHsBv0ot4RT2HQnH9I7BR2xLuOZwTBUdQ/7hZbU7l95wuPsGEnv8e6+WntSfY/RSP33GM5cOvr1F0JO8g4R7DsFXb4djvLryjW997pz0pbK1R/Ljbsq3ars0rVwshbp9SqcJB60eNhe7JJkRHajVBeu+991i6dCnnzp1j6tSpLF68GL1ej8Fg6Kj4zKK2+Du89UXsNZyi0MubXGUPbBtc6FGnYOzoUOpz1Vz6xIpUz6/o7+GOq7GAr0+tRqWyoW+/6QBM7WvNsbxGjufpKddFoXHYRG3maZRBgTedL786hxdP/IGJPaczJWAavWa9jWPwzfvYDfOOJrXw86bxBR+ef4tI72gCtL1vOK6vc2jTOKTLNbl8nvcRDwQ92s6tJIT4LdJqA6iqkoHaQpjbLQdp9+3bl2XLlpGYmMh9993H2LFjGTt2LIsXL+bgwYMdEWO7K0iPYk5uHBXGAVTZ2XBF0Zt+5SoaraG+woG43PF85p5Kktsl4oIG4+rWn8v5R4kYshDVjzPDBrir6emkYtWxGqb2tSFAXcaBgGyUfW7c36ayoZw1KQsY7DmSuQMX4xMbj7VbyzuoD/UaS6muiJyqsxTW5nP8ShIP9n30puOCnP89k+2d7B0M9hxJaAeN/RFCdC6tY6AsFilEB2jzMsZKpZKoqCi2bt3KoUOHGDJkCG+//XbT6zk5OWYJ0Byye73DNcVVpv3wOM7anfjV+hBT3ECNnYrMxDo+DdjAlx4ZuNo4EOXbGx/fEbh7hBPY466mMhQKBTNCbPC0V/JkhB1x7nEc8j/LJZeapmNMJhN//e7PuNh4sDBiNUpF683tZO1Cf7cIThR8TsKF3YS63kGwy82bAvZxDuWH6oucKU0j5cqnzApZ2H6NI4T4TfP1G4WTc+9bHyiE+FXatJJ2c46OjsTFxREX9+99tRYsWNBlepR6luXxfz2W4KL7MxPShvGYvhf9qwr4wbWIkjGnWDUinnOV1RhMRlQKJWHh/8HAQY/dNP5qUh8b7u5ljVqp4M7hM4hOyeDlb1fw8tg92GkcOH4libSrx3gl+t02j80Z5h3NwZz/pby+mPjIzS0e08sxGCUKtqT9kaiAyfRwDPrVbSKE6Bp8fIfj4zv81gcKIX6V29qLrTVdaV2OiBJfajRg6FXJy0Ff81JABU6NDXwc+Dr3DpuMvUZLhLsvQzz8gesDI1UqqxbL+mlAtUKt5rERq7FW2bLj9FrK6ot5/bsNzA5ZiJ9DzzbHFukdzdW6fPwcehLhMaLFYzQqK3o49qWysZxH+j15e5UXQgghxC39oh6klnSl2W0Bkb8jMP8c58pV6EwwoFaF0mTCOsgJJ+tfvq+XtcqGpUNfYsnRWZw7Po9Axz5M7j3ztsrwtvdnqNcY7u7xYKttOsr3LoaZxuFpd/OSAkIIIYT4ddotQepKVIOCqbl8D1WNJkxGFWE1NVx2vkxkQPSvLtvXIZCFEat5/bsNPBPxwi3HHbXkj8O23fKYB1oYvC2EEEKI9mGRCdLRK1fJqvXEWf0GBtYztLaRTKdMxvvMbZfyR/rGMtxn/C9KjoQQQgjR+SzyN/iXBUXc7eaIj109KoOWvmV66nrocbZpv6X7JTkSQgghuq52+y3eu3fXmXYaHxLKdHcXBrnHYFupwaFejXdY14lfCCGEEObV6i22lStX3rKAtWvXArB9+/Y2nzQhIYEtW7awc+dOQkJCMJlMrFixAp1Oh16vZ/369Wg0GuLj41EoFKhUKjZu3IhG0z7bWDT+zxX8zsGg6BhKq3QU2RYzODiqXcoWQgghRNfXaoLk5eVllpNqNBqGD//3Oh5ffPEF7u7uLFmyhISEBPbu3Yu9vT0jRoxg5syZ7Nixg6SkJCZPntwu57ea60fp7iqGfGRNqKKGnMBietp4tEvZQgghhOj6Wk2QFi5sfYXmjRs3/qKTTpo0iaNHjzY9Pnv2LCEhIQCEhoZy5MgRtFotDz74YNNzp06dajFBysrK+kUx1A9pZLeLGxHpRSiDTb+4nK6kvr7eIurZnCXW2xLrDJZZb0ussxAdoU2z2AoKCtixYwd5eXkYjUYA6urqKCwsZPny5a2+929/+xvHjx9vejx69Ggef/zxG45RKBQ3LDT50/o/LT3X3E+J1e3Kysrior0TPWd4MCNk6C8qo6vJysr6xe3VlVlivS2xzmCZ9b7dOqelpZkxGiG6jzYN0l62bBkGg4H77ruPnJwcpkyZgqOjIzt27Ljlex9//HHefPPNpn/NkyO4nuRkZl7fnf7MmTOEhYURGhra9FxGRgZhYTfvSfZrGE1wsUJPb2dVu5YrhBBCiK6vTT1IRUVF7N69G4A33niD6dOnExsby5IlS9i1a9dtnfDq1av86U9/IjMzk8uXLxMTE8PcuXM5dOgQzzzzDEqlknXr1qFSqYiPjyclJQUHBwfmz59/+7VrRWmjEp0eglwscikoIYQQQrSiTdmBSqWiqKgIT09PlEollZWVuLi4kJ+ff9sn9PLyarHnaf369Tc9t23brVeU/qXydWpcbRS42Mh6RUIIIYS4UZsSpHnz5nHXXXeRlpbGuHHjmDVrFn5+fjg5OZk7PrPJr1PTR3qPhBBCCNGCNmUI06dPJyYmBrVazaJFi+jXrx9lZWXce++95o7PbPJ1aoJ9ZPyREEIIIW7WpgRpxowZTJo0iYkTJ+Ll5cWUKVPMHZfZ5evU3CM9SEIIIYRoQZsG4DzxxBNkZWVx//33ExcXx+7duykuLjZ3bGaj05soblARJDPYhBBCCNGCNnWhxMbGEhsbi8Fg4OTJkxw+fJi4uDi8vb2bZrd1JTkVehRADydJkIQQQghxs9uawqVUKtFoNFhZWeHg4EBVVZW54jKrC+UGvG0MWKlaXnxSCCGEEJatTT1IycnJfPrpp3zxxRf4+PgwceJEtmzZQs+ePc0cnnlcqDDgb6vv7DCEEEII8RvVpgTp9ddfZ8KECSxYsICAgABzx2R2OZV6AiVBEkIIIcTPaDVBSk9PJywsjPfff7/F1/fs2cOsWbPMEpg5zRlgh6G4oLPDEEIIIcRvVKtjkJpvRDt79uwbHu/Zs6f9I+oAQ300OGpMtz5QCCGEEBap1QTJZLoxiSgtLW31dSGEEEKI7qDVBEmhUNzWYyGEEEKI7kB2ahVCCCGEaKbVQdoGg4GioqKmW2ktPRZCCCGE6G5aTZByc3OJioq6YazR2LFjm36WW2xCCCGE6I4Upi480jotLa2zQxBCiC5nyJAhnR2CEL95XTpBEkIIIYQwBxmkLYQQQgjRjCRIQgghhBDNSIIkhBBCCNGMJEhCCCGEEM20Os2/O6qrqyM+Ph6FQoFKpWLjxo1oNJrODsssCgsLWblyJba2tuj1el544QVWrVqFlZUVbm5urF69urNDNJu9e/dy4MABNm/ebDF13rhxI3l5eeh0OtavX8+6deu69XV+4cIFXn75Zdzc3KiqqmL58uWsXbu2237WJpOJt956i507d5KcnIxarb7pu6y8vNxirnchzM3iepD27dvHiBEj2LZtG0FBQSQlJXV2SGaTnZ3NggULePXVV/H19eXpp58mLi6OV199lcbGRr799tvODtEsCgsLycjIAOAf//iHRdQ5LS2N2tpatm/fzooVK3j//fe7/XV+7NgxYmJiePHFFwkMDCQ+Pr5bf9aVlZUEBwcTHBwMtPxdZinXuxAdweISpLNnzxISEgJAaGgoWVlZnRyR+URHRxMREUF9fT0XLlzA0dHRIuq+ZcsWnnvuOQC+//57i6hzeno6AKtWreLvf/87ly9f7vb1njp1Krt37+bZZ5/lzJkzqNXqbl1nZ2dnRo4c2fS4pe8yS7nehegIFpcgATesDN7dVwO/evUqy5YtY/ny5SiVym5f9/379zNixAjc3NyanuvudQa4du0avr6+rFmzhoEDB5KQkNDt6/3OO+/w9NNP8+qrrzJixAhSU1O7fZ2ba6m+ltYGQpiLxSVIoaGhZGZmApCRkUFYWFgnR2Q+ZWVlrFmzhtWrV9O/f/8b/qLsrnU/duwYKSkpxMfHc/HiRXJycrp9nQGCg4MxGo0AODo6Mn/+/G5/nVdVVeHs7AyAk5MTdnZ2FvFZ/6Sl7zJL+D8uREexuJW0dTod8fHxGI1GHBwcWLduHUpl98wTN23aREpKCl5eXgDce++97N+/H7VaTWBgIMuWLevkCM1rzpw5bNmyheeff77b19loNLJq1Srq6uqora1l1apVvPTSS936Os/Ly2PDhg04OztTXV3NqlWruvVnnZmZyfbt20lLSyM8PJwpU6Zw+PDhGz7jsrKybt0GQnQki0uQhBBCCCFupXv9SSmEEEII0Q4kQRJCCCGEaEYSJCGEEEKIZiRBEkIIIYRoRhIkIYQQQohmJEESFm/8+PGcOnWK06dPk52d3a5lHzt2jCtXrgCwefNm3n333XYtXwghhHlIgiTEjz744APOnj3brmW++eabTQnS4sWLmTlzZruWL4QQwjzUnR2AEL8FqampJCQk8Nlnn1FWVsajjz7Ka6+9xkcffURjYyMxMTGsWLEClUrFnDlzGDx4MElJSaxbt47AwECWL1/O5cuXaWxsZM6cOcybN4+tW7eSkpLCxYsXWbp0KUePHiUwMJD58+eTnZ3NCy+8QEVFBdbW1ixZsoQxY8Zw4sQJXnnlFSIjIzl8+DANDQ1s2LCByMjIzm4iIYSwKNKDJAQQGRnJoEGDWLp0KfPmzSMhIYHExET++c9/kpycTF5e3g23xzIyMvj4448ZPHgwO3fuxN/fn8TERN566y02b95MQUEBzz33HF5eXmzatIlJkyY1vddoNLJo0SJmz55NYmIiL774IosXL6ampga4vmJyeHg4hw4dIi4ujp07d3Z4ewghhKWTBEmIFnz++edMmzYNrVaLWq1m+vTpJCUlNb0eFRXVtHXH888/z8qVKwEICAjAw8OD/Pz8ny07Pz+fkpISJk+eDEBYWBi+vr6kp6cDYG9vT2xsLAADBgxoukUnhBCi48gtNiFaUF1dza5du9i7dy8ABoMBV1fXptednJyafk5PT2/qNVIqlRQXFzdtHNuSsrIytFrtDTutOzo6UlZWhru7O1qttul5pVLZallCCCHMQxIkIVrg6enJ+PHjmT179i2PXbp0KXPnzmXmzJkoFArGjBnT6vFubm5UVlZiMpmakqSKigrc3NzaJXYhhBC/ntxiE+JHarWa6upqAGJiYkhISECn0wHw3nvvsW/fvhbfV1paysCBA1EoFOzbtw+dTkddXd1NZf7E398fb29vDh48CMA333xDSUkJgwYNMlfVhBBC3CbpQRLiR7GxsWzatIm8vDzi4+M5d+4cDzzwAACBgYGsW7euxff94Q9/YMGCBTg7O/PII48wY8YMVq5cyTvvvMOECRNYtGgRzz77bNPxCoWCV155hdWrV7N9+3ZsbW3Ztm0bdnZ2HVJPIYQQt6YwmUymzg5CCCGEEOK3RG6xCSGEEEI0IwmSEEIIIUQzkiAJIYQQQjQjCZIQQgghRDOSIAkhhBBCNCMJkhBCCCFEM5IgCSGEEEI0IwmSEEIIIUQz/w9rRNZ1CXXtQwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x216 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.figure(figsize=figsize)\n",
        "sns.lineplot(data=data_q4_search, x='Iteration', y='Eval_AverageReturn_Smooth', hue='Config')\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiment 4 with optimal params (HalfCheetah-v2)"
      ],
      "metadata": {
        "id": "GGB9pxfO0fyw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6Vr55Y-9Fo0",
        "outputId": "dd4be383-f806-4cba-a8f0-a3c08aabd7dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "########################\n",
            "logging outputs to  /content/gdrive/My Drive/cs285_f2021/DRL_policy_grads/cs285/scripts/../../data/q4_b50000_r02_HalfCheetah-v2_08-02-2022_07-09-35\n",
            "########################\n",
            "Using GPU id 0\n",
            "Sequential(\n",
            "  (0): Linear(in_features=17, out_features=32, bias=True)\n",
            "  (1): Tanh()\n",
            "  (2): Linear(in_features=32, out_features=32, bias=True)\n",
            "  (3): Tanh()\n",
            "  (4): Linear(in_features=32, out_features=6, bias=True)\n",
            "  (5): Identity()\n",
            ")\n",
            "\n",
            "\n",
            "********** Iteration 0 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -82.24393463134766\n",
            "Eval_StdReturn : 1.7952836751937866\n",
            "Eval_MaxReturn : -79.84308624267578\n",
            "Eval_MinReturn : -84.15956115722656\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -89.52372741699219\n",
            "Train_StdReturn : 37.225181579589844\n",
            "Train_MaxReturn : -5.174495697021484\n",
            "Train_MinReturn : -219.4058380126953\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 50100\n",
            "TimeSinceStart : 65.34275436401367\n",
            "Training Loss : -0.010898959822952747\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 1 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -110.9436264038086\n",
            "Eval_StdReturn : 19.18170928955078\n",
            "Eval_MaxReturn : -84.76646423339844\n",
            "Eval_MinReturn : -130.19451904296875\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -90.09140014648438\n",
            "Train_StdReturn : 36.89088439941406\n",
            "Train_MaxReturn : 20.503734588623047\n",
            "Train_MinReturn : -218.0107421875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 100200\n",
            "TimeSinceStart : 120.4890615940094\n",
            "Training Loss : -0.008969221264123917\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 2 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -89.79686737060547\n",
            "Eval_StdReturn : 38.28302764892578\n",
            "Eval_MaxReturn : -44.33763122558594\n",
            "Eval_MinReturn : -137.99172973632812\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -96.23218536376953\n",
            "Train_StdReturn : 36.021881103515625\n",
            "Train_MaxReturn : 23.66954803466797\n",
            "Train_MinReturn : -203.5848846435547\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 150300\n",
            "TimeSinceStart : 174.81490850448608\n",
            "Training Loss : -0.014853637665510178\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 3 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -130.15724182128906\n",
            "Eval_StdReturn : 11.298761367797852\n",
            "Eval_MaxReturn : -114.40799713134766\n",
            "Eval_MinReturn : -140.36936950683594\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -93.76554107666016\n",
            "Train_StdReturn : 37.76886749267578\n",
            "Train_MaxReturn : 45.76366424560547\n",
            "Train_MinReturn : -214.43267822265625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 200400\n",
            "TimeSinceStart : 228.9757628440857\n",
            "Training Loss : -0.005569137632846832\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 4 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -101.65570068359375\n",
            "Eval_StdReturn : 7.595864295959473\n",
            "Eval_MaxReturn : -92.2685775756836\n",
            "Eval_MinReturn : -110.87222290039062\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -96.16194915771484\n",
            "Train_StdReturn : 35.62798309326172\n",
            "Train_MaxReturn : 7.6632232666015625\n",
            "Train_MinReturn : -292.8904113769531\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 250500\n",
            "TimeSinceStart : 283.3104717731476\n",
            "Training Loss : -0.01658584177494049\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 5 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -80.10272216796875\n",
            "Eval_StdReturn : 0.48382192850112915\n",
            "Eval_MaxReturn : -79.592529296875\n",
            "Eval_MinReturn : -80.7526626586914\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -91.59908294677734\n",
            "Train_StdReturn : 38.267154693603516\n",
            "Train_MaxReturn : -7.963687896728516\n",
            "Train_MinReturn : -219.14280700683594\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 300600\n",
            "TimeSinceStart : 337.64277362823486\n",
            "Training Loss : -0.02060483582317829\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 6 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -106.45612335205078\n",
            "Eval_StdReturn : 13.485237121582031\n",
            "Eval_MaxReturn : -95.39140319824219\n",
            "Eval_MinReturn : -125.44049072265625\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -92.88884735107422\n",
            "Train_StdReturn : 36.32561492919922\n",
            "Train_MaxReturn : 16.087797164916992\n",
            "Train_MinReturn : -190.1581268310547\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 350700\n",
            "TimeSinceStart : 392.16630268096924\n",
            "Training Loss : -0.0007902432698756456\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 7 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -77.54110717773438\n",
            "Eval_StdReturn : 31.994930267333984\n",
            "Eval_MaxReturn : -44.07619094848633\n",
            "Eval_MinReturn : -120.64756774902344\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -90.71312713623047\n",
            "Train_StdReturn : 35.319339752197266\n",
            "Train_MaxReturn : 19.403005599975586\n",
            "Train_MinReturn : -234.65377807617188\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 400800\n",
            "TimeSinceStart : 445.33219289779663\n",
            "Training Loss : -0.025073813274502754\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 8 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -90.71074676513672\n",
            "Eval_StdReturn : 5.2879838943481445\n",
            "Eval_MaxReturn : -83.23921203613281\n",
            "Eval_MinReturn : -94.72272491455078\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -86.72924041748047\n",
            "Train_StdReturn : 32.17053985595703\n",
            "Train_MaxReturn : 9.396955490112305\n",
            "Train_MinReturn : -183.68368530273438\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 450900\n",
            "TimeSinceStart : 499.6839723587036\n",
            "Training Loss : -0.009634324349462986\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 9 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -94.4996109008789\n",
            "Eval_StdReturn : 16.9668025970459\n",
            "Eval_MaxReturn : -78.48338317871094\n",
            "Eval_MinReturn : -117.98089599609375\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -83.12879943847656\n",
            "Train_StdReturn : 27.870086669921875\n",
            "Train_MaxReturn : 5.316591262817383\n",
            "Train_MinReturn : -196.011474609375\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 501000\n",
            "TimeSinceStart : 553.9721086025238\n",
            "Training Loss : -0.007006475236266851\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 10 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -102.33562469482422\n",
            "Eval_StdReturn : 32.222415924072266\n",
            "Eval_MaxReturn : -63.50880813598633\n",
            "Eval_MinReturn : -142.40780639648438\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -91.62947845458984\n",
            "Train_StdReturn : 25.65870475769043\n",
            "Train_MaxReturn : -17.772666931152344\n",
            "Train_MinReturn : -184.34603881835938\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 551100\n",
            "TimeSinceStart : 607.9960896968842\n",
            "Training Loss : -0.01909549906849861\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 11 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -76.14025115966797\n",
            "Eval_StdReturn : 11.267661094665527\n",
            "Eval_MaxReturn : -64.904541015625\n",
            "Eval_MinReturn : -91.54377746582031\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -91.57005310058594\n",
            "Train_StdReturn : 23.979354858398438\n",
            "Train_MaxReturn : -24.525482177734375\n",
            "Train_MinReturn : -171.29385375976562\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 601200\n",
            "TimeSinceStart : 662.156182050705\n",
            "Training Loss : -0.015922894701361656\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 12 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -73.0380630493164\n",
            "Eval_StdReturn : 7.545188903808594\n",
            "Eval_MaxReturn : -67.49832153320312\n",
            "Eval_MinReturn : -83.70592498779297\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -88.04232788085938\n",
            "Train_StdReturn : 24.823570251464844\n",
            "Train_MaxReturn : -24.967926025390625\n",
            "Train_MinReturn : -178.20083618164062\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 651300\n",
            "TimeSinceStart : 716.1194889545441\n",
            "Training Loss : -0.02770402282476425\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 13 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -88.9845199584961\n",
            "Eval_StdReturn : 12.951079368591309\n",
            "Eval_MaxReturn : -72.55232238769531\n",
            "Eval_MinReturn : -104.20653533935547\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -81.71881103515625\n",
            "Train_StdReturn : 22.72300148010254\n",
            "Train_MaxReturn : -12.961037635803223\n",
            "Train_MinReturn : -142.8470916748047\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 701400\n",
            "TimeSinceStart : 770.6813328266144\n",
            "Training Loss : -0.010412963107228279\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 14 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -87.27385711669922\n",
            "Eval_StdReturn : 7.5835466384887695\n",
            "Eval_MaxReturn : -78.51651763916016\n",
            "Eval_MinReturn : -97.01415252685547\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -75.37288665771484\n",
            "Train_StdReturn : 22.470396041870117\n",
            "Train_MaxReturn : -8.055326461791992\n",
            "Train_MinReturn : -143.2018585205078\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 751500\n",
            "TimeSinceStart : 825.1636111736298\n",
            "Training Loss : -0.012177289463579655\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 15 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -71.45889282226562\n",
            "Eval_StdReturn : 10.912291526794434\n",
            "Eval_MaxReturn : -63.31964111328125\n",
            "Eval_MinReturn : -86.8833236694336\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -69.06465148925781\n",
            "Train_StdReturn : 23.87653160095215\n",
            "Train_MaxReturn : 16.11825180053711\n",
            "Train_MinReturn : -135.52130126953125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 801600\n",
            "TimeSinceStart : 879.9286780357361\n",
            "Training Loss : -0.023180516436696053\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 16 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -53.73294448852539\n",
            "Eval_StdReturn : 28.534379959106445\n",
            "Eval_MaxReturn : -21.581052780151367\n",
            "Eval_MinReturn : -90.92779541015625\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -66.15904235839844\n",
            "Train_StdReturn : 20.452686309814453\n",
            "Train_MaxReturn : -11.391400337219238\n",
            "Train_MinReturn : -147.32174682617188\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 851700\n",
            "TimeSinceStart : 934.4247584342957\n",
            "Training Loss : -0.012528583407402039\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 17 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -61.78224182128906\n",
            "Eval_StdReturn : 15.560550689697266\n",
            "Eval_MaxReturn : -40.57570266723633\n",
            "Eval_MinReturn : -77.47550964355469\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -63.69657516479492\n",
            "Train_StdReturn : 20.28384780883789\n",
            "Train_MaxReturn : 11.842151641845703\n",
            "Train_MinReturn : -131.12132263183594\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 901800\n",
            "TimeSinceStart : 989.2193865776062\n",
            "Training Loss : -0.013225877657532692\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 18 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -53.469207763671875\n",
            "Eval_StdReturn : 6.980727672576904\n",
            "Eval_MaxReturn : -44.75872039794922\n",
            "Eval_MinReturn : -61.848304748535156\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -62.238712310791016\n",
            "Train_StdReturn : 20.398176193237305\n",
            "Train_MaxReturn : -3.835419178009033\n",
            "Train_MinReturn : -123.56649780273438\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 951900\n",
            "TimeSinceStart : 1043.67875623703\n",
            "Training Loss : -0.01598673313856125\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 19 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -72.46752166748047\n",
            "Eval_StdReturn : 15.347410202026367\n",
            "Eval_MaxReturn : -59.19066619873047\n",
            "Eval_MinReturn : -93.97566223144531\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -60.72432327270508\n",
            "Train_StdReturn : 20.401100158691406\n",
            "Train_MaxReturn : 2.7559375762939453\n",
            "Train_MinReturn : -146.02255249023438\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1002000\n",
            "TimeSinceStart : 1098.4431607723236\n",
            "Training Loss : 0.0016910453559830785\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 20 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -61.40423583984375\n",
            "Eval_StdReturn : 1.6070812940597534\n",
            "Eval_MaxReturn : -59.17140197753906\n",
            "Eval_MinReturn : -62.88794708251953\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -61.50484848022461\n",
            "Train_StdReturn : 19.789304733276367\n",
            "Train_MaxReturn : -5.650500297546387\n",
            "Train_MinReturn : -116.63812255859375\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1052100\n",
            "TimeSinceStart : 1152.6065862178802\n",
            "Training Loss : -0.003874649293720722\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 21 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -61.2091178894043\n",
            "Eval_StdReturn : 3.933148145675659\n",
            "Eval_MaxReturn : -55.83536911010742\n",
            "Eval_MinReturn : -65.13961791992188\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -59.75901794433594\n",
            "Train_StdReturn : 18.81385612487793\n",
            "Train_MaxReturn : 3.7553834915161133\n",
            "Train_MinReturn : -139.025390625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1102200\n",
            "TimeSinceStart : 1207.0273487567902\n",
            "Training Loss : -0.015445961616933346\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 22 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -72.78375244140625\n",
            "Eval_StdReturn : 16.966875076293945\n",
            "Eval_MaxReturn : -51.52587127685547\n",
            "Eval_MinReturn : -93.05059814453125\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -61.7226448059082\n",
            "Train_StdReturn : 17.945655822753906\n",
            "Train_MaxReturn : 1.5734844207763672\n",
            "Train_MinReturn : -117.26382446289062\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1152300\n",
            "TimeSinceStart : 1261.1815876960754\n",
            "Training Loss : -0.02183285541832447\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 23 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -53.790374755859375\n",
            "Eval_StdReturn : 24.024545669555664\n",
            "Eval_MaxReturn : -25.253477096557617\n",
            "Eval_MinReturn : -84.0276107788086\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -62.118133544921875\n",
            "Train_StdReturn : 18.63884925842285\n",
            "Train_MaxReturn : -6.661972522735596\n",
            "Train_MinReturn : -136.93960571289062\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1202400\n",
            "TimeSinceStart : 1315.7901875972748\n",
            "Training Loss : -0.011208206415176392\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 24 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -62.173095703125\n",
            "Eval_StdReturn : 11.274353981018066\n",
            "Eval_MaxReturn : -48.385231018066406\n",
            "Eval_MinReturn : -76.00155639648438\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -58.136940002441406\n",
            "Train_StdReturn : 17.699399948120117\n",
            "Train_MaxReturn : 0.5090427398681641\n",
            "Train_MinReturn : -146.43841552734375\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1252500\n",
            "TimeSinceStart : 1369.134599685669\n",
            "Training Loss : -0.019589269533753395\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 25 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -42.594486236572266\n",
            "Eval_StdReturn : 2.4265201091766357\n",
            "Eval_MaxReturn : -40.25712585449219\n",
            "Eval_MinReturn : -45.93907165527344\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -52.477134704589844\n",
            "Train_StdReturn : 18.863121032714844\n",
            "Train_MaxReturn : 7.289466381072998\n",
            "Train_MinReturn : -105.10325622558594\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1302600\n",
            "TimeSinceStart : 1423.3966162204742\n",
            "Training Loss : -0.013007610104978085\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 26 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -49.09743118286133\n",
            "Eval_StdReturn : 16.050004959106445\n",
            "Eval_MaxReturn : -26.867191314697266\n",
            "Eval_MinReturn : -64.18323516845703\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -47.75602340698242\n",
            "Train_StdReturn : 21.01741600036621\n",
            "Train_MaxReturn : 11.25711441040039\n",
            "Train_MinReturn : -127.26991271972656\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1352700\n",
            "TimeSinceStart : 1477.8776080608368\n",
            "Training Loss : -0.006094037555158138\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 27 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -44.367889404296875\n",
            "Eval_StdReturn : 4.211390495300293\n",
            "Eval_MaxReturn : -39.78296661376953\n",
            "Eval_MinReturn : -49.95240020751953\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -43.089603424072266\n",
            "Train_StdReturn : 21.16570281982422\n",
            "Train_MaxReturn : 22.485942840576172\n",
            "Train_MinReturn : -111.9043960571289\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1402800\n",
            "TimeSinceStart : 1532.2075078487396\n",
            "Training Loss : -0.01657106727361679\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 28 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -46.82954025268555\n",
            "Eval_StdReturn : 2.9169554710388184\n",
            "Eval_MaxReturn : -42.73356628417969\n",
            "Eval_MinReturn : -49.30200958251953\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -40.822021484375\n",
            "Train_StdReturn : 21.25786781311035\n",
            "Train_MaxReturn : 26.17708969116211\n",
            "Train_MinReturn : -123.75956726074219\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1452900\n",
            "TimeSinceStart : 1586.687031030655\n",
            "Training Loss : -0.011457709595561028\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 29 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -46.9547119140625\n",
            "Eval_StdReturn : 7.3677592277526855\n",
            "Eval_MaxReturn : -38.163944244384766\n",
            "Eval_MinReturn : -56.194435119628906\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -37.1965217590332\n",
            "Train_StdReturn : 19.228195190429688\n",
            "Train_MaxReturn : 12.243216514587402\n",
            "Train_MinReturn : -131.2639617919922\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1503000\n",
            "TimeSinceStart : 1641.2973248958588\n",
            "Training Loss : -0.008320305496454239\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 30 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -29.04962158203125\n",
            "Eval_StdReturn : 20.771902084350586\n",
            "Eval_MaxReturn : 0.08767986297607422\n",
            "Eval_MinReturn : -46.85418701171875\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -37.51988983154297\n",
            "Train_StdReturn : 19.929752349853516\n",
            "Train_MaxReturn : 13.35555648803711\n",
            "Train_MinReturn : -125.97075653076172\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1553100\n",
            "TimeSinceStart : 1695.7762722969055\n",
            "Training Loss : -0.021043939515948296\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 31 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -52.4156608581543\n",
            "Eval_StdReturn : 8.430301666259766\n",
            "Eval_MaxReturn : -42.04790496826172\n",
            "Eval_MinReturn : -62.697303771972656\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -37.79708480834961\n",
            "Train_StdReturn : 21.043212890625\n",
            "Train_MaxReturn : 26.995807647705078\n",
            "Train_MinReturn : -158.4306640625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1603200\n",
            "TimeSinceStart : 1750.4927129745483\n",
            "Training Loss : -0.0058770859614014626\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 32 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -38.33222579956055\n",
            "Eval_StdReturn : 14.074005126953125\n",
            "Eval_MaxReturn : -24.993803024291992\n",
            "Eval_MinReturn : -57.79523468017578\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -34.70518493652344\n",
            "Train_StdReturn : 19.439205169677734\n",
            "Train_MaxReturn : 16.016042709350586\n",
            "Train_MinReturn : -111.1305160522461\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1653300\n",
            "TimeSinceStart : 1804.7446522712708\n",
            "Training Loss : -0.008993738330900669\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 33 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -29.719703674316406\n",
            "Eval_StdReturn : 15.854153633117676\n",
            "Eval_MaxReturn : -7.620854377746582\n",
            "Eval_MinReturn : -44.04966735839844\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -28.776206970214844\n",
            "Train_StdReturn : 19.355403900146484\n",
            "Train_MaxReturn : 29.286081314086914\n",
            "Train_MinReturn : -118.19476318359375\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1703400\n",
            "TimeSinceStart : 1858.6945259571075\n",
            "Training Loss : 0.010706915520131588\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 34 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -23.1624813079834\n",
            "Eval_StdReturn : 36.52131652832031\n",
            "Eval_MaxReturn : 14.819031715393066\n",
            "Eval_MinReturn : -72.46434783935547\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -22.809432983398438\n",
            "Train_StdReturn : 24.687421798706055\n",
            "Train_MaxReturn : 54.288734436035156\n",
            "Train_MinReturn : -120.43379211425781\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1753500\n",
            "TimeSinceStart : 1912.6666388511658\n",
            "Training Loss : -0.009282387793064117\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 35 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -17.734445571899414\n",
            "Eval_StdReturn : 9.749372482299805\n",
            "Eval_MaxReturn : -4.025917053222656\n",
            "Eval_MinReturn : -25.866432189941406\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -16.3061466217041\n",
            "Train_StdReturn : 22.384214401245117\n",
            "Train_MaxReturn : 43.09324645996094\n",
            "Train_MinReturn : -116.09317016601562\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1803600\n",
            "TimeSinceStart : 1966.6782953739166\n",
            "Training Loss : -0.004240195266902447\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 36 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -21.026626586914062\n",
            "Eval_StdReturn : 37.460079193115234\n",
            "Eval_MaxReturn : 24.810535430908203\n",
            "Eval_MinReturn : -66.94743347167969\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -10.14487075805664\n",
            "Train_StdReturn : 23.82952117919922\n",
            "Train_MaxReturn : 73.08529663085938\n",
            "Train_MinReturn : -110.964111328125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1853700\n",
            "TimeSinceStart : 2020.3518331050873\n",
            "Training Loss : -0.017537185922265053\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 37 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -35.77772903442383\n",
            "Eval_StdReturn : 59.423439025878906\n",
            "Eval_MaxReturn : 25.83770179748535\n",
            "Eval_MinReturn : -116.07656860351562\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -6.984314918518066\n",
            "Train_StdReturn : 25.21604347229004\n",
            "Train_MaxReturn : 73.457275390625\n",
            "Train_MinReturn : -144.16091918945312\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1903800\n",
            "TimeSinceStart : 2073.595848798752\n",
            "Training Loss : -0.002526994328945875\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 38 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -4.804619312286377\n",
            "Eval_StdReturn : 21.85645294189453\n",
            "Eval_MaxReturn : 24.761947631835938\n",
            "Eval_MinReturn : -27.39305305480957\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -5.502030849456787\n",
            "Train_StdReturn : 26.213918685913086\n",
            "Train_MaxReturn : 70.34574890136719\n",
            "Train_MinReturn : -150.52220153808594\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1953900\n",
            "TimeSinceStart : 2126.993538379669\n",
            "Training Loss : -0.017347702756524086\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 39 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -4.444283962249756\n",
            "Eval_StdReturn : 14.608025550842285\n",
            "Eval_MaxReturn : 14.20656967163086\n",
            "Eval_MinReturn : -21.46392059326172\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -9.262296676635742\n",
            "Train_StdReturn : 27.959657669067383\n",
            "Train_MaxReturn : 80.81967163085938\n",
            "Train_MinReturn : -126.96728515625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2004000\n",
            "TimeSinceStart : 2180.141609430313\n",
            "Training Loss : -0.011850930750370026\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 40 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -22.91014862060547\n",
            "Eval_StdReturn : 22.246782302856445\n",
            "Eval_MaxReturn : -4.358917713165283\n",
            "Eval_MinReturn : -54.19185256958008\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -7.213962078094482\n",
            "Train_StdReturn : 22.873661041259766\n",
            "Train_MaxReturn : 86.0377426147461\n",
            "Train_MinReturn : -69.98200225830078\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2054100\n",
            "TimeSinceStart : 2233.6524591445923\n",
            "Training Loss : -0.005835141055285931\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 41 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -15.534374237060547\n",
            "Eval_StdReturn : 15.209677696228027\n",
            "Eval_MaxReturn : 1.1490389108657837\n",
            "Eval_MinReturn : -35.63402557373047\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -12.182014465332031\n",
            "Train_StdReturn : 20.834983825683594\n",
            "Train_MaxReturn : 67.78809356689453\n",
            "Train_MinReturn : -88.46690368652344\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2104200\n",
            "TimeSinceStart : 2286.8508710861206\n",
            "Training Loss : -0.010070976801216602\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 42 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -45.159698486328125\n",
            "Eval_StdReturn : 27.07457160949707\n",
            "Eval_MaxReturn : -23.495311737060547\n",
            "Eval_MinReturn : -83.33306121826172\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -18.359359741210938\n",
            "Train_StdReturn : 21.591251373291016\n",
            "Train_MaxReturn : 38.48276901245117\n",
            "Train_MinReturn : -107.76687622070312\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2154300\n",
            "TimeSinceStart : 2339.8225650787354\n",
            "Training Loss : -0.009898936375975609\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 43 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -5.4096198081970215\n",
            "Eval_StdReturn : 13.81676197052002\n",
            "Eval_MaxReturn : 10.518593788146973\n",
            "Eval_MinReturn : -23.175430297851562\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -16.21480369567871\n",
            "Train_StdReturn : 22.3454532623291\n",
            "Train_MaxReturn : 71.56356811523438\n",
            "Train_MinReturn : -128.37841796875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2204400\n",
            "TimeSinceStart : 2392.890781879425\n",
            "Training Loss : -0.014505885541439056\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 44 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -3.210557222366333\n",
            "Eval_StdReturn : 16.301755905151367\n",
            "Eval_MaxReturn : 19.843502044677734\n",
            "Eval_MinReturn : -14.79758358001709\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -19.859046936035156\n",
            "Train_StdReturn : 23.7941951751709\n",
            "Train_MaxReturn : 41.69144821166992\n",
            "Train_MinReturn : -110.80682373046875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2254500\n",
            "TimeSinceStart : 2445.9756288528442\n",
            "Training Loss : -0.016197334975004196\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 45 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 9.740050315856934\n",
            "Eval_StdReturn : 19.660715103149414\n",
            "Eval_MaxReturn : 26.978824615478516\n",
            "Eval_MinReturn : -17.772037506103516\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -13.811432838439941\n",
            "Train_StdReturn : 24.088289260864258\n",
            "Train_MaxReturn : 62.876365661621094\n",
            "Train_MinReturn : -102.52891540527344\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2304600\n",
            "TimeSinceStart : 2499.064601421356\n",
            "Training Loss : -0.01847640611231327\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 46 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -13.079127311706543\n",
            "Eval_StdReturn : 18.355411529541016\n",
            "Eval_MaxReturn : 11.735858917236328\n",
            "Eval_MinReturn : -32.085411071777344\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -9.229543685913086\n",
            "Train_StdReturn : 28.414806365966797\n",
            "Train_MaxReturn : 58.24785232543945\n",
            "Train_MinReturn : -160.32223510742188\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2354700\n",
            "TimeSinceStart : 2552.249588727951\n",
            "Training Loss : -0.002104003680869937\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 47 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -8.741211891174316\n",
            "Eval_StdReturn : 6.074689865112305\n",
            "Eval_MaxReturn : -4.037684917449951\n",
            "Eval_MinReturn : -17.318761825561523\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -14.403923988342285\n",
            "Train_StdReturn : 30.466243743896484\n",
            "Train_MaxReturn : 60.240928649902344\n",
            "Train_MinReturn : -137.69497680664062\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2404800\n",
            "TimeSinceStart : 2605.3800988197327\n",
            "Training Loss : -0.021286269649863243\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 48 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -8.155959129333496\n",
            "Eval_StdReturn : 18.371437072753906\n",
            "Eval_MaxReturn : 17.277603149414062\n",
            "Eval_MinReturn : -25.46784019470215\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -5.575056076049805\n",
            "Train_StdReturn : 30.52467155456543\n",
            "Train_MaxReturn : 87.00064086914062\n",
            "Train_MinReturn : -108.15101623535156\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2454900\n",
            "TimeSinceStart : 2658.129771709442\n",
            "Training Loss : 0.004336753860116005\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 49 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -24.54197883605957\n",
            "Eval_StdReturn : 28.559307098388672\n",
            "Eval_MaxReturn : 8.689741134643555\n",
            "Eval_MinReturn : -61.03723907470703\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -7.791290283203125\n",
            "Train_StdReturn : 34.6201171875\n",
            "Train_MaxReturn : 72.82464599609375\n",
            "Train_MinReturn : -150.00148010253906\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2505000\n",
            "TimeSinceStart : 2710.4699358940125\n",
            "Training Loss : -0.0066262646578252316\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 50 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -18.33390235900879\n",
            "Eval_StdReturn : 51.16791915893555\n",
            "Eval_MaxReturn : 24.165699005126953\n",
            "Eval_MinReturn : -90.30422973632812\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -5.893144607543945\n",
            "Train_StdReturn : 29.723188400268555\n",
            "Train_MaxReturn : 63.7691650390625\n",
            "Train_MinReturn : -124.23881530761719\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2555100\n",
            "TimeSinceStart : 2763.207463979721\n",
            "Training Loss : -0.009831000119447708\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 51 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1.57003653049469\n",
            "Eval_StdReturn : 25.0074405670166\n",
            "Eval_MaxReturn : 25.32107162475586\n",
            "Eval_MinReturn : -32.99852752685547\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -9.221030235290527\n",
            "Train_StdReturn : 25.88102149963379\n",
            "Train_MaxReturn : 74.00497436523438\n",
            "Train_MinReturn : -108.17833709716797\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2605200\n",
            "TimeSinceStart : 2816.084734916687\n",
            "Training Loss : -0.024667587131261826\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 52 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -25.713438034057617\n",
            "Eval_StdReturn : 3.1126608848571777\n",
            "Eval_MaxReturn : -21.34649658203125\n",
            "Eval_MinReturn : -28.376867294311523\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -10.911452293395996\n",
            "Train_StdReturn : 27.029361724853516\n",
            "Train_MaxReturn : 81.70433044433594\n",
            "Train_MinReturn : -112.38887023925781\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2655300\n",
            "TimeSinceStart : 2868.9957690238953\n",
            "Training Loss : -0.022098250687122345\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 53 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 3.290888547897339\n",
            "Eval_StdReturn : 10.87684440612793\n",
            "Eval_MaxReturn : 17.977649688720703\n",
            "Eval_MinReturn : -8.012657165527344\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -10.024312973022461\n",
            "Train_StdReturn : 27.31541633605957\n",
            "Train_MaxReturn : 59.217491149902344\n",
            "Train_MinReturn : -103.56058502197266\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2705400\n",
            "TimeSinceStart : 2921.7171182632446\n",
            "Training Loss : -0.015579734928905964\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 54 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -7.8923211097717285\n",
            "Eval_StdReturn : 8.878140449523926\n",
            "Eval_MaxReturn : 4.510748863220215\n",
            "Eval_MinReturn : -15.783516883850098\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -13.664567947387695\n",
            "Train_StdReturn : 25.103010177612305\n",
            "Train_MaxReturn : 88.93266296386719\n",
            "Train_MinReturn : -121.79544067382812\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2755500\n",
            "TimeSinceStart : 2974.254141330719\n",
            "Training Loss : -0.012317769229412079\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 55 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -2.2545440196990967\n",
            "Eval_StdReturn : 25.65798568725586\n",
            "Eval_MaxReturn : 29.491636276245117\n",
            "Eval_MinReturn : -33.347137451171875\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -16.308040618896484\n",
            "Train_StdReturn : 21.223678588867188\n",
            "Train_MaxReturn : 67.19448852539062\n",
            "Train_MinReturn : -123.76146697998047\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2805600\n",
            "TimeSinceStart : 3027.307048559189\n",
            "Training Loss : -0.007547358982264996\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 56 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -35.437530517578125\n",
            "Eval_StdReturn : 9.9063081741333\n",
            "Eval_MaxReturn : -22.751689910888672\n",
            "Eval_MinReturn : -46.92870330810547\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -25.31888771057129\n",
            "Train_StdReturn : 15.608518600463867\n",
            "Train_MaxReturn : 35.498172760009766\n",
            "Train_MinReturn : -90.80581665039062\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2855700\n",
            "TimeSinceStart : 3079.9248852729797\n",
            "Training Loss : -0.01563284359872341\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 57 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -33.28140640258789\n",
            "Eval_StdReturn : 15.561558723449707\n",
            "Eval_MaxReturn : -15.964082717895508\n",
            "Eval_MinReturn : -53.701271057128906\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -34.7734260559082\n",
            "Train_StdReturn : 13.2581148147583\n",
            "Train_MaxReturn : 16.933908462524414\n",
            "Train_MinReturn : -64.29679870605469\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2905800\n",
            "TimeSinceStart : 3132.785145521164\n",
            "Training Loss : 0.0034514812286943197\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 58 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -47.01835632324219\n",
            "Eval_StdReturn : 8.103972434997559\n",
            "Eval_MaxReturn : -40.36768341064453\n",
            "Eval_MinReturn : -58.426883697509766\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -39.518104553222656\n",
            "Train_StdReturn : 13.421660423278809\n",
            "Train_MaxReturn : 6.607494354248047\n",
            "Train_MinReturn : -66.25968933105469\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2955900\n",
            "TimeSinceStart : 3186.1399195194244\n",
            "Training Loss : -0.011519269086420536\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 59 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -9.784372329711914\n",
            "Eval_StdReturn : 11.5054292678833\n",
            "Eval_MaxReturn : 2.0289478302001953\n",
            "Eval_MinReturn : -25.38105010986328\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -37.049652099609375\n",
            "Train_StdReturn : 15.965448379516602\n",
            "Train_MaxReturn : 27.518959045410156\n",
            "Train_MinReturn : -71.92412567138672\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3006000\n",
            "TimeSinceStart : 3238.7594451904297\n",
            "Training Loss : -0.007785644382238388\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 60 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -14.805268287658691\n",
            "Eval_StdReturn : 7.020033836364746\n",
            "Eval_MaxReturn : -5.503697395324707\n",
            "Eval_MinReturn : -22.46136474609375\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -23.954994201660156\n",
            "Train_StdReturn : 20.202678680419922\n",
            "Train_MaxReturn : 43.5514030456543\n",
            "Train_MinReturn : -68.18022155761719\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3056100\n",
            "TimeSinceStart : 3291.322751045227\n",
            "Training Loss : -0.002541201887652278\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 61 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 4.125484943389893\n",
            "Eval_StdReturn : 14.049883842468262\n",
            "Eval_MaxReturn : 19.306201934814453\n",
            "Eval_MinReturn : -14.567045211791992\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -14.508265495300293\n",
            "Train_StdReturn : 24.475910186767578\n",
            "Train_MaxReturn : 82.57748413085938\n",
            "Train_MinReturn : -124.53348541259766\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3106200\n",
            "TimeSinceStart : 3343.5569195747375\n",
            "Training Loss : -0.009349587373435497\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 62 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 3.3124077320098877\n",
            "Eval_StdReturn : 19.37200927734375\n",
            "Eval_MaxReturn : 30.342073440551758\n",
            "Eval_MinReturn : -14.070249557495117\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -5.067323684692383\n",
            "Train_StdReturn : 23.996341705322266\n",
            "Train_MaxReturn : 79.09713745117188\n",
            "Train_MinReturn : -75.2040786743164\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3156300\n",
            "TimeSinceStart : 3396.7300477027893\n",
            "Training Loss : -0.01638953387737274\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 63 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 23.117515563964844\n",
            "Eval_StdReturn : 31.667997360229492\n",
            "Eval_MaxReturn : 65.7063217163086\n",
            "Eval_MinReturn : -10.174310684204102\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 0.9511967301368713\n",
            "Train_StdReturn : 27.512062072753906\n",
            "Train_MaxReturn : 118.38522338867188\n",
            "Train_MinReturn : -103.92723083496094\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3206400\n",
            "TimeSinceStart : 3449.71746969223\n",
            "Training Loss : -0.019141647964715958\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 64 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 19.82448387145996\n",
            "Eval_StdReturn : 10.980674743652344\n",
            "Eval_MaxReturn : 29.662952423095703\n",
            "Eval_MinReturn : 4.500143051147461\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 9.378676414489746\n",
            "Train_StdReturn : 27.196517944335938\n",
            "Train_MaxReturn : 82.36553955078125\n",
            "Train_MinReturn : -94.43128967285156\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3256500\n",
            "TimeSinceStart : 3502.8690843582153\n",
            "Training Loss : -0.009385895915329456\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 65 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 17.056034088134766\n",
            "Eval_StdReturn : 8.547773361206055\n",
            "Eval_MaxReturn : 29.131393432617188\n",
            "Eval_MinReturn : 10.532649993896484\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 23.532241821289062\n",
            "Train_StdReturn : 28.3243350982666\n",
            "Train_MaxReturn : 133.91156005859375\n",
            "Train_MinReturn : -107.48421478271484\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3306600\n",
            "TimeSinceStart : 3555.6287224292755\n",
            "Training Loss : -0.004964211490005255\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 66 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 23.244340896606445\n",
            "Eval_StdReturn : 17.62877082824707\n",
            "Eval_MaxReturn : 47.69841384887695\n",
            "Eval_MinReturn : 6.8150434494018555\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 26.504009246826172\n",
            "Train_StdReturn : 30.651935577392578\n",
            "Train_MaxReturn : 103.46070861816406\n",
            "Train_MinReturn : -122.62919616699219\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3356700\n",
            "TimeSinceStart : 3608.3233568668365\n",
            "Training Loss : -0.006330528762191534\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 67 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 3.082002639770508\n",
            "Eval_StdReturn : 22.949268341064453\n",
            "Eval_MaxReturn : 29.421937942504883\n",
            "Eval_MinReturn : -26.509267807006836\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 32.342552185058594\n",
            "Train_StdReturn : 28.982913970947266\n",
            "Train_MaxReturn : 120.78038024902344\n",
            "Train_MinReturn : -94.6949462890625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3406800\n",
            "TimeSinceStart : 3660.783528327942\n",
            "Training Loss : -0.010456196963787079\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 68 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 54.25551223754883\n",
            "Eval_StdReturn : 12.202827453613281\n",
            "Eval_MaxReturn : 69.44380187988281\n",
            "Eval_MinReturn : 39.56556701660156\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 37.77721405029297\n",
            "Train_StdReturn : 30.45864486694336\n",
            "Train_MaxReturn : 127.47241973876953\n",
            "Train_MinReturn : -120.2897720336914\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3456900\n",
            "TimeSinceStart : 3713.3340389728546\n",
            "Training Loss : 0.0067191896960139275\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 69 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 68.69146728515625\n",
            "Eval_StdReturn : 14.768407821655273\n",
            "Eval_MaxReturn : 80.03314208984375\n",
            "Eval_MinReturn : 47.832359313964844\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 45.27804946899414\n",
            "Train_StdReturn : 28.95818519592285\n",
            "Train_MaxReturn : 153.14303588867188\n",
            "Train_MinReturn : -47.16558074951172\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3507000\n",
            "TimeSinceStart : 3765.5925464630127\n",
            "Training Loss : -0.016097700223326683\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 70 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 42.60762023925781\n",
            "Eval_StdReturn : 10.47200870513916\n",
            "Eval_MaxReturn : 57.41647720336914\n",
            "Eval_MinReturn : 35.06977844238281\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 55.45500946044922\n",
            "Train_StdReturn : 30.221996307373047\n",
            "Train_MaxReturn : 175.24856567382812\n",
            "Train_MinReturn : -19.378162384033203\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3557100\n",
            "TimeSinceStart : 3817.734384536743\n",
            "Training Loss : -0.0012396337697282434\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 71 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 86.82665252685547\n",
            "Eval_StdReturn : 31.54347038269043\n",
            "Eval_MaxReturn : 124.29137420654297\n",
            "Eval_MinReturn : 47.123313903808594\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 58.0262336730957\n",
            "Train_StdReturn : 29.690523147583008\n",
            "Train_MaxReturn : 166.8958740234375\n",
            "Train_MinReturn : -33.100547790527344\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3607200\n",
            "TimeSinceStart : 3870.1071083545685\n",
            "Training Loss : -0.004670247435569763\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 72 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 50.5161018371582\n",
            "Eval_StdReturn : 27.713666915893555\n",
            "Eval_MaxReturn : 85.5982894897461\n",
            "Eval_MinReturn : 17.84222412109375\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 58.0626335144043\n",
            "Train_StdReturn : 27.228591918945312\n",
            "Train_MaxReturn : 151.08233642578125\n",
            "Train_MinReturn : -27.643985748291016\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3657300\n",
            "TimeSinceStart : 3922.4274051189423\n",
            "Training Loss : -0.017048338428139687\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 73 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 69.93938446044922\n",
            "Eval_StdReturn : 3.9919486045837402\n",
            "Eval_MaxReturn : 73.91696166992188\n",
            "Eval_MinReturn : 64.48106384277344\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 58.35227584838867\n",
            "Train_StdReturn : 26.60411262512207\n",
            "Train_MaxReturn : 133.24380493164062\n",
            "Train_MinReturn : -14.160087585449219\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3707400\n",
            "TimeSinceStart : 3974.9063699245453\n",
            "Training Loss : -0.002443438395857811\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 74 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 85.53386688232422\n",
            "Eval_StdReturn : 18.69255828857422\n",
            "Eval_MaxReturn : 110.41168212890625\n",
            "Eval_MinReturn : 65.35298156738281\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 55.12196350097656\n",
            "Train_StdReturn : 25.657285690307617\n",
            "Train_MaxReturn : 126.11761474609375\n",
            "Train_MinReturn : -19.54214859008789\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3757500\n",
            "TimeSinceStart : 4027.3422033786774\n",
            "Training Loss : -0.02236318401992321\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 75 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 55.800689697265625\n",
            "Eval_StdReturn : 16.95490837097168\n",
            "Eval_MaxReturn : 79.36153411865234\n",
            "Eval_MinReturn : 40.1643180847168\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 57.18159866333008\n",
            "Train_StdReturn : 26.330032348632812\n",
            "Train_MaxReturn : 132.17047119140625\n",
            "Train_MinReturn : -5.262880325317383\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3807600\n",
            "TimeSinceStart : 4079.9776799678802\n",
            "Training Loss : -0.000766377430409193\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 76 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 24.452428817749023\n",
            "Eval_StdReturn : 34.383277893066406\n",
            "Eval_MaxReturn : 50.59727478027344\n",
            "Eval_MinReturn : -24.125625610351562\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 55.81687545776367\n",
            "Train_StdReturn : 27.071744918823242\n",
            "Train_MaxReturn : 126.80795288085938\n",
            "Train_MinReturn : -20.271804809570312\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3857700\n",
            "TimeSinceStart : 4132.500824928284\n",
            "Training Loss : -0.012744192034006119\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 77 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 48.81022644042969\n",
            "Eval_StdReturn : 11.303359031677246\n",
            "Eval_MaxReturn : 61.03519821166992\n",
            "Eval_MinReturn : 33.778018951416016\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 55.71617889404297\n",
            "Train_StdReturn : 28.097923278808594\n",
            "Train_MaxReturn : 167.6166534423828\n",
            "Train_MinReturn : -18.997371673583984\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3907800\n",
            "TimeSinceStart : 4184.672496080399\n",
            "Training Loss : -0.019218120723962784\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 78 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 59.973262786865234\n",
            "Eval_StdReturn : 13.299796104431152\n",
            "Eval_MaxReturn : 74.17698669433594\n",
            "Eval_MinReturn : 42.19350051879883\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 47.69725799560547\n",
            "Train_StdReturn : 25.158546447753906\n",
            "Train_MaxReturn : 115.78999328613281\n",
            "Train_MinReturn : -27.309144973754883\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3957900\n",
            "TimeSinceStart : 4237.362428188324\n",
            "Training Loss : -0.006961832754313946\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 79 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 46.29133987426758\n",
            "Eval_StdReturn : 52.050662994384766\n",
            "Eval_MaxReturn : 119.64520263671875\n",
            "Eval_MinReturn : 4.29322624206543\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 49.25624465942383\n",
            "Train_StdReturn : 27.992897033691406\n",
            "Train_MaxReturn : 149.94192504882812\n",
            "Train_MinReturn : -16.1178035736084\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4008000\n",
            "TimeSinceStart : 4290.033052682877\n",
            "Training Loss : -0.012374023906886578\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 80 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 51.08772277832031\n",
            "Eval_StdReturn : 28.904016494750977\n",
            "Eval_MaxReturn : 87.3021240234375\n",
            "Eval_MinReturn : 16.56250762939453\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 56.92705535888672\n",
            "Train_StdReturn : 30.050308227539062\n",
            "Train_MaxReturn : 146.8173065185547\n",
            "Train_MinReturn : -18.910507202148438\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4058100\n",
            "TimeSinceStart : 4342.819504976273\n",
            "Training Loss : -0.012649630196392536\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 81 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 64.44672393798828\n",
            "Eval_StdReturn : 17.995086669921875\n",
            "Eval_MaxReturn : 82.76395416259766\n",
            "Eval_MinReturn : 39.987979888916016\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 70.28129577636719\n",
            "Train_StdReturn : 27.938566207885742\n",
            "Train_MaxReturn : 194.12939453125\n",
            "Train_MinReturn : -7.622915267944336\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4108200\n",
            "TimeSinceStart : 4395.410012483597\n",
            "Training Loss : -0.025986764580011368\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 82 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 79.9596176147461\n",
            "Eval_StdReturn : 9.272055625915527\n",
            "Eval_MaxReturn : 90.16276550292969\n",
            "Eval_MinReturn : 67.72513580322266\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 79.65860748291016\n",
            "Train_StdReturn : 28.3240909576416\n",
            "Train_MaxReturn : 166.93276977539062\n",
            "Train_MinReturn : 3.8550586700439453\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4158300\n",
            "TimeSinceStart : 4447.92227268219\n",
            "Training Loss : -0.020557647570967674\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 83 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 95.30379486083984\n",
            "Eval_StdReturn : 3.44454026222229\n",
            "Eval_MaxReturn : 100.14167785644531\n",
            "Eval_MinReturn : 92.39148712158203\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 84.50544738769531\n",
            "Train_StdReturn : 29.66975212097168\n",
            "Train_MaxReturn : 180.879150390625\n",
            "Train_MinReturn : -36.58734893798828\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4208400\n",
            "TimeSinceStart : 4500.044467926025\n",
            "Training Loss : -0.004522554110735655\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 84 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 89.0898208618164\n",
            "Eval_StdReturn : 25.68225860595703\n",
            "Eval_MaxReturn : 111.51921081542969\n",
            "Eval_MinReturn : 53.13528823852539\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 79.93772888183594\n",
            "Train_StdReturn : 34.587440490722656\n",
            "Train_MaxReturn : 189.03436279296875\n",
            "Train_MinReturn : -36.01369857788086\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4258500\n",
            "TimeSinceStart : 4552.263384342194\n",
            "Training Loss : -0.004775724373757839\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 85 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 62.16958999633789\n",
            "Eval_StdReturn : 47.109840393066406\n",
            "Eval_MaxReturn : 128.08287048339844\n",
            "Eval_MinReturn : 20.811452865600586\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 78.83960723876953\n",
            "Train_StdReturn : 31.81005859375\n",
            "Train_MaxReturn : 183.04122924804688\n",
            "Train_MinReturn : -5.052833557128906\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4308600\n",
            "TimeSinceStart : 4604.25591468811\n",
            "Training Loss : -0.011894823983311653\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 86 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 10.870097160339355\n",
            "Eval_StdReturn : 13.343466758728027\n",
            "Eval_MaxReturn : 28.054262161254883\n",
            "Eval_MinReturn : -4.474799633026123\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 69.16426086425781\n",
            "Train_StdReturn : 35.838104248046875\n",
            "Train_MaxReturn : 217.35421752929688\n",
            "Train_MinReturn : -36.553199768066406\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4358700\n",
            "TimeSinceStart : 4656.486137628555\n",
            "Training Loss : -0.015827788040041924\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 87 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 9.904622077941895\n",
            "Eval_StdReturn : 47.75474548339844\n",
            "Eval_MaxReturn : 70.98167419433594\n",
            "Eval_MinReturn : -45.59325408935547\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 34.146915435791016\n",
            "Train_StdReturn : 34.4261589050293\n",
            "Train_MaxReturn : 160.72879028320312\n",
            "Train_MinReturn : -49.76103973388672\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4408800\n",
            "TimeSinceStart : 4708.720638990402\n",
            "Training Loss : -0.010479139164090157\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 88 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -21.636507034301758\n",
            "Eval_StdReturn : 9.274076461791992\n",
            "Eval_MaxReturn : -8.56220531463623\n",
            "Eval_MinReturn : -29.073488235473633\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 0.2113950401544571\n",
            "Train_StdReturn : 31.77351951599121\n",
            "Train_MaxReturn : 138.4784698486328\n",
            "Train_MinReturn : -63.9395751953125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4458900\n",
            "TimeSinceStart : 4761.0365669727325\n",
            "Training Loss : -0.031038537621498108\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 89 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -25.599512100219727\n",
            "Eval_StdReturn : 44.936100006103516\n",
            "Eval_MaxReturn : 31.94512939453125\n",
            "Eval_MinReturn : -77.72434997558594\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -21.976919174194336\n",
            "Train_StdReturn : 28.828096389770508\n",
            "Train_MaxReturn : 73.35885620117188\n",
            "Train_MinReturn : -85.95511627197266\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4509000\n",
            "TimeSinceStart : 4813.7508335113525\n",
            "Training Loss : -0.010703877545893192\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 90 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -40.367706298828125\n",
            "Eval_StdReturn : 7.014318466186523\n",
            "Eval_MaxReturn : -30.837665557861328\n",
            "Eval_MinReturn : -47.51699447631836\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -28.96595573425293\n",
            "Train_StdReturn : 26.552854537963867\n",
            "Train_MaxReturn : 72.63232421875\n",
            "Train_MinReturn : -80.92330932617188\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4559100\n",
            "TimeSinceStart : 4866.8993854522705\n",
            "Training Loss : -0.00956917554140091\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 91 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -9.916468620300293\n",
            "Eval_StdReturn : 20.27044105529785\n",
            "Eval_MaxReturn : 14.115214347839355\n",
            "Eval_MinReturn : -35.46725845336914\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -20.683881759643555\n",
            "Train_StdReturn : 24.189485549926758\n",
            "Train_MaxReturn : 74.11572265625\n",
            "Train_MinReturn : -73.45838165283203\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4609200\n",
            "TimeSinceStart : 4919.669117689133\n",
            "Training Loss : -0.00013079127529636025\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 92 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 4.325689792633057\n",
            "Eval_StdReturn : 17.67359733581543\n",
            "Eval_MaxReturn : 23.601016998291016\n",
            "Eval_MinReturn : -19.09168243408203\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 0.08662103861570358\n",
            "Train_StdReturn : 25.547481536865234\n",
            "Train_MaxReturn : 88.05690002441406\n",
            "Train_MinReturn : -64.96894836425781\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4659300\n",
            "TimeSinceStart : 4972.344460487366\n",
            "Training Loss : 0.0013326351763680577\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 93 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -2.8657009601593018\n",
            "Eval_StdReturn : 8.597366333007812\n",
            "Eval_MaxReturn : 5.615886688232422\n",
            "Eval_MinReturn : -14.65096664428711\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 21.485248565673828\n",
            "Train_StdReturn : 29.08035659790039\n",
            "Train_MaxReturn : 134.06869506835938\n",
            "Train_MinReturn : -54.168556213378906\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4709400\n",
            "TimeSinceStart : 5024.694647312164\n",
            "Training Loss : -0.005497622769325972\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 94 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 30.818761825561523\n",
            "Eval_StdReturn : 12.506965637207031\n",
            "Eval_MaxReturn : 47.60026550292969\n",
            "Eval_MinReturn : 17.588367462158203\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 23.96391487121582\n",
            "Train_StdReturn : 28.708311080932617\n",
            "Train_MaxReturn : 117.02537536621094\n",
            "Train_MinReturn : -50.61030578613281\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4759500\n",
            "TimeSinceStart : 5077.169127702713\n",
            "Training Loss : -0.0056790197268128395\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 95 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -23.97498893737793\n",
            "Eval_StdReturn : 21.2999210357666\n",
            "Eval_MaxReturn : -8.322810173034668\n",
            "Eval_MinReturn : -54.08979415893555\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 2.064711809158325\n",
            "Train_StdReturn : 22.345558166503906\n",
            "Train_MaxReturn : 75.85723114013672\n",
            "Train_MinReturn : -52.62721252441406\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4809600\n",
            "TimeSinceStart : 5129.300560712814\n",
            "Training Loss : -0.003204969223588705\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 96 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -20.02744483947754\n",
            "Eval_StdReturn : 7.77329683303833\n",
            "Eval_MaxReturn : -10.1251802444458\n",
            "Eval_MinReturn : -29.113197326660156\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -8.4442720413208\n",
            "Train_StdReturn : 19.914670944213867\n",
            "Train_MaxReturn : 57.337867736816406\n",
            "Train_MinReturn : -61.56939697265625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4859700\n",
            "TimeSinceStart : 5182.236006259918\n",
            "Training Loss : -0.001276920665986836\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 97 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -19.549549102783203\n",
            "Eval_StdReturn : 7.715715408325195\n",
            "Eval_MaxReturn : -13.957722663879395\n",
            "Eval_MinReturn : -30.460079193115234\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -14.504581451416016\n",
            "Train_StdReturn : 20.599275588989258\n",
            "Train_MaxReturn : 61.325965881347656\n",
            "Train_MinReturn : -91.36772155761719\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4909800\n",
            "TimeSinceStart : 5234.47824716568\n",
            "Training Loss : -0.003982876427471638\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 98 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 3.4365570545196533\n",
            "Eval_StdReturn : 16.94341278076172\n",
            "Eval_MaxReturn : 25.13091468811035\n",
            "Eval_MinReturn : -16.221694946289062\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -12.216524124145508\n",
            "Train_StdReturn : 19.734445571899414\n",
            "Train_MaxReturn : 51.04383850097656\n",
            "Train_MinReturn : -59.20268249511719\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4959900\n",
            "TimeSinceStart : 5286.898731470108\n",
            "Training Loss : 0.0020645051263272762\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 99 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 33.58842086791992\n",
            "Eval_StdReturn : 18.864459991455078\n",
            "Eval_MaxReturn : 47.44791030883789\n",
            "Eval_MinReturn : 6.916898727416992\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 5.423159122467041\n",
            "Train_StdReturn : 22.38003158569336\n",
            "Train_MaxReturn : 79.60543823242188\n",
            "Train_MinReturn : -62.55638885498047\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 5010000\n",
            "TimeSinceStart : 5338.995512247086\n",
            "Training Loss : -0.009092147462069988\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python cs285/scripts/run_hw2.py --env_name HalfCheetah-v2 --ep_len 150 \\\n",
        "--discount 0.95 -n 100 -l 2 -s 32 -b 50000 -lr 0.02 \\\n",
        "--exp_name q4_b50000_r02"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "H5Q79wMI9Qe8",
        "outputId": "c945d8ff-bf33-4652-a94f-c6a173c3fabc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "########################\n",
            "logging outputs to  /content/gdrive/My Drive/cs285_f2021/DRL_policy_grads/cs285/scripts/../../data/q4_b50000_r02_rtg_HalfCheetah-v2_08-02-2022_08-38-40\n",
            "########################\n",
            "Using GPU id 0\n",
            "Sequential(\n",
            "  (0): Linear(in_features=17, out_features=32, bias=True)\n",
            "  (1): Tanh()\n",
            "  (2): Linear(in_features=32, out_features=32, bias=True)\n",
            "  (3): Tanh()\n",
            "  (4): Linear(in_features=32, out_features=6, bias=True)\n",
            "  (5): Identity()\n",
            ")\n",
            "\n",
            "\n",
            "********** Iteration 0 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -67.32781982421875\n",
            "Eval_StdReturn : 13.957499504089355\n",
            "Eval_MaxReturn : -47.595829010009766\n",
            "Eval_MinReturn : -77.64552307128906\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -89.52372741699219\n",
            "Train_StdReturn : 37.225181579589844\n",
            "Train_MaxReturn : -5.174495697021484\n",
            "Train_MinReturn : -219.4058380126953\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 50100\n",
            "TimeSinceStart : 52.227964639663696\n",
            "Training Loss : -0.07279901951551437\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 1 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -76.23278045654297\n",
            "Eval_StdReturn : 17.42217254638672\n",
            "Eval_MaxReturn : -56.88751983642578\n",
            "Eval_MinReturn : -99.1197509765625\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -80.01589965820312\n",
            "Train_StdReturn : 35.07271957397461\n",
            "Train_MaxReturn : 16.62759017944336\n",
            "Train_MinReturn : -244.33795166015625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 100200\n",
            "TimeSinceStart : 104.8819363117218\n",
            "Training Loss : -0.07501063495874405\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 2 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -71.61651611328125\n",
            "Eval_StdReturn : 20.05783462524414\n",
            "Eval_MaxReturn : -50.20165252685547\n",
            "Eval_MinReturn : -98.4338150024414\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -73.22703552246094\n",
            "Train_StdReturn : 30.957347869873047\n",
            "Train_MaxReturn : 9.559767723083496\n",
            "Train_MinReturn : -166.44976806640625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 150300\n",
            "TimeSinceStart : 157.34497356414795\n",
            "Training Loss : -0.08144234865903854\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 3 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -58.94102478027344\n",
            "Eval_StdReturn : 7.228002548217773\n",
            "Eval_MaxReturn : -52.49172592163086\n",
            "Eval_MinReturn : -69.03378295898438\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -69.16334533691406\n",
            "Train_StdReturn : 30.453699111938477\n",
            "Train_MaxReturn : 12.221670150756836\n",
            "Train_MinReturn : -214.4334716796875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 200400\n",
            "TimeSinceStart : 209.74821615219116\n",
            "Training Loss : -0.07341589033603668\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 4 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -49.72474670410156\n",
            "Eval_StdReturn : 16.007474899291992\n",
            "Eval_MaxReturn : -30.264713287353516\n",
            "Eval_MinReturn : -69.47171020507812\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -62.63613510131836\n",
            "Train_StdReturn : 28.202409744262695\n",
            "Train_MaxReturn : 37.41807556152344\n",
            "Train_MinReturn : -162.27394104003906\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 250500\n",
            "TimeSinceStart : 263.0284569263458\n",
            "Training Loss : -0.06621852517127991\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 5 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -81.8307113647461\n",
            "Eval_StdReturn : 31.386608123779297\n",
            "Eval_MaxReturn : -51.774715423583984\n",
            "Eval_MinReturn : -125.14574432373047\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -57.786537170410156\n",
            "Train_StdReturn : 29.20555877685547\n",
            "Train_MaxReturn : 37.12913131713867\n",
            "Train_MinReturn : -149.63372802734375\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 300600\n",
            "TimeSinceStart : 316.5566051006317\n",
            "Training Loss : -0.0938112735748291\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 6 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -54.40532302856445\n",
            "Eval_StdReturn : 14.491355895996094\n",
            "Eval_MaxReturn : -34.172157287597656\n",
            "Eval_MinReturn : -67.34384155273438\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -49.00865936279297\n",
            "Train_StdReturn : 27.859615325927734\n",
            "Train_MaxReturn : 55.841224670410156\n",
            "Train_MinReturn : -139.47402954101562\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 350700\n",
            "TimeSinceStart : 370.0178470611572\n",
            "Training Loss : -0.0662379339337349\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 7 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -47.130855560302734\n",
            "Eval_StdReturn : 10.927118301391602\n",
            "Eval_MaxReturn : -39.141273498535156\n",
            "Eval_MinReturn : -62.58111572265625\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -49.275360107421875\n",
            "Train_StdReturn : 30.799894332885742\n",
            "Train_MaxReturn : 33.860809326171875\n",
            "Train_MinReturn : -182.8935546875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 400800\n",
            "TimeSinceStart : 423.16547441482544\n",
            "Training Loss : -0.07580269873142242\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 8 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 3.463521718978882\n",
            "Eval_StdReturn : 16.25501251220703\n",
            "Eval_MaxReturn : 26.44110870361328\n",
            "Eval_MinReturn : -8.626126289367676\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -44.367488861083984\n",
            "Train_StdReturn : 26.588117599487305\n",
            "Train_MaxReturn : 28.954498291015625\n",
            "Train_MinReturn : -155.34515380859375\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 450900\n",
            "TimeSinceStart : 476.2942841053009\n",
            "Training Loss : -0.07105789333581924\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 9 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -54.486724853515625\n",
            "Eval_StdReturn : 20.82843780517578\n",
            "Eval_MaxReturn : -25.362268447875977\n",
            "Eval_MinReturn : -72.86474609375\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -43.304893493652344\n",
            "Train_StdReturn : 27.117353439331055\n",
            "Train_MaxReturn : 31.963136672973633\n",
            "Train_MinReturn : -128.0959014892578\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 501000\n",
            "TimeSinceStart : 529.3583679199219\n",
            "Training Loss : -0.08884609490633011\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 10 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -35.266292572021484\n",
            "Eval_StdReturn : 18.012487411499023\n",
            "Eval_MaxReturn : -10.949846267700195\n",
            "Eval_MinReturn : -53.99774932861328\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -45.16282653808594\n",
            "Train_StdReturn : 27.481388092041016\n",
            "Train_MaxReturn : 32.97810745239258\n",
            "Train_MinReturn : -146.15301513671875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 551100\n",
            "TimeSinceStart : 582.637368440628\n",
            "Training Loss : -0.07102708518505096\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 11 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -32.39322280883789\n",
            "Eval_StdReturn : 20.540306091308594\n",
            "Eval_MaxReturn : -4.876498699188232\n",
            "Eval_MinReturn : -54.21251678466797\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -42.39384078979492\n",
            "Train_StdReturn : 27.876760482788086\n",
            "Train_MaxReturn : 32.97944259643555\n",
            "Train_MinReturn : -149.59600830078125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 601200\n",
            "TimeSinceStart : 635.6489658355713\n",
            "Training Loss : -0.04705917462706566\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 12 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -54.94694519042969\n",
            "Eval_StdReturn : 23.039817810058594\n",
            "Eval_MaxReturn : -23.515962600708008\n",
            "Eval_MinReturn : -78.10015869140625\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -43.05998992919922\n",
            "Train_StdReturn : 30.951066970825195\n",
            "Train_MaxReturn : 59.51201629638672\n",
            "Train_MinReturn : -157.42152404785156\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 651300\n",
            "TimeSinceStart : 688.8084189891815\n",
            "Training Loss : -0.04846179857850075\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 13 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -47.346920013427734\n",
            "Eval_StdReturn : 12.674991607666016\n",
            "Eval_MaxReturn : -32.33170700073242\n",
            "Eval_MinReturn : -63.3333625793457\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -38.955570220947266\n",
            "Train_StdReturn : 27.788270950317383\n",
            "Train_MaxReturn : 77.67410278320312\n",
            "Train_MinReturn : -149.5926513671875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 701400\n",
            "TimeSinceStart : 742.0205676555634\n",
            "Training Loss : -0.057054221630096436\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 14 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -8.886839866638184\n",
            "Eval_StdReturn : 3.093585729598999\n",
            "Eval_MaxReturn : -5.021625518798828\n",
            "Eval_MinReturn : -12.59441089630127\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -34.191749572753906\n",
            "Train_StdReturn : 25.326133728027344\n",
            "Train_MaxReturn : 30.826417922973633\n",
            "Train_MinReturn : -143.72000122070312\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 751500\n",
            "TimeSinceStart : 795.0883967876434\n",
            "Training Loss : -0.057407498359680176\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 15 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -8.493958473205566\n",
            "Eval_StdReturn : 6.893975257873535\n",
            "Eval_MaxReturn : -0.4482440948486328\n",
            "Eval_MinReturn : -17.285484313964844\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -29.048080444335938\n",
            "Train_StdReturn : 21.727153778076172\n",
            "Train_MaxReturn : 46.43037414550781\n",
            "Train_MinReturn : -130.0250701904297\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 801600\n",
            "TimeSinceStart : 848.2821581363678\n",
            "Training Loss : -0.06623778492212296\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 16 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -39.55256271362305\n",
            "Eval_StdReturn : 41.9853401184082\n",
            "Eval_MaxReturn : 0.1385331153869629\n",
            "Eval_MinReturn : -97.64227294921875\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -29.274829864501953\n",
            "Train_StdReturn : 23.84470558166504\n",
            "Train_MaxReturn : 31.709178924560547\n",
            "Train_MinReturn : -117.36366271972656\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 851700\n",
            "TimeSinceStart : 901.5503277778625\n",
            "Training Loss : -0.07008499652147293\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 17 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -14.427696228027344\n",
            "Eval_StdReturn : 7.017594337463379\n",
            "Eval_MaxReturn : -5.614245414733887\n",
            "Eval_MinReturn : -22.785655975341797\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -29.205106735229492\n",
            "Train_StdReturn : 20.000581741333008\n",
            "Train_MaxReturn : 34.00132751464844\n",
            "Train_MinReturn : -131.18389892578125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 901800\n",
            "TimeSinceStart : 954.5807847976685\n",
            "Training Loss : -0.06258958578109741\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 18 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -15.40465259552002\n",
            "Eval_StdReturn : 13.00288200378418\n",
            "Eval_MaxReturn : 2.961878776550293\n",
            "Eval_MinReturn : -25.372339248657227\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -28.10262680053711\n",
            "Train_StdReturn : 22.075136184692383\n",
            "Train_MaxReturn : 35.32787322998047\n",
            "Train_MinReturn : -140.1842498779297\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 951900\n",
            "TimeSinceStart : 1007.4383118152618\n",
            "Training Loss : -0.07919610291719437\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 19 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -13.005257606506348\n",
            "Eval_StdReturn : 13.939689636230469\n",
            "Eval_MaxReturn : 6.45396089553833\n",
            "Eval_MinReturn : -25.46919059753418\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -22.551462173461914\n",
            "Train_StdReturn : 15.43191909790039\n",
            "Train_MaxReturn : 23.945377349853516\n",
            "Train_MinReturn : -78.9805908203125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1002000\n",
            "TimeSinceStart : 1060.2784459590912\n",
            "Training Loss : -0.06820668280124664\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 20 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -25.744901657104492\n",
            "Eval_StdReturn : 17.318330764770508\n",
            "Eval_MaxReturn : -1.2858400344848633\n",
            "Eval_MinReturn : -39.07109832763672\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -20.78803253173828\n",
            "Train_StdReturn : 14.618375778198242\n",
            "Train_MaxReturn : 19.093015670776367\n",
            "Train_MinReturn : -73.91862487792969\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1052100\n",
            "TimeSinceStart : 1113.3195672035217\n",
            "Training Loss : -0.06664512306451797\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 21 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -15.398124694824219\n",
            "Eval_StdReturn : 3.685952663421631\n",
            "Eval_MaxReturn : -11.946874618530273\n",
            "Eval_MinReturn : -20.506946563720703\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -16.686429977416992\n",
            "Train_StdReturn : 14.648576736450195\n",
            "Train_MaxReturn : 41.376495361328125\n",
            "Train_MinReturn : -60.98762512207031\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1102200\n",
            "TimeSinceStart : 1166.880117893219\n",
            "Training Loss : -0.07519496977329254\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 22 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -29.85912322998047\n",
            "Eval_StdReturn : 15.653413772583008\n",
            "Eval_MaxReturn : -14.082802772521973\n",
            "Eval_MinReturn : -51.19625473022461\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -14.591501235961914\n",
            "Train_StdReturn : 14.821085929870605\n",
            "Train_MaxReturn : 37.344581604003906\n",
            "Train_MinReturn : -80.67173767089844\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1152300\n",
            "TimeSinceStart : 1220.5009908676147\n",
            "Training Loss : -0.06835521012544632\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 23 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -11.703071594238281\n",
            "Eval_StdReturn : 16.608169555664062\n",
            "Eval_MaxReturn : 10.463775634765625\n",
            "Eval_MinReturn : -29.511085510253906\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -14.247572898864746\n",
            "Train_StdReturn : 13.694234848022461\n",
            "Train_MaxReturn : 33.14556884765625\n",
            "Train_MinReturn : -52.258934020996094\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1202400\n",
            "TimeSinceStart : 1274.455186843872\n",
            "Training Loss : -0.05731615051627159\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 24 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -0.5508206486701965\n",
            "Eval_StdReturn : 2.229882001876831\n",
            "Eval_MaxReturn : 2.5260019302368164\n",
            "Eval_MinReturn : -2.687924385070801\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -10.52428150177002\n",
            "Train_StdReturn : 14.50926399230957\n",
            "Train_MaxReturn : 27.52851104736328\n",
            "Train_MinReturn : -64.40290832519531\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1252500\n",
            "TimeSinceStart : 1327.832601070404\n",
            "Training Loss : -0.0431884340941906\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 25 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : -10.271069526672363\n",
            "Eval_StdReturn : 7.277187347412109\n",
            "Eval_MaxReturn : -4.764819145202637\n",
            "Eval_MinReturn : -20.55394172668457\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -7.458038330078125\n",
            "Train_StdReturn : 15.055821418762207\n",
            "Train_MaxReturn : 48.504432678222656\n",
            "Train_MinReturn : -54.28508758544922\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1302600\n",
            "TimeSinceStart : 1381.531882762909\n",
            "Training Loss : -0.05247471481561661\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 26 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1.6359119415283203\n",
            "Eval_StdReturn : 11.9027099609375\n",
            "Eval_MaxReturn : 17.19350242614746\n",
            "Eval_MinReturn : -11.709100723266602\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -3.8799917697906494\n",
            "Train_StdReturn : 14.739903450012207\n",
            "Train_MaxReturn : 43.558563232421875\n",
            "Train_MinReturn : -58.903160095214844\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1352700\n",
            "TimeSinceStart : 1435.2260150909424\n",
            "Training Loss : -0.06519383937120438\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 27 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 1.2695497274398804\n",
            "Eval_StdReturn : 16.10569953918457\n",
            "Eval_MaxReturn : 21.633474349975586\n",
            "Eval_MinReturn : -17.748319625854492\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : -1.8989850282669067\n",
            "Train_StdReturn : 14.272655487060547\n",
            "Train_MaxReturn : 49.218170166015625\n",
            "Train_MinReturn : -56.354557037353516\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1402800\n",
            "TimeSinceStart : 1488.6690511703491\n",
            "Training Loss : -0.05261089280247688\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 28 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 10.796844482421875\n",
            "Eval_StdReturn : 9.386089324951172\n",
            "Eval_MaxReturn : 20.76041030883789\n",
            "Eval_MinReturn : -1.780564308166504\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 0.40293172001838684\n",
            "Train_StdReturn : 14.07505989074707\n",
            "Train_MaxReturn : 44.63507843017578\n",
            "Train_MinReturn : -42.96674346923828\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1452900\n",
            "TimeSinceStart : 1542.1411056518555\n",
            "Training Loss : -0.06221771240234375\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 29 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 3.0230872631073\n",
            "Eval_StdReturn : 6.896983623504639\n",
            "Eval_MaxReturn : 8.445208549499512\n",
            "Eval_MinReturn : -6.709585189819336\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 5.471782684326172\n",
            "Train_StdReturn : 15.005101203918457\n",
            "Train_MaxReturn : 42.18531799316406\n",
            "Train_MinReturn : -51.7163200378418\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1503000\n",
            "TimeSinceStart : 1595.8809974193573\n",
            "Training Loss : -0.059103235602378845\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 30 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 23.70176887512207\n",
            "Eval_StdReturn : 8.339552879333496\n",
            "Eval_MaxReturn : 29.87309455871582\n",
            "Eval_MinReturn : 11.912182807922363\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 8.670255661010742\n",
            "Train_StdReturn : 13.18112850189209\n",
            "Train_MaxReturn : 41.01617431640625\n",
            "Train_MinReturn : -38.78828048706055\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1553100\n",
            "TimeSinceStart : 1649.2192952632904\n",
            "Training Loss : -0.06218724325299263\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 31 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 29.270910263061523\n",
            "Eval_StdReturn : 8.691566467285156\n",
            "Eval_MaxReturn : 41.28595733642578\n",
            "Eval_MinReturn : 21.017505645751953\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 13.491883277893066\n",
            "Train_StdReturn : 15.769510269165039\n",
            "Train_MaxReturn : 51.294593811035156\n",
            "Train_MinReturn : -58.464698791503906\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1603200\n",
            "TimeSinceStart : 1702.8928546905518\n",
            "Training Loss : -0.053524699062108994\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 32 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 9.14868450164795\n",
            "Eval_StdReturn : 24.769441604614258\n",
            "Eval_MaxReturn : 42.69904327392578\n",
            "Eval_MinReturn : -16.348190307617188\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 19.317541122436523\n",
            "Train_StdReturn : 18.470338821411133\n",
            "Train_MaxReturn : 62.51187515258789\n",
            "Train_MinReturn : -45.93943786621094\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1653300\n",
            "TimeSinceStart : 1756.3332884311676\n",
            "Training Loss : -0.0749116837978363\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 33 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 32.368927001953125\n",
            "Eval_StdReturn : 4.644591808319092\n",
            "Eval_MaxReturn : 38.920654296875\n",
            "Eval_MinReturn : 28.687469482421875\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 26.37032127380371\n",
            "Train_StdReturn : 19.736745834350586\n",
            "Train_MaxReturn : 72.913330078125\n",
            "Train_MinReturn : -48.26506042480469\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1703400\n",
            "TimeSinceStart : 1809.26571726799\n",
            "Training Loss : -0.07229211181402206\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 34 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 42.327701568603516\n",
            "Eval_StdReturn : 21.2579288482666\n",
            "Eval_MaxReturn : 71.91182708740234\n",
            "Eval_MinReturn : 22.905954360961914\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 30.184091567993164\n",
            "Train_StdReturn : 21.21990394592285\n",
            "Train_MaxReturn : 75.20146179199219\n",
            "Train_MinReturn : -63.95188903808594\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1753500\n",
            "TimeSinceStart : 1862.2019124031067\n",
            "Training Loss : -0.06325504183769226\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 35 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 4.405892848968506\n",
            "Eval_StdReturn : 28.994468688964844\n",
            "Eval_MaxReturn : 41.090354919433594\n",
            "Eval_MinReturn : -29.801597595214844\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 38.10877227783203\n",
            "Train_StdReturn : 20.502552032470703\n",
            "Train_MaxReturn : 82.71460723876953\n",
            "Train_MinReturn : -34.68755340576172\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1803600\n",
            "TimeSinceStart : 1915.3171908855438\n",
            "Training Loss : -0.0780685618519783\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 36 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 67.87423706054688\n",
            "Eval_StdReturn : 5.670217514038086\n",
            "Eval_MaxReturn : 75.89263916015625\n",
            "Eval_MinReturn : 63.78791809082031\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 46.43147659301758\n",
            "Train_StdReturn : 21.584665298461914\n",
            "Train_MaxReturn : 94.12236022949219\n",
            "Train_MinReturn : -46.11835479736328\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1853700\n",
            "TimeSinceStart : 1968.7856786251068\n",
            "Training Loss : -0.06847109645605087\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 37 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 47.53706741333008\n",
            "Eval_StdReturn : 12.474555015563965\n",
            "Eval_MaxReturn : 58.56943130493164\n",
            "Eval_MinReturn : 30.09876251220703\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 49.27153015136719\n",
            "Train_StdReturn : 22.16775131225586\n",
            "Train_MaxReturn : 105.5805892944336\n",
            "Train_MinReturn : -33.63899612426758\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1903800\n",
            "TimeSinceStart : 2022.1618094444275\n",
            "Training Loss : -0.06985978037118912\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 38 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 54.80573654174805\n",
            "Eval_StdReturn : 11.563250541687012\n",
            "Eval_MaxReturn : 70.31500244140625\n",
            "Eval_MinReturn : 42.561100006103516\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 51.92000198364258\n",
            "Train_StdReturn : 19.825178146362305\n",
            "Train_MaxReturn : 93.9096908569336\n",
            "Train_MinReturn : -18.096843719482422\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 1953900\n",
            "TimeSinceStart : 2075.59171295166\n",
            "Training Loss : -0.06378795951604843\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 39 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 51.2379150390625\n",
            "Eval_StdReturn : 16.851369857788086\n",
            "Eval_MaxReturn : 74.95738220214844\n",
            "Eval_MinReturn : 37.37989807128906\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 59.4052734375\n",
            "Train_StdReturn : 21.790178298950195\n",
            "Train_MaxReturn : 109.82394409179688\n",
            "Train_MinReturn : -23.703046798706055\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2004000\n",
            "TimeSinceStart : 2129.115845680237\n",
            "Training Loss : -0.07446006685495377\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 40 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 76.81705474853516\n",
            "Eval_StdReturn : 18.971731185913086\n",
            "Eval_MaxReturn : 96.63177490234375\n",
            "Eval_MinReturn : 51.24372482299805\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 66.67144012451172\n",
            "Train_StdReturn : 22.25101089477539\n",
            "Train_MaxReturn : 112.88603210449219\n",
            "Train_MinReturn : -32.43439865112305\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2054100\n",
            "TimeSinceStart : 2181.9449684619904\n",
            "Training Loss : -0.0452779121696949\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 41 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 58.74699401855469\n",
            "Eval_StdReturn : 17.47565269470215\n",
            "Eval_MaxReturn : 74.13243103027344\n",
            "Eval_MinReturn : 34.30423355102539\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 65.80687713623047\n",
            "Train_StdReturn : 28.330495834350586\n",
            "Train_MaxReturn : 117.71282958984375\n",
            "Train_MinReturn : -48.22206115722656\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2104200\n",
            "TimeSinceStart : 2235.2557334899902\n",
            "Training Loss : -0.06028958782553673\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 42 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 67.82595825195312\n",
            "Eval_StdReturn : 3.7328052520751953\n",
            "Eval_MaxReturn : 73.0617904663086\n",
            "Eval_MinReturn : 64.62471771240234\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 74.40049743652344\n",
            "Train_StdReturn : 25.417570114135742\n",
            "Train_MaxReturn : 127.52425384521484\n",
            "Train_MinReturn : -22.6046142578125\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2154300\n",
            "TimeSinceStart : 2288.3234603405\n",
            "Training Loss : -0.05718989670276642\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 43 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 97.53824615478516\n",
            "Eval_StdReturn : 5.790187835693359\n",
            "Eval_MaxReturn : 105.4558334350586\n",
            "Eval_MinReturn : 91.77023315429688\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 74.2254409790039\n",
            "Train_StdReturn : 24.2125186920166\n",
            "Train_MaxReturn : 132.29385375976562\n",
            "Train_MinReturn : -11.445075988769531\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2204400\n",
            "TimeSinceStart : 2341.1094596385956\n",
            "Training Loss : -0.045464735478162766\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 44 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 49.86728286743164\n",
            "Eval_StdReturn : 5.7190446853637695\n",
            "Eval_MaxReturn : 55.841156005859375\n",
            "Eval_MinReturn : 42.15850067138672\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 77.0082015991211\n",
            "Train_StdReturn : 26.40191650390625\n",
            "Train_MaxReturn : 151.65914916992188\n",
            "Train_MinReturn : -23.682491302490234\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2254500\n",
            "TimeSinceStart : 2394.271096229553\n",
            "Training Loss : -0.04573141783475876\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 45 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 77.5432357788086\n",
            "Eval_StdReturn : 6.281225681304932\n",
            "Eval_MaxReturn : 83.30236053466797\n",
            "Eval_MinReturn : 68.80662536621094\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 74.8824691772461\n",
            "Train_StdReturn : 27.026994705200195\n",
            "Train_MaxReturn : 127.29151916503906\n",
            "Train_MinReturn : -30.266647338867188\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2304600\n",
            "TimeSinceStart : 2447.352567911148\n",
            "Training Loss : -0.06684087961912155\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 46 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 99.0234375\n",
            "Eval_StdReturn : 14.593738555908203\n",
            "Eval_MaxReturn : 118.193603515625\n",
            "Eval_MinReturn : 82.81684875488281\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 78.5913314819336\n",
            "Train_StdReturn : 20.47681427001953\n",
            "Train_MaxReturn : 131.86880493164062\n",
            "Train_MinReturn : 1.358846664428711\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2354700\n",
            "TimeSinceStart : 2500.3822963237762\n",
            "Training Loss : -0.03466576710343361\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 47 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 96.1395034790039\n",
            "Eval_StdReturn : 16.603464126586914\n",
            "Eval_MaxReturn : 108.31319427490234\n",
            "Eval_MinReturn : 72.66405487060547\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 87.8311767578125\n",
            "Train_StdReturn : 20.157730102539062\n",
            "Train_MaxReturn : 135.4364013671875\n",
            "Train_MinReturn : 10.877233505249023\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2404800\n",
            "TimeSinceStart : 2553.322557926178\n",
            "Training Loss : -0.06528535485267639\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 48 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 101.75101470947266\n",
            "Eval_StdReturn : 13.614253997802734\n",
            "Eval_MaxReturn : 115.12879943847656\n",
            "Eval_MinReturn : 83.07054138183594\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 84.58150482177734\n",
            "Train_StdReturn : 20.924592971801758\n",
            "Train_MaxReturn : 136.79507446289062\n",
            "Train_MinReturn : 15.012004852294922\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2454900\n",
            "TimeSinceStart : 2606.5405809879303\n",
            "Training Loss : -0.048961933702230453\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 49 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 110.71060180664062\n",
            "Eval_StdReturn : 5.189715385437012\n",
            "Eval_MaxReturn : 117.54991149902344\n",
            "Eval_MinReturn : 104.98495483398438\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 101.98250579833984\n",
            "Train_StdReturn : 22.223039627075195\n",
            "Train_MaxReturn : 145.79751586914062\n",
            "Train_MinReturn : 12.065718650817871\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2505000\n",
            "TimeSinceStart : 2659.390879392624\n",
            "Training Loss : -0.061854708939790726\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 50 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 117.61751556396484\n",
            "Eval_StdReturn : 10.818814277648926\n",
            "Eval_MaxReturn : 125.44086456298828\n",
            "Eval_MinReturn : 102.31871032714844\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 99.05885314941406\n",
            "Train_StdReturn : 24.984874725341797\n",
            "Train_MaxReturn : 148.66650390625\n",
            "Train_MinReturn : -3.374490261077881\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2555100\n",
            "TimeSinceStart : 2712.1864125728607\n",
            "Training Loss : -0.04362732172012329\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 51 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 116.05169677734375\n",
            "Eval_StdReturn : 5.8929877281188965\n",
            "Eval_MaxReturn : 122.22534942626953\n",
            "Eval_MinReturn : 108.11662292480469\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 104.17754364013672\n",
            "Train_StdReturn : 26.885766983032227\n",
            "Train_MaxReturn : 153.47201538085938\n",
            "Train_MinReturn : -49.57499694824219\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2605200\n",
            "TimeSinceStart : 2765.1147763729095\n",
            "Training Loss : -0.043796736747026443\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 52 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 96.6186294555664\n",
            "Eval_StdReturn : 5.795628547668457\n",
            "Eval_MaxReturn : 104.39695739746094\n",
            "Eval_MinReturn : 90.49179077148438\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 107.99620819091797\n",
            "Train_StdReturn : 22.18780517578125\n",
            "Train_MaxReturn : 169.37112426757812\n",
            "Train_MinReturn : 3.478219985961914\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2655300\n",
            "TimeSinceStart : 2817.9131469726562\n",
            "Training Loss : -0.06292075663805008\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 53 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 129.40756225585938\n",
            "Eval_StdReturn : 16.975170135498047\n",
            "Eval_MaxReturn : 149.3538818359375\n",
            "Eval_MinReturn : 107.8653564453125\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 106.3207778930664\n",
            "Train_StdReturn : 24.036312103271484\n",
            "Train_MaxReturn : 161.76756286621094\n",
            "Train_MinReturn : 13.624354362487793\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2705400\n",
            "TimeSinceStart : 2870.8167521953583\n",
            "Training Loss : -0.042450178414583206\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 54 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 117.48394012451172\n",
            "Eval_StdReturn : 3.828845977783203\n",
            "Eval_MaxReturn : 122.8390121459961\n",
            "Eval_MinReturn : 114.11178588867188\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 109.2728271484375\n",
            "Train_StdReturn : 28.117023468017578\n",
            "Train_MaxReturn : 171.6660614013672\n",
            "Train_MinReturn : -15.61574935913086\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2755500\n",
            "TimeSinceStart : 2923.603535890579\n",
            "Training Loss : -0.043676115572452545\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 55 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 114.70738983154297\n",
            "Eval_StdReturn : 12.864241600036621\n",
            "Eval_MaxReturn : 131.03414916992188\n",
            "Eval_MinReturn : 99.59341430664062\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 99.1241226196289\n",
            "Train_StdReturn : 38.0752067565918\n",
            "Train_MaxReturn : 163.81442260742188\n",
            "Train_MinReturn : -44.64570999145508\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2805600\n",
            "TimeSinceStart : 2976.5984687805176\n",
            "Training Loss : -0.04412959888577461\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 56 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 103.8388900756836\n",
            "Eval_StdReturn : 24.865562438964844\n",
            "Eval_MaxReturn : 123.31842041015625\n",
            "Eval_MinReturn : 68.74453735351562\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 102.35595703125\n",
            "Train_StdReturn : 33.548011779785156\n",
            "Train_MaxReturn : 155.25717163085938\n",
            "Train_MinReturn : -29.32434844970703\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2855700\n",
            "TimeSinceStart : 3029.3530938625336\n",
            "Training Loss : -0.032623205333948135\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 57 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 122.83040618896484\n",
            "Eval_StdReturn : 6.4517598152160645\n",
            "Eval_MaxReturn : 131.410888671875\n",
            "Eval_MinReturn : 115.8532943725586\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 111.38208770751953\n",
            "Train_StdReturn : 24.327566146850586\n",
            "Train_MaxReturn : 166.728271484375\n",
            "Train_MinReturn : -45.643348693847656\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2905800\n",
            "TimeSinceStart : 3081.924793958664\n",
            "Training Loss : -0.01793738082051277\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 58 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 91.06136322021484\n",
            "Eval_StdReturn : 34.53570556640625\n",
            "Eval_MaxReturn : 118.57870483398438\n",
            "Eval_MinReturn : 42.357460021972656\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 105.33172607421875\n",
            "Train_StdReturn : 21.99773597717285\n",
            "Train_MaxReturn : 161.91184997558594\n",
            "Train_MinReturn : 32.8145866394043\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 2955900\n",
            "TimeSinceStart : 3134.543297290802\n",
            "Training Loss : -0.029853813350200653\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 59 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 122.54581451416016\n",
            "Eval_StdReturn : 8.118742942810059\n",
            "Eval_MaxReturn : 130.43479919433594\n",
            "Eval_MinReturn : 111.37678527832031\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 103.49556732177734\n",
            "Train_StdReturn : 24.07556915283203\n",
            "Train_MaxReturn : 154.32449340820312\n",
            "Train_MinReturn : -22.053607940673828\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3006000\n",
            "TimeSinceStart : 3187.3669033050537\n",
            "Training Loss : -0.03695553168654442\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 60 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 142.0359344482422\n",
            "Eval_StdReturn : 18.406124114990234\n",
            "Eval_MaxReturn : 160.31338500976562\n",
            "Eval_MinReturn : 116.84637451171875\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 116.57337951660156\n",
            "Train_StdReturn : 22.99466323852539\n",
            "Train_MaxReturn : 168.9820098876953\n",
            "Train_MinReturn : 13.604665756225586\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3056100\n",
            "TimeSinceStart : 3240.146378517151\n",
            "Training Loss : -0.03936618193984032\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 61 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 133.32655334472656\n",
            "Eval_StdReturn : 27.53929328918457\n",
            "Eval_MaxReturn : 163.1204833984375\n",
            "Eval_MinReturn : 96.70724487304688\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 132.4738311767578\n",
            "Train_StdReturn : 17.960636138916016\n",
            "Train_MaxReturn : 186.79640197753906\n",
            "Train_MinReturn : 67.1485366821289\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3106200\n",
            "TimeSinceStart : 3292.6492953300476\n",
            "Training Loss : -0.049627017229795456\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 62 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 141.4370880126953\n",
            "Eval_StdReturn : 7.1389570236206055\n",
            "Eval_MaxReturn : 151.34385681152344\n",
            "Eval_MinReturn : 134.79876708984375\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 136.4173126220703\n",
            "Train_StdReturn : 18.96306610107422\n",
            "Train_MaxReturn : 179.72543334960938\n",
            "Train_MinReturn : 38.11445617675781\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3156300\n",
            "TimeSinceStart : 3345.2985606193542\n",
            "Training Loss : -0.04128535836935043\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 63 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 137.23509216308594\n",
            "Eval_StdReturn : 11.960655212402344\n",
            "Eval_MaxReturn : 153.79791259765625\n",
            "Eval_MinReturn : 125.98036193847656\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 137.82611083984375\n",
            "Train_StdReturn : 18.033613204956055\n",
            "Train_MaxReturn : 179.1971435546875\n",
            "Train_MinReturn : 61.87712478637695\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3206400\n",
            "TimeSinceStart : 3397.9408569335938\n",
            "Training Loss : -0.04244706779718399\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 64 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 137.33009338378906\n",
            "Eval_StdReturn : 10.412686347961426\n",
            "Eval_MaxReturn : 151.9744415283203\n",
            "Eval_MinReturn : 128.66876220703125\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 133.36325073242188\n",
            "Train_StdReturn : 15.451666831970215\n",
            "Train_MaxReturn : 172.5948486328125\n",
            "Train_MinReturn : 89.38706970214844\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3256500\n",
            "TimeSinceStart : 3451.0592789649963\n",
            "Training Loss : -0.0425962433218956\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 65 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 151.65414428710938\n",
            "Eval_StdReturn : 14.666264533996582\n",
            "Eval_MaxReturn : 162.52288818359375\n",
            "Eval_MinReturn : 130.9210205078125\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 131.99501037597656\n",
            "Train_StdReturn : 17.342557907104492\n",
            "Train_MaxReturn : 177.2812042236328\n",
            "Train_MinReturn : 73.8775405883789\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3306600\n",
            "TimeSinceStart : 3503.9652619361877\n",
            "Training Loss : -0.04454099014401436\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 66 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 148.9603729248047\n",
            "Eval_StdReturn : 11.74689769744873\n",
            "Eval_MaxReturn : 165.51071166992188\n",
            "Eval_MinReturn : 139.44061279296875\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 140.8468780517578\n",
            "Train_StdReturn : 20.646282196044922\n",
            "Train_MaxReturn : 194.9734344482422\n",
            "Train_MinReturn : 56.6578369140625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3356700\n",
            "TimeSinceStart : 3556.8455522060394\n",
            "Training Loss : -0.03162846341729164\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 67 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 148.4286346435547\n",
            "Eval_StdReturn : 17.198827743530273\n",
            "Eval_MaxReturn : 167.94174194335938\n",
            "Eval_MinReturn : 126.09716796875\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 148.27418518066406\n",
            "Train_StdReturn : 22.420209884643555\n",
            "Train_MaxReturn : 200.9058837890625\n",
            "Train_MinReturn : 59.770626068115234\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3406800\n",
            "TimeSinceStart : 3610.0679779052734\n",
            "Training Loss : -0.030715566128492355\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 68 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 154.00108337402344\n",
            "Eval_StdReturn : 16.855907440185547\n",
            "Eval_MaxReturn : 176.6953125\n",
            "Eval_MinReturn : 136.33642578125\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 146.29818725585938\n",
            "Train_StdReturn : 21.39133071899414\n",
            "Train_MaxReturn : 192.66868591308594\n",
            "Train_MinReturn : 76.21871185302734\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3456900\n",
            "TimeSinceStart : 3663.3283154964447\n",
            "Training Loss : -0.03671884909272194\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 69 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 152.4983367919922\n",
            "Eval_StdReturn : 23.30158805847168\n",
            "Eval_MaxReturn : 170.61256408691406\n",
            "Eval_MinReturn : 119.60108947753906\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 148.84178161621094\n",
            "Train_StdReturn : 20.763601303100586\n",
            "Train_MaxReturn : 199.11679077148438\n",
            "Train_MinReturn : 75.35047149658203\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3507000\n",
            "TimeSinceStart : 3716.2719583511353\n",
            "Training Loss : -0.030250895768404007\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 70 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 149.02186584472656\n",
            "Eval_StdReturn : 5.934826374053955\n",
            "Eval_MaxReturn : 153.4222869873047\n",
            "Eval_MinReturn : 140.63211059570312\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 143.91134643554688\n",
            "Train_StdReturn : 20.767555236816406\n",
            "Train_MaxReturn : 195.70620727539062\n",
            "Train_MinReturn : 63.23357009887695\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3557100\n",
            "TimeSinceStart : 3769.178382396698\n",
            "Training Loss : -0.037831105291843414\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 71 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 125.50619506835938\n",
            "Eval_StdReturn : 21.1678466796875\n",
            "Eval_MaxReturn : 155.41033935546875\n",
            "Eval_MinReturn : 109.36105346679688\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 144.44802856445312\n",
            "Train_StdReturn : 22.076248168945312\n",
            "Train_MaxReturn : 188.3876953125\n",
            "Train_MinReturn : 15.690800666809082\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3607200\n",
            "TimeSinceStart : 3821.9862332344055\n",
            "Training Loss : -0.02488180436193943\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 72 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 159.58021545410156\n",
            "Eval_StdReturn : 14.492591857910156\n",
            "Eval_MaxReturn : 170.58982849121094\n",
            "Eval_MinReturn : 139.10397338867188\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 144.48263549804688\n",
            "Train_StdReturn : 24.77657699584961\n",
            "Train_MaxReturn : 197.1171875\n",
            "Train_MinReturn : 24.973569869995117\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3657300\n",
            "TimeSinceStart : 3875.0289211273193\n",
            "Training Loss : -0.011441652663052082\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 73 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 150.3323974609375\n",
            "Eval_StdReturn : 12.456840515136719\n",
            "Eval_MaxReturn : 167.87179565429688\n",
            "Eval_MinReturn : 140.1356201171875\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 149.70680236816406\n",
            "Train_StdReturn : 21.32421875\n",
            "Train_MaxReturn : 208.51683044433594\n",
            "Train_MinReturn : 16.772586822509766\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3707400\n",
            "TimeSinceStart : 3928.286370038986\n",
            "Training Loss : -0.02396283857524395\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 74 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 144.5880126953125\n",
            "Eval_StdReturn : 15.887426376342773\n",
            "Eval_MaxReturn : 166.19662475585938\n",
            "Eval_MinReturn : 128.4530029296875\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 155.1582489013672\n",
            "Train_StdReturn : 22.649904251098633\n",
            "Train_MaxReturn : 208.39593505859375\n",
            "Train_MinReturn : 20.0031795501709\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3757500\n",
            "TimeSinceStart : 3981.4235854148865\n",
            "Training Loss : -0.03045606054365635\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 75 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 147.56951904296875\n",
            "Eval_StdReturn : 13.259050369262695\n",
            "Eval_MaxReturn : 166.32034301757812\n",
            "Eval_MinReturn : 138.10218811035156\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 150.49386596679688\n",
            "Train_StdReturn : 25.6434268951416\n",
            "Train_MaxReturn : 199.9464111328125\n",
            "Train_MinReturn : 40.44758605957031\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3807600\n",
            "TimeSinceStart : 4034.601161003113\n",
            "Training Loss : -0.019745033234357834\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 76 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 158.52870178222656\n",
            "Eval_StdReturn : 2.866194248199463\n",
            "Eval_MaxReturn : 162.36996459960938\n",
            "Eval_MinReturn : 155.4873046875\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 144.83067321777344\n",
            "Train_StdReturn : 32.40110778808594\n",
            "Train_MaxReturn : 209.90737915039062\n",
            "Train_MinReturn : 24.686397552490234\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3857700\n",
            "TimeSinceStart : 4087.5966017246246\n",
            "Training Loss : -0.017354222014546394\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 77 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 130.2313995361328\n",
            "Eval_StdReturn : 22.026992797851562\n",
            "Eval_MaxReturn : 146.8699188232422\n",
            "Eval_MinReturn : 99.10528564453125\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 148.07997131347656\n",
            "Train_StdReturn : 31.185958862304688\n",
            "Train_MaxReturn : 215.0178985595703\n",
            "Train_MinReturn : -9.189729690551758\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3907800\n",
            "TimeSinceStart : 4140.443936347961\n",
            "Training Loss : -0.03616493195295334\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 78 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 151.0136260986328\n",
            "Eval_StdReturn : 19.436046600341797\n",
            "Eval_MaxReturn : 173.93228149414062\n",
            "Eval_MinReturn : 126.41309356689453\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 149.08944702148438\n",
            "Train_StdReturn : 29.115549087524414\n",
            "Train_MaxReturn : 201.21896362304688\n",
            "Train_MinReturn : -41.84228515625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 3957900\n",
            "TimeSinceStart : 4193.264492034912\n",
            "Training Loss : -0.02852976880967617\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 79 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 123.96185302734375\n",
            "Eval_StdReturn : 36.63460922241211\n",
            "Eval_MaxReturn : 151.01512145996094\n",
            "Eval_MinReturn : 72.169921875\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 140.3514862060547\n",
            "Train_StdReturn : 25.290260314941406\n",
            "Train_MaxReturn : 202.26031494140625\n",
            "Train_MinReturn : -37.15248107910156\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4008000\n",
            "TimeSinceStart : 4245.911377668381\n",
            "Training Loss : -0.032668568193912506\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 80 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 148.44300842285156\n",
            "Eval_StdReturn : 29.738300323486328\n",
            "Eval_MaxReturn : 181.0825653076172\n",
            "Eval_MinReturn : 109.15489959716797\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 133.28616333007812\n",
            "Train_StdReturn : 23.314353942871094\n",
            "Train_MaxReturn : 190.44764709472656\n",
            "Train_MinReturn : 31.853084564208984\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4058100\n",
            "TimeSinceStart : 4298.813350439072\n",
            "Training Loss : -0.03909097611904144\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 81 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 136.03228759765625\n",
            "Eval_StdReturn : 3.726351022720337\n",
            "Eval_MaxReturn : 138.69747924804688\n",
            "Eval_MinReturn : 130.76254272460938\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 141.62771606445312\n",
            "Train_StdReturn : 20.559743881225586\n",
            "Train_MaxReturn : 192.2723846435547\n",
            "Train_MinReturn : 31.754302978515625\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4108200\n",
            "TimeSinceStart : 4351.634772777557\n",
            "Training Loss : -0.02630702406167984\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 82 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 146.86521911621094\n",
            "Eval_StdReturn : 17.524032592773438\n",
            "Eval_MaxReturn : 167.77816772460938\n",
            "Eval_MinReturn : 124.89249420166016\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 148.70721435546875\n",
            "Train_StdReturn : 20.979171752929688\n",
            "Train_MaxReturn : 201.818115234375\n",
            "Train_MinReturn : 34.50991439819336\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4158300\n",
            "TimeSinceStart : 4404.451201438904\n",
            "Training Loss : -0.029889477416872978\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 83 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 149.5903778076172\n",
            "Eval_StdReturn : 15.589585304260254\n",
            "Eval_MaxReturn : 164.77340698242188\n",
            "Eval_MinReturn : 128.1547393798828\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 138.4543914794922\n",
            "Train_StdReturn : 24.493005752563477\n",
            "Train_MaxReturn : 188.25318908691406\n",
            "Train_MinReturn : 13.846867561340332\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4208400\n",
            "TimeSinceStart : 4457.523434877396\n",
            "Training Loss : -0.026535771787166595\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 84 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 165.92417907714844\n",
            "Eval_StdReturn : 10.215848922729492\n",
            "Eval_MaxReturn : 180.28543090820312\n",
            "Eval_MinReturn : 157.3792724609375\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 148.90975952148438\n",
            "Train_StdReturn : 19.48621940612793\n",
            "Train_MaxReturn : 190.96023559570312\n",
            "Train_MinReturn : 65.6130599975586\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4258500\n",
            "TimeSinceStart : 4510.092963695526\n",
            "Training Loss : -0.02680116891860962\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 85 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 134.6342315673828\n",
            "Eval_StdReturn : 7.0903167724609375\n",
            "Eval_MaxReturn : 144.54563903808594\n",
            "Eval_MinReturn : 128.3624725341797\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 140.57179260253906\n",
            "Train_StdReturn : 22.414831161499023\n",
            "Train_MaxReturn : 191.57867431640625\n",
            "Train_MinReturn : 50.94392395019531\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4308600\n",
            "TimeSinceStart : 4563.065616130829\n",
            "Training Loss : -0.005642482079565525\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 86 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 117.06832122802734\n",
            "Eval_StdReturn : 21.15186882019043\n",
            "Eval_MaxReturn : 139.22509765625\n",
            "Eval_MinReturn : 88.58561706542969\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 122.43733978271484\n",
            "Train_StdReturn : 25.75628089904785\n",
            "Train_MaxReturn : 183.1030731201172\n",
            "Train_MinReturn : -17.03510093688965\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4358700\n",
            "TimeSinceStart : 4616.155167579651\n",
            "Training Loss : -0.02710665576159954\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 87 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 146.0509796142578\n",
            "Eval_StdReturn : 23.66654396057129\n",
            "Eval_MaxReturn : 178.06317138671875\n",
            "Eval_MinReturn : 121.5848159790039\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 141.3677520751953\n",
            "Train_StdReturn : 21.908451080322266\n",
            "Train_MaxReturn : 195.2677001953125\n",
            "Train_MinReturn : 56.87017059326172\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4408800\n",
            "TimeSinceStart : 4668.997970342636\n",
            "Training Loss : -0.020658522844314575\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 88 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 159.69667053222656\n",
            "Eval_StdReturn : 5.523195266723633\n",
            "Eval_MaxReturn : 164.94851684570312\n",
            "Eval_MinReturn : 152.06353759765625\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 151.39501953125\n",
            "Train_StdReturn : 20.24465560913086\n",
            "Train_MaxReturn : 200.10733032226562\n",
            "Train_MinReturn : 79.6072998046875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4458900\n",
            "TimeSinceStart : 4721.7911014556885\n",
            "Training Loss : -0.02040550298988819\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 89 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 144.99607849121094\n",
            "Eval_StdReturn : 23.223142623901367\n",
            "Eval_MaxReturn : 172.14425659179688\n",
            "Eval_MinReturn : 115.41561889648438\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 151.24354553222656\n",
            "Train_StdReturn : 19.521259307861328\n",
            "Train_MaxReturn : 194.7347869873047\n",
            "Train_MinReturn : 28.614957809448242\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4509000\n",
            "TimeSinceStart : 4775.114557504654\n",
            "Training Loss : -0.034323398023843765\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 90 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 146.41970825195312\n",
            "Eval_StdReturn : 4.411900520324707\n",
            "Eval_MaxReturn : 152.638427734375\n",
            "Eval_MinReturn : 142.87109375\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 157.528564453125\n",
            "Train_StdReturn : 20.831167221069336\n",
            "Train_MaxReturn : 207.31851196289062\n",
            "Train_MinReturn : 66.35467529296875\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4559100\n",
            "TimeSinceStart : 4828.050663232803\n",
            "Training Loss : -0.01794096641242504\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 91 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 149.0552215576172\n",
            "Eval_StdReturn : 15.334500312805176\n",
            "Eval_MaxReturn : 170.5775909423828\n",
            "Eval_MinReturn : 135.98944091796875\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 154.77879333496094\n",
            "Train_StdReturn : 24.254169464111328\n",
            "Train_MaxReturn : 199.49029541015625\n",
            "Train_MinReturn : 13.337653160095215\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4609200\n",
            "TimeSinceStart : 4880.775760412216\n",
            "Training Loss : -0.02009359374642372\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 92 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 165.32675170898438\n",
            "Eval_StdReturn : 18.211017608642578\n",
            "Eval_MaxReturn : 183.56842041015625\n",
            "Eval_MinReturn : 140.4613037109375\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 160.11801147460938\n",
            "Train_StdReturn : 21.033672332763672\n",
            "Train_MaxReturn : 211.70294189453125\n",
            "Train_MinReturn : 59.02189636230469\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4659300\n",
            "TimeSinceStart : 4933.739176273346\n",
            "Training Loss : -0.02402395009994507\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 93 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 170.31988525390625\n",
            "Eval_StdReturn : 4.955552577972412\n",
            "Eval_MaxReturn : 177.30250549316406\n",
            "Eval_MinReturn : 166.31039428710938\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 165.19534301757812\n",
            "Train_StdReturn : 19.833404541015625\n",
            "Train_MaxReturn : 205.16824340820312\n",
            "Train_MinReturn : -22.096342086791992\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4709400\n",
            "TimeSinceStart : 4986.351166009903\n",
            "Training Loss : -0.011993716470897198\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 94 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 156.4345245361328\n",
            "Eval_StdReturn : 7.206175804138184\n",
            "Eval_MaxReturn : 166.5489044189453\n",
            "Eval_MinReturn : 150.29656982421875\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 155.5322723388672\n",
            "Train_StdReturn : 25.53343391418457\n",
            "Train_MaxReturn : 221.91610717773438\n",
            "Train_MinReturn : 15.298025131225586\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4759500\n",
            "TimeSinceStart : 5039.133466005325\n",
            "Training Loss : -0.011096959933638573\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 95 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 161.47393798828125\n",
            "Eval_StdReturn : 7.022659778594971\n",
            "Eval_MaxReturn : 167.65048217773438\n",
            "Eval_MinReturn : 151.65036010742188\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 156.0398406982422\n",
            "Train_StdReturn : 24.160293579101562\n",
            "Train_MaxReturn : 213.07760620117188\n",
            "Train_MinReturn : 7.603487491607666\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4809600\n",
            "TimeSinceStart : 5092.086438894272\n",
            "Training Loss : -0.008892940357327461\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 96 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 173.5432891845703\n",
            "Eval_StdReturn : 20.321041107177734\n",
            "Eval_MaxReturn : 196.22341918945312\n",
            "Eval_MinReturn : 146.91839599609375\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 157.50738525390625\n",
            "Train_StdReturn : 24.79648208618164\n",
            "Train_MaxReturn : 207.73712158203125\n",
            "Train_MinReturn : -16.903417587280273\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4859700\n",
            "TimeSinceStart : 5144.845423460007\n",
            "Training Loss : -0.023555360734462738\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 97 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 163.21145629882812\n",
            "Eval_StdReturn : 9.643844604492188\n",
            "Eval_MaxReturn : 175.36282348632812\n",
            "Eval_MinReturn : 151.7725830078125\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 159.4727783203125\n",
            "Train_StdReturn : 19.363121032714844\n",
            "Train_MaxReturn : 207.72393798828125\n",
            "Train_MinReturn : 52.947021484375\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4909800\n",
            "TimeSinceStart : 5197.990601062775\n",
            "Training Loss : -0.028594011440873146\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 98 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 156.3939208984375\n",
            "Eval_StdReturn : 17.581392288208008\n",
            "Eval_MaxReturn : 175.26828002929688\n",
            "Eval_MinReturn : 132.93971252441406\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 159.54391479492188\n",
            "Train_StdReturn : 15.719330787658691\n",
            "Train_MaxReturn : 201.45333862304688\n",
            "Train_MinReturn : 97.8453140258789\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 4959900\n",
            "TimeSinceStart : 5250.962441444397\n",
            "Training Loss : -0.031359363347291946\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 99 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([50100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 161.64849853515625\n",
            "Eval_StdReturn : 25.922016143798828\n",
            "Eval_MaxReturn : 194.03005981445312\n",
            "Eval_MinReturn : 130.57476806640625\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 166.55674743652344\n",
            "Train_StdReturn : 15.743474006652832\n",
            "Train_MaxReturn : 203.45132446289062\n",
            "Train_MinReturn : 88.04843139648438\n",
            "Train_AverageEpLen : 150.0\n",
            "Train_EnvstepsSoFar : 5010000\n",
            "TimeSinceStart : 5303.684170484543\n",
            "Training Loss : -0.046907663345336914\n",
            "Initial_DataCollection_AverageReturn : -89.52372741699219\n",
            "Done logging...\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python cs285/scripts/run_hw2.py --env_name HalfCheetah-v2 --ep_len 150 \\\n",
        "--discount 0.95 -n 100 -l 2 -s 32 -b 50000 -lr 0.02 -rtg \\\n",
        "--exp_name q4_b50000_r02_rtg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lwYZZrOv9XuS"
      },
      "outputs": [],
      "source": [
        "!python cs285/scripts/run_hw2.py --env_name HalfCheetah-v2 --ep_len 150 \\\n",
        "--discount 0.95 -n 100 -l 2 -s 32 -b 50000 -lr 0.02 --nn_baseline \\\n",
        "--exp_name q4_b50000_r02_nnbaseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G9T2Dgjd9e6d"
      },
      "outputs": [],
      "source": [
        "# same one as rtg_nnbaseline\n",
        "!python cs285/scripts/run_hw2.py --env_name HalfCheetah-v2 --ep_len 150 \\\n",
        "--discount 0.95 -n 100 -l 2 -s 32 -b 50000 -lr 0.02 -rtg --nn_baseline \\\n",
        "--exp_name q4_b50000_r02_rtg_nnbaseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "kgs_LZ8m8zov",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "outputId": "154e247a-fe90-45ff-f264-2e3d59e76a9b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-ccaba131-dfaa-474d-b38b-70b20db0c595\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Iteration</th>\n",
              "      <th>Config</th>\n",
              "      <th>Train_EnvstepsSoFar</th>\n",
              "      <th>Eval_AverageReturn</th>\n",
              "      <th>Eval_AverageReturn_Smooth</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>b50000_r02</td>\n",
              "      <td>50100.0</td>\n",
              "      <td>-82.243935</td>\n",
              "      <td>-82.243935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>b50000_r02</td>\n",
              "      <td>100200.0</td>\n",
              "      <td>-110.943626</td>\n",
              "      <td>-102.743714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>b50000_r02</td>\n",
              "      <td>150300.0</td>\n",
              "      <td>-89.796867</td>\n",
              "      <td>-94.444454</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>b50000_r02</td>\n",
              "      <td>200400.0</td>\n",
              "      <td>-130.157242</td>\n",
              "      <td>-116.435087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>b50000_r02</td>\n",
              "      <td>250500.0</td>\n",
              "      <td>-101.655701</td>\n",
              "      <td>-107.475711</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>395</th>\n",
              "      <td>95</td>\n",
              "      <td>b50000_lr02_rtg_nnbaseline</td>\n",
              "      <td>4809600.0</td>\n",
              "      <td>137.258072</td>\n",
              "      <td>133.909599</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>396</th>\n",
              "      <td>96</td>\n",
              "      <td>b50000_lr02_rtg_nnbaseline</td>\n",
              "      <td>4859700.0</td>\n",
              "      <td>128.365143</td>\n",
              "      <td>130.582925</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>397</th>\n",
              "      <td>97</td>\n",
              "      <td>b50000_lr02_rtg_nnbaseline</td>\n",
              "      <td>4909800.0</td>\n",
              "      <td>104.644722</td>\n",
              "      <td>115.020003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>398</th>\n",
              "      <td>98</td>\n",
              "      <td>b50000_lr02_rtg_nnbaseline</td>\n",
              "      <td>4959900.0</td>\n",
              "      <td>143.491440</td>\n",
              "      <td>132.102865</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>399</th>\n",
              "      <td>99</td>\n",
              "      <td>b50000_lr02_rtg_nnbaseline</td>\n",
              "      <td>5010000.0</td>\n",
              "      <td>165.770981</td>\n",
              "      <td>152.303735</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>400 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ccaba131-dfaa-474d-b38b-70b20db0c595')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ccaba131-dfaa-474d-b38b-70b20db0c595 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ccaba131-dfaa-474d-b38b-70b20db0c595');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     Iteration  ... Eval_AverageReturn_Smooth\n",
              "0            0  ...                -82.243935\n",
              "1            1  ...               -102.743714\n",
              "2            2  ...                -94.444454\n",
              "3            3  ...               -116.435087\n",
              "4            4  ...               -107.475711\n",
              "..         ...  ...                       ...\n",
              "395         95  ...                133.909599\n",
              "396         96  ...                130.582925\n",
              "397         97  ...                115.020003\n",
              "398         98  ...                132.102865\n",
              "399         99  ...                152.303735\n",
              "\n",
              "[400 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ],
      "source": [
        "def read_q4_optimal_data():\n",
        "    full_data = pd.DataFrame()\n",
        "\n",
        "    for folder in os.listdir('data'):\n",
        "        split = folder.split('_')\n",
        "        if 'HalfCheetah-v2' in split and 'search' not in split:\n",
        "            config_list = split[split.index('q4')+1:split.index('HalfCheetah-v2')]\n",
        "            config = '_'.join(config_list)\n",
        "\n",
        "            logdir = os.path.join('data', folder, 'events*')\n",
        "            eventfile = glob.glob(logdir)[0]\n",
        "\n",
        "            X, Y = get_section_results(eventfile)\n",
        "            data = pd.DataFrame({'Iteration': range(len(X)), \n",
        "                                 'Config': np.repeat(config, len(X)), \n",
        "                                 'Train_EnvstepsSoFar': X, \n",
        "                                 'Eval_AverageReturn': Y})\n",
        "            data['Eval_AverageReturn_Smooth'] = data['Eval_AverageReturn'].ewm(alpha=0.6).mean()\n",
        "\n",
        "            full_data = pd.concat([full_data, data], axis=0, ignore_index=True)\n",
        "        \n",
        "    return full_data\n",
        "\n",
        "data_q4_optimal = read_q4_optimal_data()\n",
        "data_q4_optimal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "r1lup24A82-l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "f0aefe29-d16f-4c83-d949-3cd02a44a49f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fa4a074aa50>"
            ]
          },
          "metadata": {},
          "execution_count": 92
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x216 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.figure(figsize=figsize)\n",
        "sns.lineplot(data=data_q4_optimal, x='Iteration', y='Eval_AverageReturn_Smooth', hue='Config')\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fybtCZON880y"
      },
      "source": [
        "#Experiment 5 (Hopper-v2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Ks2SNQ5I9qdG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76271f22-7e37-497c-c617-bb44e2cb6b5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mLe flux de sortie a été tronqué et ne contient que les 5000 dernières lignes.\u001b[0m\n",
            "Train_AverageReturn : 101.3658218383789\n",
            "Train_StdReturn : 66.60111236572266\n",
            "Train_MaxReturn : 207.67022705078125\n",
            "Train_MinReturn : 20.300355911254883\n",
            "Train_AverageEpLen : 53.1025641025641\n",
            "Train_EnvstepsSoFar : 259078\n",
            "TimeSinceStart : 213.99264240264893\n",
            "Training Loss : -0.005714706145226955\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 128 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2016])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 133.71253967285156\n",
            "Eval_StdReturn : 60.90595245361328\n",
            "Eval_MaxReturn : 199.6595916748047\n",
            "Eval_MinReturn : 42.351871490478516\n",
            "Eval_AverageEpLen : 66.83333333333333\n",
            "Train_AverageReturn : 120.83549499511719\n",
            "Train_StdReturn : 67.71434783935547\n",
            "Train_MaxReturn : 214.1842498779297\n",
            "Train_MinReturn : 14.940618515014648\n",
            "Train_AverageEpLen : 61.09090909090909\n",
            "Train_EnvstepsSoFar : 261094\n",
            "TimeSinceStart : 215.58004593849182\n",
            "Training Loss : 0.0024344581179320812\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 129 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2071])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 176.83676147460938\n",
            "Eval_StdReturn : 40.422550201416016\n",
            "Eval_MaxReturn : 212.3878936767578\n",
            "Eval_MinReturn : 99.15877532958984\n",
            "Eval_AverageEpLen : 85.6\n",
            "Train_AverageReturn : 151.68812561035156\n",
            "Train_StdReturn : 56.909420013427734\n",
            "Train_MaxReturn : 213.74603271484375\n",
            "Train_MinReturn : 28.552278518676758\n",
            "Train_AverageEpLen : 73.96428571428571\n",
            "Train_EnvstepsSoFar : 263165\n",
            "TimeSinceStart : 217.20312452316284\n",
            "Training Loss : 0.01865771971642971\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 130 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2036])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 195.57516479492188\n",
            "Eval_StdReturn : 16.476505279541016\n",
            "Eval_MaxReturn : 224.85256958007812\n",
            "Eval_MinReturn : 173.67333984375\n",
            "Eval_AverageEpLen : 89.8\n",
            "Train_AverageReturn : 162.88995361328125\n",
            "Train_StdReturn : 55.4090461730957\n",
            "Train_MaxReturn : 216.26475524902344\n",
            "Train_MinReturn : 30.841276168823242\n",
            "Train_AverageEpLen : 78.3076923076923\n",
            "Train_EnvstepsSoFar : 265201\n",
            "TimeSinceStart : 218.8335702419281\n",
            "Training Loss : -0.0038768679369241\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 131 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2046])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 147.7768096923828\n",
            "Eval_StdReturn : 76.45879364013672\n",
            "Eval_MaxReturn : 219.63133239746094\n",
            "Eval_MinReturn : 24.69632339477539\n",
            "Eval_AverageEpLen : 71.83333333333333\n",
            "Train_AverageReturn : 192.3665008544922\n",
            "Train_StdReturn : 19.56680679321289\n",
            "Train_MaxReturn : 220.52598571777344\n",
            "Train_MinReturn : 116.34778594970703\n",
            "Train_AverageEpLen : 88.95652173913044\n",
            "Train_EnvstepsSoFar : 267247\n",
            "TimeSinceStart : 220.4735610485077\n",
            "Training Loss : -0.015007413923740387\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 132 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2063])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 196.29873657226562\n",
            "Eval_StdReturn : 9.512916564941406\n",
            "Eval_MaxReturn : 214.05838012695312\n",
            "Eval_MinReturn : 185.83668518066406\n",
            "Eval_AverageEpLen : 90.0\n",
            "Train_AverageReturn : 194.63108825683594\n",
            "Train_StdReturn : 29.842044830322266\n",
            "Train_MaxReturn : 217.76463317871094\n",
            "Train_MinReturn : 61.59423828125\n",
            "Train_AverageEpLen : 89.69565217391305\n",
            "Train_EnvstepsSoFar : 269310\n",
            "TimeSinceStart : 222.12072563171387\n",
            "Training Loss : -0.059573329985141754\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 133 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2048])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 202.967041015625\n",
            "Eval_StdReturn : 26.62618064880371\n",
            "Eval_MaxReturn : 237.18150329589844\n",
            "Eval_MinReturn : 155.08834838867188\n",
            "Eval_AverageEpLen : 94.8\n",
            "Train_AverageReturn : 193.23529052734375\n",
            "Train_StdReturn : 31.405214309692383\n",
            "Train_MaxReturn : 226.04641723632812\n",
            "Train_MinReturn : 58.9727668762207\n",
            "Train_AverageEpLen : 89.04347826086956\n",
            "Train_EnvstepsSoFar : 271358\n",
            "TimeSinceStart : 223.80732607841492\n",
            "Training Loss : -0.05700261890888214\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 134 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2015])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 196.8077850341797\n",
            "Eval_StdReturn : 14.156662940979004\n",
            "Eval_MaxReturn : 215.02783203125\n",
            "Eval_MinReturn : 171.763916015625\n",
            "Eval_AverageEpLen : 88.2\n",
            "Train_AverageReturn : 189.83424377441406\n",
            "Train_StdReturn : 34.38596725463867\n",
            "Train_MaxReturn : 217.77273559570312\n",
            "Train_MinReturn : 78.31849670410156\n",
            "Train_AverageEpLen : 87.6086956521739\n",
            "Train_EnvstepsSoFar : 273373\n",
            "TimeSinceStart : 225.41570591926575\n",
            "Training Loss : 0.008401460945606232\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 135 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2017])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 189.2078094482422\n",
            "Eval_StdReturn : 35.56563186645508\n",
            "Eval_MaxReturn : 223.06285095214844\n",
            "Eval_MinReturn : 130.97457885742188\n",
            "Eval_AverageEpLen : 89.4\n",
            "Train_AverageReturn : 199.5178985595703\n",
            "Train_StdReturn : 33.58192825317383\n",
            "Train_MaxReturn : 239.0635986328125\n",
            "Train_MinReturn : 55.594722747802734\n",
            "Train_AverageEpLen : 91.78260869565217\n",
            "Train_EnvstepsSoFar : 275484\n",
            "TimeSinceStart : 227.1036241054535\n",
            "Training Loss : 0.03537505492568016\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 136 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2039])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 177.7403106689453\n",
            "Eval_StdReturn : 12.608329772949219\n",
            "Eval_MaxReturn : 200.0821075439453\n",
            "Eval_MinReturn : 166.24830627441406\n",
            "Eval_AverageEpLen : 83.8\n",
            "Train_AverageReturn : 203.53456115722656\n",
            "Train_StdReturn : 17.571365356445312\n",
            "Train_MaxReturn : 224.92379760742188\n",
            "Train_MinReturn : 151.41781616210938\n",
            "Train_AverageEpLen : 92.68181818181819\n",
            "Train_EnvstepsSoFar : 277523\n",
            "TimeSinceStart : 228.70048189163208\n",
            "Training Loss : -0.009473052807152271\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 137 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2028])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 214.9980926513672\n",
            "Eval_StdReturn : 3.889880657196045\n",
            "Eval_MaxReturn : 220.92076110839844\n",
            "Eval_MinReturn : 209.53184509277344\n",
            "Eval_AverageEpLen : 95.2\n",
            "Train_AverageReturn : 196.52532958984375\n",
            "Train_StdReturn : 27.40899085998535\n",
            "Train_MaxReturn : 225.02842712402344\n",
            "Train_MinReturn : 84.47432708740234\n",
            "Train_AverageEpLen : 90.3913043478261\n",
            "Train_EnvstepsSoFar : 279602\n",
            "TimeSinceStart : 230.37514758110046\n",
            "Training Loss : -0.04780523106455803\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 138 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2017])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 193.506591796875\n",
            "Eval_StdReturn : 28.689369201660156\n",
            "Eval_MaxReturn : 230.72940063476562\n",
            "Eval_MinReturn : 155.04019165039062\n",
            "Eval_AverageEpLen : 89.8\n",
            "Train_AverageReturn : 187.28753662109375\n",
            "Train_StdReturn : 44.24277114868164\n",
            "Train_MaxReturn : 233.65054321289062\n",
            "Train_MinReturn : 35.0081672668457\n",
            "Train_AverageEpLen : 87.69565217391305\n",
            "Train_EnvstepsSoFar : 281619\n",
            "TimeSinceStart : 231.98702359199524\n",
            "Training Loss : -0.03609006106853485\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 139 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2004])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 166.93978881835938\n",
            "Eval_StdReturn : 30.19970703125\n",
            "Eval_MaxReturn : 206.42494201660156\n",
            "Eval_MinReturn : 124.5613021850586\n",
            "Eval_AverageEpLen : 80.8\n",
            "Train_AverageReturn : 183.4351043701172\n",
            "Train_StdReturn : 36.45145034790039\n",
            "Train_MaxReturn : 234.36148071289062\n",
            "Train_MinReturn : 89.20699310302734\n",
            "Train_AverageEpLen : 86.29166666666667\n",
            "Train_EnvstepsSoFar : 283690\n",
            "TimeSinceStart : 233.6026542186737\n",
            "Training Loss : -0.054469995200634\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 140 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2058])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 203.5293731689453\n",
            "Eval_StdReturn : 17.13016128540039\n",
            "Eval_MaxReturn : 225.13209533691406\n",
            "Eval_MinReturn : 176.39596557617188\n",
            "Eval_AverageEpLen : 92.6\n",
            "Train_AverageReturn : 184.4152374267578\n",
            "Train_StdReturn : 34.578792572021484\n",
            "Train_MaxReturn : 225.2415313720703\n",
            "Train_MinReturn : 98.53221893310547\n",
            "Train_AverageEpLen : 85.75\n",
            "Train_EnvstepsSoFar : 285748\n",
            "TimeSinceStart : 235.2282474040985\n",
            "Training Loss : -0.019437158480286598\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 141 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2005])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 204.8026885986328\n",
            "Eval_StdReturn : 19.449609756469727\n",
            "Eval_MaxReturn : 223.68284606933594\n",
            "Eval_MinReturn : 167.40672302246094\n",
            "Eval_AverageEpLen : 94.4\n",
            "Train_AverageReturn : 174.8881378173828\n",
            "Train_StdReturn : 34.40262222290039\n",
            "Train_MaxReturn : 227.05467224121094\n",
            "Train_MinReturn : 102.37973022460938\n",
            "Train_AverageEpLen : 83.54166666666667\n",
            "Train_EnvstepsSoFar : 287753\n",
            "TimeSinceStart : 236.82055044174194\n",
            "Training Loss : -0.027748791500926018\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 142 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2029])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 170.9650115966797\n",
            "Eval_StdReturn : 29.26955223083496\n",
            "Eval_MaxReturn : 212.76885986328125\n",
            "Eval_MinReturn : 137.9928436279297\n",
            "Eval_AverageEpLen : 80.83333333333333\n",
            "Train_AverageReturn : 161.5568084716797\n",
            "Train_StdReturn : 42.79147720336914\n",
            "Train_MaxReturn : 226.00198364257812\n",
            "Train_MinReturn : 80.54065704345703\n",
            "Train_AverageEpLen : 78.03846153846153\n",
            "Train_EnvstepsSoFar : 289782\n",
            "TimeSinceStart : 238.47249102592468\n",
            "Training Loss : -0.036754973232746124\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 143 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2022])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 160.7827606201172\n",
            "Eval_StdReturn : 29.12131690979004\n",
            "Eval_MaxReturn : 205.97706604003906\n",
            "Eval_MinReturn : 124.26022338867188\n",
            "Eval_AverageEpLen : 77.16666666666667\n",
            "Train_AverageReturn : 165.8479461669922\n",
            "Train_StdReturn : 31.618247985839844\n",
            "Train_MaxReturn : 222.7215576171875\n",
            "Train_MinReturn : 99.00728607177734\n",
            "Train_AverageEpLen : 80.88\n",
            "Train_EnvstepsSoFar : 291804\n",
            "TimeSinceStart : 240.0794014930725\n",
            "Training Loss : -0.052645955234766006\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 144 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2020])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 145.4790802001953\n",
            "Eval_StdReturn : 21.630556106567383\n",
            "Eval_MaxReturn : 178.0396728515625\n",
            "Eval_MinReturn : 115.953125\n",
            "Eval_AverageEpLen : 72.66666666666667\n",
            "Train_AverageReturn : 159.59507751464844\n",
            "Train_StdReturn : 35.30430603027344\n",
            "Train_MaxReturn : 220.17138671875\n",
            "Train_MinReturn : 88.6483383178711\n",
            "Train_AverageEpLen : 77.6923076923077\n",
            "Train_EnvstepsSoFar : 293824\n",
            "TimeSinceStart : 241.66931343078613\n",
            "Training Loss : -0.06723223626613617\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 145 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2003])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 131.41232299804688\n",
            "Eval_StdReturn : 43.878108978271484\n",
            "Eval_MaxReturn : 198.45419311523438\n",
            "Eval_MinReturn : 86.02970123291016\n",
            "Eval_AverageEpLen : 68.14285714285714\n",
            "Train_AverageReturn : 160.8368377685547\n",
            "Train_StdReturn : 37.393287658691406\n",
            "Train_MaxReturn : 258.297119140625\n",
            "Train_MinReturn : 86.57142639160156\n",
            "Train_AverageEpLen : 79.61538461538461\n",
            "Train_EnvstepsSoFar : 295894\n",
            "TimeSinceStart : 243.34622192382812\n",
            "Training Loss : -0.08069871366024017\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 146 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2047])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 125.43457794189453\n",
            "Eval_StdReturn : 22.72450065612793\n",
            "Eval_MaxReturn : 151.8433837890625\n",
            "Eval_MinReturn : 83.17017364501953\n",
            "Eval_AverageEpLen : 67.16666666666667\n",
            "Train_AverageReturn : 149.67930603027344\n",
            "Train_StdReturn : 26.48969078063965\n",
            "Train_MaxReturn : 217.2117919921875\n",
            "Train_MinReturn : 107.08712768554688\n",
            "Train_AverageEpLen : 75.81481481481481\n",
            "Train_EnvstepsSoFar : 297941\n",
            "TimeSinceStart : 244.94266891479492\n",
            "Training Loss : -0.055887095630168915\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 147 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2042])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 149.70321655273438\n",
            "Eval_StdReturn : 54.737876892089844\n",
            "Eval_MaxReturn : 228.1284942626953\n",
            "Eval_MinReturn : 90.38053131103516\n",
            "Eval_AverageEpLen : 76.5\n",
            "Train_AverageReturn : 143.80455017089844\n",
            "Train_StdReturn : 28.16876983642578\n",
            "Train_MaxReturn : 217.59947204589844\n",
            "Train_MinReturn : 94.73892974853516\n",
            "Train_AverageEpLen : 72.92857142857143\n",
            "Train_EnvstepsSoFar : 299983\n",
            "TimeSinceStart : 246.56506395339966\n",
            "Training Loss : -0.05533740296959877\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 148 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2027])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 126.6122055053711\n",
            "Eval_StdReturn : 14.617341995239258\n",
            "Eval_MaxReturn : 146.77455139160156\n",
            "Eval_MinReturn : 106.12306213378906\n",
            "Eval_AverageEpLen : 67.83333333333333\n",
            "Train_AverageReturn : 148.28541564941406\n",
            "Train_StdReturn : 30.592533111572266\n",
            "Train_MaxReturn : 210.49789428710938\n",
            "Train_MinReturn : 100.6999282836914\n",
            "Train_AverageEpLen : 75.07407407407408\n",
            "Train_EnvstepsSoFar : 302010\n",
            "TimeSinceStart : 248.17363262176514\n",
            "Training Loss : -0.06330779939889908\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 149 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2040])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 141.65342712402344\n",
            "Eval_StdReturn : 23.240821838378906\n",
            "Eval_MaxReturn : 163.6724853515625\n",
            "Eval_MinReturn : 107.20186614990234\n",
            "Eval_AverageEpLen : 73.66666666666667\n",
            "Train_AverageReturn : 135.75689697265625\n",
            "Train_StdReturn : 24.2434139251709\n",
            "Train_MaxReturn : 188.8042755126953\n",
            "Train_MinReturn : 93.70819091796875\n",
            "Train_AverageEpLen : 70.34482758620689\n",
            "Train_EnvstepsSoFar : 304050\n",
            "TimeSinceStart : 249.7745440006256\n",
            "Training Loss : -0.017977196723222733\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 150 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2020])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 124.35359191894531\n",
            "Eval_StdReturn : 15.992208480834961\n",
            "Eval_MaxReturn : 146.64710998535156\n",
            "Eval_MinReturn : 101.52421569824219\n",
            "Eval_AverageEpLen : 65.14285714285714\n",
            "Train_AverageReturn : 124.24493408203125\n",
            "Train_StdReturn : 33.24980926513672\n",
            "Train_MaxReturn : 205.624267578125\n",
            "Train_MinReturn : 74.58295440673828\n",
            "Train_AverageEpLen : 65.16129032258064\n",
            "Train_EnvstepsSoFar : 306070\n",
            "TimeSinceStart : 251.40468788146973\n",
            "Training Loss : -0.07540374994277954\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 151 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2055])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 115.92662048339844\n",
            "Eval_StdReturn : 27.758590698242188\n",
            "Eval_MaxReturn : 168.60861206054688\n",
            "Eval_MinReturn : 90.402099609375\n",
            "Eval_AverageEpLen : 63.857142857142854\n",
            "Train_AverageReturn : 126.07451629638672\n",
            "Train_StdReturn : 27.727991104125977\n",
            "Train_MaxReturn : 189.6577911376953\n",
            "Train_MinReturn : 59.435523986816406\n",
            "Train_AverageEpLen : 66.29032258064517\n",
            "Train_EnvstepsSoFar : 308125\n",
            "TimeSinceStart : 253.05901074409485\n",
            "Training Loss : -0.02838081307709217\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 152 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2026])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 118.2812728881836\n",
            "Eval_StdReturn : 28.10906982421875\n",
            "Eval_MaxReturn : 164.79241943359375\n",
            "Eval_MinReturn : 77.91847229003906\n",
            "Eval_AverageEpLen : 64.42857142857143\n",
            "Train_AverageReturn : 126.37960815429688\n",
            "Train_StdReturn : 31.782011032104492\n",
            "Train_MaxReturn : 187.87295532226562\n",
            "Train_MinReturn : 83.16517639160156\n",
            "Train_AverageEpLen : 67.45161290322581\n",
            "Train_EnvstepsSoFar : 310216\n",
            "TimeSinceStart : 254.71698760986328\n",
            "Training Loss : -0.056373558938503265\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 153 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2043])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 112.26956939697266\n",
            "Eval_StdReturn : 27.049928665161133\n",
            "Eval_MaxReturn : 153.89947509765625\n",
            "Eval_MinReturn : 70.50863647460938\n",
            "Eval_AverageEpLen : 60.142857142857146\n",
            "Train_AverageReturn : 114.63409423828125\n",
            "Train_StdReturn : 29.024662017822266\n",
            "Train_MaxReturn : 186.269775390625\n",
            "Train_MinReturn : 62.504638671875\n",
            "Train_AverageEpLen : 61.90909090909091\n",
            "Train_EnvstepsSoFar : 312259\n",
            "TimeSinceStart : 256.3088138103485\n",
            "Training Loss : -0.03468584269285202\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 154 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2059])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 125.14996337890625\n",
            "Eval_StdReturn : 13.36927604675293\n",
            "Eval_MaxReturn : 148.8983612060547\n",
            "Eval_MinReturn : 102.2025146484375\n",
            "Eval_AverageEpLen : 67.0\n",
            "Train_AverageReturn : 119.96859741210938\n",
            "Train_StdReturn : 31.241025924682617\n",
            "Train_MaxReturn : 189.284912109375\n",
            "Train_MinReturn : 73.40506744384766\n",
            "Train_AverageEpLen : 64.34375\n",
            "Train_EnvstepsSoFar : 314318\n",
            "TimeSinceStart : 257.96639800071716\n",
            "Training Loss : -0.10071367770433426\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 155 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2051])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 103.98897552490234\n",
            "Eval_StdReturn : 25.947710037231445\n",
            "Eval_MaxReturn : 157.2815704345703\n",
            "Eval_MinReturn : 68.12535095214844\n",
            "Eval_AverageEpLen : 56.625\n",
            "Train_AverageReturn : 114.68988037109375\n",
            "Train_StdReturn : 26.206287384033203\n",
            "Train_MaxReturn : 158.69985961914062\n",
            "Train_MinReturn : 68.50540161132812\n",
            "Train_AverageEpLen : 62.15151515151515\n",
            "Train_EnvstepsSoFar : 316369\n",
            "TimeSinceStart : 259.61896777153015\n",
            "Training Loss : -0.04820815101265907\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 156 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2024])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 98.0830078125\n",
            "Eval_StdReturn : 22.7131404876709\n",
            "Eval_MaxReturn : 141.98367309570312\n",
            "Eval_MinReturn : 72.92357635498047\n",
            "Eval_AverageEpLen : 55.375\n",
            "Train_AverageReturn : 97.71017456054688\n",
            "Train_StdReturn : 19.619338989257812\n",
            "Train_MaxReturn : 135.6004638671875\n",
            "Train_MinReturn : 63.200950622558594\n",
            "Train_AverageEpLen : 54.7027027027027\n",
            "Train_EnvstepsSoFar : 318393\n",
            "TimeSinceStart : 261.2116904258728\n",
            "Training Loss : -0.06563487648963928\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 157 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2001])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 107.22166442871094\n",
            "Eval_StdReturn : 32.53929901123047\n",
            "Eval_MaxReturn : 178.78709411621094\n",
            "Eval_MinReturn : 77.98651123046875\n",
            "Eval_AverageEpLen : 60.0\n",
            "Train_AverageReturn : 93.17121887207031\n",
            "Train_StdReturn : 19.000518798828125\n",
            "Train_MaxReturn : 129.77169799804688\n",
            "Train_MinReturn : 58.718177795410156\n",
            "Train_AverageEpLen : 52.6578947368421\n",
            "Train_EnvstepsSoFar : 320394\n",
            "TimeSinceStart : 262.82641887664795\n",
            "Training Loss : -0.03716711327433586\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 158 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2008])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 90.87098693847656\n",
            "Eval_StdReturn : 19.865829467773438\n",
            "Eval_MaxReturn : 134.30372619628906\n",
            "Eval_MinReturn : 74.14359283447266\n",
            "Eval_AverageEpLen : 51.625\n",
            "Train_AverageReturn : 96.84171295166016\n",
            "Train_StdReturn : 27.352628707885742\n",
            "Train_MaxReturn : 174.31124877929688\n",
            "Train_MinReturn : 63.75783157348633\n",
            "Train_AverageEpLen : 54.270270270270274\n",
            "Train_EnvstepsSoFar : 322402\n",
            "TimeSinceStart : 264.3987693786621\n",
            "Training Loss : -0.05599247291684151\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 159 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2040])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 90.58529663085938\n",
            "Eval_StdReturn : 18.815736770629883\n",
            "Eval_MaxReturn : 121.09314727783203\n",
            "Eval_MinReturn : 71.76597595214844\n",
            "Eval_AverageEpLen : 51.125\n",
            "Train_AverageReturn : 89.43806457519531\n",
            "Train_StdReturn : 22.83842658996582\n",
            "Train_MaxReturn : 155.51614379882812\n",
            "Train_MinReturn : 53.74240493774414\n",
            "Train_AverageEpLen : 51.0\n",
            "Train_EnvstepsSoFar : 324442\n",
            "TimeSinceStart : 265.9937918186188\n",
            "Training Loss : -0.10229147970676422\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 160 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2023])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 91.76026916503906\n",
            "Eval_StdReturn : 27.389577865600586\n",
            "Eval_MaxReturn : 147.8539276123047\n",
            "Eval_MinReturn : 57.23843765258789\n",
            "Eval_AverageEpLen : 52.125\n",
            "Train_AverageReturn : 84.3097152709961\n",
            "Train_StdReturn : 19.025022506713867\n",
            "Train_MaxReturn : 145.0259552001953\n",
            "Train_MinReturn : 52.405601501464844\n",
            "Train_AverageEpLen : 48.166666666666664\n",
            "Train_EnvstepsSoFar : 326465\n",
            "TimeSinceStart : 267.6082925796509\n",
            "Training Loss : -0.02587135136127472\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 161 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2009])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 77.45780181884766\n",
            "Eval_StdReturn : 19.657039642333984\n",
            "Eval_MaxReturn : 113.80674743652344\n",
            "Eval_MinReturn : 53.3419303894043\n",
            "Eval_AverageEpLen : 45.22222222222222\n",
            "Train_AverageReturn : 82.88044738769531\n",
            "Train_StdReturn : 19.74614715576172\n",
            "Train_MaxReturn : 153.92047119140625\n",
            "Train_MinReturn : 50.35870361328125\n",
            "Train_AverageEpLen : 47.833333333333336\n",
            "Train_EnvstepsSoFar : 328474\n",
            "TimeSinceStart : 269.17682433128357\n",
            "Training Loss : -0.06517761945724487\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 162 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2013])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 85.44206237792969\n",
            "Eval_StdReturn : 17.656044006347656\n",
            "Eval_MaxReturn : 115.06009674072266\n",
            "Eval_MinReturn : 64.30233764648438\n",
            "Eval_AverageEpLen : 48.888888888888886\n",
            "Train_AverageReturn : 81.55902862548828\n",
            "Train_StdReturn : 23.694021224975586\n",
            "Train_MaxReturn : 169.01878356933594\n",
            "Train_MinReturn : 46.51462936401367\n",
            "Train_AverageEpLen : 46.81395348837209\n",
            "Train_EnvstepsSoFar : 330487\n",
            "TimeSinceStart : 270.7916820049286\n",
            "Training Loss : -0.06424596160650253\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 163 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2014])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 80.83350372314453\n",
            "Eval_StdReturn : 17.380111694335938\n",
            "Eval_MaxReturn : 115.71027374267578\n",
            "Eval_MinReturn : 55.78324890136719\n",
            "Eval_AverageEpLen : 47.111111111111114\n",
            "Train_AverageReturn : 78.21170043945312\n",
            "Train_StdReturn : 16.198318481445312\n",
            "Train_MaxReturn : 118.15154266357422\n",
            "Train_MinReturn : 53.742130279541016\n",
            "Train_AverageEpLen : 45.46666666666667\n",
            "Train_EnvstepsSoFar : 332533\n",
            "TimeSinceStart : 272.41612482070923\n",
            "Training Loss : -0.06725893914699554\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 164 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2023])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 68.87295532226562\n",
            "Eval_StdReturn : 11.501565933227539\n",
            "Eval_MaxReturn : 82.42352294921875\n",
            "Eval_MinReturn : 50.85303497314453\n",
            "Eval_AverageEpLen : 40.27272727272727\n",
            "Train_AverageReturn : 78.01235961914062\n",
            "Train_StdReturn : 19.170320510864258\n",
            "Train_MaxReturn : 145.9432830810547\n",
            "Train_MinReturn : 51.69783020019531\n",
            "Train_AverageEpLen : 44.955555555555556\n",
            "Train_EnvstepsSoFar : 334556\n",
            "TimeSinceStart : 274.0544590950012\n",
            "Training Loss : -0.032712019979953766\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 165 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2006])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 74.20519256591797\n",
            "Eval_StdReturn : 18.003921508789062\n",
            "Eval_MaxReturn : 106.07910919189453\n",
            "Eval_MinReturn : 47.79787826538086\n",
            "Eval_AverageEpLen : 42.9\n",
            "Train_AverageReturn : 75.30912017822266\n",
            "Train_StdReturn : 16.91347885131836\n",
            "Train_MaxReturn : 128.79513549804688\n",
            "Train_MinReturn : 50.034305572509766\n",
            "Train_AverageEpLen : 43.608695652173914\n",
            "Train_EnvstepsSoFar : 336562\n",
            "TimeSinceStart : 275.64983105659485\n",
            "Training Loss : -0.040143758058547974\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 166 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2008])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 70.74882507324219\n",
            "Eval_StdReturn : 14.948904037475586\n",
            "Eval_MaxReturn : 108.86203002929688\n",
            "Eval_MinReturn : 58.28273391723633\n",
            "Eval_AverageEpLen : 41.0\n",
            "Train_AverageReturn : 73.34335327148438\n",
            "Train_StdReturn : 16.106048583984375\n",
            "Train_MaxReturn : 126.83306121826172\n",
            "Train_MinReturn : 46.4933967590332\n",
            "Train_AverageEpLen : 42.723404255319146\n",
            "Train_EnvstepsSoFar : 338570\n",
            "TimeSinceStart : 277.23330068588257\n",
            "Training Loss : -0.08557959645986557\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 167 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2015])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 70.81101989746094\n",
            "Eval_StdReturn : 14.838077545166016\n",
            "Eval_MaxReturn : 90.82310485839844\n",
            "Eval_MinReturn : 46.780059814453125\n",
            "Eval_AverageEpLen : 41.1\n",
            "Train_AverageReturn : 71.54158782958984\n",
            "Train_StdReturn : 13.278124809265137\n",
            "Train_MaxReturn : 104.96686553955078\n",
            "Train_MinReturn : 48.253868103027344\n",
            "Train_AverageEpLen : 41.979166666666664\n",
            "Train_EnvstepsSoFar : 340585\n",
            "TimeSinceStart : 278.8353717327118\n",
            "Training Loss : -0.038129772990942\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 168 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2011])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 61.818538665771484\n",
            "Eval_StdReturn : 7.030141830444336\n",
            "Eval_MaxReturn : 75.20734405517578\n",
            "Eval_MinReturn : 51.186344146728516\n",
            "Eval_AverageEpLen : 36.36363636363637\n",
            "Train_AverageReturn : 69.94027709960938\n",
            "Train_StdReturn : 17.099266052246094\n",
            "Train_MaxReturn : 148.88043212890625\n",
            "Train_MinReturn : 46.328617095947266\n",
            "Train_AverageEpLen : 41.04081632653061\n",
            "Train_EnvstepsSoFar : 342596\n",
            "TimeSinceStart : 280.42058205604553\n",
            "Training Loss : -0.013875710777938366\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 169 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2029])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 76.97219848632812\n",
            "Eval_StdReturn : 17.241424560546875\n",
            "Eval_MaxReturn : 110.37357330322266\n",
            "Eval_MinReturn : 62.81568908691406\n",
            "Eval_AverageEpLen : 44.666666666666664\n",
            "Train_AverageReturn : 63.81489181518555\n",
            "Train_StdReturn : 11.46451187133789\n",
            "Train_MaxReturn : 109.08821105957031\n",
            "Train_MinReturn : 48.38084411621094\n",
            "Train_AverageEpLen : 37.574074074074076\n",
            "Train_EnvstepsSoFar : 344625\n",
            "TimeSinceStart : 282.0389349460602\n",
            "Training Loss : -0.045526690781116486\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 170 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2019])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 61.84598159790039\n",
            "Eval_StdReturn : 16.54993438720703\n",
            "Eval_MaxReturn : 108.0859603881836\n",
            "Eval_MinReturn : 44.32415008544922\n",
            "Eval_AverageEpLen : 35.916666666666664\n",
            "Train_AverageReturn : 63.81119918823242\n",
            "Train_StdReturn : 11.809420585632324\n",
            "Train_MaxReturn : 108.3121337890625\n",
            "Train_MinReturn : 48.559051513671875\n",
            "Train_AverageEpLen : 37.388888888888886\n",
            "Train_EnvstepsSoFar : 346644\n",
            "TimeSinceStart : 283.66086435317993\n",
            "Training Loss : -0.05410660430788994\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 171 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2032])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 61.67344665527344\n",
            "Eval_StdReturn : 17.93108558654785\n",
            "Eval_MaxReturn : 107.69197082519531\n",
            "Eval_MinReturn : 43.109493255615234\n",
            "Eval_AverageEpLen : 36.0\n",
            "Train_AverageReturn : 61.91021728515625\n",
            "Train_StdReturn : 9.534377098083496\n",
            "Train_MaxReturn : 90.3963851928711\n",
            "Train_MinReturn : 48.07150650024414\n",
            "Train_AverageEpLen : 36.285714285714285\n",
            "Train_EnvstepsSoFar : 348676\n",
            "TimeSinceStart : 285.28790044784546\n",
            "Training Loss : -0.011746917851269245\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 172 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2011])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 60.81076431274414\n",
            "Eval_StdReturn : 8.567798614501953\n",
            "Eval_MaxReturn : 74.80044555664062\n",
            "Eval_MinReturn : 48.1984748840332\n",
            "Eval_AverageEpLen : 35.75\n",
            "Train_AverageReturn : 63.42710876464844\n",
            "Train_StdReturn : 12.594270706176758\n",
            "Train_MaxReturn : 101.49427032470703\n",
            "Train_MinReturn : 41.71013641357422\n",
            "Train_AverageEpLen : 37.24074074074074\n",
            "Train_EnvstepsSoFar : 350687\n",
            "TimeSinceStart : 286.8837480545044\n",
            "Training Loss : -0.0760137289762497\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 173 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2003])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 63.24935531616211\n",
            "Eval_StdReturn : 13.703643798828125\n",
            "Eval_MaxReturn : 99.91200256347656\n",
            "Eval_MinReturn : 50.80521011352539\n",
            "Eval_AverageEpLen : 36.63636363636363\n",
            "Train_AverageReturn : 64.39800262451172\n",
            "Train_StdReturn : 12.547067642211914\n",
            "Train_MaxReturn : 106.10281372070312\n",
            "Train_MinReturn : 49.40471267700195\n",
            "Train_AverageEpLen : 37.648148148148145\n",
            "Train_EnvstepsSoFar : 352720\n",
            "TimeSinceStart : 288.49181938171387\n",
            "Training Loss : -0.03951432928442955\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 174 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2004])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 58.48472213745117\n",
            "Eval_StdReturn : 9.737788200378418\n",
            "Eval_MaxReturn : 75.80960083007812\n",
            "Eval_MinReturn : 44.07161331176758\n",
            "Eval_AverageEpLen : 33.833333333333336\n",
            "Train_AverageReturn : 60.819400787353516\n",
            "Train_StdReturn : 12.270296096801758\n",
            "Train_MaxReturn : 108.31234741210938\n",
            "Train_MinReturn : 46.027488708496094\n",
            "Train_AverageEpLen : 35.63157894736842\n",
            "Train_EnvstepsSoFar : 354751\n",
            "TimeSinceStart : 290.0827214717865\n",
            "Training Loss : -0.010906280018389225\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 175 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2014])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 62.53115463256836\n",
            "Eval_StdReturn : 12.46580982208252\n",
            "Eval_MaxReturn : 86.27957153320312\n",
            "Eval_MinReturn : 44.39728546142578\n",
            "Eval_AverageEpLen : 36.63636363636363\n",
            "Train_AverageReturn : 60.48272705078125\n",
            "Train_StdReturn : 10.414692878723145\n",
            "Train_MaxReturn : 95.54830932617188\n",
            "Train_MinReturn : 43.76506423950195\n",
            "Train_AverageEpLen : 35.333333333333336\n",
            "Train_EnvstepsSoFar : 356765\n",
            "TimeSinceStart : 291.68161273002625\n",
            "Training Loss : -0.051224298775196075\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 176 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2021])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 58.15116882324219\n",
            "Eval_StdReturn : 13.136775970458984\n",
            "Eval_MaxReturn : 88.51715087890625\n",
            "Eval_MinReturn : 45.54240417480469\n",
            "Eval_AverageEpLen : 34.0\n",
            "Train_AverageReturn : 59.64623260498047\n",
            "Train_StdReturn : 12.435945510864258\n",
            "Train_MaxReturn : 108.94113159179688\n",
            "Train_MinReturn : 42.740665435791016\n",
            "Train_AverageEpLen : 34.8448275862069\n",
            "Train_EnvstepsSoFar : 358786\n",
            "TimeSinceStart : 293.32830286026\n",
            "Training Loss : -0.03002341091632843\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 177 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2026])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 59.59141540527344\n",
            "Eval_StdReturn : 13.647665977478027\n",
            "Eval_MaxReturn : 98.4548568725586\n",
            "Eval_MinReturn : 45.56756591796875\n",
            "Eval_AverageEpLen : 34.916666666666664\n",
            "Train_AverageReturn : 57.75470733642578\n",
            "Train_StdReturn : 9.591033935546875\n",
            "Train_MaxReturn : 86.39529418945312\n",
            "Train_MinReturn : 43.98003387451172\n",
            "Train_AverageEpLen : 33.766666666666666\n",
            "Train_EnvstepsSoFar : 360812\n",
            "TimeSinceStart : 294.9311535358429\n",
            "Training Loss : 0.00044561445247381926\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 178 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2006])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 57.34751510620117\n",
            "Eval_StdReturn : 5.928620338439941\n",
            "Eval_MaxReturn : 68.42428588867188\n",
            "Eval_MinReturn : 49.028228759765625\n",
            "Eval_AverageEpLen : 33.416666666666664\n",
            "Train_AverageReturn : 57.04789733886719\n",
            "Train_StdReturn : 7.874431610107422\n",
            "Train_MaxReturn : 76.28856658935547\n",
            "Train_MinReturn : 43.16352462768555\n",
            "Train_AverageEpLen : 33.43333333333333\n",
            "Train_EnvstepsSoFar : 362818\n",
            "TimeSinceStart : 296.52883791923523\n",
            "Training Loss : -0.04825294017791748\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 179 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2023])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 58.11009216308594\n",
            "Eval_StdReturn : 10.264752388000488\n",
            "Eval_MaxReturn : 79.31256103515625\n",
            "Eval_MinReturn : 43.63783645629883\n",
            "Eval_AverageEpLen : 33.75\n",
            "Train_AverageReturn : 55.719505310058594\n",
            "Train_StdReturn : 9.152859687805176\n",
            "Train_MaxReturn : 91.78865814208984\n",
            "Train_MinReturn : 44.132015228271484\n",
            "Train_AverageEpLen : 32.62903225806452\n",
            "Train_EnvstepsSoFar : 364841\n",
            "TimeSinceStart : 298.1383943557739\n",
            "Training Loss : -0.018953487277030945\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 180 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2041])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 59.596309661865234\n",
            "Eval_StdReturn : 7.860767364501953\n",
            "Eval_MaxReturn : 78.83134460449219\n",
            "Eval_MinReturn : 48.4425048828125\n",
            "Eval_AverageEpLen : 34.666666666666664\n",
            "Train_AverageReturn : 58.39354705810547\n",
            "Train_StdReturn : 10.816576957702637\n",
            "Train_MaxReturn : 101.46182250976562\n",
            "Train_MinReturn : 42.60287857055664\n",
            "Train_AverageEpLen : 34.016666666666666\n",
            "Train_EnvstepsSoFar : 366882\n",
            "TimeSinceStart : 299.7772741317749\n",
            "Training Loss : -0.02357448637485504\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 181 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2002])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 64.7762451171875\n",
            "Eval_StdReturn : 10.369309425354004\n",
            "Eval_MaxReturn : 83.79927825927734\n",
            "Eval_MinReturn : 49.22463607788086\n",
            "Eval_AverageEpLen : 37.54545454545455\n",
            "Train_AverageReturn : 57.40413284301758\n",
            "Train_StdReturn : 9.659422874450684\n",
            "Train_MaxReturn : 105.18260955810547\n",
            "Train_MinReturn : 44.47172164916992\n",
            "Train_AverageEpLen : 33.36666666666667\n",
            "Train_EnvstepsSoFar : 368884\n",
            "TimeSinceStart : 301.3528928756714\n",
            "Training Loss : -0.012960392981767654\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 182 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2016])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 57.155147552490234\n",
            "Eval_StdReturn : 5.799919128417969\n",
            "Eval_MaxReturn : 71.7134017944336\n",
            "Eval_MinReturn : 49.121498107910156\n",
            "Eval_AverageEpLen : 33.5\n",
            "Train_AverageReturn : 56.745201110839844\n",
            "Train_StdReturn : 9.5941743850708\n",
            "Train_MaxReturn : 100.61589050292969\n",
            "Train_MinReturn : 43.33351135253906\n",
            "Train_AverageEpLen : 33.049180327868854\n",
            "Train_EnvstepsSoFar : 370900\n",
            "TimeSinceStart : 302.9775404930115\n",
            "Training Loss : -0.01561117172241211\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 183 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2025])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 59.868408203125\n",
            "Eval_StdReturn : 11.345662117004395\n",
            "Eval_MaxReturn : 87.38770294189453\n",
            "Eval_MinReturn : 47.70054626464844\n",
            "Eval_AverageEpLen : 34.5\n",
            "Train_AverageReturn : 57.73329162597656\n",
            "Train_StdReturn : 10.134207725524902\n",
            "Train_MaxReturn : 87.11314392089844\n",
            "Train_MinReturn : 40.9161376953125\n",
            "Train_AverageEpLen : 33.75\n",
            "Train_EnvstepsSoFar : 372925\n",
            "TimeSinceStart : 304.6275751590729\n",
            "Training Loss : 0.007707671262323856\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 184 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2009])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 59.783599853515625\n",
            "Eval_StdReturn : 10.305703163146973\n",
            "Eval_MaxReturn : 83.38319396972656\n",
            "Eval_MinReturn : 46.78012466430664\n",
            "Eval_AverageEpLen : 34.5\n",
            "Train_AverageReturn : 59.414615631103516\n",
            "Train_StdReturn : 11.016998291015625\n",
            "Train_MaxReturn : 94.76709747314453\n",
            "Train_MinReturn : 41.896324157714844\n",
            "Train_AverageEpLen : 34.559322033898304\n",
            "Train_EnvstepsSoFar : 374964\n",
            "TimeSinceStart : 306.22582173347473\n",
            "Training Loss : -0.018744343891739845\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 185 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2011])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 64.17900085449219\n",
            "Eval_StdReturn : 13.17897891998291\n",
            "Eval_MaxReturn : 87.68730926513672\n",
            "Eval_MinReturn : 48.37620162963867\n",
            "Eval_AverageEpLen : 37.63636363636363\n",
            "Train_AverageReturn : 59.8080940246582\n",
            "Train_StdReturn : 10.703292846679688\n",
            "Train_MaxReturn : 87.5530776977539\n",
            "Train_MinReturn : 44.76667022705078\n",
            "Train_AverageEpLen : 34.672413793103445\n",
            "Train_EnvstepsSoFar : 376975\n",
            "TimeSinceStart : 307.8344690799713\n",
            "Training Loss : -0.05020906403660774\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 186 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2010])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 60.58891677856445\n",
            "Eval_StdReturn : 11.739824295043945\n",
            "Eval_MaxReturn : 79.74907684326172\n",
            "Eval_MinReturn : 45.457000732421875\n",
            "Eval_AverageEpLen : 35.25\n",
            "Train_AverageReturn : 59.647151947021484\n",
            "Train_StdReturn : 10.545137405395508\n",
            "Train_MaxReturn : 91.77513122558594\n",
            "Train_MinReturn : 43.98764419555664\n",
            "Train_AverageEpLen : 34.6551724137931\n",
            "Train_EnvstepsSoFar : 378985\n",
            "TimeSinceStart : 309.4570806026459\n",
            "Training Loss : 0.002135535003617406\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 187 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 56.413143157958984\n",
            "Eval_StdReturn : 6.032858371734619\n",
            "Eval_MaxReturn : 68.28765106201172\n",
            "Eval_MinReturn : 48.06950378417969\n",
            "Eval_AverageEpLen : 32.69230769230769\n",
            "Train_AverageReturn : 61.4571533203125\n",
            "Train_StdReturn : 12.4188232421875\n",
            "Train_MaxReturn : 97.31022644042969\n",
            "Train_MinReturn : 44.97431945800781\n",
            "Train_AverageEpLen : 35.714285714285715\n",
            "Train_EnvstepsSoFar : 380985\n",
            "TimeSinceStart : 311.0610148906708\n",
            "Training Loss : 0.041378311812877655\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 188 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2008])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 58.63236999511719\n",
            "Eval_StdReturn : 11.434289932250977\n",
            "Eval_MaxReturn : 85.11837005615234\n",
            "Eval_MinReturn : 46.78582000732422\n",
            "Eval_AverageEpLen : 33.76923076923077\n",
            "Train_AverageReturn : 60.563758850097656\n",
            "Train_StdReturn : 12.139659881591797\n",
            "Train_MaxReturn : 91.71902465820312\n",
            "Train_MinReturn : 40.150672912597656\n",
            "Train_AverageEpLen : 35.228070175438596\n",
            "Train_EnvstepsSoFar : 382993\n",
            "TimeSinceStart : 312.68413853645325\n",
            "Training Loss : -0.030360333621501923\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 189 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2007])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 64.51464080810547\n",
            "Eval_StdReturn : 15.425752639770508\n",
            "Eval_MaxReturn : 89.51605224609375\n",
            "Eval_MinReturn : 45.76956558227539\n",
            "Eval_AverageEpLen : 37.72727272727273\n",
            "Train_AverageReturn : 62.09035873413086\n",
            "Train_StdReturn : 14.95313835144043\n",
            "Train_MaxReturn : 126.12408447265625\n",
            "Train_MinReturn : 43.10795211791992\n",
            "Train_AverageEpLen : 35.839285714285715\n",
            "Train_EnvstepsSoFar : 385000\n",
            "TimeSinceStart : 314.26811385154724\n",
            "Training Loss : -0.025313904508948326\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 190 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2004])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 64.38381958007812\n",
            "Eval_StdReturn : 9.126791000366211\n",
            "Eval_MaxReturn : 77.75728607177734\n",
            "Eval_MinReturn : 51.67522430419922\n",
            "Eval_AverageEpLen : 37.27272727272727\n",
            "Train_AverageReturn : 69.17318725585938\n",
            "Train_StdReturn : 16.409048080444336\n",
            "Train_MaxReturn : 121.9872817993164\n",
            "Train_MinReturn : 45.65221405029297\n",
            "Train_AverageEpLen : 40.08\n",
            "Train_EnvstepsSoFar : 387004\n",
            "TimeSinceStart : 315.8450622558594\n",
            "Training Loss : -0.038013607263565063\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 191 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2006])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 66.29537200927734\n",
            "Eval_StdReturn : 13.204657554626465\n",
            "Eval_MaxReturn : 88.56719970703125\n",
            "Eval_MinReturn : 50.13589859008789\n",
            "Eval_AverageEpLen : 38.54545454545455\n",
            "Train_AverageReturn : 66.62210083007812\n",
            "Train_StdReturn : 13.07720947265625\n",
            "Train_MaxReturn : 98.65235900878906\n",
            "Train_MinReturn : 41.87580490112305\n",
            "Train_AverageEpLen : 38.57692307692308\n",
            "Train_EnvstepsSoFar : 389010\n",
            "TimeSinceStart : 317.40480518341064\n",
            "Training Loss : 0.000627374101895839\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 192 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2029])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 89.35551452636719\n",
            "Eval_StdReturn : 36.4328498840332\n",
            "Eval_MaxReturn : 158.83795166015625\n",
            "Eval_MinReturn : 47.963077545166016\n",
            "Eval_AverageEpLen : 50.875\n",
            "Train_AverageReturn : 74.59239959716797\n",
            "Train_StdReturn : 25.010772705078125\n",
            "Train_MaxReturn : 185.99520874023438\n",
            "Train_MinReturn : 48.40740203857422\n",
            "Train_AverageEpLen : 43.170212765957444\n",
            "Train_EnvstepsSoFar : 391039\n",
            "TimeSinceStart : 319.01182317733765\n",
            "Training Loss : -0.004281541798263788\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 193 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2038])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 83.44081115722656\n",
            "Eval_StdReturn : 32.994384765625\n",
            "Eval_MaxReturn : 141.37506103515625\n",
            "Eval_MinReturn : 47.032894134521484\n",
            "Eval_AverageEpLen : 48.22222222222222\n",
            "Train_AverageReturn : 76.27899169921875\n",
            "Train_StdReturn : 21.93158721923828\n",
            "Train_MaxReturn : 143.91329956054688\n",
            "Train_MinReturn : 50.82279968261719\n",
            "Train_AverageEpLen : 44.30434782608695\n",
            "Train_EnvstepsSoFar : 393077\n",
            "TimeSinceStart : 320.62224864959717\n",
            "Training Loss : 0.021929729729890823\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 194 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2040])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 85.90538787841797\n",
            "Eval_StdReturn : 25.284351348876953\n",
            "Eval_MaxReturn : 142.6185760498047\n",
            "Eval_MinReturn : 53.238563537597656\n",
            "Eval_AverageEpLen : 49.888888888888886\n",
            "Train_AverageReturn : 84.46389770507812\n",
            "Train_StdReturn : 31.46048355102539\n",
            "Train_MaxReturn : 187.90635681152344\n",
            "Train_MinReturn : 48.74966812133789\n",
            "Train_AverageEpLen : 48.57142857142857\n",
            "Train_EnvstepsSoFar : 395117\n",
            "TimeSinceStart : 322.2128665447235\n",
            "Training Loss : -0.0026243743486702442\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 195 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2051])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 103.111328125\n",
            "Eval_StdReturn : 37.02611541748047\n",
            "Eval_MaxReturn : 181.98619079589844\n",
            "Eval_MinReturn : 62.47441864013672\n",
            "Eval_AverageEpLen : 59.42857142857143\n",
            "Train_AverageReturn : 92.73278045654297\n",
            "Train_StdReturn : 38.1224365234375\n",
            "Train_MaxReturn : 199.32272338867188\n",
            "Train_MinReturn : 44.8493766784668\n",
            "Train_AverageEpLen : 53.973684210526315\n",
            "Train_EnvstepsSoFar : 397168\n",
            "TimeSinceStart : 323.87289667129517\n",
            "Training Loss : -0.030910959467291832\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 196 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2035])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 107.063720703125\n",
            "Eval_StdReturn : 40.04020690917969\n",
            "Eval_MaxReturn : 166.2642364501953\n",
            "Eval_MinReturn : 46.41096878051758\n",
            "Eval_AverageEpLen : 61.42857142857143\n",
            "Train_AverageReturn : 113.52967834472656\n",
            "Train_StdReturn : 43.242061614990234\n",
            "Train_MaxReturn : 191.3326873779297\n",
            "Train_MinReturn : 46.60824966430664\n",
            "Train_AverageEpLen : 65.64516129032258\n",
            "Train_EnvstepsSoFar : 399203\n",
            "TimeSinceStart : 325.4919283390045\n",
            "Training Loss : -0.010372632183134556\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 197 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2004])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 114.55220794677734\n",
            "Eval_StdReturn : 34.013099670410156\n",
            "Eval_MaxReturn : 164.07797241210938\n",
            "Eval_MinReturn : 57.649051666259766\n",
            "Eval_AverageEpLen : 67.16666666666667\n",
            "Train_AverageReturn : 115.42976379394531\n",
            "Train_StdReturn : 35.19062805175781\n",
            "Train_MaxReturn : 173.70074462890625\n",
            "Train_MinReturn : 51.363372802734375\n",
            "Train_AverageEpLen : 66.8\n",
            "Train_EnvstepsSoFar : 401207\n",
            "TimeSinceStart : 327.045711517334\n",
            "Training Loss : 0.010759946890175343\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 198 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2029])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 139.6558837890625\n",
            "Eval_StdReturn : 37.94194793701172\n",
            "Eval_MaxReturn : 177.29234313964844\n",
            "Eval_MinReturn : 75.07282257080078\n",
            "Eval_AverageEpLen : 84.4\n",
            "Train_AverageReturn : 131.0980224609375\n",
            "Train_StdReturn : 36.36899948120117\n",
            "Train_MaxReturn : 188.68344116210938\n",
            "Train_MinReturn : 54.94528579711914\n",
            "Train_AverageEpLen : 76.55555555555556\n",
            "Train_EnvstepsSoFar : 403274\n",
            "TimeSinceStart : 328.67373275756836\n",
            "Training Loss : -0.013301290571689606\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 199 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2032])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 139.70382690429688\n",
            "Eval_StdReturn : 15.657363891601562\n",
            "Eval_MaxReturn : 152.82113647460938\n",
            "Eval_MinReturn : 109.48877716064453\n",
            "Eval_AverageEpLen : 85.2\n",
            "Train_AverageReturn : 128.80284118652344\n",
            "Train_StdReturn : 28.959901809692383\n",
            "Train_MaxReturn : 177.79461669921875\n",
            "Train_MinReturn : 69.86375427246094\n",
            "Train_AverageEpLen : 78.15384615384616\n",
            "Train_EnvstepsSoFar : 405306\n",
            "TimeSinceStart : 330.25206184387207\n",
            "Training Loss : -0.024671122431755066\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 200 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2046])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 152.34066772460938\n",
            "Eval_StdReturn : 11.984640121459961\n",
            "Eval_MaxReturn : 165.81236267089844\n",
            "Eval_MinReturn : 132.4683380126953\n",
            "Eval_AverageEpLen : 91.4\n",
            "Train_AverageReturn : 130.5880584716797\n",
            "Train_StdReturn : 23.817218780517578\n",
            "Train_MaxReturn : 173.65655517578125\n",
            "Train_MinReturn : 89.52092742919922\n",
            "Train_AverageEpLen : 81.84\n",
            "Train_EnvstepsSoFar : 407352\n",
            "TimeSinceStart : 331.8513185977936\n",
            "Training Loss : -0.028075002133846283\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 201 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2045])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 100.07398223876953\n",
            "Eval_StdReturn : 19.568410873413086\n",
            "Eval_MaxReturn : 122.61308288574219\n",
            "Eval_MinReturn : 60.6734504699707\n",
            "Eval_AverageEpLen : 66.83333333333333\n",
            "Train_AverageReturn : 118.6328125\n",
            "Train_StdReturn : 25.738630294799805\n",
            "Train_MaxReturn : 161.72506713867188\n",
            "Train_MinReturn : 65.96907806396484\n",
            "Train_AverageEpLen : 75.74074074074075\n",
            "Train_EnvstepsSoFar : 409397\n",
            "TimeSinceStart : 333.4398612976074\n",
            "Training Loss : -0.032256122678518295\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 202 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2046])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 81.65435791015625\n",
            "Eval_StdReturn : 17.962575912475586\n",
            "Eval_MaxReturn : 104.77918243408203\n",
            "Eval_MinReturn : 51.7073974609375\n",
            "Eval_AverageEpLen : 57.375\n",
            "Train_AverageReturn : 103.00421905517578\n",
            "Train_StdReturn : 28.50722312927246\n",
            "Train_MaxReturn : 159.67481994628906\n",
            "Train_MinReturn : 53.74506378173828\n",
            "Train_AverageEpLen : 68.2\n",
            "Train_EnvstepsSoFar : 411443\n",
            "TimeSinceStart : 335.0540030002594\n",
            "Training Loss : -0.03533443436026573\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 203 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2030])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 59.05119705200195\n",
            "Eval_StdReturn : 17.800750732421875\n",
            "Eval_MaxReturn : 97.2890853881836\n",
            "Eval_MinReturn : 31.131227493286133\n",
            "Eval_AverageEpLen : 41.8\n",
            "Train_AverageReturn : 87.17547607421875\n",
            "Train_StdReturn : 22.477985382080078\n",
            "Train_MaxReturn : 132.96212768554688\n",
            "Train_MinReturn : 45.53472137451172\n",
            "Train_AverageEpLen : 59.705882352941174\n",
            "Train_EnvstepsSoFar : 413473\n",
            "TimeSinceStart : 336.64699387550354\n",
            "Training Loss : -0.03488403931260109\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 204 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2008])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 51.32966613769531\n",
            "Eval_StdReturn : 19.906631469726562\n",
            "Eval_MaxReturn : 85.86951446533203\n",
            "Eval_MinReturn : 22.315994262695312\n",
            "Eval_AverageEpLen : 37.54545454545455\n",
            "Train_AverageReturn : 64.51496887207031\n",
            "Train_StdReturn : 18.913545608520508\n",
            "Train_MaxReturn : 111.49102783203125\n",
            "Train_MinReturn : 31.371631622314453\n",
            "Train_AverageEpLen : 45.62222222222222\n",
            "Train_EnvstepsSoFar : 415526\n",
            "TimeSinceStart : 338.26709508895874\n",
            "Training Loss : -0.019984016194939613\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 205 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2005])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 46.23356628417969\n",
            "Eval_StdReturn : 23.180578231811523\n",
            "Eval_MaxReturn : 105.66473388671875\n",
            "Eval_MinReturn : 11.757841110229492\n",
            "Eval_AverageEpLen : 34.30769230769231\n",
            "Train_AverageReturn : 56.956024169921875\n",
            "Train_StdReturn : 16.033554077148438\n",
            "Train_MaxReturn : 101.10406494140625\n",
            "Train_MinReturn : 31.34383201599121\n",
            "Train_AverageEpLen : 40.91836734693877\n",
            "Train_EnvstepsSoFar : 417531\n",
            "TimeSinceStart : 339.8911678791046\n",
            "Training Loss : -0.020401606336236\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 206 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2016])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 45.411861419677734\n",
            "Eval_StdReturn : 8.999979972839355\n",
            "Eval_MaxReturn : 57.825321197509766\n",
            "Eval_MinReturn : 31.304283142089844\n",
            "Eval_AverageEpLen : 33.5\n",
            "Train_AverageReturn : 51.475196838378906\n",
            "Train_StdReturn : 16.260744094848633\n",
            "Train_MaxReturn : 113.534423828125\n",
            "Train_MinReturn : 15.533026695251465\n",
            "Train_AverageEpLen : 37.333333333333336\n",
            "Train_EnvstepsSoFar : 419547\n",
            "TimeSinceStart : 341.4971740245819\n",
            "Training Loss : 0.0013284797314554453\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 207 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2002])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 38.41205596923828\n",
            "Eval_StdReturn : 7.8030571937561035\n",
            "Eval_MaxReturn : 52.96165084838867\n",
            "Eval_MinReturn : 25.30357551574707\n",
            "Eval_AverageEpLen : 29.357142857142858\n",
            "Train_AverageReturn : 44.904903411865234\n",
            "Train_StdReturn : 13.300435066223145\n",
            "Train_MaxReturn : 79.0205078125\n",
            "Train_MinReturn : 16.540761947631836\n",
            "Train_AverageEpLen : 33.21311475409836\n",
            "Train_EnvstepsSoFar : 421573\n",
            "TimeSinceStart : 343.13723516464233\n",
            "Training Loss : 0.00773243885487318\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 208 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2002])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 39.43330764770508\n",
            "Eval_StdReturn : 10.72965145111084\n",
            "Eval_MaxReturn : 64.27849578857422\n",
            "Eval_MinReturn : 21.113582611083984\n",
            "Eval_AverageEpLen : 29.428571428571427\n",
            "Train_AverageReturn : 36.67600631713867\n",
            "Train_StdReturn : 12.35814094543457\n",
            "Train_MaxReturn : 74.39203643798828\n",
            "Train_MinReturn : 17.296300888061523\n",
            "Train_AverageEpLen : 28.197183098591548\n",
            "Train_EnvstepsSoFar : 423575\n",
            "TimeSinceStart : 344.7298309803009\n",
            "Training Loss : -0.0075890193693339825\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 209 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2006])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 32.10806655883789\n",
            "Eval_StdReturn : 13.813835144042969\n",
            "Eval_MaxReturn : 57.730491638183594\n",
            "Eval_MinReturn : 12.837932586669922\n",
            "Eval_AverageEpLen : 25.647058823529413\n",
            "Train_AverageReturn : 35.57361602783203\n",
            "Train_StdReturn : 10.420165061950684\n",
            "Train_MaxReturn : 57.46889877319336\n",
            "Train_MinReturn : 13.305761337280273\n",
            "Train_AverageEpLen : 27.472972972972972\n",
            "Train_EnvstepsSoFar : 425608\n",
            "TimeSinceStart : 346.3663568496704\n",
            "Training Loss : -0.056017883121967316\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 210 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2017])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 31.64500617980957\n",
            "Eval_StdReturn : 11.816544532775879\n",
            "Eval_MaxReturn : 54.38253402709961\n",
            "Eval_MinReturn : 10.517325401306152\n",
            "Eval_AverageEpLen : 25.25\n",
            "Train_AverageReturn : 33.2892951965332\n",
            "Train_StdReturn : 11.976099967956543\n",
            "Train_MaxReturn : 61.84233093261719\n",
            "Train_MinReturn : 6.727997779846191\n",
            "Train_AverageEpLen : 26.194805194805195\n",
            "Train_EnvstepsSoFar : 427625\n",
            "TimeSinceStart : 347.96302008628845\n",
            "Training Loss : -0.01619846001267433\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 211 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2025])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 32.44214630126953\n",
            "Eval_StdReturn : 10.594510078430176\n",
            "Eval_MaxReturn : 50.47616958618164\n",
            "Eval_MinReturn : 17.433761596679688\n",
            "Eval_AverageEpLen : 25.8125\n",
            "Train_AverageReturn : 33.538082122802734\n",
            "Train_StdReturn : 10.814508438110352\n",
            "Train_MaxReturn : 56.48521423339844\n",
            "Train_MinReturn : 10.759726524353027\n",
            "Train_AverageEpLen : 26.2987012987013\n",
            "Train_EnvstepsSoFar : 429650\n",
            "TimeSinceStart : 349.6028571128845\n",
            "Training Loss : -0.034971967339515686\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 212 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2020])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 30.177038192749023\n",
            "Eval_StdReturn : 11.358278274536133\n",
            "Eval_MaxReturn : 54.192325592041016\n",
            "Eval_MinReturn : 12.355457305908203\n",
            "Eval_AverageEpLen : 24.470588235294116\n",
            "Train_AverageReturn : 29.69943618774414\n",
            "Train_StdReturn : 8.983765602111816\n",
            "Train_MaxReturn : 51.410282135009766\n",
            "Train_MinReturn : 11.867626190185547\n",
            "Train_AverageEpLen : 24.047619047619047\n",
            "Train_EnvstepsSoFar : 431670\n",
            "TimeSinceStart : 351.2326581478119\n",
            "Training Loss : 0.021892238408327103\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 213 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2010])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 27.28391456604004\n",
            "Eval_StdReturn : 7.94894552230835\n",
            "Eval_MaxReturn : 42.05404281616211\n",
            "Eval_MinReturn : 14.500434875488281\n",
            "Eval_AverageEpLen : 22.666666666666668\n",
            "Train_AverageReturn : 27.61590003967285\n",
            "Train_StdReturn : 9.727360725402832\n",
            "Train_MaxReturn : 49.81578826904297\n",
            "Train_MinReturn : 8.875969886779785\n",
            "Train_AverageEpLen : 22.84090909090909\n",
            "Train_EnvstepsSoFar : 433680\n",
            "TimeSinceStart : 352.87673139572144\n",
            "Training Loss : -0.03510725498199463\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 214 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2017])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 28.445234298706055\n",
            "Eval_StdReturn : 7.395777702331543\n",
            "Eval_MaxReturn : 41.84853744506836\n",
            "Eval_MinReturn : 13.697364807128906\n",
            "Eval_AverageEpLen : 23.333333333333332\n",
            "Train_AverageReturn : 30.1660099029541\n",
            "Train_StdReturn : 9.15954303741455\n",
            "Train_MaxReturn : 55.820499420166016\n",
            "Train_MinReturn : 8.87491226196289\n",
            "Train_AverageEpLen : 24.301204819277107\n",
            "Train_EnvstepsSoFar : 435697\n",
            "TimeSinceStart : 354.50349712371826\n",
            "Training Loss : 0.003987835254520178\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 215 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2010])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 29.68643569946289\n",
            "Eval_StdReturn : 9.271590232849121\n",
            "Eval_MaxReturn : 48.768680572509766\n",
            "Eval_MinReturn : 17.2764892578125\n",
            "Eval_AverageEpLen : 24.11764705882353\n",
            "Train_AverageReturn : 28.01094627380371\n",
            "Train_StdReturn : 10.517412185668945\n",
            "Train_MaxReturn : 57.2171630859375\n",
            "Train_MinReturn : 7.353146553039551\n",
            "Train_AverageEpLen : 23.103448275862068\n",
            "Train_EnvstepsSoFar : 437707\n",
            "TimeSinceStart : 356.12439942359924\n",
            "Training Loss : 0.010667168535292149\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 216 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2007])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 30.160314559936523\n",
            "Eval_StdReturn : 8.917366981506348\n",
            "Eval_MaxReturn : 46.15048599243164\n",
            "Eval_MinReturn : 12.954595565795898\n",
            "Eval_AverageEpLen : 24.352941176470587\n",
            "Train_AverageReturn : 29.521228790283203\n",
            "Train_StdReturn : 9.851901054382324\n",
            "Train_MaxReturn : 60.32064437866211\n",
            "Train_MinReturn : 7.048728942871094\n",
            "Train_AverageEpLen : 23.892857142857142\n",
            "Train_EnvstepsSoFar : 439714\n",
            "TimeSinceStart : 357.7565128803253\n",
            "Training Loss : 0.05210818350315094\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 217 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2003])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 31.075870513916016\n",
            "Eval_StdReturn : 10.104469299316406\n",
            "Eval_MaxReturn : 52.097286224365234\n",
            "Eval_MinReturn : 14.355575561523438\n",
            "Eval_AverageEpLen : 24.823529411764707\n",
            "Train_AverageReturn : 30.366073608398438\n",
            "Train_StdReturn : 9.919584274291992\n",
            "Train_MaxReturn : 53.65626525878906\n",
            "Train_MinReturn : 10.362598419189453\n",
            "Train_AverageEpLen : 24.426829268292682\n",
            "Train_EnvstepsSoFar : 441717\n",
            "TimeSinceStart : 359.38224387168884\n",
            "Training Loss : 0.09197764843702316\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 218 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2023])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 37.68002700805664\n",
            "Eval_StdReturn : 8.83056926727295\n",
            "Eval_MaxReturn : 49.07703399658203\n",
            "Eval_MinReturn : 12.649850845336914\n",
            "Eval_AverageEpLen : 28.642857142857142\n",
            "Train_AverageReturn : 32.325252532958984\n",
            "Train_StdReturn : 9.797539710998535\n",
            "Train_MaxReturn : 56.13700866699219\n",
            "Train_MinReturn : 11.363665580749512\n",
            "Train_AverageEpLen : 25.60759493670886\n",
            "Train_EnvstepsSoFar : 443740\n",
            "TimeSinceStart : 360.9921748638153\n",
            "Training Loss : 0.014599036425352097\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 219 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2005])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 39.9175910949707\n",
            "Eval_StdReturn : 10.548684120178223\n",
            "Eval_MaxReturn : 60.716529846191406\n",
            "Eval_MinReturn : 19.176376342773438\n",
            "Eval_AverageEpLen : 30.142857142857142\n",
            "Train_AverageReturn : 33.72565460205078\n",
            "Train_StdReturn : 11.810389518737793\n",
            "Train_MaxReturn : 65.88259887695312\n",
            "Train_MinReturn : 9.627005577087402\n",
            "Train_AverageEpLen : 26.38157894736842\n",
            "Train_EnvstepsSoFar : 445745\n",
            "TimeSinceStart : 362.5909352302551\n",
            "Training Loss : 0.029659727588295937\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 220 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2001])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 48.52740478515625\n",
            "Eval_StdReturn : 10.721284866333008\n",
            "Eval_MaxReturn : 66.39057922363281\n",
            "Eval_MinReturn : 29.490877151489258\n",
            "Eval_AverageEpLen : 35.25\n",
            "Train_AverageReturn : 40.399742126464844\n",
            "Train_StdReturn : 10.112900733947754\n",
            "Train_MaxReturn : 62.87382507324219\n",
            "Train_MinReturn : 22.470041275024414\n",
            "Train_AverageEpLen : 30.328358208955223\n",
            "Train_EnvstepsSoFar : 447777\n",
            "TimeSinceStart : 364.21949338912964\n",
            "Training Loss : 0.040546517819166183\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 221 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2017])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 44.63943099975586\n",
            "Eval_StdReturn : 8.306496620178223\n",
            "Eval_MaxReturn : 53.838748931884766\n",
            "Eval_MinReturn : 26.572450637817383\n",
            "Eval_AverageEpLen : 32.69230769230769\n",
            "Train_AverageReturn : 40.751399993896484\n",
            "Train_StdReturn : 12.470149993896484\n",
            "Train_MaxReturn : 80.28874206542969\n",
            "Train_MinReturn : 14.276445388793945\n",
            "Train_AverageEpLen : 30.560606060606062\n",
            "Train_EnvstepsSoFar : 449794\n",
            "TimeSinceStart : 365.82001399993896\n",
            "Training Loss : 0.04535064473748207\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 222 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2005])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 46.71633529663086\n",
            "Eval_StdReturn : 6.27142858505249\n",
            "Eval_MaxReturn : 55.13121032714844\n",
            "Eval_MinReturn : 34.83036422729492\n",
            "Eval_AverageEpLen : 34.166666666666664\n",
            "Train_AverageReturn : 44.78491973876953\n",
            "Train_StdReturn : 11.249061584472656\n",
            "Train_MaxReturn : 71.45671844482422\n",
            "Train_MinReturn : 17.53406524658203\n",
            "Train_AverageEpLen : 32.868852459016395\n",
            "Train_EnvstepsSoFar : 451799\n",
            "TimeSinceStart : 367.4130504131317\n",
            "Training Loss : 0.015357881784439087\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 223 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2002])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 57.55717849731445\n",
            "Eval_StdReturn : 11.384564399719238\n",
            "Eval_MaxReturn : 72.00106811523438\n",
            "Eval_MinReturn : 39.04017639160156\n",
            "Eval_AverageEpLen : 41.0\n",
            "Train_AverageReturn : 53.58708953857422\n",
            "Train_StdReturn : 12.076709747314453\n",
            "Train_MaxReturn : 78.96959686279297\n",
            "Train_MinReturn : 32.69469451904297\n",
            "Train_AverageEpLen : 38.5\n",
            "Train_EnvstepsSoFar : 453801\n",
            "TimeSinceStart : 368.9988121986389\n",
            "Training Loss : 0.011792637407779694\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 224 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2010])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 63.54568862915039\n",
            "Eval_StdReturn : 12.69571590423584\n",
            "Eval_MaxReturn : 80.75287628173828\n",
            "Eval_MinReturn : 47.07572937011719\n",
            "Eval_AverageEpLen : 45.0\n",
            "Train_AverageReturn : 58.7874755859375\n",
            "Train_StdReturn : 11.985045433044434\n",
            "Train_MaxReturn : 91.83497619628906\n",
            "Train_MinReturn : 38.11960983276367\n",
            "Train_AverageEpLen : 41.875\n",
            "Train_EnvstepsSoFar : 455811\n",
            "TimeSinceStart : 370.5906403064728\n",
            "Training Loss : 0.00668306602165103\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 225 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 72.3426513671875\n",
            "Eval_StdReturn : 13.315500259399414\n",
            "Eval_MaxReturn : 97.92153930664062\n",
            "Eval_MinReturn : 56.593605041503906\n",
            "Eval_AverageEpLen : 50.25\n",
            "Train_AverageReturn : 65.86185455322266\n",
            "Train_StdReturn : 13.69841194152832\n",
            "Train_MaxReturn : 91.19054412841797\n",
            "Train_MinReturn : 41.28879165649414\n",
            "Train_AverageEpLen : 46.51162790697674\n",
            "Train_EnvstepsSoFar : 457811\n",
            "TimeSinceStart : 372.1666855812073\n",
            "Training Loss : -0.00378113123588264\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 226 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2003])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 75.75686645507812\n",
            "Eval_StdReturn : 15.288406372070312\n",
            "Eval_MaxReturn : 96.60026550292969\n",
            "Eval_MinReturn : 49.643611907958984\n",
            "Eval_AverageEpLen : 53.5\n",
            "Train_AverageReturn : 73.19051361083984\n",
            "Train_StdReturn : 13.98167610168457\n",
            "Train_MaxReturn : 97.0877456665039\n",
            "Train_MinReturn : 45.37548828125\n",
            "Train_AverageEpLen : 51.35897435897436\n",
            "Train_EnvstepsSoFar : 459814\n",
            "TimeSinceStart : 373.755078792572\n",
            "Training Loss : -0.004862410016357899\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 227 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2008])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 95.49357604980469\n",
            "Eval_StdReturn : 26.572336196899414\n",
            "Eval_MaxReturn : 142.2247314453125\n",
            "Eval_MinReturn : 59.95150375366211\n",
            "Eval_AverageEpLen : 64.42857142857143\n",
            "Train_AverageReturn : 84.76470947265625\n",
            "Train_StdReturn : 18.912364959716797\n",
            "Train_MaxReturn : 138.04933166503906\n",
            "Train_MinReturn : 43.904232025146484\n",
            "Train_AverageEpLen : 59.05882352941177\n",
            "Train_EnvstepsSoFar : 461822\n",
            "TimeSinceStart : 375.3503682613373\n",
            "Training Loss : 0.03666508197784424\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 228 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2023])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 84.25366973876953\n",
            "Eval_StdReturn : 24.307052612304688\n",
            "Eval_MaxReturn : 110.11248779296875\n",
            "Eval_MinReturn : 52.8613166809082\n",
            "Eval_AverageEpLen : 57.714285714285715\n",
            "Train_AverageReturn : 89.6038589477539\n",
            "Train_StdReturn : 23.139219284057617\n",
            "Train_MaxReturn : 158.20150756835938\n",
            "Train_MinReturn : 52.264549255371094\n",
            "Train_AverageEpLen : 61.303030303030305\n",
            "Train_EnvstepsSoFar : 463845\n",
            "TimeSinceStart : 376.9217472076416\n",
            "Training Loss : 0.026319943368434906\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 229 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2006])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 119.95453643798828\n",
            "Eval_StdReturn : 21.17831039428711\n",
            "Eval_MaxReturn : 159.4651641845703\n",
            "Eval_MinReturn : 92.95449829101562\n",
            "Eval_AverageEpLen : 78.5\n",
            "Train_AverageReturn : 101.28343200683594\n",
            "Train_StdReturn : 15.579402923583984\n",
            "Train_MaxReturn : 138.1663360595703\n",
            "Train_MinReturn : 76.02662658691406\n",
            "Train_AverageEpLen : 69.17241379310344\n",
            "Train_EnvstepsSoFar : 465851\n",
            "TimeSinceStart : 378.52860260009766\n",
            "Training Loss : -0.015559281222522259\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 230 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2031])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 135.67636108398438\n",
            "Eval_StdReturn : 18.816421508789062\n",
            "Eval_MaxReturn : 162.97268676757812\n",
            "Eval_MinReturn : 105.89933776855469\n",
            "Eval_AverageEpLen : 83.6\n",
            "Train_AverageReturn : 120.291748046875\n",
            "Train_StdReturn : 23.770381927490234\n",
            "Train_MaxReturn : 181.71658325195312\n",
            "Train_MinReturn : 65.02754211425781\n",
            "Train_AverageEpLen : 78.11538461538461\n",
            "Train_EnvstepsSoFar : 467882\n",
            "TimeSinceStart : 380.1120185852051\n",
            "Training Loss : 0.004379883874207735\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 231 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2019])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 154.44577026367188\n",
            "Eval_StdReturn : 23.531131744384766\n",
            "Eval_MaxReturn : 192.14816284179688\n",
            "Eval_MinReturn : 118.17213439941406\n",
            "Eval_AverageEpLen : 93.8\n",
            "Train_AverageReturn : 132.6586151123047\n",
            "Train_StdReturn : 21.542190551757812\n",
            "Train_MaxReturn : 176.10581970214844\n",
            "Train_MinReturn : 84.83435821533203\n",
            "Train_AverageEpLen : 84.125\n",
            "Train_EnvstepsSoFar : 469901\n",
            "TimeSinceStart : 381.74123525619507\n",
            "Training Loss : -0.07386209070682526\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 232 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2031])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 167.47830200195312\n",
            "Eval_StdReturn : 19.196788787841797\n",
            "Eval_MaxReturn : 191.1614990234375\n",
            "Eval_MinReturn : 137.75778198242188\n",
            "Eval_AverageEpLen : 102.25\n",
            "Train_AverageReturn : 145.45230102539062\n",
            "Train_StdReturn : 19.90782928466797\n",
            "Train_MaxReturn : 181.02027893066406\n",
            "Train_MinReturn : 98.50192260742188\n",
            "Train_AverageEpLen : 88.30434782608695\n",
            "Train_EnvstepsSoFar : 471932\n",
            "TimeSinceStart : 383.36072182655334\n",
            "Training Loss : -0.05551156774163246\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 233 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2045])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 190.41940307617188\n",
            "Eval_StdReturn : 15.168047904968262\n",
            "Eval_MaxReturn : 207.68988037109375\n",
            "Eval_MinReturn : 166.29273986816406\n",
            "Eval_AverageEpLen : 104.0\n",
            "Train_AverageReturn : 155.32594299316406\n",
            "Train_StdReturn : 21.80742645263672\n",
            "Train_MaxReturn : 202.13235473632812\n",
            "Train_MinReturn : 109.54141235351562\n",
            "Train_AverageEpLen : 92.95454545454545\n",
            "Train_EnvstepsSoFar : 473977\n",
            "TimeSinceStart : 384.9499032497406\n",
            "Training Loss : -0.014674460515379906\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 234 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2028])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 155.95755004882812\n",
            "Eval_StdReturn : 48.362056732177734\n",
            "Eval_MaxReturn : 203.8150634765625\n",
            "Eval_MinReturn : 64.3830337524414\n",
            "Eval_AverageEpLen : 86.0\n",
            "Train_AverageReturn : 166.8013458251953\n",
            "Train_StdReturn : 24.307937622070312\n",
            "Train_MaxReturn : 201.65176391601562\n",
            "Train_MinReturn : 95.29386901855469\n",
            "Train_AverageEpLen : 96.57142857142857\n",
            "Train_EnvstepsSoFar : 476005\n",
            "TimeSinceStart : 386.5373487472534\n",
            "Training Loss : -0.08027846366167068\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 235 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2031])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 201.330322265625\n",
            "Eval_StdReturn : 4.593847274780273\n",
            "Eval_MaxReturn : 208.60009765625\n",
            "Eval_MinReturn : 196.29833984375\n",
            "Eval_AverageEpLen : 111.5\n",
            "Train_AverageReturn : 176.4911651611328\n",
            "Train_StdReturn : 23.9807186126709\n",
            "Train_MaxReturn : 206.11544799804688\n",
            "Train_MinReturn : 104.8302230834961\n",
            "Train_AverageEpLen : 99.66666666666667\n",
            "Train_EnvstepsSoFar : 478098\n",
            "TimeSinceStart : 388.1565878391266\n",
            "Training Loss : -0.02783864736557007\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 236 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2075])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 198.9042510986328\n",
            "Eval_StdReturn : 15.665234565734863\n",
            "Eval_MaxReturn : 220.10687255859375\n",
            "Eval_MinReturn : 177.72116088867188\n",
            "Eval_AverageEpLen : 108.75\n",
            "Train_AverageReturn : 178.69886779785156\n",
            "Train_StdReturn : 26.034208297729492\n",
            "Train_MaxReturn : 207.0567169189453\n",
            "Train_MinReturn : 88.96790313720703\n",
            "Train_AverageEpLen : 98.80952380952381\n",
            "Train_EnvstepsSoFar : 480173\n",
            "TimeSinceStart : 389.7862422466278\n",
            "Training Loss : 0.018257733434438705\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 237 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2075])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 166.36203002929688\n",
            "Eval_StdReturn : 32.67210388183594\n",
            "Eval_MaxReturn : 206.6532440185547\n",
            "Eval_MinReturn : 120.1188735961914\n",
            "Eval_AverageEpLen : 85.6\n",
            "Train_AverageReturn : 179.81195068359375\n",
            "Train_StdReturn : 21.05392837524414\n",
            "Train_MaxReturn : 204.62388610839844\n",
            "Train_MinReturn : 120.27548217773438\n",
            "Train_AverageEpLen : 98.80952380952381\n",
            "Train_EnvstepsSoFar : 482248\n",
            "TimeSinceStart : 391.3999629020691\n",
            "Training Loss : -0.05783314257860184\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 238 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2069])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 153.139892578125\n",
            "Eval_StdReturn : 49.66949462890625\n",
            "Eval_MaxReturn : 196.53494262695312\n",
            "Eval_MinReturn : 84.76312255859375\n",
            "Eval_AverageEpLen : 80.6\n",
            "Train_AverageReturn : 176.57789611816406\n",
            "Train_StdReturn : 35.907920837402344\n",
            "Train_MaxReturn : 212.688720703125\n",
            "Train_MinReturn : 48.126731872558594\n",
            "Train_AverageEpLen : 94.04545454545455\n",
            "Train_EnvstepsSoFar : 484317\n",
            "TimeSinceStart : 393.01588106155396\n",
            "Training Loss : -0.02147589437663555\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 239 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2006])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 164.0809326171875\n",
            "Eval_StdReturn : 49.38101577758789\n",
            "Eval_MaxReturn : 201.01443481445312\n",
            "Eval_MinReturn : 93.37626647949219\n",
            "Eval_AverageEpLen : 81.66666666666667\n",
            "Train_AverageReturn : 182.1831512451172\n",
            "Train_StdReturn : 27.551883697509766\n",
            "Train_MaxReturn : 215.03475952148438\n",
            "Train_MinReturn : 115.81117248535156\n",
            "Train_AverageEpLen : 95.52380952380952\n",
            "Train_EnvstepsSoFar : 486323\n",
            "TimeSinceStart : 394.6394271850586\n",
            "Training Loss : -0.04259426146745682\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 240 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2013])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 199.08175659179688\n",
            "Eval_StdReturn : 7.336112976074219\n",
            "Eval_MaxReturn : 209.41079711914062\n",
            "Eval_MinReturn : 189.7224578857422\n",
            "Eval_AverageEpLen : 100.0\n",
            "Train_AverageReturn : 185.2817840576172\n",
            "Train_StdReturn : 27.83784294128418\n",
            "Train_MaxReturn : 223.1995849609375\n",
            "Train_MinReturn : 108.63847351074219\n",
            "Train_AverageEpLen : 94.5909090909091\n",
            "Train_EnvstepsSoFar : 488404\n",
            "TimeSinceStart : 396.2473168373108\n",
            "Training Loss : 0.015790019184350967\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 241 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2016])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 187.3534393310547\n",
            "Eval_StdReturn : 19.45496368408203\n",
            "Eval_MaxReturn : 202.85414123535156\n",
            "Eval_MinReturn : 149.89492797851562\n",
            "Eval_AverageEpLen : 88.8\n",
            "Train_AverageReturn : 180.92669677734375\n",
            "Train_StdReturn : 34.949188232421875\n",
            "Train_MaxReturn : 215.8461151123047\n",
            "Train_MinReturn : 82.8466796875\n",
            "Train_AverageEpLen : 90.47826086956522\n",
            "Train_EnvstepsSoFar : 490485\n",
            "TimeSinceStart : 397.9068088531494\n",
            "Training Loss : -0.01753232814371586\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 242 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2063])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 176.19088745117188\n",
            "Eval_StdReturn : 19.53900718688965\n",
            "Eval_MaxReturn : 200.9690399169922\n",
            "Eval_MinReturn : 155.70443725585938\n",
            "Eval_AverageEpLen : 88.8\n",
            "Train_AverageReturn : 179.0701904296875\n",
            "Train_StdReturn : 34.94832229614258\n",
            "Train_MaxReturn : 218.33865356445312\n",
            "Train_MinReturn : 100.5408706665039\n",
            "Train_AverageEpLen : 89.69565217391305\n",
            "Train_EnvstepsSoFar : 492548\n",
            "TimeSinceStart : 399.5312089920044\n",
            "Training Loss : 0.0024859418626874685\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 243 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2072])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 201.40817260742188\n",
            "Eval_StdReturn : 6.003287315368652\n",
            "Eval_MaxReturn : 212.88458251953125\n",
            "Eval_MinReturn : 196.43524169921875\n",
            "Eval_AverageEpLen : 97.0\n",
            "Train_AverageReturn : 182.00357055664062\n",
            "Train_StdReturn : 29.227005004882812\n",
            "Train_MaxReturn : 215.8931884765625\n",
            "Train_MinReturn : 106.38512420654297\n",
            "Train_AverageEpLen : 90.08695652173913\n",
            "Train_EnvstepsSoFar : 494620\n",
            "TimeSinceStart : 401.2251467704773\n",
            "Training Loss : -0.023861229419708252\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 244 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2017])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 190.07736206054688\n",
            "Eval_StdReturn : 26.64552116394043\n",
            "Eval_MaxReturn : 206.63430786132812\n",
            "Eval_MinReturn : 136.98165893554688\n",
            "Eval_AverageEpLen : 93.4\n",
            "Train_AverageReturn : 184.92037963867188\n",
            "Train_StdReturn : 32.736427307128906\n",
            "Train_MaxReturn : 217.8109130859375\n",
            "Train_MinReturn : 100.13908386230469\n",
            "Train_AverageEpLen : 91.68181818181819\n",
            "Train_EnvstepsSoFar : 496637\n",
            "TimeSinceStart : 402.8608958721161\n",
            "Training Loss : -0.06895406544208527\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 245 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2013])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 208.71060180664062\n",
            "Eval_StdReturn : 8.0436372756958\n",
            "Eval_MaxReturn : 216.66943359375\n",
            "Eval_MinReturn : 196.2549591064453\n",
            "Eval_AverageEpLen : 96.0\n",
            "Train_AverageReturn : 188.19435119628906\n",
            "Train_StdReturn : 33.15013885498047\n",
            "Train_MaxReturn : 215.71131896972656\n",
            "Train_MinReturn : 55.60446548461914\n",
            "Train_AverageEpLen : 91.5\n",
            "Train_EnvstepsSoFar : 498650\n",
            "TimeSinceStart : 404.4917366504669\n",
            "Training Loss : -0.0733950138092041\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 246 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2006])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 203.4325714111328\n",
            "Eval_StdReturn : 11.654176712036133\n",
            "Eval_MaxReturn : 218.62083435058594\n",
            "Eval_MinReturn : 186.70751953125\n",
            "Eval_AverageEpLen : 98.0\n",
            "Train_AverageReturn : 193.12591552734375\n",
            "Train_StdReturn : 30.445344924926758\n",
            "Train_MaxReturn : 213.719482421875\n",
            "Train_MinReturn : 101.57913970947266\n",
            "Train_AverageEpLen : 95.52380952380952\n",
            "Train_EnvstepsSoFar : 500656\n",
            "TimeSinceStart : 406.12964725494385\n",
            "Training Loss : -0.026731956750154495\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 247 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2040])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 192.10519409179688\n",
            "Eval_StdReturn : 12.09459400177002\n",
            "Eval_MaxReturn : 206.93182373046875\n",
            "Eval_MinReturn : 170.772216796875\n",
            "Eval_AverageEpLen : 92.6\n",
            "Train_AverageReturn : 193.30445861816406\n",
            "Train_StdReturn : 21.235368728637695\n",
            "Train_MaxReturn : 221.1699981689453\n",
            "Train_MinReturn : 107.47514343261719\n",
            "Train_AverageEpLen : 92.72727272727273\n",
            "Train_EnvstepsSoFar : 502696\n",
            "TimeSinceStart : 407.75750160217285\n",
            "Training Loss : -0.08029039204120636\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 248 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2063])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 206.845458984375\n",
            "Eval_StdReturn : 8.644123077392578\n",
            "Eval_MaxReturn : 218.9303741455078\n",
            "Eval_MinReturn : 194.444580078125\n",
            "Eval_AverageEpLen : 96.2\n",
            "Train_AverageReturn : 198.62579345703125\n",
            "Train_StdReturn : 18.415895462036133\n",
            "Train_MaxReturn : 216.79983520507812\n",
            "Train_MinReturn : 116.95101928710938\n",
            "Train_AverageEpLen : 93.77272727272727\n",
            "Train_EnvstepsSoFar : 504759\n",
            "TimeSinceStart : 409.43700313568115\n",
            "Training Loss : -0.02073579467833042\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 249 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2011])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 192.82313537597656\n",
            "Eval_StdReturn : 6.479151725769043\n",
            "Eval_MaxReturn : 198.3887176513672\n",
            "Eval_MinReturn : 180.4154052734375\n",
            "Eval_AverageEpLen : 91.0\n",
            "Train_AverageReturn : 199.94970703125\n",
            "Train_StdReturn : 6.891104221343994\n",
            "Train_MaxReturn : 213.36549377441406\n",
            "Train_MinReturn : 183.9146270751953\n",
            "Train_AverageEpLen : 95.68181818181819\n",
            "Train_EnvstepsSoFar : 506864\n",
            "TimeSinceStart : 411.1180398464203\n",
            "Training Loss : -0.03971843048930168\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 250 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2047])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 195.82095336914062\n",
            "Eval_StdReturn : 4.958194255828857\n",
            "Eval_MaxReturn : 204.1769561767578\n",
            "Eval_MinReturn : 188.81739807128906\n",
            "Eval_AverageEpLen : 91.6\n",
            "Train_AverageReturn : 197.4560089111328\n",
            "Train_StdReturn : 18.833139419555664\n",
            "Train_MaxReturn : 215.67852783203125\n",
            "Train_MinReturn : 117.13457489013672\n",
            "Train_AverageEpLen : 93.04545454545455\n",
            "Train_EnvstepsSoFar : 508911\n",
            "TimeSinceStart : 412.765079498291\n",
            "Training Loss : -0.015535936690866947\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 251 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2041])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 200.9487762451172\n",
            "Eval_StdReturn : 10.434863090515137\n",
            "Eval_MaxReturn : 217.79330444335938\n",
            "Eval_MinReturn : 189.36524963378906\n",
            "Eval_AverageEpLen : 95.8\n",
            "Train_AverageReturn : 198.8065948486328\n",
            "Train_StdReturn : 7.884968280792236\n",
            "Train_MaxReturn : 217.90684509277344\n",
            "Train_MinReturn : 184.85137939453125\n",
            "Train_AverageEpLen : 92.77272727272727\n",
            "Train_EnvstepsSoFar : 510952\n",
            "TimeSinceStart : 414.42984914779663\n",
            "Training Loss : -0.001067356439307332\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 252 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2072])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 199.84817504882812\n",
            "Eval_StdReturn : 5.812277317047119\n",
            "Eval_MaxReturn : 208.973876953125\n",
            "Eval_MinReturn : 191.96881103515625\n",
            "Eval_AverageEpLen : 95.6\n",
            "Train_AverageReturn : 196.46778869628906\n",
            "Train_StdReturn : 6.913862228393555\n",
            "Train_MaxReturn : 209.9324951171875\n",
            "Train_MinReturn : 181.47427368164062\n",
            "Train_AverageEpLen : 94.18181818181819\n",
            "Train_EnvstepsSoFar : 513024\n",
            "TimeSinceStart : 416.09396624565125\n",
            "Training Loss : -0.020831026136875153\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 253 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2042])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 197.7654571533203\n",
            "Eval_StdReturn : 4.6397223472595215\n",
            "Eval_MaxReturn : 204.14906311035156\n",
            "Eval_MinReturn : 190.140380859375\n",
            "Eval_AverageEpLen : 95.6\n",
            "Train_AverageReturn : 192.8773956298828\n",
            "Train_StdReturn : 30.280302047729492\n",
            "Train_MaxReturn : 211.95079040527344\n",
            "Train_MinReturn : 56.19119644165039\n",
            "Train_AverageEpLen : 92.81818181818181\n",
            "Train_EnvstepsSoFar : 515066\n",
            "TimeSinceStart : 417.7203755378723\n",
            "Training Loss : -0.04441703483462334\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 254 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2058])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 193.38372802734375\n",
            "Eval_StdReturn : 9.043766975402832\n",
            "Eval_MaxReturn : 207.64405822753906\n",
            "Eval_MinReturn : 182.89805603027344\n",
            "Eval_AverageEpLen : 93.4\n",
            "Train_AverageReturn : 197.1484375\n",
            "Train_StdReturn : 7.927395820617676\n",
            "Train_MaxReturn : 212.88009643554688\n",
            "Train_MinReturn : 181.1387939453125\n",
            "Train_AverageEpLen : 93.54545454545455\n",
            "Train_EnvstepsSoFar : 517124\n",
            "TimeSinceStart : 419.36886501312256\n",
            "Training Loss : 0.003950841724872589\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 255 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2012])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 196.94119262695312\n",
            "Eval_StdReturn : 4.505852699279785\n",
            "Eval_MaxReturn : 202.77894592285156\n",
            "Eval_MinReturn : 189.7840576171875\n",
            "Eval_AverageEpLen : 94.2\n",
            "Train_AverageReturn : 196.51943969726562\n",
            "Train_StdReturn : 6.983403205871582\n",
            "Train_MaxReturn : 207.14183044433594\n",
            "Train_MinReturn : 173.66232299804688\n",
            "Train_AverageEpLen : 95.80952380952381\n",
            "Train_EnvstepsSoFar : 519136\n",
            "TimeSinceStart : 420.96985054016113\n",
            "Training Loss : -0.05393045395612717\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 256 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2040])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 202.15809631347656\n",
            "Eval_StdReturn : 3.9248178005218506\n",
            "Eval_MaxReturn : 207.77381896972656\n",
            "Eval_MinReturn : 198.6410675048828\n",
            "Eval_AverageEpLen : 95.8\n",
            "Train_AverageReturn : 193.25587463378906\n",
            "Train_StdReturn : 6.118943691253662\n",
            "Train_MaxReturn : 207.42843627929688\n",
            "Train_MinReturn : 177.79200744628906\n",
            "Train_AverageEpLen : 92.72727272727273\n",
            "Train_EnvstepsSoFar : 521176\n",
            "TimeSinceStart : 422.6167161464691\n",
            "Training Loss : -0.06201671063899994\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 257 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2066])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 193.71377563476562\n",
            "Eval_StdReturn : 4.8620686531066895\n",
            "Eval_MaxReturn : 201.9318084716797\n",
            "Eval_MinReturn : 187.25003051757812\n",
            "Eval_AverageEpLen : 97.2\n",
            "Train_AverageReturn : 194.79734802246094\n",
            "Train_StdReturn : 9.188987731933594\n",
            "Train_MaxReturn : 210.5035400390625\n",
            "Train_MinReturn : 171.5400390625\n",
            "Train_AverageEpLen : 93.9090909090909\n",
            "Train_EnvstepsSoFar : 523242\n",
            "TimeSinceStart : 424.29390120506287\n",
            "Training Loss : -0.013587569817900658\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 258 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2039])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 182.1561279296875\n",
            "Eval_StdReturn : 12.484745979309082\n",
            "Eval_MaxReturn : 192.5137176513672\n",
            "Eval_MinReturn : 158.2980194091797\n",
            "Eval_AverageEpLen : 90.2\n",
            "Train_AverageReturn : 194.08755493164062\n",
            "Train_StdReturn : 10.082347869873047\n",
            "Train_MaxReturn : 207.8031463623047\n",
            "Train_MinReturn : 162.90565490722656\n",
            "Train_AverageEpLen : 92.68181818181819\n",
            "Train_EnvstepsSoFar : 525281\n",
            "TimeSinceStart : 425.9066288471222\n",
            "Training Loss : -0.003207844216376543\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 259 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2040])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 190.83900451660156\n",
            "Eval_StdReturn : 5.6015753746032715\n",
            "Eval_MaxReturn : 200.6966094970703\n",
            "Eval_MinReturn : 184.1812744140625\n",
            "Eval_AverageEpLen : 96.4\n",
            "Train_AverageReturn : 188.69219970703125\n",
            "Train_StdReturn : 11.602298736572266\n",
            "Train_MaxReturn : 205.5195770263672\n",
            "Train_MinReturn : 162.91363525390625\n",
            "Train_AverageEpLen : 92.72727272727273\n",
            "Train_EnvstepsSoFar : 527321\n",
            "TimeSinceStart : 427.5451464653015\n",
            "Training Loss : -0.03297488018870354\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 260 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2059])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 169.46575927734375\n",
            "Eval_StdReturn : 22.088157653808594\n",
            "Eval_MaxReturn : 192.08457946777344\n",
            "Eval_MinReturn : 135.9420623779297\n",
            "Eval_AverageEpLen : 83.2\n",
            "Train_AverageReturn : 193.021728515625\n",
            "Train_StdReturn : 11.089405059814453\n",
            "Train_MaxReturn : 207.23489379882812\n",
            "Train_MinReturn : 154.6188201904297\n",
            "Train_AverageEpLen : 93.5909090909091\n",
            "Train_EnvstepsSoFar : 529380\n",
            "TimeSinceStart : 429.15329599380493\n",
            "Training Loss : -0.0544481985270977\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 261 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2049])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 163.26022338867188\n",
            "Eval_StdReturn : 22.1181640625\n",
            "Eval_MaxReturn : 196.7354278564453\n",
            "Eval_MinReturn : 127.09770202636719\n",
            "Eval_AverageEpLen : 82.2\n",
            "Train_AverageReturn : 190.65928649902344\n",
            "Train_StdReturn : 9.554773330688477\n",
            "Train_MaxReturn : 205.20306396484375\n",
            "Train_MinReturn : 167.89193725585938\n",
            "Train_AverageEpLen : 93.13636363636364\n",
            "Train_EnvstepsSoFar : 531429\n",
            "TimeSinceStart : 430.7866168022156\n",
            "Training Loss : -0.013174095191061497\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 262 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2019])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 164.85328674316406\n",
            "Eval_StdReturn : 29.1347599029541\n",
            "Eval_MaxReturn : 199.50164794921875\n",
            "Eval_MinReturn : 129.0503387451172\n",
            "Eval_AverageEpLen : 87.0\n",
            "Train_AverageReturn : 174.8015899658203\n",
            "Train_StdReturn : 21.128883361816406\n",
            "Train_MaxReturn : 204.04635620117188\n",
            "Train_MinReturn : 127.62796783447266\n",
            "Train_AverageEpLen : 87.78260869565217\n",
            "Train_EnvstepsSoFar : 533448\n",
            "TimeSinceStart : 432.4179210662842\n",
            "Training Loss : -0.022143496200442314\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 263 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2041])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 178.86961364746094\n",
            "Eval_StdReturn : 13.549073219299316\n",
            "Eval_MaxReturn : 198.2585906982422\n",
            "Eval_MinReturn : 159.30111694335938\n",
            "Eval_AverageEpLen : 88.6\n",
            "Train_AverageReturn : 174.56907653808594\n",
            "Train_StdReturn : 22.838010787963867\n",
            "Train_MaxReturn : 206.82562255859375\n",
            "Train_MinReturn : 123.2027587890625\n",
            "Train_AverageEpLen : 88.73913043478261\n",
            "Train_EnvstepsSoFar : 535489\n",
            "TimeSinceStart : 434.0462393760681\n",
            "Training Loss : 0.025536704808473587\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 264 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2062])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 174.55921936035156\n",
            "Eval_StdReturn : 20.388683319091797\n",
            "Eval_MaxReturn : 194.23509216308594\n",
            "Eval_MinReturn : 140.04183959960938\n",
            "Eval_AverageEpLen : 89.6\n",
            "Train_AverageReturn : 167.51043701171875\n",
            "Train_StdReturn : 22.583881378173828\n",
            "Train_MaxReturn : 194.3064422607422\n",
            "Train_MinReturn : 105.4566879272461\n",
            "Train_AverageEpLen : 85.91666666666667\n",
            "Train_EnvstepsSoFar : 537551\n",
            "TimeSinceStart : 435.66896629333496\n",
            "Training Loss : -0.03945343941450119\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 265 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 165.31072998046875\n",
            "Eval_StdReturn : 24.39668083190918\n",
            "Eval_MaxReturn : 193.29690551757812\n",
            "Eval_MinReturn : 133.5200653076172\n",
            "Eval_AverageEpLen : 81.33333333333333\n",
            "Train_AverageReturn : 179.64878845214844\n",
            "Train_StdReturn : 22.453371047973633\n",
            "Train_MaxReturn : 202.72052001953125\n",
            "Train_MinReturn : 117.05974578857422\n",
            "Train_AverageEpLen : 90.9090909090909\n",
            "Train_EnvstepsSoFar : 539551\n",
            "TimeSinceStart : 437.2876629829407\n",
            "Training Loss : -0.004691862966865301\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 266 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2005])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 187.8968048095703\n",
            "Eval_StdReturn : 12.500980377197266\n",
            "Eval_MaxReturn : 202.6760711669922\n",
            "Eval_MinReturn : 166.30029296875\n",
            "Eval_AverageEpLen : 93.8\n",
            "Train_AverageReturn : 163.4873046875\n",
            "Train_StdReturn : 25.038097381591797\n",
            "Train_MaxReturn : 195.66156005859375\n",
            "Train_MinReturn : 118.60919952392578\n",
            "Train_AverageEpLen : 83.54166666666667\n",
            "Train_EnvstepsSoFar : 541556\n",
            "TimeSinceStart : 438.8939447402954\n",
            "Training Loss : -0.0003119280736427754\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 267 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2042])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 172.70237731933594\n",
            "Eval_StdReturn : 10.169934272766113\n",
            "Eval_MaxReturn : 191.5939483642578\n",
            "Eval_MinReturn : 162.45750427246094\n",
            "Eval_AverageEpLen : 86.2\n",
            "Train_AverageReturn : 164.34283447265625\n",
            "Train_StdReturn : 24.931638717651367\n",
            "Train_MaxReturn : 201.6202850341797\n",
            "Train_MinReturn : 107.38015747070312\n",
            "Train_AverageEpLen : 85.08333333333333\n",
            "Train_EnvstepsSoFar : 543598\n",
            "TimeSinceStart : 440.49711656570435\n",
            "Training Loss : -0.049951523542404175\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 268 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2014])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 176.35330200195312\n",
            "Eval_StdReturn : 19.701108932495117\n",
            "Eval_MaxReturn : 191.87374877929688\n",
            "Eval_MinReturn : 141.28445434570312\n",
            "Eval_AverageEpLen : 90.2\n",
            "Train_AverageReturn : 156.0749053955078\n",
            "Train_StdReturn : 21.187170028686523\n",
            "Train_MaxReturn : 191.8281707763672\n",
            "Train_MinReturn : 116.89909362792969\n",
            "Train_AverageEpLen : 80.56\n",
            "Train_EnvstepsSoFar : 545612\n",
            "TimeSinceStart : 442.1080901622772\n",
            "Training Loss : 0.029209906235337257\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 269 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2008])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 164.06399536132812\n",
            "Eval_StdReturn : 24.983552932739258\n",
            "Eval_MaxReturn : 198.90785217285156\n",
            "Eval_MinReturn : 139.01695251464844\n",
            "Eval_AverageEpLen : 84.4\n",
            "Train_AverageReturn : 158.4228057861328\n",
            "Train_StdReturn : 25.354990005493164\n",
            "Train_MaxReturn : 199.79473876953125\n",
            "Train_MinReturn : 104.87301635742188\n",
            "Train_AverageEpLen : 83.66666666666667\n",
            "Train_EnvstepsSoFar : 547620\n",
            "TimeSinceStart : 443.73532485961914\n",
            "Training Loss : 0.00046570462291128933\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 270 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2013])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 177.61106872558594\n",
            "Eval_StdReturn : 17.45813751220703\n",
            "Eval_MaxReturn : 195.52871704101562\n",
            "Eval_MinReturn : 149.60365295410156\n",
            "Eval_AverageEpLen : 89.0\n",
            "Train_AverageReturn : 161.20750427246094\n",
            "Train_StdReturn : 22.732690811157227\n",
            "Train_MaxReturn : 203.3181610107422\n",
            "Train_MinReturn : 129.2491912841797\n",
            "Train_AverageEpLen : 83.875\n",
            "Train_EnvstepsSoFar : 549633\n",
            "TimeSinceStart : 445.3308880329132\n",
            "Training Loss : -0.017301440238952637\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 271 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2048])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 160.30810546875\n",
            "Eval_StdReturn : 8.594884872436523\n",
            "Eval_MaxReturn : 173.08395385742188\n",
            "Eval_MinReturn : 148.9127960205078\n",
            "Eval_AverageEpLen : 83.0\n",
            "Train_AverageReturn : 150.03103637695312\n",
            "Train_StdReturn : 18.02570915222168\n",
            "Train_MaxReturn : 193.09043884277344\n",
            "Train_MinReturn : 117.39076232910156\n",
            "Train_AverageEpLen : 78.76923076923077\n",
            "Train_EnvstepsSoFar : 551681\n",
            "TimeSinceStart : 446.9339716434479\n",
            "Training Loss : -0.019934238865971565\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 272 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2046])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 148.1758270263672\n",
            "Eval_StdReturn : 18.26741600036621\n",
            "Eval_MaxReturn : 178.748046875\n",
            "Eval_MinReturn : 121.09793090820312\n",
            "Eval_AverageEpLen : 79.0\n",
            "Train_AverageReturn : 156.4951629638672\n",
            "Train_StdReturn : 24.19554901123047\n",
            "Train_MaxReturn : 199.05650329589844\n",
            "Train_MinReturn : 113.264404296875\n",
            "Train_AverageEpLen : 85.25\n",
            "Train_EnvstepsSoFar : 553727\n",
            "TimeSinceStart : 448.5783038139343\n",
            "Training Loss : -0.024783357977867126\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 273 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2033])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 149.6023712158203\n",
            "Eval_StdReturn : 17.743064880371094\n",
            "Eval_MaxReturn : 165.3931427001953\n",
            "Eval_MinReturn : 118.43551635742188\n",
            "Eval_AverageEpLen : 79.16666666666667\n",
            "Train_AverageReturn : 159.9604949951172\n",
            "Train_StdReturn : 27.319583892822266\n",
            "Train_MaxReturn : 197.7308349609375\n",
            "Train_MinReturn : 90.73664855957031\n",
            "Train_AverageEpLen : 84.70833333333333\n",
            "Train_EnvstepsSoFar : 555760\n",
            "TimeSinceStart : 450.2187490463257\n",
            "Training Loss : -0.034010615199804306\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 274 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2006])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 165.38446044921875\n",
            "Eval_StdReturn : 21.794527053833008\n",
            "Eval_MaxReturn : 197.23348999023438\n",
            "Eval_MinReturn : 131.04507446289062\n",
            "Eval_AverageEpLen : 83.6\n",
            "Train_AverageReturn : 146.08424377441406\n",
            "Train_StdReturn : 23.855579376220703\n",
            "Train_MaxReturn : 195.63967895507812\n",
            "Train_MinReturn : 94.21607971191406\n",
            "Train_AverageEpLen : 80.24\n",
            "Train_EnvstepsSoFar : 557766\n",
            "TimeSinceStart : 451.78104877471924\n",
            "Training Loss : -0.0638580247759819\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 275 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2003])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 143.13525390625\n",
            "Eval_StdReturn : 15.5972900390625\n",
            "Eval_MaxReturn : 159.47036743164062\n",
            "Eval_MinReturn : 111.5886001586914\n",
            "Eval_AverageEpLen : 79.16666666666667\n",
            "Train_AverageReturn : 142.44834899902344\n",
            "Train_StdReturn : 19.406206130981445\n",
            "Train_MaxReturn : 191.15530395507812\n",
            "Train_MinReturn : 99.72930145263672\n",
            "Train_AverageEpLen : 77.03846153846153\n",
            "Train_EnvstepsSoFar : 559769\n",
            "TimeSinceStart : 453.4144263267517\n",
            "Training Loss : -0.043364573270082474\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 276 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2061])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 155.10675048828125\n",
            "Eval_StdReturn : 21.31814193725586\n",
            "Eval_MaxReturn : 194.5440673828125\n",
            "Eval_MinReturn : 134.89418029785156\n",
            "Eval_AverageEpLen : 86.6\n",
            "Train_AverageReturn : 153.20729064941406\n",
            "Train_StdReturn : 24.776992797851562\n",
            "Train_MaxReturn : 193.941650390625\n",
            "Train_MinReturn : 95.72655487060547\n",
            "Train_AverageEpLen : 82.44\n",
            "Train_EnvstepsSoFar : 561830\n",
            "TimeSinceStart : 455.0577540397644\n",
            "Training Loss : -0.003009500913321972\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 277 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2034])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 147.86265563964844\n",
            "Eval_StdReturn : 13.674997329711914\n",
            "Eval_MaxReturn : 162.0474090576172\n",
            "Eval_MinReturn : 122.10108947753906\n",
            "Eval_AverageEpLen : 82.2\n",
            "Train_AverageReturn : 152.7925567626953\n",
            "Train_StdReturn : 21.683366775512695\n",
            "Train_MaxReturn : 189.28457641601562\n",
            "Train_MinReturn : 109.90824890136719\n",
            "Train_AverageEpLen : 81.36\n",
            "Train_EnvstepsSoFar : 563864\n",
            "TimeSinceStart : 456.65503096580505\n",
            "Training Loss : 0.001403282512910664\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 278 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2041])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 181.28973388671875\n",
            "Eval_StdReturn : 23.95976448059082\n",
            "Eval_MaxReturn : 203.0740966796875\n",
            "Eval_MinReturn : 149.9553680419922\n",
            "Eval_AverageEpLen : 95.8\n",
            "Train_AverageReturn : 152.02679443359375\n",
            "Train_StdReturn : 22.90529441833496\n",
            "Train_MaxReturn : 198.24722290039062\n",
            "Train_MinReturn : 110.94278717041016\n",
            "Train_AverageEpLen : 81.64\n",
            "Train_EnvstepsSoFar : 565905\n",
            "TimeSinceStart : 458.3315749168396\n",
            "Training Loss : -0.020256521180272102\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 279 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2009])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 179.24685668945312\n",
            "Eval_StdReturn : 14.151473999023438\n",
            "Eval_MaxReturn : 193.16390991210938\n",
            "Eval_MinReturn : 154.39678955078125\n",
            "Eval_AverageEpLen : 95.4\n",
            "Train_AverageReturn : 147.08316040039062\n",
            "Train_StdReturn : 26.466556549072266\n",
            "Train_MaxReturn : 199.38662719726562\n",
            "Train_MinReturn : 93.55076599121094\n",
            "Train_AverageEpLen : 80.07692307692308\n",
            "Train_EnvstepsSoFar : 567987\n",
            "TimeSinceStart : 460.01362705230713\n",
            "Training Loss : -0.06341004371643066\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 280 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2036])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 164.70858764648438\n",
            "Eval_StdReturn : 18.94457244873047\n",
            "Eval_MaxReturn : 184.32032775878906\n",
            "Eval_MinReturn : 130.53408813476562\n",
            "Eval_AverageEpLen : 93.0\n",
            "Train_AverageReturn : 162.489501953125\n",
            "Train_StdReturn : 26.852245330810547\n",
            "Train_MaxReturn : 197.00750732421875\n",
            "Train_MinReturn : 113.60413360595703\n",
            "Train_AverageEpLen : 88.52173913043478\n",
            "Train_EnvstepsSoFar : 570023\n",
            "TimeSinceStart : 461.67551946640015\n",
            "Training Loss : 0.009511483833193779\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 281 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2008])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 171.58123779296875\n",
            "Eval_StdReturn : 22.42587661743164\n",
            "Eval_MaxReturn : 194.37548828125\n",
            "Eval_MinReturn : 129.79884338378906\n",
            "Eval_AverageEpLen : 92.6\n",
            "Train_AverageReturn : 161.29014587402344\n",
            "Train_StdReturn : 25.87226676940918\n",
            "Train_MaxReturn : 190.25100708007812\n",
            "Train_MinReturn : 108.6543960571289\n",
            "Train_AverageEpLen : 87.16666666666667\n",
            "Train_EnvstepsSoFar : 572115\n",
            "TimeSinceStart : 463.4456112384796\n",
            "Training Loss : -0.04944497346878052\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 282 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2001])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 150.40904235839844\n",
            "Eval_StdReturn : 14.064736366271973\n",
            "Eval_MaxReturn : 173.9641571044922\n",
            "Eval_MinReturn : 129.63636779785156\n",
            "Eval_AverageEpLen : 81.8\n",
            "Train_AverageReturn : 171.45668029785156\n",
            "Train_StdReturn : 28.697322845458984\n",
            "Train_MaxReturn : 205.80331420898438\n",
            "Train_MinReturn : 102.76688385009766\n",
            "Train_AverageEpLen : 90.91304347826087\n",
            "Train_EnvstepsSoFar : 574206\n",
            "TimeSinceStart : 465.0906159877777\n",
            "Training Loss : -0.02534126117825508\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 283 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2007])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 160.8046875\n",
            "Eval_StdReturn : 20.17791748046875\n",
            "Eval_MaxReturn : 192.24789428710938\n",
            "Eval_MinReturn : 138.46575927734375\n",
            "Eval_AverageEpLen : 89.0\n",
            "Train_AverageReturn : 170.09596252441406\n",
            "Train_StdReturn : 20.060056686401367\n",
            "Train_MaxReturn : 193.1577606201172\n",
            "Train_MinReturn : 124.23738861083984\n",
            "Train_AverageEpLen : 91.22727272727273\n",
            "Train_EnvstepsSoFar : 576213\n",
            "TimeSinceStart : 466.703054189682\n",
            "Training Loss : -0.05143741890788078\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 284 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2029])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 178.17153930664062\n",
            "Eval_StdReturn : 20.08340072631836\n",
            "Eval_MaxReturn : 195.1697235107422\n",
            "Eval_MinReturn : 138.7222137451172\n",
            "Eval_AverageEpLen : 93.2\n",
            "Train_AverageReturn : 171.00543212890625\n",
            "Train_StdReturn : 20.73086929321289\n",
            "Train_MaxReturn : 206.62278747558594\n",
            "Train_MinReturn : 127.62708282470703\n",
            "Train_AverageEpLen : 92.22727272727273\n",
            "Train_EnvstepsSoFar : 578242\n",
            "TimeSinceStart : 468.34392833709717\n",
            "Training Loss : 0.007889620959758759\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 285 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2064])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 186.17105102539062\n",
            "Eval_StdReturn : 21.488239288330078\n",
            "Eval_MaxReturn : 197.82643127441406\n",
            "Eval_MinReturn : 143.22471618652344\n",
            "Eval_AverageEpLen : 96.4\n",
            "Train_AverageReturn : 176.70042419433594\n",
            "Train_StdReturn : 19.193767547607422\n",
            "Train_MaxReturn : 203.68470764160156\n",
            "Train_MinReturn : 117.75628662109375\n",
            "Train_AverageEpLen : 93.81818181818181\n",
            "Train_EnvstepsSoFar : 580306\n",
            "TimeSinceStart : 469.9952962398529\n",
            "Training Loss : 0.035099610686302185\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 286 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2051])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 184.146484375\n",
            "Eval_StdReturn : 6.091811180114746\n",
            "Eval_MaxReturn : 190.466796875\n",
            "Eval_MinReturn : 172.66787719726562\n",
            "Eval_AverageEpLen : 97.6\n",
            "Train_AverageReturn : 181.74923706054688\n",
            "Train_StdReturn : 18.738380432128906\n",
            "Train_MaxReturn : 201.69696044921875\n",
            "Train_MinReturn : 138.5102996826172\n",
            "Train_AverageEpLen : 97.66666666666667\n",
            "Train_EnvstepsSoFar : 582357\n",
            "TimeSinceStart : 471.6591248512268\n",
            "Training Loss : 0.002149906475096941\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 287 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2019])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 188.5556182861328\n",
            "Eval_StdReturn : 19.249637603759766\n",
            "Eval_MaxReturn : 203.54714965820312\n",
            "Eval_MinReturn : 150.54629516601562\n",
            "Eval_AverageEpLen : 99.8\n",
            "Train_AverageReturn : 183.20164489746094\n",
            "Train_StdReturn : 19.7330379486084\n",
            "Train_MaxReturn : 212.56214904785156\n",
            "Train_MinReturn : 139.0962677001953\n",
            "Train_AverageEpLen : 96.14285714285714\n",
            "Train_EnvstepsSoFar : 584376\n",
            "TimeSinceStart : 473.34272170066833\n",
            "Training Loss : -0.047082748264074326\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 288 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2030])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 190.00613403320312\n",
            "Eval_StdReturn : 10.053644180297852\n",
            "Eval_MaxReturn : 208.34698486328125\n",
            "Eval_MinReturn : 181.99525451660156\n",
            "Eval_AverageEpLen : 101.8\n",
            "Train_AverageReturn : 179.93800354003906\n",
            "Train_StdReturn : 16.619783401489258\n",
            "Train_MaxReturn : 199.99612426757812\n",
            "Train_MinReturn : 142.5601043701172\n",
            "Train_AverageEpLen : 96.66666666666667\n",
            "Train_EnvstepsSoFar : 586406\n",
            "TimeSinceStart : 475.03963112831116\n",
            "Training Loss : -0.04055485874414444\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 289 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2083])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 178.47802734375\n",
            "Eval_StdReturn : 15.051935195922852\n",
            "Eval_MaxReturn : 190.6587677001953\n",
            "Eval_MinReturn : 149.33236694335938\n",
            "Eval_AverageEpLen : 98.4\n",
            "Train_AverageReturn : 193.6709442138672\n",
            "Train_StdReturn : 11.157294273376465\n",
            "Train_MaxReturn : 212.35885620117188\n",
            "Train_MinReturn : 167.38771057128906\n",
            "Train_AverageEpLen : 104.15\n",
            "Train_EnvstepsSoFar : 588489\n",
            "TimeSinceStart : 476.74767088890076\n",
            "Training Loss : -0.004540472291409969\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 290 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2080])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 187.76181030273438\n",
            "Eval_StdReturn : 8.274019241333008\n",
            "Eval_MaxReturn : 200.43658447265625\n",
            "Eval_MinReturn : 174.8806915283203\n",
            "Eval_AverageEpLen : 100.6\n",
            "Train_AverageReturn : 187.1121368408203\n",
            "Train_StdReturn : 14.228565216064453\n",
            "Train_MaxReturn : 204.7125244140625\n",
            "Train_MinReturn : 143.24005126953125\n",
            "Train_AverageEpLen : 99.04761904761905\n",
            "Train_EnvstepsSoFar : 590569\n",
            "TimeSinceStart : 478.4443926811218\n",
            "Training Loss : -0.023462001234292984\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 291 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2085])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 189.95602416992188\n",
            "Eval_StdReturn : 1.6622322797775269\n",
            "Eval_MaxReturn : 191.90052795410156\n",
            "Eval_MinReturn : 187.36209106445312\n",
            "Eval_AverageEpLen : 107.0\n",
            "Train_AverageReturn : 185.74948120117188\n",
            "Train_StdReturn : 14.15140151977539\n",
            "Train_MaxReturn : 202.56565856933594\n",
            "Train_MinReturn : 153.67050170898438\n",
            "Train_AverageEpLen : 99.28571428571429\n",
            "Train_EnvstepsSoFar : 592654\n",
            "TimeSinceStart : 480.07824754714966\n",
            "Training Loss : 0.017207294702529907\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 292 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2078])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 194.6367950439453\n",
            "Eval_StdReturn : 8.888489723205566\n",
            "Eval_MaxReturn : 205.0815887451172\n",
            "Eval_MinReturn : 179.43988037109375\n",
            "Eval_AverageEpLen : 99.2\n",
            "Train_AverageReturn : 193.06015014648438\n",
            "Train_StdReturn : 7.463043212890625\n",
            "Train_MaxReturn : 203.47988891601562\n",
            "Train_MinReturn : 169.389892578125\n",
            "Train_AverageEpLen : 103.9\n",
            "Train_EnvstepsSoFar : 594732\n",
            "TimeSinceStart : 481.75535559654236\n",
            "Training Loss : -0.02731824293732643\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 293 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2069])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 183.92442321777344\n",
            "Eval_StdReturn : 13.155545234680176\n",
            "Eval_MaxReturn : 195.56935119628906\n",
            "Eval_MinReturn : 161.95045471191406\n",
            "Eval_AverageEpLen : 102.5\n",
            "Train_AverageReturn : 193.1942138671875\n",
            "Train_StdReturn : 5.283491611480713\n",
            "Train_MaxReturn : 204.3043670654297\n",
            "Train_MinReturn : 185.44798278808594\n",
            "Train_AverageEpLen : 103.45\n",
            "Train_EnvstepsSoFar : 596801\n",
            "TimeSinceStart : 483.37437772750854\n",
            "Training Loss : 0.007735833525657654\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 294 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2060])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 197.11599731445312\n",
            "Eval_StdReturn : 5.314452171325684\n",
            "Eval_MaxReturn : 201.75741577148438\n",
            "Eval_MinReturn : 188.09347534179688\n",
            "Eval_AverageEpLen : 105.25\n",
            "Train_AverageReturn : 188.50570678710938\n",
            "Train_StdReturn : 9.638190269470215\n",
            "Train_MaxReturn : 201.83934020996094\n",
            "Train_MinReturn : 161.43028259277344\n",
            "Train_AverageEpLen : 103.0\n",
            "Train_EnvstepsSoFar : 598861\n",
            "TimeSinceStart : 484.99011850357056\n",
            "Training Loss : -0.007827815599739552\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 295 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2045])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 190.61410522460938\n",
            "Eval_StdReturn : 5.0427165031433105\n",
            "Eval_MaxReturn : 197.79010009765625\n",
            "Eval_MinReturn : 184.8160400390625\n",
            "Eval_AverageEpLen : 101.25\n",
            "Train_AverageReturn : 193.07923889160156\n",
            "Train_StdReturn : 6.647719860076904\n",
            "Train_MaxReturn : 203.20921325683594\n",
            "Train_MinReturn : 182.0513916015625\n",
            "Train_AverageEpLen : 102.25\n",
            "Train_EnvstepsSoFar : 600906\n",
            "TimeSinceStart : 486.62948417663574\n",
            "Training Loss : -0.018329814076423645\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 296 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2084])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 195.6466522216797\n",
            "Eval_StdReturn : 8.885664939880371\n",
            "Eval_MaxReturn : 210.08193969726562\n",
            "Eval_MinReturn : 186.36038208007812\n",
            "Eval_AverageEpLen : 108.5\n",
            "Train_AverageReturn : 192.907470703125\n",
            "Train_StdReturn : 9.530413627624512\n",
            "Train_MaxReturn : 207.55657958984375\n",
            "Train_MinReturn : 174.20706176757812\n",
            "Train_AverageEpLen : 104.2\n",
            "Train_EnvstepsSoFar : 602990\n",
            "TimeSinceStart : 488.3163547515869\n",
            "Training Loss : 0.020600251853466034\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 297 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2049])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 193.47889709472656\n",
            "Eval_StdReturn : 3.929086208343506\n",
            "Eval_MaxReturn : 197.69839477539062\n",
            "Eval_MinReturn : 187.0384063720703\n",
            "Eval_AverageEpLen : 103.75\n",
            "Train_AverageReturn : 191.487548828125\n",
            "Train_StdReturn : 9.257712364196777\n",
            "Train_MaxReturn : 201.81275939941406\n",
            "Train_MinReturn : 157.72018432617188\n",
            "Train_AverageEpLen : 102.45\n",
            "Train_EnvstepsSoFar : 605039\n",
            "TimeSinceStart : 489.92885661125183\n",
            "Training Loss : -0.029033631086349487\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 298 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2063])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 194.1981658935547\n",
            "Eval_StdReturn : 9.846892356872559\n",
            "Eval_MaxReturn : 210.82131958007812\n",
            "Eval_MinReturn : 185.4547576904297\n",
            "Eval_AverageEpLen : 100.5\n",
            "Train_AverageReturn : 189.65870666503906\n",
            "Train_StdReturn : 7.593156814575195\n",
            "Train_MaxReturn : 200.98550415039062\n",
            "Train_MinReturn : 172.55870056152344\n",
            "Train_AverageEpLen : 103.15\n",
            "Train_EnvstepsSoFar : 607102\n",
            "TimeSinceStart : 491.58069372177124\n",
            "Training Loss : 0.006490676663815975\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 299 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2059])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 194.99742126464844\n",
            "Eval_StdReturn : 7.387578010559082\n",
            "Eval_MaxReturn : 205.2501983642578\n",
            "Eval_MinReturn : 185.59298706054688\n",
            "Eval_AverageEpLen : 106.5\n",
            "Train_AverageReturn : 192.0538330078125\n",
            "Train_StdReturn : 8.581147193908691\n",
            "Train_MaxReturn : 209.30807495117188\n",
            "Train_MinReturn : 179.32333374023438\n",
            "Train_AverageEpLen : 102.95\n",
            "Train_EnvstepsSoFar : 609161\n",
            "TimeSinceStart : 493.2663450241089\n",
            "Training Loss : -0.08539827167987823\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python cs285/scripts/run_hw2.py \\\n",
        "--env_name Hopper-v2 --ep_len 1000 \\\n",
        "--discount 0.99 -n 300 -l 2 -s 32 -b 2000 -lr 0.001 \\\n",
        "--reward_to_go --nn_baseline --action_noise_std 0.5 --gae_lambda 0 \\\n",
        "--exp_name q5_b2000_r0.001_lambda0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "3Jqjmyaa9w9r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c73b88bd-1910-4cdb-a2a2-ee821b3446b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mLe flux de sortie a été tronqué et ne contient que les 5000 dernières lignes.\u001b[0m\n",
            "Train_AverageReturn : 211.31582641601562\n",
            "Train_StdReturn : 20.132266998291016\n",
            "Train_MaxReturn : 247.2313995361328\n",
            "Train_MinReturn : 174.91432189941406\n",
            "Train_AverageEpLen : 99.28571428571429\n",
            "Train_EnvstepsSoFar : 261526\n",
            "TimeSinceStart : 213.4280662536621\n",
            "Training Loss : -0.01769251376390457\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 128 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2052])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 226.76416015625\n",
            "Eval_StdReturn : 10.067989349365234\n",
            "Eval_MaxReturn : 241.91302490234375\n",
            "Eval_MinReturn : 214.6602783203125\n",
            "Eval_AverageEpLen : 108.25\n",
            "Train_AverageReturn : 213.5774383544922\n",
            "Train_StdReturn : 29.962560653686523\n",
            "Train_MaxReturn : 281.2386779785156\n",
            "Train_MinReturn : 133.13941955566406\n",
            "Train_AverageEpLen : 102.6\n",
            "Train_EnvstepsSoFar : 263578\n",
            "TimeSinceStart : 215.04356718063354\n",
            "Training Loss : -0.03124401345849037\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 129 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2019])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 225.05264282226562\n",
            "Eval_StdReturn : 13.825860977172852\n",
            "Eval_MaxReturn : 245.1927947998047\n",
            "Eval_MinReturn : 208.58038330078125\n",
            "Eval_AverageEpLen : 104.5\n",
            "Train_AverageReturn : 222.3347625732422\n",
            "Train_StdReturn : 33.913597106933594\n",
            "Train_MaxReturn : 260.36041259765625\n",
            "Train_MinReturn : 107.75425720214844\n",
            "Train_AverageEpLen : 106.26315789473684\n",
            "Train_EnvstepsSoFar : 265597\n",
            "TimeSinceStart : 216.6365728378296\n",
            "Training Loss : -0.005331294611096382\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 130 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2065])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 213.186279296875\n",
            "Eval_StdReturn : 6.788553237915039\n",
            "Eval_MaxReturn : 226.1438751220703\n",
            "Eval_MinReturn : 207.51498413085938\n",
            "Eval_AverageEpLen : 97.6\n",
            "Train_AverageReturn : 218.1842498779297\n",
            "Train_StdReturn : 16.937013626098633\n",
            "Train_MaxReturn : 262.95123291015625\n",
            "Train_MinReturn : 188.1626434326172\n",
            "Train_AverageEpLen : 103.25\n",
            "Train_EnvstepsSoFar : 267662\n",
            "TimeSinceStart : 218.31107425689697\n",
            "Training Loss : 0.003230043686926365\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 131 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2032])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 233.19053649902344\n",
            "Eval_StdReturn : 9.297804832458496\n",
            "Eval_MaxReturn : 242.90237426757812\n",
            "Eval_MinReturn : 223.65432739257812\n",
            "Eval_AverageEpLen : 118.25\n",
            "Train_AverageReturn : 223.6318817138672\n",
            "Train_StdReturn : 23.457965850830078\n",
            "Train_MaxReturn : 278.12200927734375\n",
            "Train_MinReturn : 180.39279174804688\n",
            "Train_AverageEpLen : 106.94736842105263\n",
            "Train_EnvstepsSoFar : 269694\n",
            "TimeSinceStart : 219.94551968574524\n",
            "Training Loss : 0.0692334771156311\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 132 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2045])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 204.5410614013672\n",
            "Eval_StdReturn : 22.820972442626953\n",
            "Eval_MaxReturn : 234.5687713623047\n",
            "Eval_MinReturn : 175.65704345703125\n",
            "Eval_AverageEpLen : 98.6\n",
            "Train_AverageReturn : 214.79965209960938\n",
            "Train_StdReturn : 26.503162384033203\n",
            "Train_MaxReturn : 252.40042114257812\n",
            "Train_MinReturn : 120.15977478027344\n",
            "Train_AverageEpLen : 102.25\n",
            "Train_EnvstepsSoFar : 271739\n",
            "TimeSinceStart : 221.62286281585693\n",
            "Training Loss : 0.016677629202604294\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 133 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2042])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 217.99661254882812\n",
            "Eval_StdReturn : 13.087302207946777\n",
            "Eval_MaxReturn : 238.87640380859375\n",
            "Eval_MinReturn : 202.76962280273438\n",
            "Eval_AverageEpLen : 106.0\n",
            "Train_AverageReturn : 219.9725341796875\n",
            "Train_StdReturn : 10.709410667419434\n",
            "Train_MaxReturn : 241.95748901367188\n",
            "Train_MinReturn : 202.6280059814453\n",
            "Train_AverageEpLen : 102.1\n",
            "Train_EnvstepsSoFar : 273781\n",
            "TimeSinceStart : 223.22373151779175\n",
            "Training Loss : -0.0028509809635579586\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 134 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2005])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 228.8941650390625\n",
            "Eval_StdReturn : 7.762035369873047\n",
            "Eval_MaxReturn : 240.10208129882812\n",
            "Eval_MinReturn : 218.66925048828125\n",
            "Eval_AverageEpLen : 107.25\n",
            "Train_AverageReturn : 217.3506317138672\n",
            "Train_StdReturn : 47.633644104003906\n",
            "Train_MaxReturn : 299.2714538574219\n",
            "Train_MinReturn : 44.46417236328125\n",
            "Train_AverageEpLen : 105.52631578947368\n",
            "Train_EnvstepsSoFar : 275786\n",
            "TimeSinceStart : 224.8306701183319\n",
            "Training Loss : 0.006663880776613951\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 135 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2029])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 212.46334838867188\n",
            "Eval_StdReturn : 10.268484115600586\n",
            "Eval_MaxReturn : 230.57191467285156\n",
            "Eval_MinReturn : 204.04310607910156\n",
            "Eval_AverageEpLen : 100.4\n",
            "Train_AverageReturn : 220.59742736816406\n",
            "Train_StdReturn : 20.64621925354004\n",
            "Train_MaxReturn : 255.66119384765625\n",
            "Train_MinReturn : 181.18955993652344\n",
            "Train_AverageEpLen : 106.78947368421052\n",
            "Train_EnvstepsSoFar : 277815\n",
            "TimeSinceStart : 226.48728728294373\n",
            "Training Loss : 0.009931262582540512\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 136 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2014])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 223.4008331298828\n",
            "Eval_StdReturn : 13.309510231018066\n",
            "Eval_MaxReturn : 242.2811737060547\n",
            "Eval_MinReturn : 210.35906982421875\n",
            "Eval_AverageEpLen : 108.0\n",
            "Train_AverageReturn : 221.14036560058594\n",
            "Train_StdReturn : 19.07610321044922\n",
            "Train_MaxReturn : 256.5865478515625\n",
            "Train_MinReturn : 186.47247314453125\n",
            "Train_AverageEpLen : 106.0\n",
            "Train_EnvstepsSoFar : 279829\n",
            "TimeSinceStart : 228.09976840019226\n",
            "Training Loss : 0.01253555715084076\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 137 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2103])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 224.22793579101562\n",
            "Eval_StdReturn : 12.6826753616333\n",
            "Eval_MaxReturn : 241.38699340820312\n",
            "Eval_MinReturn : 209.91258239746094\n",
            "Eval_AverageEpLen : 104.25\n",
            "Train_AverageReturn : 227.48129272460938\n",
            "Train_StdReturn : 16.350236892700195\n",
            "Train_MaxReturn : 264.56536865234375\n",
            "Train_MinReturn : 196.9932098388672\n",
            "Train_AverageEpLen : 110.6842105263158\n",
            "Train_EnvstepsSoFar : 281932\n",
            "TimeSinceStart : 229.76223969459534\n",
            "Training Loss : -0.0033296633046120405\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 138 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2016])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 219.7372589111328\n",
            "Eval_StdReturn : 17.052297592163086\n",
            "Eval_MaxReturn : 245.8045654296875\n",
            "Eval_MinReturn : 198.5723114013672\n",
            "Eval_AverageEpLen : 102.25\n",
            "Train_AverageReturn : 220.76321411132812\n",
            "Train_StdReturn : 28.776395797729492\n",
            "Train_MaxReturn : 292.8868408203125\n",
            "Train_MinReturn : 129.3008270263672\n",
            "Train_AverageEpLen : 106.10526315789474\n",
            "Train_EnvstepsSoFar : 283948\n",
            "TimeSinceStart : 231.3348047733307\n",
            "Training Loss : -0.019312972202897072\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 139 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2002])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 224.59854125976562\n",
            "Eval_StdReturn : 16.13345718383789\n",
            "Eval_MaxReturn : 242.33274841308594\n",
            "Eval_MinReturn : 200.01451110839844\n",
            "Eval_AverageEpLen : 110.25\n",
            "Train_AverageReturn : 221.7777862548828\n",
            "Train_StdReturn : 27.618927001953125\n",
            "Train_MaxReturn : 272.4066467285156\n",
            "Train_MinReturn : 129.9290313720703\n",
            "Train_AverageEpLen : 105.36842105263158\n",
            "Train_EnvstepsSoFar : 285950\n",
            "TimeSinceStart : 232.93711280822754\n",
            "Training Loss : 0.035715606063604355\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 140 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2081])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 220.3017578125\n",
            "Eval_StdReturn : 10.27208423614502\n",
            "Eval_MaxReturn : 231.29257202148438\n",
            "Eval_MinReturn : 203.4542236328125\n",
            "Eval_AverageEpLen : 103.5\n",
            "Train_AverageReturn : 220.4866943359375\n",
            "Train_StdReturn : 19.860979080200195\n",
            "Train_MaxReturn : 289.5004577636719\n",
            "Train_MinReturn : 182.76409912109375\n",
            "Train_AverageEpLen : 104.05\n",
            "Train_EnvstepsSoFar : 288031\n",
            "TimeSinceStart : 234.5823757648468\n",
            "Training Loss : 0.00972069427371025\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 141 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2052])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 222.6728057861328\n",
            "Eval_StdReturn : 43.54291915893555\n",
            "Eval_MaxReturn : 280.0103759765625\n",
            "Eval_MinReturn : 145.95103454589844\n",
            "Eval_AverageEpLen : 104.8\n",
            "Train_AverageReturn : 223.67739868164062\n",
            "Train_StdReturn : 20.580102920532227\n",
            "Train_MaxReturn : 272.1404113769531\n",
            "Train_MinReturn : 188.1490936279297\n",
            "Train_AverageEpLen : 108.0\n",
            "Train_EnvstepsSoFar : 290083\n",
            "TimeSinceStart : 236.29265689849854\n",
            "Training Loss : 0.027144957333803177\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 142 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2057])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 219.2277374267578\n",
            "Eval_StdReturn : 23.780561447143555\n",
            "Eval_MaxReturn : 253.31900024414062\n",
            "Eval_MinReturn : 186.3443145751953\n",
            "Eval_AverageEpLen : 101.0\n",
            "Train_AverageReturn : 220.4005126953125\n",
            "Train_StdReturn : 19.176307678222656\n",
            "Train_MaxReturn : 263.72784423828125\n",
            "Train_MinReturn : 169.6306610107422\n",
            "Train_AverageEpLen : 102.85\n",
            "Train_EnvstepsSoFar : 292140\n",
            "TimeSinceStart : 238.01501607894897\n",
            "Training Loss : 0.006575652398169041\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 143 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2082])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 222.32125854492188\n",
            "Eval_StdReturn : 21.22472381591797\n",
            "Eval_MaxReturn : 257.4300842285156\n",
            "Eval_MinReturn : 204.107421875\n",
            "Eval_AverageEpLen : 108.0\n",
            "Train_AverageReturn : 221.8006591796875\n",
            "Train_StdReturn : 18.51866340637207\n",
            "Train_MaxReturn : 267.4565124511719\n",
            "Train_MinReturn : 193.23779296875\n",
            "Train_AverageEpLen : 109.57894736842105\n",
            "Train_EnvstepsSoFar : 294222\n",
            "TimeSinceStart : 239.67146682739258\n",
            "Training Loss : 0.033683907240629196\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 144 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2053])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 220.97537231445312\n",
            "Eval_StdReturn : 19.28384780883789\n",
            "Eval_MaxReturn : 249.51292419433594\n",
            "Eval_MinReturn : 195.37254333496094\n",
            "Eval_AverageEpLen : 109.5\n",
            "Train_AverageReturn : 226.20880126953125\n",
            "Train_StdReturn : 15.79154109954834\n",
            "Train_MaxReturn : 269.90093994140625\n",
            "Train_MinReturn : 208.05650329589844\n",
            "Train_AverageEpLen : 108.05263157894737\n",
            "Train_EnvstepsSoFar : 296275\n",
            "TimeSinceStart : 241.32879829406738\n",
            "Training Loss : -0.002502966672182083\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 145 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2013])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 233.809814453125\n",
            "Eval_StdReturn : 19.869300842285156\n",
            "Eval_MaxReturn : 265.2674560546875\n",
            "Eval_MinReturn : 214.24725341796875\n",
            "Eval_AverageEpLen : 113.5\n",
            "Train_AverageReturn : 226.95697021484375\n",
            "Train_StdReturn : 25.30035972595215\n",
            "Train_MaxReturn : 287.5228576660156\n",
            "Train_MinReturn : 189.12596130371094\n",
            "Train_AverageEpLen : 111.83333333333333\n",
            "Train_EnvstepsSoFar : 298288\n",
            "TimeSinceStart : 242.93622088432312\n",
            "Training Loss : -0.027781089767813683\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 146 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 223.947509765625\n",
            "Eval_StdReturn : 14.474261283874512\n",
            "Eval_MaxReturn : 242.2861785888672\n",
            "Eval_MinReturn : 207.8500213623047\n",
            "Eval_AverageEpLen : 107.25\n",
            "Train_AverageReturn : 223.21754455566406\n",
            "Train_StdReturn : 15.222103118896484\n",
            "Train_MaxReturn : 248.03045654296875\n",
            "Train_MinReturn : 189.23013305664062\n",
            "Train_AverageEpLen : 105.26315789473684\n",
            "Train_EnvstepsSoFar : 300288\n",
            "TimeSinceStart : 244.53564286231995\n",
            "Training Loss : -0.013817421160638332\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 147 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 219.1077880859375\n",
            "Eval_StdReturn : 14.301610946655273\n",
            "Eval_MaxReturn : 234.39601135253906\n",
            "Eval_MinReturn : 196.9428253173828\n",
            "Eval_AverageEpLen : 104.75\n",
            "Train_AverageReturn : 233.64669799804688\n",
            "Train_StdReturn : 18.54769515991211\n",
            "Train_MaxReturn : 284.11346435546875\n",
            "Train_MinReturn : 204.28018188476562\n",
            "Train_AverageEpLen : 113.88888888888889\n",
            "Train_EnvstepsSoFar : 302338\n",
            "TimeSinceStart : 246.17058563232422\n",
            "Training Loss : -0.006327091716229916\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 148 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2021])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 241.70814514160156\n",
            "Eval_StdReturn : 33.26358413696289\n",
            "Eval_MaxReturn : 299.1690979003906\n",
            "Eval_MinReturn : 218.79469299316406\n",
            "Eval_AverageEpLen : 119.0\n",
            "Train_AverageReturn : 225.1205291748047\n",
            "Train_StdReturn : 19.09789276123047\n",
            "Train_MaxReturn : 276.2806396484375\n",
            "Train_MinReturn : 191.5745086669922\n",
            "Train_AverageEpLen : 106.36842105263158\n",
            "Train_EnvstepsSoFar : 304359\n",
            "TimeSinceStart : 247.84028697013855\n",
            "Training Loss : 0.0021582311019301414\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 149 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2091])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 231.53976440429688\n",
            "Eval_StdReturn : 10.427759170532227\n",
            "Eval_MaxReturn : 240.0862579345703\n",
            "Eval_MinReturn : 214.0028533935547\n",
            "Eval_AverageEpLen : 108.75\n",
            "Train_AverageReturn : 228.9571533203125\n",
            "Train_StdReturn : 16.029071807861328\n",
            "Train_MaxReturn : 264.15264892578125\n",
            "Train_MinReturn : 194.9466094970703\n",
            "Train_AverageEpLen : 110.05263157894737\n",
            "Train_EnvstepsSoFar : 306450\n",
            "TimeSinceStart : 249.4890480041504\n",
            "Training Loss : -0.023474227637052536\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 150 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2004])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 230.531982421875\n",
            "Eval_StdReturn : 9.65621280670166\n",
            "Eval_MaxReturn : 240.8495330810547\n",
            "Eval_MinReturn : 215.1055908203125\n",
            "Eval_AverageEpLen : 104.25\n",
            "Train_AverageReturn : 231.32579040527344\n",
            "Train_StdReturn : 22.49144744873047\n",
            "Train_MaxReturn : 287.0091247558594\n",
            "Train_MinReturn : 192.19143676757812\n",
            "Train_AverageEpLen : 111.52631578947368\n",
            "Train_EnvstepsSoFar : 308569\n",
            "TimeSinceStart : 251.11721086502075\n",
            "Training Loss : -0.021677888929843903\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 151 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2029])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 209.19850158691406\n",
            "Eval_StdReturn : 22.856672286987305\n",
            "Eval_MaxReturn : 224.470458984375\n",
            "Eval_MinReturn : 169.6939239501953\n",
            "Eval_AverageEpLen : 100.75\n",
            "Train_AverageReturn : 226.11196899414062\n",
            "Train_StdReturn : 21.549589157104492\n",
            "Train_MaxReturn : 276.2161865234375\n",
            "Train_MinReturn : 191.15457153320312\n",
            "Train_AverageEpLen : 106.78947368421052\n",
            "Train_EnvstepsSoFar : 310598\n",
            "TimeSinceStart : 252.70304226875305\n",
            "Training Loss : 0.025397375226020813\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 152 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2075])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 216.30862426757812\n",
            "Eval_StdReturn : 22.232772827148438\n",
            "Eval_MaxReturn : 247.76499938964844\n",
            "Eval_MinReturn : 194.91258239746094\n",
            "Eval_AverageEpLen : 102.5\n",
            "Train_AverageReturn : 225.8542022705078\n",
            "Train_StdReturn : 32.027549743652344\n",
            "Train_MaxReturn : 274.13348388671875\n",
            "Train_MinReturn : 144.929443359375\n",
            "Train_AverageEpLen : 109.21052631578948\n",
            "Train_EnvstepsSoFar : 312673\n",
            "TimeSinceStart : 254.31962609291077\n",
            "Training Loss : -0.0720735639333725\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 153 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2047])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 180.91275024414062\n",
            "Eval_StdReturn : 79.28634643554688\n",
            "Eval_MaxReturn : 228.89845275878906\n",
            "Eval_MinReturn : 22.936920166015625\n",
            "Eval_AverageEpLen : 85.8\n",
            "Train_AverageReturn : 221.2401885986328\n",
            "Train_StdReturn : 31.60610580444336\n",
            "Train_MaxReturn : 262.3773498535156\n",
            "Train_MinReturn : 100.79556274414062\n",
            "Train_AverageEpLen : 105.25\n",
            "Train_EnvstepsSoFar : 314778\n",
            "TimeSinceStart : 255.9588532447815\n",
            "Training Loss : 0.013791275210678577\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 154 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2094])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 215.7665557861328\n",
            "Eval_StdReturn : 5.747644901275635\n",
            "Eval_MaxReturn : 225.16127014160156\n",
            "Eval_MinReturn : 208.04095458984375\n",
            "Eval_AverageEpLen : 99.4\n",
            "Train_AverageReturn : 229.9842987060547\n",
            "Train_StdReturn : 39.477516174316406\n",
            "Train_MaxReturn : 331.91680908203125\n",
            "Train_MinReturn : 116.93731689453125\n",
            "Train_AverageEpLen : 110.21052631578948\n",
            "Train_EnvstepsSoFar : 316872\n",
            "TimeSinceStart : 257.6690845489502\n",
            "Training Loss : -0.005627031903713942\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 155 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2064])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 233.58908081054688\n",
            "Eval_StdReturn : 21.71882438659668\n",
            "Eval_MaxReturn : 259.92828369140625\n",
            "Eval_MinReturn : 203.9563446044922\n",
            "Eval_AverageEpLen : 107.25\n",
            "Train_AverageReturn : 224.9818115234375\n",
            "Train_StdReturn : 55.90993118286133\n",
            "Train_MaxReturn : 288.239013671875\n",
            "Train_MinReturn : 18.08552360534668\n",
            "Train_AverageEpLen : 114.66666666666667\n",
            "Train_EnvstepsSoFar : 318936\n",
            "TimeSinceStart : 259.2797348499298\n",
            "Training Loss : 0.01059031207114458\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 156 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2086])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 257.6748962402344\n",
            "Eval_StdReturn : 50.6622428894043\n",
            "Eval_MaxReturn : 326.684814453125\n",
            "Eval_MinReturn : 206.49008178710938\n",
            "Eval_AverageEpLen : 134.33333333333334\n",
            "Train_AverageReturn : 230.46067810058594\n",
            "Train_StdReturn : 28.11703109741211\n",
            "Train_MaxReturn : 278.29681396484375\n",
            "Train_MinReturn : 146.73892211914062\n",
            "Train_AverageEpLen : 109.78947368421052\n",
            "Train_EnvstepsSoFar : 321022\n",
            "TimeSinceStart : 260.96042346954346\n",
            "Training Loss : 0.0014631100930273533\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 157 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2009])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 237.24403381347656\n",
            "Eval_StdReturn : 14.990068435668945\n",
            "Eval_MaxReturn : 260.14361572265625\n",
            "Eval_MinReturn : 220.35887145996094\n",
            "Eval_AverageEpLen : 116.25\n",
            "Train_AverageReturn : 225.1158905029297\n",
            "Train_StdReturn : 32.892494201660156\n",
            "Train_MaxReturn : 329.109130859375\n",
            "Train_MinReturn : 149.8206787109375\n",
            "Train_AverageEpLen : 105.3\n",
            "Train_EnvstepsSoFar : 323128\n",
            "TimeSinceStart : 262.64592933654785\n",
            "Training Loss : -0.02566755749285221\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 158 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2068])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 237.6405792236328\n",
            "Eval_StdReturn : 51.59836959838867\n",
            "Eval_MaxReturn : 326.21490478515625\n",
            "Eval_MinReturn : 200.96803283691406\n",
            "Eval_AverageEpLen : 112.25\n",
            "Train_AverageReturn : 228.96627807617188\n",
            "Train_StdReturn : 17.47582244873047\n",
            "Train_MaxReturn : 262.01995849609375\n",
            "Train_MinReturn : 185.47470092773438\n",
            "Train_AverageEpLen : 108.84210526315789\n",
            "Train_EnvstepsSoFar : 325196\n",
            "TimeSinceStart : 264.2838578224182\n",
            "Training Loss : -0.023250572383403778\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 159 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2019])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 224.1279754638672\n",
            "Eval_StdReturn : 8.344852447509766\n",
            "Eval_MaxReturn : 234.05995178222656\n",
            "Eval_MinReturn : 211.9042205810547\n",
            "Eval_AverageEpLen : 101.0\n",
            "Train_AverageReturn : 230.73760986328125\n",
            "Train_StdReturn : 33.62429428100586\n",
            "Train_MaxReturn : 311.84271240234375\n",
            "Train_MinReturn : 137.47955322265625\n",
            "Train_AverageEpLen : 112.16666666666667\n",
            "Train_EnvstepsSoFar : 327215\n",
            "TimeSinceStart : 265.8650803565979\n",
            "Training Loss : -0.022722290828824043\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 160 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2012])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 201.69007873535156\n",
            "Eval_StdReturn : 57.57377624511719\n",
            "Eval_MaxReturn : 245.62730407714844\n",
            "Eval_MinReturn : 99.777099609375\n",
            "Eval_AverageEpLen : 100.0\n",
            "Train_AverageReturn : 232.23611450195312\n",
            "Train_StdReturn : 33.66257858276367\n",
            "Train_MaxReturn : 291.3297424316406\n",
            "Train_MinReturn : 156.7768096923828\n",
            "Train_AverageEpLen : 111.77777777777777\n",
            "Train_EnvstepsSoFar : 329227\n",
            "TimeSinceStart : 267.51410388946533\n",
            "Training Loss : 0.002096361480653286\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 161 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2052])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 236.12193298339844\n",
            "Eval_StdReturn : 6.260402202606201\n",
            "Eval_MaxReturn : 243.6280059814453\n",
            "Eval_MinReturn : 227.7723388671875\n",
            "Eval_AverageEpLen : 105.5\n",
            "Train_AverageReturn : 240.37579345703125\n",
            "Train_StdReturn : 17.222755432128906\n",
            "Train_MaxReturn : 275.7044677734375\n",
            "Train_MinReturn : 202.04844665527344\n",
            "Train_AverageEpLen : 114.0\n",
            "Train_EnvstepsSoFar : 331279\n",
            "TimeSinceStart : 269.13650250434875\n",
            "Training Loss : -0.001799337100237608\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 162 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2096])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 228.00152587890625\n",
            "Eval_StdReturn : 56.25343322753906\n",
            "Eval_MaxReturn : 294.0629577636719\n",
            "Eval_MinReturn : 146.13095092773438\n",
            "Eval_AverageEpLen : 113.75\n",
            "Train_AverageReturn : 228.46823120117188\n",
            "Train_StdReturn : 25.107982635498047\n",
            "Train_MaxReturn : 282.75701904296875\n",
            "Train_MinReturn : 165.39280700683594\n",
            "Train_AverageEpLen : 110.3157894736842\n",
            "Train_EnvstepsSoFar : 333375\n",
            "TimeSinceStart : 270.81364583969116\n",
            "Training Loss : 0.03550570085644722\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 163 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2036])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 239.26773071289062\n",
            "Eval_StdReturn : 23.697778701782227\n",
            "Eval_MaxReturn : 265.57843017578125\n",
            "Eval_MinReturn : 201.78587341308594\n",
            "Eval_AverageEpLen : 113.0\n",
            "Train_AverageReturn : 233.0506134033203\n",
            "Train_StdReturn : 25.57976531982422\n",
            "Train_MaxReturn : 288.11944580078125\n",
            "Train_MinReturn : 175.8042449951172\n",
            "Train_AverageEpLen : 113.11111111111111\n",
            "Train_EnvstepsSoFar : 335411\n",
            "TimeSinceStart : 272.43625378608704\n",
            "Training Loss : -0.012476776726543903\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 164 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2081])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 232.48898315429688\n",
            "Eval_StdReturn : 8.831995010375977\n",
            "Eval_MaxReturn : 246.69020080566406\n",
            "Eval_MinReturn : 224.0201416015625\n",
            "Eval_AverageEpLen : 104.25\n",
            "Train_AverageReturn : 240.55148315429688\n",
            "Train_StdReturn : 21.605628967285156\n",
            "Train_MaxReturn : 282.0795593261719\n",
            "Train_MinReturn : 204.9639129638672\n",
            "Train_AverageEpLen : 115.61111111111111\n",
            "Train_EnvstepsSoFar : 337492\n",
            "TimeSinceStart : 274.0692067146301\n",
            "Training Loss : -0.01142263412475586\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 165 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2016])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 232.16983032226562\n",
            "Eval_StdReturn : 12.967047691345215\n",
            "Eval_MaxReturn : 245.53073120117188\n",
            "Eval_MinReturn : 216.0623016357422\n",
            "Eval_AverageEpLen : 108.5\n",
            "Train_AverageReturn : 242.29908752441406\n",
            "Train_StdReturn : 35.391353607177734\n",
            "Train_MaxReturn : 304.5966796875\n",
            "Train_MinReturn : 140.0577850341797\n",
            "Train_AverageEpLen : 118.58823529411765\n",
            "Train_EnvstepsSoFar : 339508\n",
            "TimeSinceStart : 275.67060256004333\n",
            "Training Loss : 0.024791082367300987\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 166 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2029])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 238.5484619140625\n",
            "Eval_StdReturn : 42.98457336425781\n",
            "Eval_MaxReturn : 282.8401184082031\n",
            "Eval_MinReturn : 176.83558654785156\n",
            "Eval_AverageEpLen : 122.75\n",
            "Train_AverageReturn : 222.43475341796875\n",
            "Train_StdReturn : 22.704822540283203\n",
            "Train_MaxReturn : 255.61187744140625\n",
            "Train_MinReturn : 140.56141662597656\n",
            "Train_AverageEpLen : 106.78947368421052\n",
            "Train_EnvstepsSoFar : 341537\n",
            "TimeSinceStart : 277.3303322792053\n",
            "Training Loss : -0.050859395414590836\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 167 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2011])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 247.45867919921875\n",
            "Eval_StdReturn : 28.385475158691406\n",
            "Eval_MaxReturn : 291.3461608886719\n",
            "Eval_MinReturn : 214.13107299804688\n",
            "Eval_AverageEpLen : 115.25\n",
            "Train_AverageReturn : 236.34815979003906\n",
            "Train_StdReturn : 37.7714958190918\n",
            "Train_MaxReturn : 295.6429748535156\n",
            "Train_MinReturn : 146.01742553710938\n",
            "Train_AverageEpLen : 118.29411764705883\n",
            "Train_EnvstepsSoFar : 343548\n",
            "TimeSinceStart : 278.9493713378906\n",
            "Training Loss : 0.008349621668457985\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 168 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2078])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 235.56619262695312\n",
            "Eval_StdReturn : 31.616058349609375\n",
            "Eval_MaxReturn : 271.9131774902344\n",
            "Eval_MinReturn : 190.00830078125\n",
            "Eval_AverageEpLen : 111.0\n",
            "Train_AverageReturn : 244.42391967773438\n",
            "Train_StdReturn : 39.69792938232422\n",
            "Train_MaxReturn : 359.7779235839844\n",
            "Train_MinReturn : 192.6565399169922\n",
            "Train_AverageEpLen : 122.23529411764706\n",
            "Train_EnvstepsSoFar : 345626\n",
            "TimeSinceStart : 280.5892345905304\n",
            "Training Loss : 0.005826351698487997\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 169 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2052])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 240.66661071777344\n",
            "Eval_StdReturn : 10.577119827270508\n",
            "Eval_MaxReturn : 250.06985473632812\n",
            "Eval_MinReturn : 223.7161102294922\n",
            "Eval_AverageEpLen : 123.0\n",
            "Train_AverageReturn : 241.9462890625\n",
            "Train_StdReturn : 38.08903884887695\n",
            "Train_MaxReturn : 328.00140380859375\n",
            "Train_MinReturn : 176.28956604003906\n",
            "Train_AverageEpLen : 120.70588235294117\n",
            "Train_EnvstepsSoFar : 347678\n",
            "TimeSinceStart : 282.2563352584839\n",
            "Training Loss : -0.004175557754933834\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 170 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2022])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 248.091796875\n",
            "Eval_StdReturn : 8.931686401367188\n",
            "Eval_MaxReturn : 256.9060363769531\n",
            "Eval_MinReturn : 236.10385131835938\n",
            "Eval_AverageEpLen : 117.0\n",
            "Train_AverageReturn : 248.1151123046875\n",
            "Train_StdReturn : 45.62977981567383\n",
            "Train_MaxReturn : 314.8013000488281\n",
            "Train_MinReturn : 160.46035766601562\n",
            "Train_AverageEpLen : 126.375\n",
            "Train_EnvstepsSoFar : 349700\n",
            "TimeSinceStart : 283.8922679424286\n",
            "Training Loss : -0.016089465469121933\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 171 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2109])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 254.3334503173828\n",
            "Eval_StdReturn : 72.41761779785156\n",
            "Eval_MaxReturn : 368.03729248046875\n",
            "Eval_MinReturn : 169.9892578125\n",
            "Eval_AverageEpLen : 134.5\n",
            "Train_AverageReturn : 230.06903076171875\n",
            "Train_StdReturn : 41.09829330444336\n",
            "Train_MaxReturn : 311.25970458984375\n",
            "Train_MinReturn : 146.34805297851562\n",
            "Train_AverageEpLen : 111.0\n",
            "Train_EnvstepsSoFar : 351809\n",
            "TimeSinceStart : 285.61397790908813\n",
            "Training Loss : -0.03296521678566933\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 172 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2013])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 234.7186279296875\n",
            "Eval_StdReturn : 30.86752700805664\n",
            "Eval_MaxReturn : 258.2552795410156\n",
            "Eval_MinReturn : 181.9135284423828\n",
            "Eval_AverageEpLen : 116.25\n",
            "Train_AverageReturn : 236.98573303222656\n",
            "Train_StdReturn : 25.377111434936523\n",
            "Train_MaxReturn : 271.7933654785156\n",
            "Train_MinReturn : 169.06948852539062\n",
            "Train_AverageEpLen : 118.41176470588235\n",
            "Train_EnvstepsSoFar : 353822\n",
            "TimeSinceStart : 287.2512402534485\n",
            "Training Loss : -0.02703065425157547\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 173 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2113])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 243.12242126464844\n",
            "Eval_StdReturn : 35.997894287109375\n",
            "Eval_MaxReturn : 303.6000671386719\n",
            "Eval_MinReturn : 210.70616149902344\n",
            "Eval_AverageEpLen : 124.0\n",
            "Train_AverageReturn : 249.95875549316406\n",
            "Train_StdReturn : 23.91832160949707\n",
            "Train_MaxReturn : 289.50445556640625\n",
            "Train_MinReturn : 189.3822784423828\n",
            "Train_AverageEpLen : 124.29411764705883\n",
            "Train_EnvstepsSoFar : 355935\n",
            "TimeSinceStart : 288.95825123786926\n",
            "Training Loss : -0.0032804757356643677\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 174 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2031])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 221.5793914794922\n",
            "Eval_StdReturn : 46.79524612426758\n",
            "Eval_MaxReturn : 275.4327697753906\n",
            "Eval_MinReturn : 147.00497436523438\n",
            "Eval_AverageEpLen : 110.5\n",
            "Train_AverageReturn : 244.810546875\n",
            "Train_StdReturn : 36.56996154785156\n",
            "Train_MaxReturn : 332.16455078125\n",
            "Train_MinReturn : 165.93505859375\n",
            "Train_AverageEpLen : 118.61111111111111\n",
            "Train_EnvstepsSoFar : 358070\n",
            "TimeSinceStart : 290.6251714229584\n",
            "Training Loss : -0.027134016156196594\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 175 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2090])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 269.9307861328125\n",
            "Eval_StdReturn : 49.208370208740234\n",
            "Eval_MaxReturn : 353.81085205078125\n",
            "Eval_MinReturn : 233.154296875\n",
            "Eval_AverageEpLen : 123.25\n",
            "Train_AverageReturn : 262.7347412109375\n",
            "Train_StdReturn : 33.41959762573242\n",
            "Train_MaxReturn : 336.8977355957031\n",
            "Train_MinReturn : 207.27809143066406\n",
            "Train_AverageEpLen : 130.625\n",
            "Train_EnvstepsSoFar : 360160\n",
            "TimeSinceStart : 292.30976915359497\n",
            "Training Loss : -0.06141108646988869\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 176 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2015])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 300.8071594238281\n",
            "Eval_StdReturn : 26.159669876098633\n",
            "Eval_MaxReturn : 322.8886413574219\n",
            "Eval_MinReturn : 264.0604248046875\n",
            "Eval_AverageEpLen : 163.33333333333334\n",
            "Train_AverageReturn : 237.19671630859375\n",
            "Train_StdReturn : 33.6088981628418\n",
            "Train_MaxReturn : 293.0843811035156\n",
            "Train_MinReturn : 128.681884765625\n",
            "Train_AverageEpLen : 111.94444444444444\n",
            "Train_EnvstepsSoFar : 362175\n",
            "TimeSinceStart : 293.9316203594208\n",
            "Training Loss : -0.027868516743183136\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 177 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2022])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 268.17498779296875\n",
            "Eval_StdReturn : 33.39579391479492\n",
            "Eval_MaxReturn : 322.13848876953125\n",
            "Eval_MinReturn : 231.39889526367188\n",
            "Eval_AverageEpLen : 137.25\n",
            "Train_AverageReturn : 248.80276489257812\n",
            "Train_StdReturn : 28.194751739501953\n",
            "Train_MaxReturn : 304.2920227050781\n",
            "Train_MinReturn : 203.98106384277344\n",
            "Train_AverageEpLen : 118.94117647058823\n",
            "Train_EnvstepsSoFar : 364197\n",
            "TimeSinceStart : 295.60062527656555\n",
            "Training Loss : 0.014070396311581135\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 178 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2082])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 244.41366577148438\n",
            "Eval_StdReturn : 27.68890953063965\n",
            "Eval_MaxReturn : 283.615966796875\n",
            "Eval_MinReturn : 205.3280792236328\n",
            "Eval_AverageEpLen : 128.75\n",
            "Train_AverageReturn : 245.58079528808594\n",
            "Train_StdReturn : 25.724546432495117\n",
            "Train_MaxReturn : 325.9398498535156\n",
            "Train_MinReturn : 208.02610778808594\n",
            "Train_AverageEpLen : 122.47058823529412\n",
            "Train_EnvstepsSoFar : 366279\n",
            "TimeSinceStart : 297.3044526576996\n",
            "Training Loss : 0.04329528287053108\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 179 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2012])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 246.67628479003906\n",
            "Eval_StdReturn : 18.26789093017578\n",
            "Eval_MaxReturn : 273.2079162597656\n",
            "Eval_MinReturn : 221.6793975830078\n",
            "Eval_AverageEpLen : 123.5\n",
            "Train_AverageReturn : 237.17666625976562\n",
            "Train_StdReturn : 38.521236419677734\n",
            "Train_MaxReturn : 295.92034912109375\n",
            "Train_MinReturn : 167.16830444335938\n",
            "Train_AverageEpLen : 118.3529411764706\n",
            "Train_EnvstepsSoFar : 368291\n",
            "TimeSinceStart : 298.91443276405334\n",
            "Training Loss : -0.004710956942290068\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 180 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2003])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 261.8743896484375\n",
            "Eval_StdReturn : 43.3656120300293\n",
            "Eval_MaxReturn : 320.36651611328125\n",
            "Eval_MinReturn : 200.70782470703125\n",
            "Eval_AverageEpLen : 130.75\n",
            "Train_AverageReturn : 268.8946533203125\n",
            "Train_StdReturn : 34.86601257324219\n",
            "Train_MaxReturn : 320.2503356933594\n",
            "Train_MinReturn : 201.08572387695312\n",
            "Train_AverageEpLen : 133.53333333333333\n",
            "Train_EnvstepsSoFar : 370294\n",
            "TimeSinceStart : 300.5721626281738\n",
            "Training Loss : 0.03595390543341637\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 181 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2020])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 271.8149719238281\n",
            "Eval_StdReturn : 7.654299736022949\n",
            "Eval_MaxReturn : 281.2820129394531\n",
            "Eval_MinReturn : 262.53570556640625\n",
            "Eval_AverageEpLen : 135.0\n",
            "Train_AverageReturn : 254.71990966796875\n",
            "Train_StdReturn : 74.89710235595703\n",
            "Train_MaxReturn : 404.69805908203125\n",
            "Train_MinReturn : 52.916324615478516\n",
            "Train_AverageEpLen : 134.66666666666666\n",
            "Train_EnvstepsSoFar : 372314\n",
            "TimeSinceStart : 302.1419835090637\n",
            "Training Loss : 0.018988745287060738\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 182 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2062])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 302.4327697753906\n",
            "Eval_StdReturn : 41.279632568359375\n",
            "Eval_MaxReturn : 348.5627136230469\n",
            "Eval_MinReturn : 248.38339233398438\n",
            "Eval_AverageEpLen : 167.0\n",
            "Train_AverageReturn : 258.99688720703125\n",
            "Train_StdReturn : 38.35609817504883\n",
            "Train_MaxReturn : 342.414794921875\n",
            "Train_MinReturn : 204.5232696533203\n",
            "Train_AverageEpLen : 121.29411764705883\n",
            "Train_EnvstepsSoFar : 374376\n",
            "TimeSinceStart : 303.81061911582947\n",
            "Training Loss : 0.009691686369478703\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 183 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2069])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 247.49368286132812\n",
            "Eval_StdReturn : 9.765350341796875\n",
            "Eval_MaxReturn : 257.60308837890625\n",
            "Eval_MinReturn : 236.642578125\n",
            "Eval_AverageEpLen : 120.75\n",
            "Train_AverageReturn : 268.26605224609375\n",
            "Train_StdReturn : 35.944053649902344\n",
            "Train_MaxReturn : 353.6302490234375\n",
            "Train_MinReturn : 216.393798828125\n",
            "Train_AverageEpLen : 129.3125\n",
            "Train_EnvstepsSoFar : 376445\n",
            "TimeSinceStart : 305.4824016094208\n",
            "Training Loss : -0.0022456683218479156\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 184 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2054])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 282.8653564453125\n",
            "Eval_StdReturn : 29.361888885498047\n",
            "Eval_MaxReturn : 316.20819091796875\n",
            "Eval_MinReturn : 244.76097106933594\n",
            "Eval_AverageEpLen : 141.0\n",
            "Train_AverageReturn : 263.99530029296875\n",
            "Train_StdReturn : 31.89533805847168\n",
            "Train_MaxReturn : 328.33819580078125\n",
            "Train_MinReturn : 220.70730590820312\n",
            "Train_AverageEpLen : 128.375\n",
            "Train_EnvstepsSoFar : 378499\n",
            "TimeSinceStart : 307.5008292198181\n",
            "Training Loss : 0.04713771119713783\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 185 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2081])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 292.6209716796875\n",
            "Eval_StdReturn : 7.406718730926514\n",
            "Eval_MaxReturn : 300.15380859375\n",
            "Eval_MinReturn : 280.4136962890625\n",
            "Eval_AverageEpLen : 131.25\n",
            "Train_AverageReturn : 276.2881774902344\n",
            "Train_StdReturn : 39.0544548034668\n",
            "Train_MaxReturn : 384.45172119140625\n",
            "Train_MinReturn : 208.8551483154297\n",
            "Train_AverageEpLen : 138.73333333333332\n",
            "Train_EnvstepsSoFar : 380580\n",
            "TimeSinceStart : 309.47280621528625\n",
            "Training Loss : -0.07344727218151093\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 186 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2025])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 234.5685272216797\n",
            "Eval_StdReturn : 46.67301559448242\n",
            "Eval_MaxReturn : 269.68328857421875\n",
            "Eval_MinReturn : 155.184326171875\n",
            "Eval_AverageEpLen : 119.75\n",
            "Train_AverageReturn : 252.2169189453125\n",
            "Train_StdReturn : 67.5487060546875\n",
            "Train_MaxReturn : 324.3639221191406\n",
            "Train_MinReturn : 19.29537582397461\n",
            "Train_AverageEpLen : 126.5625\n",
            "Train_EnvstepsSoFar : 382605\n",
            "TimeSinceStart : 312.005051612854\n",
            "Training Loss : -0.07373948395252228\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 187 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2108])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 276.1706237792969\n",
            "Eval_StdReturn : 27.87545394897461\n",
            "Eval_MaxReturn : 307.7395324707031\n",
            "Eval_MinReturn : 232.90660095214844\n",
            "Eval_AverageEpLen : 132.25\n",
            "Train_AverageReturn : 308.31170654296875\n",
            "Train_StdReturn : 53.31544494628906\n",
            "Train_MaxReturn : 416.8743591308594\n",
            "Train_MinReturn : 244.89083862304688\n",
            "Train_AverageEpLen : 162.15384615384616\n",
            "Train_EnvstepsSoFar : 384713\n",
            "TimeSinceStart : 314.11111760139465\n",
            "Training Loss : 0.007874091155827045\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 188 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2107])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 274.03118896484375\n",
            "Eval_StdReturn : 32.235477447509766\n",
            "Eval_MaxReturn : 302.8574523925781\n",
            "Eval_MinReturn : 229.0325469970703\n",
            "Eval_AverageEpLen : 149.0\n",
            "Train_AverageReturn : 265.17437744140625\n",
            "Train_StdReturn : 30.50867462158203\n",
            "Train_MaxReturn : 328.50140380859375\n",
            "Train_MinReturn : 203.18634033203125\n",
            "Train_AverageEpLen : 131.6875\n",
            "Train_EnvstepsSoFar : 386820\n",
            "TimeSinceStart : 315.74609565734863\n",
            "Training Loss : -0.05844910815358162\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 189 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2058])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 258.9271240234375\n",
            "Eval_StdReturn : 66.41572570800781\n",
            "Eval_MaxReturn : 321.27734375\n",
            "Eval_MinReturn : 158.65155029296875\n",
            "Eval_AverageEpLen : 121.75\n",
            "Train_AverageReturn : 282.3471374511719\n",
            "Train_StdReturn : 47.02336502075195\n",
            "Train_MaxReturn : 376.4138488769531\n",
            "Train_MinReturn : 176.96197509765625\n",
            "Train_AverageEpLen : 137.2\n",
            "Train_EnvstepsSoFar : 388878\n",
            "TimeSinceStart : 317.41366267204285\n",
            "Training Loss : 0.00015258093480952084\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 190 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2101])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 305.4266357421875\n",
            "Eval_StdReturn : 18.3162784576416\n",
            "Eval_MaxReturn : 327.5032653808594\n",
            "Eval_MinReturn : 282.6539306640625\n",
            "Eval_AverageEpLen : 140.33333333333334\n",
            "Train_AverageReturn : 271.2756652832031\n",
            "Train_StdReturn : 42.41249465942383\n",
            "Train_MaxReturn : 353.44940185546875\n",
            "Train_MinReturn : 162.99366760253906\n",
            "Train_AverageEpLen : 140.06666666666666\n",
            "Train_EnvstepsSoFar : 390979\n",
            "TimeSinceStart : 319.0538306236267\n",
            "Training Loss : 0.0049791703931987286\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 191 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2104])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 356.8740539550781\n",
            "Eval_StdReturn : 108.70211029052734\n",
            "Eval_MaxReturn : 465.576171875\n",
            "Eval_MinReturn : 248.1719512939453\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 279.8948974609375\n",
            "Train_StdReturn : 43.003135681152344\n",
            "Train_MaxReturn : 361.2433776855469\n",
            "Train_MinReturn : 224.9667510986328\n",
            "Train_AverageEpLen : 140.26666666666668\n",
            "Train_EnvstepsSoFar : 393083\n",
            "TimeSinceStart : 320.7170512676239\n",
            "Training Loss : 0.022156476974487305\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 192 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2132])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 329.3379821777344\n",
            "Eval_StdReturn : 34.43457794189453\n",
            "Eval_MaxReturn : 377.7187194824219\n",
            "Eval_MinReturn : 300.3426208496094\n",
            "Eval_AverageEpLen : 175.66666666666666\n",
            "Train_AverageReturn : 302.36962890625\n",
            "Train_StdReturn : 35.143798828125\n",
            "Train_MaxReturn : 355.0708312988281\n",
            "Train_MinReturn : 231.2301483154297\n",
            "Train_AverageEpLen : 152.28571428571428\n",
            "Train_EnvstepsSoFar : 395215\n",
            "TimeSinceStart : 322.5104446411133\n",
            "Training Loss : 0.042077306658029556\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 193 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2083])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 316.6844482421875\n",
            "Eval_StdReturn : 41.97639846801758\n",
            "Eval_MaxReturn : 365.50445556640625\n",
            "Eval_MinReturn : 263.02581787109375\n",
            "Eval_AverageEpLen : 154.33333333333334\n",
            "Train_AverageReturn : 314.7666320800781\n",
            "Train_StdReturn : 33.167484283447266\n",
            "Train_MaxReturn : 375.30279541015625\n",
            "Train_MinReturn : 265.9949645996094\n",
            "Train_AverageEpLen : 160.23076923076923\n",
            "Train_EnvstepsSoFar : 397298\n",
            "TimeSinceStart : 324.1740164756775\n",
            "Training Loss : 0.038946229964494705\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 194 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2136])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 284.1145935058594\n",
            "Eval_StdReturn : 8.222810745239258\n",
            "Eval_MaxReturn : 291.4895935058594\n",
            "Eval_MinReturn : 270.3833923339844\n",
            "Eval_AverageEpLen : 130.5\n",
            "Train_AverageReturn : 282.2446594238281\n",
            "Train_StdReturn : 70.7743911743164\n",
            "Train_MaxReturn : 395.2132568359375\n",
            "Train_MinReturn : 47.42620086669922\n",
            "Train_AverageEpLen : 142.4\n",
            "Train_EnvstepsSoFar : 399434\n",
            "TimeSinceStart : 325.9008140563965\n",
            "Training Loss : 0.014777849428355694\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 195 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2072])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 348.8602294921875\n",
            "Eval_StdReturn : 20.934640884399414\n",
            "Eval_MaxReturn : 375.438720703125\n",
            "Eval_MinReturn : 324.2760009765625\n",
            "Eval_AverageEpLen : 179.0\n",
            "Train_AverageReturn : 317.5152587890625\n",
            "Train_StdReturn : 49.22049331665039\n",
            "Train_MaxReturn : 399.3913269042969\n",
            "Train_MinReturn : 242.4062957763672\n",
            "Train_AverageEpLen : 159.3846153846154\n",
            "Train_EnvstepsSoFar : 401506\n",
            "TimeSinceStart : 327.6160726547241\n",
            "Training Loss : 0.03443191200494766\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 196 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2104])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 298.1282653808594\n",
            "Eval_StdReturn : 39.55009078979492\n",
            "Eval_MaxReturn : 333.769775390625\n",
            "Eval_MinReturn : 242.9768524169922\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 315.4146728515625\n",
            "Train_StdReturn : 21.375507354736328\n",
            "Train_MaxReturn : 347.8934326171875\n",
            "Train_MinReturn : 283.67572021484375\n",
            "Train_AverageEpLen : 161.84615384615384\n",
            "Train_EnvstepsSoFar : 403610\n",
            "TimeSinceStart : 329.290424823761\n",
            "Training Loss : -0.00018630735576152802\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 197 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2007])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 323.51995849609375\n",
            "Eval_StdReturn : 30.90843391418457\n",
            "Eval_MaxReturn : 352.688720703125\n",
            "Eval_MinReturn : 280.74188232421875\n",
            "Eval_AverageEpLen : 158.33333333333334\n",
            "Train_AverageReturn : 291.2524108886719\n",
            "Train_StdReturn : 45.048057556152344\n",
            "Train_MaxReturn : 360.190185546875\n",
            "Train_MinReturn : 204.5564422607422\n",
            "Train_AverageEpLen : 143.35714285714286\n",
            "Train_EnvstepsSoFar : 405617\n",
            "TimeSinceStart : 330.89306926727295\n",
            "Training Loss : -0.013058854267001152\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 198 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2145])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 340.5608825683594\n",
            "Eval_StdReturn : 9.53923225402832\n",
            "Eval_MaxReturn : 351.3326721191406\n",
            "Eval_MinReturn : 328.141357421875\n",
            "Eval_AverageEpLen : 170.66666666666666\n",
            "Train_AverageReturn : 297.3165588378906\n",
            "Train_StdReturn : 49.543373107910156\n",
            "Train_MaxReturn : 379.2847595214844\n",
            "Train_MinReturn : 200.11988830566406\n",
            "Train_AverageEpLen : 153.21428571428572\n",
            "Train_EnvstepsSoFar : 407762\n",
            "TimeSinceStart : 332.6057505607605\n",
            "Training Loss : -0.016782231628894806\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 199 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2084])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 314.6899108886719\n",
            "Eval_StdReturn : 17.227495193481445\n",
            "Eval_MaxReturn : 335.73468017578125\n",
            "Eval_MinReturn : 293.5365295410156\n",
            "Eval_AverageEpLen : 157.66666666666666\n",
            "Train_AverageReturn : 316.5149230957031\n",
            "Train_StdReturn : 22.215587615966797\n",
            "Train_MaxReturn : 345.4090881347656\n",
            "Train_MinReturn : 268.85430908203125\n",
            "Train_AverageEpLen : 160.30769230769232\n",
            "Train_EnvstepsSoFar : 409846\n",
            "TimeSinceStart : 334.2485809326172\n",
            "Training Loss : -0.02235046960413456\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 200 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2004])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 358.0941467285156\n",
            "Eval_StdReturn : 7.877593994140625\n",
            "Eval_MaxReturn : 369.1920166015625\n",
            "Eval_MinReturn : 351.7008361816406\n",
            "Eval_AverageEpLen : 184.66666666666666\n",
            "Train_AverageReturn : 318.52154541015625\n",
            "Train_StdReturn : 39.09518814086914\n",
            "Train_MaxReturn : 384.78558349609375\n",
            "Train_MinReturn : 249.4193878173828\n",
            "Train_AverageEpLen : 154.15384615384616\n",
            "Train_EnvstepsSoFar : 411850\n",
            "TimeSinceStart : 335.89645195007324\n",
            "Training Loss : -0.013085796497762203\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 201 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2007])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 292.29925537109375\n",
            "Eval_StdReturn : 3.4128239154815674\n",
            "Eval_MaxReturn : 296.10137939453125\n",
            "Eval_MinReturn : 287.8235168457031\n",
            "Eval_AverageEpLen : 149.0\n",
            "Train_AverageReturn : 320.2030944824219\n",
            "Train_StdReturn : 37.880462646484375\n",
            "Train_MaxReturn : 407.305419921875\n",
            "Train_MinReturn : 265.7005615234375\n",
            "Train_AverageEpLen : 165.23076923076923\n",
            "Train_EnvstepsSoFar : 413998\n",
            "TimeSinceStart : 337.5937006473541\n",
            "Training Loss : 0.0242999866604805\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 202 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2018])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 313.5225524902344\n",
            "Eval_StdReturn : 34.636470794677734\n",
            "Eval_MaxReturn : 353.8442687988281\n",
            "Eval_MinReturn : 269.27545166015625\n",
            "Eval_AverageEpLen : 150.66666666666666\n",
            "Train_AverageReturn : 334.343994140625\n",
            "Train_StdReturn : 62.50371551513672\n",
            "Train_MaxReturn : 490.8935852050781\n",
            "Train_MinReturn : 238.9235076904297\n",
            "Train_AverageEpLen : 168.16666666666666\n",
            "Train_EnvstepsSoFar : 416016\n",
            "TimeSinceStart : 339.16641545295715\n",
            "Training Loss : 0.043720655143260956\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 203 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2133])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 321.8923034667969\n",
            "Eval_StdReturn : 13.965010643005371\n",
            "Eval_MaxReturn : 339.596435546875\n",
            "Eval_MinReturn : 305.4603271484375\n",
            "Eval_AverageEpLen : 161.0\n",
            "Train_AverageReturn : 329.7225036621094\n",
            "Train_StdReturn : 72.42253112792969\n",
            "Train_MaxReturn : 430.26068115234375\n",
            "Train_MinReturn : 124.66106414794922\n",
            "Train_AverageEpLen : 164.07692307692307\n",
            "Train_EnvstepsSoFar : 418149\n",
            "TimeSinceStart : 340.8452076911926\n",
            "Training Loss : -0.0015244472306221724\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 204 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2093])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 232.78550720214844\n",
            "Eval_StdReturn : 112.0367202758789\n",
            "Eval_MaxReturn : 329.20013427734375\n",
            "Eval_MinReturn : 75.69061279296875\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 321.4465026855469\n",
            "Train_StdReturn : 59.31228256225586\n",
            "Train_MaxReturn : 383.425537109375\n",
            "Train_MinReturn : 137.71267700195312\n",
            "Train_AverageEpLen : 161.0\n",
            "Train_EnvstepsSoFar : 420242\n",
            "TimeSinceStart : 342.4866523742676\n",
            "Training Loss : 0.0027034711092710495\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 205 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2055])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 360.5101013183594\n",
            "Eval_StdReturn : 13.795583724975586\n",
            "Eval_MaxReturn : 379.2529296875\n",
            "Eval_MinReturn : 346.44757080078125\n",
            "Eval_AverageEpLen : 180.0\n",
            "Train_AverageReturn : 323.07342529296875\n",
            "Train_StdReturn : 31.32549285888672\n",
            "Train_MaxReturn : 367.78350830078125\n",
            "Train_MinReturn : 242.8501434326172\n",
            "Train_AverageEpLen : 158.07692307692307\n",
            "Train_EnvstepsSoFar : 422297\n",
            "TimeSinceStart : 344.1379430294037\n",
            "Training Loss : 0.017949407920241356\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 206 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2077])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 284.253173828125\n",
            "Eval_StdReturn : 45.438602447509766\n",
            "Eval_MaxReturn : 347.691162109375\n",
            "Eval_MinReturn : 243.66195678710938\n",
            "Eval_AverageEpLen : 163.66666666666666\n",
            "Train_AverageReturn : 317.74420166015625\n",
            "Train_StdReturn : 40.532257080078125\n",
            "Train_MaxReturn : 418.0115966796875\n",
            "Train_MinReturn : 239.6965789794922\n",
            "Train_AverageEpLen : 159.76923076923077\n",
            "Train_EnvstepsSoFar : 424374\n",
            "TimeSinceStart : 345.79532194137573\n",
            "Training Loss : 0.009602448903024197\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 207 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 381.0539245605469\n",
            "Eval_StdReturn : 25.153411865234375\n",
            "Eval_MaxReturn : 406.20733642578125\n",
            "Eval_MinReturn : 355.9005126953125\n",
            "Eval_AverageEpLen : 203.0\n",
            "Train_AverageReturn : 287.06195068359375\n",
            "Train_StdReturn : 85.88641357421875\n",
            "Train_MaxReturn : 438.01385498046875\n",
            "Train_MinReturn : 107.77625274658203\n",
            "Train_AverageEpLen : 157.69230769230768\n",
            "Train_EnvstepsSoFar : 426424\n",
            "TimeSinceStart : 347.3944823741913\n",
            "Training Loss : -0.037741079926490784\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 208 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2082])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 382.9339599609375\n",
            "Eval_StdReturn : 28.423110961914062\n",
            "Eval_MaxReturn : 411.3570556640625\n",
            "Eval_MinReturn : 354.5108337402344\n",
            "Eval_AverageEpLen : 206.0\n",
            "Train_AverageReturn : 350.4927978515625\n",
            "Train_StdReturn : 90.40805053710938\n",
            "Train_MaxReturn : 457.30413818359375\n",
            "Train_MinReturn : 93.12500762939453\n",
            "Train_AverageEpLen : 189.27272727272728\n",
            "Train_EnvstepsSoFar : 428506\n",
            "TimeSinceStart : 349.0472502708435\n",
            "Training Loss : 0.007999109104275703\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 209 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2040])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 375.2750244140625\n",
            "Eval_StdReturn : 19.380126953125\n",
            "Eval_MaxReturn : 392.33544921875\n",
            "Eval_MinReturn : 348.168212890625\n",
            "Eval_AverageEpLen : 209.66666666666666\n",
            "Train_AverageReturn : 347.8811340332031\n",
            "Train_StdReturn : 51.233619689941406\n",
            "Train_MaxReturn : 472.1992492675781\n",
            "Train_MinReturn : 288.58392333984375\n",
            "Train_AverageEpLen : 185.45454545454547\n",
            "Train_EnvstepsSoFar : 430546\n",
            "TimeSinceStart : 350.77279782295227\n",
            "Training Loss : -0.07517063617706299\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 210 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2175])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 313.30975341796875\n",
            "Eval_StdReturn : 13.5343599319458\n",
            "Eval_MaxReturn : 326.32427978515625\n",
            "Eval_MinReturn : 294.6478576660156\n",
            "Eval_AverageEpLen : 153.33333333333334\n",
            "Train_AverageReturn : 364.0464782714844\n",
            "Train_StdReturn : 85.25537109375\n",
            "Train_MaxReturn : 457.02044677734375\n",
            "Train_MinReturn : 116.42250061035156\n",
            "Train_AverageEpLen : 197.72727272727272\n",
            "Train_EnvstepsSoFar : 432721\n",
            "TimeSinceStart : 352.4753921031952\n",
            "Training Loss : 0.000356580363586545\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 211 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2040])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 404.2066955566406\n",
            "Eval_StdReturn : 9.30439281463623\n",
            "Eval_MaxReturn : 417.0534973144531\n",
            "Eval_MinReturn : 395.3179931640625\n",
            "Eval_AverageEpLen : 184.33333333333334\n",
            "Train_AverageReturn : 366.03826904296875\n",
            "Train_StdReturn : 40.500370025634766\n",
            "Train_MaxReturn : 419.1907958984375\n",
            "Train_MinReturn : 297.2708740234375\n",
            "Train_AverageEpLen : 185.45454545454547\n",
            "Train_EnvstepsSoFar : 434761\n",
            "TimeSinceStart : 354.1794979572296\n",
            "Training Loss : 0.015408985316753387\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 212 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 403.5081787109375\n",
            "Eval_StdReturn : 2.43731689453125\n",
            "Eval_MaxReturn : 405.94549560546875\n",
            "Eval_MinReturn : 401.07086181640625\n",
            "Eval_AverageEpLen : 219.5\n",
            "Train_AverageReturn : 350.6315002441406\n",
            "Train_StdReturn : 55.41714859008789\n",
            "Train_MaxReturn : 473.05560302734375\n",
            "Train_MinReturn : 260.1494140625\n",
            "Train_AverageEpLen : 175.0\n",
            "Train_EnvstepsSoFar : 436861\n",
            "TimeSinceStart : 355.8527901172638\n",
            "Training Loss : -0.025359774008393288\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 213 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2051])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 369.89794921875\n",
            "Eval_StdReturn : 53.39381408691406\n",
            "Eval_MaxReturn : 423.2917785644531\n",
            "Eval_MinReturn : 316.504150390625\n",
            "Eval_AverageEpLen : 205.0\n",
            "Train_AverageReturn : 338.688720703125\n",
            "Train_StdReturn : 70.09773254394531\n",
            "Train_MaxReturn : 466.93206787109375\n",
            "Train_MinReturn : 195.54937744140625\n",
            "Train_AverageEpLen : 170.91666666666666\n",
            "Train_EnvstepsSoFar : 438912\n",
            "TimeSinceStart : 357.460608959198\n",
            "Training Loss : -0.024119775742292404\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 214 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2036])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 399.02386474609375\n",
            "Eval_StdReturn : 41.63786315917969\n",
            "Eval_MaxReturn : 440.6617126464844\n",
            "Eval_MinReturn : 357.385986328125\n",
            "Eval_AverageEpLen : 216.0\n",
            "Train_AverageReturn : 330.07489013671875\n",
            "Train_StdReturn : 91.3669204711914\n",
            "Train_MaxReturn : 411.12847900390625\n",
            "Train_MinReturn : 55.965023040771484\n",
            "Train_AverageEpLen : 169.66666666666666\n",
            "Train_EnvstepsSoFar : 440948\n",
            "TimeSinceStart : 359.05373311042786\n",
            "Training Loss : 0.0015835087979212403\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 215 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2052])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 312.458251953125\n",
            "Eval_StdReturn : 5.6941752433776855\n",
            "Eval_MaxReturn : 318.05816650390625\n",
            "Eval_MinReturn : 304.6466979980469\n",
            "Eval_AverageEpLen : 178.33333333333334\n",
            "Train_AverageReturn : 365.2061462402344\n",
            "Train_StdReturn : 53.34596252441406\n",
            "Train_MaxReturn : 433.11944580078125\n",
            "Train_MinReturn : 246.88522338867188\n",
            "Train_AverageEpLen : 186.54545454545453\n",
            "Train_EnvstepsSoFar : 443000\n",
            "TimeSinceStart : 360.7117040157318\n",
            "Training Loss : 0.019634542986750603\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 216 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2147])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 330.2281494140625\n",
            "Eval_StdReturn : 7.629415035247803\n",
            "Eval_MaxReturn : 340.352783203125\n",
            "Eval_MinReturn : 321.9361572265625\n",
            "Eval_AverageEpLen : 160.33333333333334\n",
            "Train_AverageReturn : 352.7520446777344\n",
            "Train_StdReturn : 55.76646423339844\n",
            "Train_MaxReturn : 440.5413513183594\n",
            "Train_MinReturn : 257.43621826171875\n",
            "Train_AverageEpLen : 178.91666666666666\n",
            "Train_EnvstepsSoFar : 445147\n",
            "TimeSinceStart : 362.41959142684937\n",
            "Training Loss : 0.007227856200188398\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 217 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2085])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 457.8206787109375\n",
            "Eval_StdReturn : 81.9193115234375\n",
            "Eval_MaxReturn : 539.739990234375\n",
            "Eval_MinReturn : 375.9013671875\n",
            "Eval_AverageEpLen : 281.5\n",
            "Train_AverageReturn : 288.1319580078125\n",
            "Train_StdReturn : 85.31478118896484\n",
            "Train_MaxReturn : 408.74615478515625\n",
            "Train_MinReturn : 178.39369201660156\n",
            "Train_AverageEpLen : 160.3846153846154\n",
            "Train_EnvstepsSoFar : 447232\n",
            "TimeSinceStart : 364.13383293151855\n",
            "Training Loss : -0.0027239713817834854\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 218 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2018])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 361.947265625\n",
            "Eval_StdReturn : 19.8642635345459\n",
            "Eval_MaxReturn : 389.7382507324219\n",
            "Eval_MinReturn : 344.49786376953125\n",
            "Eval_AverageEpLen : 181.0\n",
            "Train_AverageReturn : 333.1767272949219\n",
            "Train_StdReturn : 80.29711151123047\n",
            "Train_MaxReturn : 466.6285400390625\n",
            "Train_MinReturn : 162.08941650390625\n",
            "Train_AverageEpLen : 183.45454545454547\n",
            "Train_EnvstepsSoFar : 449250\n",
            "TimeSinceStart : 365.79801893234253\n",
            "Training Loss : -0.025724023580551147\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 219 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2002])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 419.32098388671875\n",
            "Eval_StdReturn : 33.56013488769531\n",
            "Eval_MaxReturn : 452.8811340332031\n",
            "Eval_MinReturn : 385.7608642578125\n",
            "Eval_AverageEpLen : 217.0\n",
            "Train_AverageReturn : 364.7986145019531\n",
            "Train_StdReturn : 39.198455810546875\n",
            "Train_MaxReturn : 442.406494140625\n",
            "Train_MinReturn : 315.1396484375\n",
            "Train_AverageEpLen : 182.0\n",
            "Train_EnvstepsSoFar : 451252\n",
            "TimeSinceStart : 367.42160534858704\n",
            "Training Loss : -0.019097182899713516\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 220 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2150])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 331.69989013671875\n",
            "Eval_StdReturn : 15.466296195983887\n",
            "Eval_MaxReturn : 353.40313720703125\n",
            "Eval_MinReturn : 318.4953918457031\n",
            "Eval_AverageEpLen : 184.66666666666666\n",
            "Train_AverageReturn : 418.5526123046875\n",
            "Train_StdReturn : 59.58682632446289\n",
            "Train_MaxReturn : 564.6795654296875\n",
            "Train_MinReturn : 347.546630859375\n",
            "Train_AverageEpLen : 238.88888888888889\n",
            "Train_EnvstepsSoFar : 453402\n",
            "TimeSinceStart : 369.18873023986816\n",
            "Training Loss : -0.026498422026634216\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 221 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2093])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 390.1364440917969\n",
            "Eval_StdReturn : 61.25865936279297\n",
            "Eval_MaxReturn : 464.7862548828125\n",
            "Eval_MinReturn : 314.7393798828125\n",
            "Eval_AverageEpLen : 209.0\n",
            "Train_AverageReturn : 389.787353515625\n",
            "Train_StdReturn : 25.111677169799805\n",
            "Train_MaxReturn : 439.20806884765625\n",
            "Train_MinReturn : 339.86456298828125\n",
            "Train_AverageEpLen : 209.3\n",
            "Train_EnvstepsSoFar : 455495\n",
            "TimeSinceStart : 370.92510175704956\n",
            "Training Loss : 0.04136538878083229\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 222 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2019])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 395.5749206542969\n",
            "Eval_StdReturn : 17.057830810546875\n",
            "Eval_MaxReturn : 412.63275146484375\n",
            "Eval_MinReturn : 378.51708984375\n",
            "Eval_AverageEpLen : 206.5\n",
            "Train_AverageReturn : 390.10003662109375\n",
            "Train_StdReturn : 57.8504638671875\n",
            "Train_MaxReturn : 463.40081787109375\n",
            "Train_MinReturn : 275.63763427734375\n",
            "Train_AverageEpLen : 201.9\n",
            "Train_EnvstepsSoFar : 457514\n",
            "TimeSinceStart : 372.4996430873871\n",
            "Training Loss : 0.02535071223974228\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 223 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2014])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 344.0965881347656\n",
            "Eval_StdReturn : 15.493644714355469\n",
            "Eval_MaxReturn : 365.5159912109375\n",
            "Eval_MinReturn : 329.38861083984375\n",
            "Eval_AverageEpLen : 176.33333333333334\n",
            "Train_AverageReturn : 382.93218994140625\n",
            "Train_StdReturn : 53.84459686279297\n",
            "Train_MaxReturn : 482.4473876953125\n",
            "Train_MinReturn : 297.00091552734375\n",
            "Train_AverageEpLen : 201.4\n",
            "Train_EnvstepsSoFar : 459528\n",
            "TimeSinceStart : 374.145530462265\n",
            "Training Loss : -0.056941092014312744\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 224 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2155])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 333.24658203125\n",
            "Eval_StdReturn : 31.113628387451172\n",
            "Eval_MaxReturn : 364.6841125488281\n",
            "Eval_MinReturn : 290.8660888671875\n",
            "Eval_AverageEpLen : 169.0\n",
            "Train_AverageReturn : 347.911865234375\n",
            "Train_StdReturn : 52.47349548339844\n",
            "Train_MaxReturn : 425.1708984375\n",
            "Train_MinReturn : 215.18313598632812\n",
            "Train_AverageEpLen : 179.58333333333334\n",
            "Train_EnvstepsSoFar : 461683\n",
            "TimeSinceStart : 375.8469727039337\n",
            "Training Loss : -0.03244836628437042\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 225 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2106])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 286.8391418457031\n",
            "Eval_StdReturn : 69.260009765625\n",
            "Eval_MaxReturn : 354.7455749511719\n",
            "Eval_MinReturn : 191.75523376464844\n",
            "Eval_AverageEpLen : 164.33333333333334\n",
            "Train_AverageReturn : 365.8766174316406\n",
            "Train_StdReturn : 40.227596282958984\n",
            "Train_MaxReturn : 451.49188232421875\n",
            "Train_MinReturn : 293.5791931152344\n",
            "Train_AverageEpLen : 175.5\n",
            "Train_EnvstepsSoFar : 463789\n",
            "TimeSinceStart : 377.53972148895264\n",
            "Training Loss : 0.031383153051137924\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 226 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2012])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 368.7689514160156\n",
            "Eval_StdReturn : 47.90057373046875\n",
            "Eval_MaxReturn : 413.06158447265625\n",
            "Eval_MinReturn : 302.234375\n",
            "Eval_AverageEpLen : 202.66666666666666\n",
            "Train_AverageReturn : 357.3436279296875\n",
            "Train_StdReturn : 96.66673278808594\n",
            "Train_MaxReturn : 453.90130615234375\n",
            "Train_MinReturn : 72.47471618652344\n",
            "Train_AverageEpLen : 182.9090909090909\n",
            "Train_EnvstepsSoFar : 465801\n",
            "TimeSinceStart : 379.2823312282562\n",
            "Training Loss : -0.0767509862780571\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 227 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2114])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 425.0364685058594\n",
            "Eval_StdReturn : 65.95222473144531\n",
            "Eval_MaxReturn : 518.271728515625\n",
            "Eval_MinReturn : 376.197998046875\n",
            "Eval_AverageEpLen : 221.33333333333334\n",
            "Train_AverageReturn : 346.714599609375\n",
            "Train_StdReturn : 45.27180099487305\n",
            "Train_MaxReturn : 418.08209228515625\n",
            "Train_MinReturn : 256.9605712890625\n",
            "Train_AverageEpLen : 176.16666666666666\n",
            "Train_EnvstepsSoFar : 467915\n",
            "TimeSinceStart : 381.09310269355774\n",
            "Training Loss : -0.03153396025300026\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 228 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2112])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 343.4980773925781\n",
            "Eval_StdReturn : 47.34642791748047\n",
            "Eval_MaxReturn : 410.2793273925781\n",
            "Eval_MinReturn : 305.89715576171875\n",
            "Eval_AverageEpLen : 192.66666666666666\n",
            "Train_AverageReturn : 352.3167419433594\n",
            "Train_StdReturn : 26.864500045776367\n",
            "Train_MaxReturn : 414.2397766113281\n",
            "Train_MinReturn : 300.30731201171875\n",
            "Train_AverageEpLen : 176.0\n",
            "Train_EnvstepsSoFar : 470027\n",
            "TimeSinceStart : 382.8600244522095\n",
            "Training Loss : 0.018442735075950623\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 229 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2003])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 310.3702697753906\n",
            "Eval_StdReturn : 36.846771240234375\n",
            "Eval_MaxReturn : 354.61248779296875\n",
            "Eval_MinReturn : 264.406005859375\n",
            "Eval_AverageEpLen : 172.0\n",
            "Train_AverageReturn : 371.37969970703125\n",
            "Train_StdReturn : 62.701175689697266\n",
            "Train_MaxReturn : 507.19891357421875\n",
            "Train_MinReturn : 216.52626037597656\n",
            "Train_AverageEpLen : 197.36363636363637\n",
            "Train_EnvstepsSoFar : 472198\n",
            "TimeSinceStart : 384.6159756183624\n",
            "Training Loss : 0.008532513864338398\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 230 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2176])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 354.452392578125\n",
            "Eval_StdReturn : 2.140692710876465\n",
            "Eval_MaxReturn : 357.3577575683594\n",
            "Eval_MinReturn : 352.2628173828125\n",
            "Eval_AverageEpLen : 180.0\n",
            "Train_AverageReturn : 377.6263427734375\n",
            "Train_StdReturn : 64.54327392578125\n",
            "Train_MaxReturn : 511.0386657714844\n",
            "Train_MinReturn : 300.8871154785156\n",
            "Train_AverageEpLen : 197.8181818181818\n",
            "Train_EnvstepsSoFar : 474374\n",
            "TimeSinceStart : 386.364759683609\n",
            "Training Loss : -0.019928567111492157\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 231 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2147])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 305.8194885253906\n",
            "Eval_StdReturn : 87.98689270019531\n",
            "Eval_MaxReturn : 386.7113037109375\n",
            "Eval_MinReturn : 183.489990234375\n",
            "Eval_AverageEpLen : 154.33333333333334\n",
            "Train_AverageReturn : 383.3643798828125\n",
            "Train_StdReturn : 62.19028091430664\n",
            "Train_MaxReturn : 496.55596923828125\n",
            "Train_MinReturn : 239.91622924804688\n",
            "Train_AverageEpLen : 195.1818181818182\n",
            "Train_EnvstepsSoFar : 476521\n",
            "TimeSinceStart : 388.05618381500244\n",
            "Training Loss : -0.0051470533944666386\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 232 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2118])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 327.9991455078125\n",
            "Eval_StdReturn : 2.5028457641601562\n",
            "Eval_MaxReturn : 331.34918212890625\n",
            "Eval_MinReturn : 325.33453369140625\n",
            "Eval_AverageEpLen : 163.33333333333334\n",
            "Train_AverageReturn : 378.0987548828125\n",
            "Train_StdReturn : 46.80592346191406\n",
            "Train_MaxReturn : 462.59368896484375\n",
            "Train_MinReturn : 318.510986328125\n",
            "Train_AverageEpLen : 192.54545454545453\n",
            "Train_EnvstepsSoFar : 478639\n",
            "TimeSinceStart : 389.74989104270935\n",
            "Training Loss : -0.04696880280971527\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 233 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2096])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 320.6763000488281\n",
            "Eval_StdReturn : 83.48822784423828\n",
            "Eval_MaxReturn : 396.8560791015625\n",
            "Eval_MinReturn : 204.46530151367188\n",
            "Eval_AverageEpLen : 170.66666666666666\n",
            "Train_AverageReturn : 376.63916015625\n",
            "Train_StdReturn : 24.773435592651367\n",
            "Train_MaxReturn : 420.531494140625\n",
            "Train_MinReturn : 346.982666015625\n",
            "Train_AverageEpLen : 190.54545454545453\n",
            "Train_EnvstepsSoFar : 480735\n",
            "TimeSinceStart : 391.41678190231323\n",
            "Training Loss : -0.02844291180372238\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 234 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2089])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 336.6610107421875\n",
            "Eval_StdReturn : 30.275331497192383\n",
            "Eval_MaxReturn : 379.4657287597656\n",
            "Eval_MinReturn : 314.41571044921875\n",
            "Eval_AverageEpLen : 165.33333333333334\n",
            "Train_AverageReturn : 339.4385681152344\n",
            "Train_StdReturn : 95.37238311767578\n",
            "Train_MaxReturn : 438.1418151855469\n",
            "Train_MinReturn : 82.45758056640625\n",
            "Train_AverageEpLen : 178.58333333333334\n",
            "Train_EnvstepsSoFar : 482878\n",
            "TimeSinceStart : 393.11226773262024\n",
            "Training Loss : 0.02526051737368107\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 235 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2032])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 379.82000732421875\n",
            "Eval_StdReturn : 39.79400634765625\n",
            "Eval_MaxReturn : 419.614013671875\n",
            "Eval_MinReturn : 340.0260009765625\n",
            "Eval_AverageEpLen : 204.0\n",
            "Train_AverageReturn : 375.7668762207031\n",
            "Train_StdReturn : 39.89226150512695\n",
            "Train_MaxReturn : 440.8644714355469\n",
            "Train_MinReturn : 314.142333984375\n",
            "Train_AverageEpLen : 184.72727272727272\n",
            "Train_EnvstepsSoFar : 484910\n",
            "TimeSinceStart : 394.6992259025574\n",
            "Training Loss : -0.04781355708837509\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 236 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2065])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 287.9429016113281\n",
            "Eval_StdReturn : 43.396949768066406\n",
            "Eval_MaxReturn : 333.0216064453125\n",
            "Eval_MinReturn : 229.33590698242188\n",
            "Eval_AverageEpLen : 153.0\n",
            "Train_AverageReturn : 344.0904541015625\n",
            "Train_StdReturn : 57.6512336730957\n",
            "Train_MaxReturn : 464.6299743652344\n",
            "Train_MinReturn : 215.3524627685547\n",
            "Train_AverageEpLen : 172.08333333333334\n",
            "Train_EnvstepsSoFar : 486975\n",
            "TimeSinceStart : 396.3072645664215\n",
            "Training Loss : -0.015336226671934128\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 237 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2075])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 370.6319274902344\n",
            "Eval_StdReturn : 49.295318603515625\n",
            "Eval_MaxReturn : 430.02862548828125\n",
            "Eval_MinReturn : 309.3255615234375\n",
            "Eval_AverageEpLen : 185.33333333333334\n",
            "Train_AverageReturn : 314.9604187011719\n",
            "Train_StdReturn : 87.91034698486328\n",
            "Train_MaxReturn : 464.6776123046875\n",
            "Train_MinReturn : 138.56626892089844\n",
            "Train_AverageEpLen : 159.6153846153846\n",
            "Train_EnvstepsSoFar : 489050\n",
            "TimeSinceStart : 398.01714420318604\n",
            "Training Loss : 0.001716693746857345\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 238 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2021])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 416.9627990722656\n",
            "Eval_StdReturn : 73.98779296875\n",
            "Eval_MaxReturn : 490.9505920410156\n",
            "Eval_MinReturn : 342.9750061035156\n",
            "Eval_AverageEpLen : 213.5\n",
            "Train_AverageReturn : 347.9700012207031\n",
            "Train_StdReturn : 79.79621124267578\n",
            "Train_MaxReturn : 466.3892517089844\n",
            "Train_MinReturn : 209.6558837890625\n",
            "Train_AverageEpLen : 182.08333333333334\n",
            "Train_EnvstepsSoFar : 491235\n",
            "TimeSinceStart : 399.7039496898651\n",
            "Training Loss : -0.008263654075562954\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 239 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2057])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 379.73193359375\n",
            "Eval_StdReturn : 40.271034240722656\n",
            "Eval_MaxReturn : 414.38287353515625\n",
            "Eval_MinReturn : 323.2641906738281\n",
            "Eval_AverageEpLen : 180.0\n",
            "Train_AverageReturn : 367.17529296875\n",
            "Train_StdReturn : 34.947994232177734\n",
            "Train_MaxReturn : 445.62548828125\n",
            "Train_MinReturn : 306.60882568359375\n",
            "Train_AverageEpLen : 182.16666666666666\n",
            "Train_EnvstepsSoFar : 493421\n",
            "TimeSinceStart : 401.43687987327576\n",
            "Training Loss : -0.014151015318930149\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 240 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2153])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 379.8625793457031\n",
            "Eval_StdReturn : 83.40357971191406\n",
            "Eval_MaxReturn : 489.33935546875\n",
            "Eval_MinReturn : 287.10626220703125\n",
            "Eval_AverageEpLen : 184.33333333333334\n",
            "Train_AverageReturn : 324.4951171875\n",
            "Train_StdReturn : 60.543277740478516\n",
            "Train_MaxReturn : 459.79644775390625\n",
            "Train_MinReturn : 211.928955078125\n",
            "Train_AverageEpLen : 153.78571428571428\n",
            "Train_EnvstepsSoFar : 495574\n",
            "TimeSinceStart : 403.16339802742004\n",
            "Training Loss : -0.039835408329963684\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 241 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 311.1226501464844\n",
            "Eval_StdReturn : 18.91253662109375\n",
            "Eval_MaxReturn : 337.69775390625\n",
            "Eval_MinReturn : 295.2180480957031\n",
            "Eval_AverageEpLen : 154.33333333333334\n",
            "Train_AverageReturn : 370.0888366699219\n",
            "Train_StdReturn : 88.02789306640625\n",
            "Train_MaxReturn : 593.6790161132812\n",
            "Train_MinReturn : 255.33074951171875\n",
            "Train_AverageEpLen : 184.25\n",
            "Train_EnvstepsSoFar : 497785\n",
            "TimeSinceStart : 404.9012711048126\n",
            "Training Loss : 0.023782113566994667\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 242 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2075])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 310.6111755371094\n",
            "Eval_StdReturn : 45.05856704711914\n",
            "Eval_MaxReturn : 357.83099365234375\n",
            "Eval_MinReturn : 249.94552612304688\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 320.3913269042969\n",
            "Train_StdReturn : 70.1235580444336\n",
            "Train_MaxReturn : 441.2583312988281\n",
            "Train_MinReturn : 113.45787811279297\n",
            "Train_AverageEpLen : 159.6153846153846\n",
            "Train_EnvstepsSoFar : 499860\n",
            "TimeSinceStart : 406.5490970611572\n",
            "Training Loss : -0.05116073414683342\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 243 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2007])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 280.7879638671875\n",
            "Eval_StdReturn : 129.83621215820312\n",
            "Eval_MaxReturn : 390.436767578125\n",
            "Eval_MinReturn : 98.41348266601562\n",
            "Eval_AverageEpLen : 140.33333333333334\n",
            "Train_AverageReturn : 332.6097106933594\n",
            "Train_StdReturn : 77.8873062133789\n",
            "Train_MaxReturn : 497.12445068359375\n",
            "Train_MinReturn : 166.13673400878906\n",
            "Train_AverageEpLen : 167.25\n",
            "Train_EnvstepsSoFar : 501867\n",
            "TimeSinceStart : 408.14420890808105\n",
            "Training Loss : 0.01783926971256733\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 244 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2045])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 455.77703857421875\n",
            "Eval_StdReturn : 127.08222961425781\n",
            "Eval_MaxReturn : 582.8592529296875\n",
            "Eval_MinReturn : 328.6947937011719\n",
            "Eval_AverageEpLen : 268.5\n",
            "Train_AverageReturn : 335.196044921875\n",
            "Train_StdReturn : 83.47419738769531\n",
            "Train_MaxReturn : 469.0557556152344\n",
            "Train_MinReturn : 138.95880126953125\n",
            "Train_AverageEpLen : 170.41666666666666\n",
            "Train_EnvstepsSoFar : 503912\n",
            "TimeSinceStart : 409.8162462711334\n",
            "Training Loss : -0.04805675894021988\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 245 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2057])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 313.0157775878906\n",
            "Eval_StdReturn : 44.277225494384766\n",
            "Eval_MaxReturn : 375.1042785644531\n",
            "Eval_MinReturn : 274.9378662109375\n",
            "Eval_AverageEpLen : 153.33333333333334\n",
            "Train_AverageReturn : 327.49652099609375\n",
            "Train_StdReturn : 46.49062728881836\n",
            "Train_MaxReturn : 404.733154296875\n",
            "Train_MinReturn : 235.7530975341797\n",
            "Train_AverageEpLen : 158.23076923076923\n",
            "Train_EnvstepsSoFar : 505969\n",
            "TimeSinceStart : 411.47090911865234\n",
            "Training Loss : -0.0707549899816513\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 246 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2002])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 324.1715087890625\n",
            "Eval_StdReturn : 46.308555603027344\n",
            "Eval_MaxReturn : 374.4320068359375\n",
            "Eval_MinReturn : 262.6800842285156\n",
            "Eval_AverageEpLen : 152.33333333333334\n",
            "Train_AverageReturn : 360.3316345214844\n",
            "Train_StdReturn : 109.95117950439453\n",
            "Train_MaxReturn : 590.8497314453125\n",
            "Train_MinReturn : 145.91091918945312\n",
            "Train_AverageEpLen : 180.75\n",
            "Train_EnvstepsSoFar : 508138\n",
            "TimeSinceStart : 413.2062654495239\n",
            "Training Loss : -0.019093919545412064\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 247 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 341.4557189941406\n",
            "Eval_StdReturn : 24.766225814819336\n",
            "Eval_MaxReturn : 375.87158203125\n",
            "Eval_MinReturn : 318.6165771484375\n",
            "Eval_AverageEpLen : 175.66666666666666\n",
            "Train_AverageReturn : 329.6171875\n",
            "Train_StdReturn : 59.23676300048828\n",
            "Train_MaxReturn : 385.0778503417969\n",
            "Train_MinReturn : 145.9744873046875\n",
            "Train_AverageEpLen : 157.69230769230768\n",
            "Train_EnvstepsSoFar : 510188\n",
            "TimeSinceStart : 414.8937475681305\n",
            "Training Loss : 0.019539380446076393\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 248 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2046])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 330.6770324707031\n",
            "Eval_StdReturn : 38.583919525146484\n",
            "Eval_MaxReturn : 358.7647705078125\n",
            "Eval_MinReturn : 276.119140625\n",
            "Eval_AverageEpLen : 152.0\n",
            "Train_AverageReturn : 350.62451171875\n",
            "Train_StdReturn : 45.510074615478516\n",
            "Train_MaxReturn : 428.24420166015625\n",
            "Train_MinReturn : 257.9540710449219\n",
            "Train_AverageEpLen : 170.5\n",
            "Train_EnvstepsSoFar : 512234\n",
            "TimeSinceStart : 416.5269727706909\n",
            "Training Loss : -0.008380151353776455\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 249 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2095])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 287.25048828125\n",
            "Eval_StdReturn : 117.98887634277344\n",
            "Eval_MaxReturn : 384.21392822265625\n",
            "Eval_MinReturn : 121.16505432128906\n",
            "Eval_AverageEpLen : 135.0\n",
            "Train_AverageReturn : 353.8862609863281\n",
            "Train_StdReturn : 25.59898567199707\n",
            "Train_MaxReturn : 407.5596618652344\n",
            "Train_MinReturn : 302.9208679199219\n",
            "Train_AverageEpLen : 174.58333333333334\n",
            "Train_EnvstepsSoFar : 514329\n",
            "TimeSinceStart : 418.18062710762024\n",
            "Training Loss : -0.032446254044771194\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 250 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2063])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 373.9544372558594\n",
            "Eval_StdReturn : 39.623809814453125\n",
            "Eval_MaxReturn : 429.0148620605469\n",
            "Eval_MinReturn : 337.4058532714844\n",
            "Eval_AverageEpLen : 176.33333333333334\n",
            "Train_AverageReturn : 353.07568359375\n",
            "Train_StdReturn : 59.192325592041016\n",
            "Train_MaxReturn : 449.72161865234375\n",
            "Train_MinReturn : 253.45523071289062\n",
            "Train_AverageEpLen : 171.91666666666666\n",
            "Train_EnvstepsSoFar : 516392\n",
            "TimeSinceStart : 419.874418258667\n",
            "Training Loss : 0.006451417692005634\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 251 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2002])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 300.3046569824219\n",
            "Eval_StdReturn : 26.955881118774414\n",
            "Eval_MaxReturn : 319.8233642578125\n",
            "Eval_MinReturn : 262.1869812011719\n",
            "Eval_AverageEpLen : 141.66666666666666\n",
            "Train_AverageReturn : 340.71380615234375\n",
            "Train_StdReturn : 85.31645202636719\n",
            "Train_MaxReturn : 514.943603515625\n",
            "Train_MinReturn : 160.61468505859375\n",
            "Train_AverageEpLen : 166.83333333333334\n",
            "Train_EnvstepsSoFar : 518394\n",
            "TimeSinceStart : 421.488685131073\n",
            "Training Loss : 0.036205507814884186\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 252 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2061])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 363.8240661621094\n",
            "Eval_StdReturn : 40.45454788208008\n",
            "Eval_MaxReturn : 420.75445556640625\n",
            "Eval_MinReturn : 330.45440673828125\n",
            "Eval_AverageEpLen : 159.33333333333334\n",
            "Train_AverageReturn : 356.1747131347656\n",
            "Train_StdReturn : 34.370540618896484\n",
            "Train_MaxReturn : 421.32391357421875\n",
            "Train_MinReturn : 300.1379699707031\n",
            "Train_AverageEpLen : 171.75\n",
            "Train_EnvstepsSoFar : 520455\n",
            "TimeSinceStart : 423.13019704818726\n",
            "Training Loss : -0.05831662565469742\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 253 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2008])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 332.0267639160156\n",
            "Eval_StdReturn : 32.519222259521484\n",
            "Eval_MaxReturn : 371.6018981933594\n",
            "Eval_MinReturn : 291.95111083984375\n",
            "Eval_AverageEpLen : 156.33333333333334\n",
            "Train_AverageReturn : 318.6122741699219\n",
            "Train_StdReturn : 69.3383560180664\n",
            "Train_MaxReturn : 443.3139953613281\n",
            "Train_MinReturn : 209.51202392578125\n",
            "Train_AverageEpLen : 154.46153846153845\n",
            "Train_EnvstepsSoFar : 522463\n",
            "TimeSinceStart : 424.75224471092224\n",
            "Training Loss : -0.040532518178224564\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 254 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2015])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 354.580810546875\n",
            "Eval_StdReturn : 32.90411376953125\n",
            "Eval_MaxReturn : 393.8797607421875\n",
            "Eval_MinReturn : 313.35089111328125\n",
            "Eval_AverageEpLen : 168.33333333333334\n",
            "Train_AverageReturn : 324.0994873046875\n",
            "Train_StdReturn : 43.447235107421875\n",
            "Train_MaxReturn : 387.64752197265625\n",
            "Train_MinReturn : 228.11160278320312\n",
            "Train_AverageEpLen : 155.0\n",
            "Train_EnvstepsSoFar : 524478\n",
            "TimeSinceStart : 426.38049721717834\n",
            "Training Loss : 0.047593116760253906\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 255 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2019])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 260.4180908203125\n",
            "Eval_StdReturn : 73.28903198242188\n",
            "Eval_MaxReturn : 348.533447265625\n",
            "Eval_MinReturn : 151.96627807617188\n",
            "Eval_AverageEpLen : 127.75\n",
            "Train_AverageReturn : 351.06689453125\n",
            "Train_StdReturn : 86.26488494873047\n",
            "Train_MaxReturn : 567.509765625\n",
            "Train_MinReturn : 203.7243194580078\n",
            "Train_AverageEpLen : 168.25\n",
            "Train_EnvstepsSoFar : 526497\n",
            "TimeSinceStart : 428.0432004928589\n",
            "Training Loss : -0.0035725536290556192\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 256 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2030])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 388.1719055175781\n",
            "Eval_StdReturn : 22.82477569580078\n",
            "Eval_MaxReturn : 419.8943176269531\n",
            "Eval_MinReturn : 367.141357421875\n",
            "Eval_AverageEpLen : 186.66666666666666\n",
            "Train_AverageReturn : 303.3357238769531\n",
            "Train_StdReturn : 54.115150451660156\n",
            "Train_MaxReturn : 370.7618408203125\n",
            "Train_MinReturn : 178.14093017578125\n",
            "Train_AverageEpLen : 145.0\n",
            "Train_EnvstepsSoFar : 528527\n",
            "TimeSinceStart : 429.7291314601898\n",
            "Training Loss : 0.002508443547412753\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 257 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2083])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 358.2225341796875\n",
            "Eval_StdReturn : 11.18775749206543\n",
            "Eval_MaxReturn : 370.2806091308594\n",
            "Eval_MinReturn : 343.3221435546875\n",
            "Eval_AverageEpLen : 177.33333333333334\n",
            "Train_AverageReturn : 377.3048095703125\n",
            "Train_StdReturn : 43.974449157714844\n",
            "Train_MaxReturn : 480.4700622558594\n",
            "Train_MinReturn : 324.62933349609375\n",
            "Train_AverageEpLen : 187.91666666666666\n",
            "Train_EnvstepsSoFar : 530782\n",
            "TimeSinceStart : 431.523384809494\n",
            "Training Loss : -0.032699909061193466\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 258 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2090])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 418.5160827636719\n",
            "Eval_StdReturn : 42.56204605102539\n",
            "Eval_MaxReturn : 478.2415771484375\n",
            "Eval_MinReturn : 382.17724609375\n",
            "Eval_AverageEpLen : 204.66666666666666\n",
            "Train_AverageReturn : 330.859130859375\n",
            "Train_StdReturn : 74.38140106201172\n",
            "Train_MaxReturn : 432.73553466796875\n",
            "Train_MinReturn : 122.49822998046875\n",
            "Train_AverageEpLen : 149.28571428571428\n",
            "Train_EnvstepsSoFar : 532872\n",
            "TimeSinceStart : 433.2714195251465\n",
            "Training Loss : 0.03061322681605816\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 259 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2012])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 343.0287170410156\n",
            "Eval_StdReturn : 54.53616714477539\n",
            "Eval_MaxReturn : 390.59283447265625\n",
            "Eval_MinReturn : 266.6678466796875\n",
            "Eval_AverageEpLen : 166.66666666666666\n",
            "Train_AverageReturn : 346.588623046875\n",
            "Train_StdReturn : 74.04248046875\n",
            "Train_MaxReturn : 478.0384521484375\n",
            "Train_MinReturn : 205.81602478027344\n",
            "Train_AverageEpLen : 167.66666666666666\n",
            "Train_EnvstepsSoFar : 534884\n",
            "TimeSinceStart : 434.9055063724518\n",
            "Training Loss : -0.01683938503265381\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 260 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2048])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 365.861083984375\n",
            "Eval_StdReturn : 18.28233528137207\n",
            "Eval_MaxReturn : 388.3597412109375\n",
            "Eval_MinReturn : 343.57891845703125\n",
            "Eval_AverageEpLen : 180.66666666666666\n",
            "Train_AverageReturn : 350.59423828125\n",
            "Train_StdReturn : 93.76338195800781\n",
            "Train_MaxReturn : 495.5975341796875\n",
            "Train_MinReturn : 137.12112426757812\n",
            "Train_AverageEpLen : 170.66666666666666\n",
            "Train_EnvstepsSoFar : 536932\n",
            "TimeSinceStart : 436.5872337818146\n",
            "Training Loss : 0.032137177884578705\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 261 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2130])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 338.3482360839844\n",
            "Eval_StdReturn : 32.7816162109375\n",
            "Eval_MaxReturn : 369.4752197265625\n",
            "Eval_MinReturn : 293.031005859375\n",
            "Eval_AverageEpLen : 164.33333333333334\n",
            "Train_AverageReturn : 344.9558410644531\n",
            "Train_StdReturn : 53.77663040161133\n",
            "Train_MaxReturn : 428.0589599609375\n",
            "Train_MinReturn : 226.018310546875\n",
            "Train_AverageEpLen : 163.84615384615384\n",
            "Train_EnvstepsSoFar : 539062\n",
            "TimeSinceStart : 438.3040089607239\n",
            "Training Loss : 0.042831502854824066\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 262 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2091])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 386.2724609375\n",
            "Eval_StdReturn : 35.55073165893555\n",
            "Eval_MaxReturn : 430.7444152832031\n",
            "Eval_MinReturn : 343.72723388671875\n",
            "Eval_AverageEpLen : 173.33333333333334\n",
            "Train_AverageReturn : 319.2388610839844\n",
            "Train_StdReturn : 97.05406951904297\n",
            "Train_MaxReturn : 530.0777587890625\n",
            "Train_MinReturn : 119.25944519042969\n",
            "Train_AverageEpLen : 154.28571428571428\n",
            "Train_EnvstepsSoFar : 541222\n",
            "TimeSinceStart : 440.0641644001007\n",
            "Training Loss : 0.023400017991662025\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 263 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2019])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 370.27490234375\n",
            "Eval_StdReturn : 18.344301223754883\n",
            "Eval_MaxReturn : 389.5263671875\n",
            "Eval_MinReturn : 345.5890808105469\n",
            "Eval_AverageEpLen : 178.33333333333334\n",
            "Train_AverageReturn : 341.9288330078125\n",
            "Train_StdReturn : 86.29425811767578\n",
            "Train_MaxReturn : 414.36688232421875\n",
            "Train_MinReturn : 141.52923583984375\n",
            "Train_AverageEpLen : 168.25\n",
            "Train_EnvstepsSoFar : 543241\n",
            "TimeSinceStart : 441.7161648273468\n",
            "Training Loss : 0.016553469002246857\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 264 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2125])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 452.4986267089844\n",
            "Eval_StdReturn : 100.72348022460938\n",
            "Eval_MaxReturn : 553.2221069335938\n",
            "Eval_MinReturn : 351.775146484375\n",
            "Eval_AverageEpLen : 218.5\n",
            "Train_AverageReturn : 333.517578125\n",
            "Train_StdReturn : 99.76774597167969\n",
            "Train_MaxReturn : 550.1473999023438\n",
            "Train_MinReturn : 114.44927978515625\n",
            "Train_AverageEpLen : 163.46153846153845\n",
            "Train_EnvstepsSoFar : 545366\n",
            "TimeSinceStart : 443.37207102775574\n",
            "Training Loss : 0.0301830992102623\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 265 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2039])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 345.0897521972656\n",
            "Eval_StdReturn : 12.933658599853516\n",
            "Eval_MaxReturn : 362.78997802734375\n",
            "Eval_MinReturn : 332.2464599609375\n",
            "Eval_AverageEpLen : 156.66666666666666\n",
            "Train_AverageReturn : 390.6480407714844\n",
            "Train_StdReturn : 80.31626892089844\n",
            "Train_MaxReturn : 557.0204467773438\n",
            "Train_MinReturn : 276.4291687011719\n",
            "Train_AverageEpLen : 185.36363636363637\n",
            "Train_EnvstepsSoFar : 547405\n",
            "TimeSinceStart : 445.04181718826294\n",
            "Training Loss : 0.0033594551496207714\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 266 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2079])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 432.04949951171875\n",
            "Eval_StdReturn : 281.96636962890625\n",
            "Eval_MaxReturn : 714.015869140625\n",
            "Eval_MinReturn : 150.0831298828125\n",
            "Eval_AverageEpLen : 225.0\n",
            "Train_AverageReturn : 376.861083984375\n",
            "Train_StdReturn : 106.74687194824219\n",
            "Train_MaxReturn : 620.0982055664062\n",
            "Train_MinReturn : 198.08096313476562\n",
            "Train_AverageEpLen : 173.25\n",
            "Train_EnvstepsSoFar : 549484\n",
            "TimeSinceStart : 446.7151756286621\n",
            "Training Loss : -0.006308166775852442\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 267 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2106])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 264.3161926269531\n",
            "Eval_StdReturn : 71.28773498535156\n",
            "Eval_MaxReturn : 364.1018371582031\n",
            "Eval_MinReturn : 201.97235107421875\n",
            "Eval_AverageEpLen : 138.33333333333334\n",
            "Train_AverageReturn : 379.37890625\n",
            "Train_StdReturn : 69.06338500976562\n",
            "Train_MaxReturn : 539.325439453125\n",
            "Train_MinReturn : 262.8867492675781\n",
            "Train_AverageEpLen : 188.5\n",
            "Train_EnvstepsSoFar : 551746\n",
            "TimeSinceStart : 448.46841979026794\n",
            "Training Loss : 0.00709051638841629\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 268 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2074])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 352.4517517089844\n",
            "Eval_StdReturn : 32.548030853271484\n",
            "Eval_MaxReturn : 379.64459228515625\n",
            "Eval_MinReturn : 306.69207763671875\n",
            "Eval_AverageEpLen : 154.66666666666666\n",
            "Train_AverageReturn : 367.9296569824219\n",
            "Train_StdReturn : 69.43124389648438\n",
            "Train_MaxReturn : 471.1553955078125\n",
            "Train_MinReturn : 207.62120056152344\n",
            "Train_AverageEpLen : 181.66666666666666\n",
            "Train_EnvstepsSoFar : 553926\n",
            "TimeSinceStart : 450.18952441215515\n",
            "Training Loss : -0.026112917810678482\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 269 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 289.9895935058594\n",
            "Eval_StdReturn : 178.12762451171875\n",
            "Eval_MaxReturn : 539.350830078125\n",
            "Eval_MinReturn : 134.35093688964844\n",
            "Eval_AverageEpLen : 137.66666666666666\n",
            "Train_AverageReturn : 400.6712951660156\n",
            "Train_StdReturn : 100.38845825195312\n",
            "Train_MaxReturn : 563.3499755859375\n",
            "Train_MinReturn : 171.37930297851562\n",
            "Train_AverageEpLen : 186.36363636363637\n",
            "Train_EnvstepsSoFar : 555976\n",
            "TimeSinceStart : 451.74685311317444\n",
            "Training Loss : -0.018007509410381317\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 270 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2104])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 321.3073425292969\n",
            "Eval_StdReturn : 168.91567993164062\n",
            "Eval_MaxReturn : 481.6435546875\n",
            "Eval_MinReturn : 87.78348541259766\n",
            "Eval_AverageEpLen : 139.66666666666666\n",
            "Train_AverageReturn : 385.3469543457031\n",
            "Train_StdReturn : 111.21196746826172\n",
            "Train_MaxReturn : 574.84814453125\n",
            "Train_MinReturn : 145.95669555664062\n",
            "Train_AverageEpLen : 191.27272727272728\n",
            "Train_EnvstepsSoFar : 558080\n",
            "TimeSinceStart : 453.38472628593445\n",
            "Training Loss : 0.02391122281551361\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 271 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2054])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 310.4937744140625\n",
            "Eval_StdReturn : 137.8291015625\n",
            "Eval_MaxReturn : 456.9705505371094\n",
            "Eval_MinReturn : 125.88343811035156\n",
            "Eval_AverageEpLen : 141.66666666666666\n",
            "Train_AverageReturn : 355.977294921875\n",
            "Train_StdReturn : 70.40162658691406\n",
            "Train_MaxReturn : 463.83441162109375\n",
            "Train_MinReturn : 243.93344116210938\n",
            "Train_AverageEpLen : 171.16666666666666\n",
            "Train_EnvstepsSoFar : 560134\n",
            "TimeSinceStart : 454.9924557209015\n",
            "Training Loss : -0.030760232359170914\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 272 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2094])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 311.1517639160156\n",
            "Eval_StdReturn : 49.330665588378906\n",
            "Eval_MaxReturn : 380.90960693359375\n",
            "Eval_MinReturn : 275.46392822265625\n",
            "Eval_AverageEpLen : 134.66666666666666\n",
            "Train_AverageReturn : 335.48028564453125\n",
            "Train_StdReturn : 137.68336486816406\n",
            "Train_MaxReturn : 671.8299560546875\n",
            "Train_MinReturn : 114.93843841552734\n",
            "Train_AverageEpLen : 161.07692307692307\n",
            "Train_EnvstepsSoFar : 562228\n",
            "TimeSinceStart : 456.59782123565674\n",
            "Training Loss : 0.020360389724373817\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 273 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2085])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 300.0083923339844\n",
            "Eval_StdReturn : 71.14030456542969\n",
            "Eval_MaxReturn : 377.42474365234375\n",
            "Eval_MinReturn : 205.6544952392578\n",
            "Eval_AverageEpLen : 146.0\n",
            "Train_AverageReturn : 376.0424499511719\n",
            "Train_StdReturn : 160.9065399169922\n",
            "Train_MaxReturn : 641.2039794921875\n",
            "Train_MinReturn : 138.70639038085938\n",
            "Train_AverageEpLen : 173.75\n",
            "Train_EnvstepsSoFar : 564313\n",
            "TimeSinceStart : 458.2614052295685\n",
            "Training Loss : -0.037528183311223984\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 274 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2043])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 307.4957580566406\n",
            "Eval_StdReturn : 119.47158813476562\n",
            "Eval_MaxReturn : 457.96002197265625\n",
            "Eval_MinReturn : 165.7010955810547\n",
            "Eval_AverageEpLen : 142.33333333333334\n",
            "Train_AverageReturn : 325.2086181640625\n",
            "Train_StdReturn : 108.23402404785156\n",
            "Train_MaxReturn : 473.4375\n",
            "Train_MinReturn : 127.8144760131836\n",
            "Train_AverageEpLen : 157.15384615384616\n",
            "Train_EnvstepsSoFar : 566356\n",
            "TimeSinceStart : 459.85032320022583\n",
            "Training Loss : 0.01503668911755085\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 275 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2106])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 378.3707580566406\n",
            "Eval_StdReturn : 158.90499877929688\n",
            "Eval_MaxReturn : 537.2757568359375\n",
            "Eval_MinReturn : 219.4657745361328\n",
            "Eval_AverageEpLen : 204.0\n",
            "Train_AverageReturn : 296.5604553222656\n",
            "Train_StdReturn : 106.293701171875\n",
            "Train_MaxReturn : 528.6229248046875\n",
            "Train_MinReturn : 110.9499282836914\n",
            "Train_AverageEpLen : 150.42857142857142\n",
            "Train_EnvstepsSoFar : 568462\n",
            "TimeSinceStart : 461.4728398323059\n",
            "Training Loss : 0.006989376153796911\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 276 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2015])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 440.6309814453125\n",
            "Eval_StdReturn : 28.921218872070312\n",
            "Eval_MaxReturn : 469.5522155761719\n",
            "Eval_MinReturn : 411.70977783203125\n",
            "Eval_AverageEpLen : 215.5\n",
            "Train_AverageReturn : 369.5650939941406\n",
            "Train_StdReturn : 142.21273803710938\n",
            "Train_MaxReturn : 634.6730346679688\n",
            "Train_MinReturn : 78.63494873046875\n",
            "Train_AverageEpLen : 165.84615384615384\n",
            "Train_EnvstepsSoFar : 570618\n",
            "TimeSinceStart : 463.1407661437988\n",
            "Training Loss : -0.03443704545497894\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 277 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2118])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 412.8146057128906\n",
            "Eval_StdReturn : 72.73039245605469\n",
            "Eval_MaxReturn : 505.76043701171875\n",
            "Eval_MinReturn : 328.1923828125\n",
            "Eval_AverageEpLen : 192.66666666666666\n",
            "Train_AverageReturn : 440.0010681152344\n",
            "Train_StdReturn : 136.74607849121094\n",
            "Train_MaxReturn : 575.9027099609375\n",
            "Train_MinReturn : 110.98052978515625\n",
            "Train_AverageEpLen : 211.8\n",
            "Train_EnvstepsSoFar : 572736\n",
            "TimeSinceStart : 464.8500657081604\n",
            "Training Loss : -0.057398829609155655\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 278 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2042])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 300.3676452636719\n",
            "Eval_StdReturn : 87.21922302246094\n",
            "Eval_MaxReturn : 371.7663269042969\n",
            "Eval_MinReturn : 177.562255859375\n",
            "Eval_AverageEpLen : 153.33333333333334\n",
            "Train_AverageReturn : 353.8403015136719\n",
            "Train_StdReturn : 105.77912139892578\n",
            "Train_MaxReturn : 525.4010009765625\n",
            "Train_MinReturn : 154.53968811035156\n",
            "Train_AverageEpLen : 170.16666666666666\n",
            "Train_EnvstepsSoFar : 574778\n",
            "TimeSinceStart : 466.44950914382935\n",
            "Training Loss : 0.01662459969520569\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 279 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2115])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 369.8785095214844\n",
            "Eval_StdReturn : 172.32882690429688\n",
            "Eval_MaxReturn : 547.5551147460938\n",
            "Eval_MinReturn : 136.57876586914062\n",
            "Eval_AverageEpLen : 172.0\n",
            "Train_AverageReturn : 354.9634704589844\n",
            "Train_StdReturn : 139.24392700195312\n",
            "Train_MaxReturn : 636.9638671875\n",
            "Train_MinReturn : 96.72313690185547\n",
            "Train_AverageEpLen : 176.25\n",
            "Train_EnvstepsSoFar : 576893\n",
            "TimeSinceStart : 468.1312532424927\n",
            "Training Loss : -0.0069487569853663445\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 280 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2125])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 453.02349853515625\n",
            "Eval_StdReturn : 45.1478271484375\n",
            "Eval_MaxReturn : 498.17132568359375\n",
            "Eval_MinReturn : 407.87567138671875\n",
            "Eval_AverageEpLen : 216.0\n",
            "Train_AverageReturn : 341.6494445800781\n",
            "Train_StdReturn : 103.82272338867188\n",
            "Train_MaxReturn : 531.8006591796875\n",
            "Train_MinReturn : 164.4492950439453\n",
            "Train_AverageEpLen : 163.46153846153845\n",
            "Train_EnvstepsSoFar : 579018\n",
            "TimeSinceStart : 469.7719235420227\n",
            "Training Loss : -0.020409079268574715\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 281 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2042])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 351.5246887207031\n",
            "Eval_StdReturn : 112.81757354736328\n",
            "Eval_MaxReturn : 492.32135009765625\n",
            "Eval_MinReturn : 216.1345672607422\n",
            "Eval_AverageEpLen : 167.66666666666666\n",
            "Train_AverageReturn : 352.1011657714844\n",
            "Train_StdReturn : 137.68496704101562\n",
            "Train_MaxReturn : 539.9216918945312\n",
            "Train_MinReturn : 114.9081039428711\n",
            "Train_AverageEpLen : 170.16666666666666\n",
            "Train_EnvstepsSoFar : 581060\n",
            "TimeSinceStart : 471.408132314682\n",
            "Training Loss : -0.034757450222969055\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 282 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2102])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 383.8842468261719\n",
            "Eval_StdReturn : 164.52374267578125\n",
            "Eval_MaxReturn : 525.19775390625\n",
            "Eval_MinReturn : 153.14950561523438\n",
            "Eval_AverageEpLen : 200.33333333333334\n",
            "Train_AverageReturn : 376.0207824707031\n",
            "Train_StdReturn : 194.78521728515625\n",
            "Train_MaxReturn : 896.7230224609375\n",
            "Train_MinReturn : 78.64727783203125\n",
            "Train_AverageEpLen : 175.16666666666666\n",
            "Train_EnvstepsSoFar : 583162\n",
            "TimeSinceStart : 473.14323139190674\n",
            "Training Loss : -0.0580715611577034\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 283 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2141])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 356.4157409667969\n",
            "Eval_StdReturn : 11.690627098083496\n",
            "Eval_MaxReturn : 367.28118896484375\n",
            "Eval_MinReturn : 340.19122314453125\n",
            "Eval_AverageEpLen : 155.66666666666666\n",
            "Train_AverageReturn : 376.83935546875\n",
            "Train_StdReturn : 103.05847930908203\n",
            "Train_MaxReturn : 572.5211181640625\n",
            "Train_MinReturn : 165.3283233642578\n",
            "Train_AverageEpLen : 178.41666666666666\n",
            "Train_EnvstepsSoFar : 585303\n",
            "TimeSinceStart : 474.8244740962982\n",
            "Training Loss : -0.02191304974257946\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 284 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2019])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 430.1623229980469\n",
            "Eval_StdReturn : 65.46552276611328\n",
            "Eval_MaxReturn : 516.1947021484375\n",
            "Eval_MinReturn : 357.5247802734375\n",
            "Eval_AverageEpLen : 182.0\n",
            "Train_AverageReturn : 344.8504638671875\n",
            "Train_StdReturn : 106.02166748046875\n",
            "Train_MaxReturn : 533.2103271484375\n",
            "Train_MinReturn : 194.3114776611328\n",
            "Train_AverageEpLen : 168.25\n",
            "Train_EnvstepsSoFar : 587322\n",
            "TimeSinceStart : 476.4884765148163\n",
            "Training Loss : 0.009747411124408245\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 285 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2001])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 469.34429931640625\n",
            "Eval_StdReturn : 23.639572143554688\n",
            "Eval_MaxReturn : 492.9838562011719\n",
            "Eval_MinReturn : 445.7047119140625\n",
            "Eval_AverageEpLen : 223.0\n",
            "Train_AverageReturn : 388.16143798828125\n",
            "Train_StdReturn : 100.2668685913086\n",
            "Train_MaxReturn : 540.1260986328125\n",
            "Train_MinReturn : 154.74343872070312\n",
            "Train_AverageEpLen : 181.9090909090909\n",
            "Train_EnvstepsSoFar : 589323\n",
            "TimeSinceStart : 478.06320548057556\n",
            "Training Loss : -0.022092407569289207\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 286 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2045])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 365.6476745605469\n",
            "Eval_StdReturn : 183.53456115722656\n",
            "Eval_MaxReturn : 549.1822509765625\n",
            "Eval_MinReturn : 182.1131134033203\n",
            "Eval_AverageEpLen : 210.5\n",
            "Train_AverageReturn : 384.39764404296875\n",
            "Train_StdReturn : 174.5673370361328\n",
            "Train_MaxReturn : 660.630859375\n",
            "Train_MinReturn : 102.88162994384766\n",
            "Train_AverageEpLen : 204.5\n",
            "Train_EnvstepsSoFar : 591368\n",
            "TimeSinceStart : 479.6608531475067\n",
            "Training Loss : -0.007385063450783491\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 287 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2125])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 324.57861328125\n",
            "Eval_StdReturn : 31.82371711730957\n",
            "Eval_MaxReturn : 368.70782470703125\n",
            "Eval_MinReturn : 294.86004638671875\n",
            "Eval_AverageEpLen : 161.33333333333334\n",
            "Train_AverageReturn : 444.6582946777344\n",
            "Train_StdReturn : 90.81713104248047\n",
            "Train_MaxReturn : 559.9030151367188\n",
            "Train_MinReturn : 288.12725830078125\n",
            "Train_AverageEpLen : 212.5\n",
            "Train_EnvstepsSoFar : 593493\n",
            "TimeSinceStart : 481.32213830947876\n",
            "Training Loss : -0.02299216389656067\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 288 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2018])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 294.9310607910156\n",
            "Eval_StdReturn : 163.8275146484375\n",
            "Eval_MaxReturn : 526.5433349609375\n",
            "Eval_MinReturn : 174.02566528320312\n",
            "Eval_AverageEpLen : 168.33333333333334\n",
            "Train_AverageReturn : 356.3323974609375\n",
            "Train_StdReturn : 136.44863891601562\n",
            "Train_MaxReturn : 509.81463623046875\n",
            "Train_MinReturn : 75.09895324707031\n",
            "Train_AverageEpLen : 168.16666666666666\n",
            "Train_EnvstepsSoFar : 595511\n",
            "TimeSinceStart : 482.9347550868988\n",
            "Training Loss : -0.06631217896938324\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 289 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2002])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 374.7842102050781\n",
            "Eval_StdReturn : 35.63451385498047\n",
            "Eval_MaxReturn : 425.17755126953125\n",
            "Eval_MinReturn : 349.2529296875\n",
            "Eval_AverageEpLen : 188.33333333333334\n",
            "Train_AverageReturn : 436.76800537109375\n",
            "Train_StdReturn : 86.07835388183594\n",
            "Train_MaxReturn : 562.1656494140625\n",
            "Train_MinReturn : 281.8027648925781\n",
            "Train_AverageEpLen : 200.2\n",
            "Train_EnvstepsSoFar : 597513\n",
            "TimeSinceStart : 484.56910848617554\n",
            "Training Loss : 0.0031057624146342278\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 290 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2094])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 392.8278503417969\n",
            "Eval_StdReturn : 49.858253479003906\n",
            "Eval_MaxReturn : 438.564697265625\n",
            "Eval_MinReturn : 323.4849853515625\n",
            "Eval_AverageEpLen : 177.33333333333334\n",
            "Train_AverageReturn : 378.310302734375\n",
            "Train_StdReturn : 147.999755859375\n",
            "Train_MaxReturn : 606.4241943359375\n",
            "Train_MinReturn : 129.27833557128906\n",
            "Train_AverageEpLen : 174.5\n",
            "Train_EnvstepsSoFar : 599607\n",
            "TimeSinceStart : 486.25282883644104\n",
            "Training Loss : -0.05281030386686325\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 291 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2062])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 431.7403564453125\n",
            "Eval_StdReturn : 169.7086181640625\n",
            "Eval_MaxReturn : 617.656982421875\n",
            "Eval_MinReturn : 207.33706665039062\n",
            "Eval_AverageEpLen : 186.33333333333334\n",
            "Train_AverageReturn : 380.1254577636719\n",
            "Train_StdReturn : 139.6750946044922\n",
            "Train_MaxReturn : 609.622314453125\n",
            "Train_MinReturn : 143.43792724609375\n",
            "Train_AverageEpLen : 187.45454545454547\n",
            "Train_EnvstepsSoFar : 601669\n",
            "TimeSinceStart : 487.95863938331604\n",
            "Training Loss : 0.05321631580591202\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 292 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2103])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 784.95654296875\n",
            "Eval_StdReturn : 0.0\n",
            "Eval_MaxReturn : 784.95654296875\n",
            "Eval_MinReturn : 784.95654296875\n",
            "Eval_AverageEpLen : 413.0\n",
            "Train_AverageReturn : 508.39703369140625\n",
            "Train_StdReturn : 144.22613525390625\n",
            "Train_MaxReturn : 821.9732055664062\n",
            "Train_MinReturn : 342.15521240234375\n",
            "Train_AverageEpLen : 252.22222222222223\n",
            "Train_EnvstepsSoFar : 603939\n",
            "TimeSinceStart : 489.64899921417236\n",
            "Training Loss : 0.02321949042379856\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 293 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2007])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 330.5331115722656\n",
            "Eval_StdReturn : 20.194622039794922\n",
            "Eval_MaxReturn : 359.0924377441406\n",
            "Eval_MinReturn : 316.16314697265625\n",
            "Eval_AverageEpLen : 159.0\n",
            "Train_AverageReturn : 352.6657409667969\n",
            "Train_StdReturn : 94.29234313964844\n",
            "Train_MaxReturn : 542.1654663085938\n",
            "Train_MinReturn : 215.33543395996094\n",
            "Train_AverageEpLen : 167.6153846153846\n",
            "Train_EnvstepsSoFar : 606118\n",
            "TimeSinceStart : 491.35321164131165\n",
            "Training Loss : -0.042194440960884094\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 294 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2098])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 420.7587890625\n",
            "Eval_StdReturn : 60.010536193847656\n",
            "Eval_MaxReturn : 502.6800842285156\n",
            "Eval_MinReturn : 360.59991455078125\n",
            "Eval_AverageEpLen : 203.66666666666666\n",
            "Train_AverageReturn : 361.3132629394531\n",
            "Train_StdReturn : 132.40745544433594\n",
            "Train_MaxReturn : 584.4578247070312\n",
            "Train_MinReturn : 112.94623565673828\n",
            "Train_AverageEpLen : 174.83333333333334\n",
            "Train_EnvstepsSoFar : 608216\n",
            "TimeSinceStart : 493.0817756652832\n",
            "Training Loss : 0.029035374522209167\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 295 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2062])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 379.4275817871094\n",
            "Eval_StdReturn : 20.019548416137695\n",
            "Eval_MaxReturn : 402.7164306640625\n",
            "Eval_MinReturn : 353.840576171875\n",
            "Eval_AverageEpLen : 171.0\n",
            "Train_AverageReturn : 390.3831787109375\n",
            "Train_StdReturn : 99.2451400756836\n",
            "Train_MaxReturn : 584.8980712890625\n",
            "Train_MinReturn : 200.72865295410156\n",
            "Train_AverageEpLen : 171.83333333333334\n",
            "Train_EnvstepsSoFar : 610278\n",
            "TimeSinceStart : 494.7365641593933\n",
            "Training Loss : 0.024830061942338943\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 296 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2155])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 471.66046142578125\n",
            "Eval_StdReturn : 88.20048522949219\n",
            "Eval_MaxReturn : 559.8609619140625\n",
            "Eval_MinReturn : 383.4599914550781\n",
            "Eval_AverageEpLen : 271.5\n",
            "Train_AverageReturn : 388.7218322753906\n",
            "Train_StdReturn : 89.99834442138672\n",
            "Train_MaxReturn : 574.0007934570312\n",
            "Train_MinReturn : 255.49734497070312\n",
            "Train_AverageEpLen : 179.58333333333334\n",
            "Train_EnvstepsSoFar : 612433\n",
            "TimeSinceStart : 496.4753768444061\n",
            "Training Loss : 0.026703400537371635\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 297 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2144])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 497.69903564453125\n",
            "Eval_StdReturn : 81.36993408203125\n",
            "Eval_MaxReturn : 579.0689697265625\n",
            "Eval_MinReturn : 416.3291015625\n",
            "Eval_AverageEpLen : 259.0\n",
            "Train_AverageReturn : 412.227294921875\n",
            "Train_StdReturn : 138.84860229492188\n",
            "Train_MaxReturn : 779.7930908203125\n",
            "Train_MinReturn : 269.04595947265625\n",
            "Train_AverageEpLen : 214.4\n",
            "Train_EnvstepsSoFar : 614577\n",
            "TimeSinceStart : 498.19405579566956\n",
            "Training Loss : 0.023397322744131088\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 298 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2066])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 459.2547607421875\n",
            "Eval_StdReturn : 28.95213508605957\n",
            "Eval_MaxReturn : 488.2069091796875\n",
            "Eval_MinReturn : 430.3026428222656\n",
            "Eval_AverageEpLen : 231.0\n",
            "Train_AverageReturn : 350.2261962890625\n",
            "Train_StdReturn : 73.60625457763672\n",
            "Train_MaxReturn : 505.5332336425781\n",
            "Train_MinReturn : 185.37359619140625\n",
            "Train_AverageEpLen : 170.23076923076923\n",
            "Train_EnvstepsSoFar : 616790\n",
            "TimeSinceStart : 499.8908941745758\n",
            "Training Loss : -0.01376839354634285\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 299 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2045])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 358.3788146972656\n",
            "Eval_StdReturn : 76.5188217163086\n",
            "Eval_MaxReturn : 458.1322937011719\n",
            "Eval_MinReturn : 272.1753845214844\n",
            "Eval_AverageEpLen : 179.0\n",
            "Train_AverageReturn : 438.52862548828125\n",
            "Train_StdReturn : 176.27247619628906\n",
            "Train_MaxReturn : 880.8048706054688\n",
            "Train_MinReturn : 268.2520446777344\n",
            "Train_AverageEpLen : 219.6\n",
            "Train_EnvstepsSoFar : 618986\n",
            "TimeSinceStart : 501.6493728160858\n",
            "Training Loss : -0.0015381727134808898\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python cs285/scripts/run_hw2.py \\\n",
        "--env_name Hopper-v2 --ep_len 1000 \\\n",
        "--discount 0.99 -n 300 -l 2 -s 32 -b 2000 -lr 0.001 \\\n",
        "--reward_to_go --nn_baseline --action_noise_std 0.5 --gae_lambda 0.95 \\\n",
        "--exp_name q5_b2000_r0.001_lambda95"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "PKALQAqn9xjC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b48c604-ec4d-46c7-957b-664e439ba9bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mLe flux de sortie a été tronqué et ne contient que les 5000 dernières lignes.\u001b[0m\n",
            "Train_AverageReturn : 224.15591430664062\n",
            "Train_StdReturn : 11.354201316833496\n",
            "Train_MaxReturn : 249.1650390625\n",
            "Train_MinReturn : 205.15843200683594\n",
            "Train_AverageEpLen : 104.25\n",
            "Train_EnvstepsSoFar : 261465\n",
            "TimeSinceStart : 221.42065286636353\n",
            "Training Loss : -0.0022252227645367384\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 128 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2049])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 241.89195251464844\n",
            "Eval_StdReturn : 23.25869369506836\n",
            "Eval_MaxReturn : 282.0006408691406\n",
            "Eval_MinReturn : 226.1431884765625\n",
            "Eval_AverageEpLen : 120.25\n",
            "Train_AverageReturn : 227.4958038330078\n",
            "Train_StdReturn : 13.66073226928711\n",
            "Train_MaxReturn : 268.2718811035156\n",
            "Train_MinReturn : 204.4717559814453\n",
            "Train_AverageEpLen : 107.84210526315789\n",
            "Train_EnvstepsSoFar : 263514\n",
            "TimeSinceStart : 223.069757938385\n",
            "Training Loss : 0.01858002133667469\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 129 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2090])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 241.54379272460938\n",
            "Eval_StdReturn : 19.541934967041016\n",
            "Eval_MaxReturn : 266.99090576171875\n",
            "Eval_MinReturn : 218.12908935546875\n",
            "Eval_AverageEpLen : 118.5\n",
            "Train_AverageReturn : 232.88641357421875\n",
            "Train_StdReturn : 29.55974006652832\n",
            "Train_MaxReturn : 282.8725891113281\n",
            "Train_MinReturn : 144.46141052246094\n",
            "Train_AverageEpLen : 116.11111111111111\n",
            "Train_EnvstepsSoFar : 265604\n",
            "TimeSinceStart : 224.76552438735962\n",
            "Training Loss : 0.02296694554388523\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 130 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2057])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 230.09817504882812\n",
            "Eval_StdReturn : 9.959752082824707\n",
            "Eval_MaxReturn : 242.321533203125\n",
            "Eval_MinReturn : 216.06375122070312\n",
            "Eval_AverageEpLen : 109.0\n",
            "Train_AverageReturn : 227.9989776611328\n",
            "Train_StdReturn : 12.404778480529785\n",
            "Train_MaxReturn : 253.24771118164062\n",
            "Train_MinReturn : 209.22645568847656\n",
            "Train_AverageEpLen : 108.26315789473684\n",
            "Train_EnvstepsSoFar : 267661\n",
            "TimeSinceStart : 226.35005593299866\n",
            "Training Loss : 0.0030652449931949377\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 131 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2012])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 238.76739501953125\n",
            "Eval_StdReturn : 3.260584592819214\n",
            "Eval_MaxReturn : 242.1506805419922\n",
            "Eval_MinReturn : 233.8087921142578\n",
            "Eval_AverageEpLen : 115.5\n",
            "Train_AverageReturn : 230.8251953125\n",
            "Train_StdReturn : 25.056161880493164\n",
            "Train_MaxReturn : 264.19439697265625\n",
            "Train_MinReturn : 151.6965789794922\n",
            "Train_AverageEpLen : 111.77777777777777\n",
            "Train_EnvstepsSoFar : 269673\n",
            "TimeSinceStart : 227.96511840820312\n",
            "Training Loss : 0.014022902585566044\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 132 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2077])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 219.60623168945312\n",
            "Eval_StdReturn : 8.126769065856934\n",
            "Eval_MaxReturn : 229.19168090820312\n",
            "Eval_MinReturn : 207.51785278320312\n",
            "Eval_AverageEpLen : 102.75\n",
            "Train_AverageReturn : 228.02639770507812\n",
            "Train_StdReturn : 14.510618209838867\n",
            "Train_MaxReturn : 259.3376770019531\n",
            "Train_MinReturn : 197.54055786132812\n",
            "Train_AverageEpLen : 109.3157894736842\n",
            "Train_EnvstepsSoFar : 271750\n",
            "TimeSinceStart : 229.59931993484497\n",
            "Training Loss : 0.022480018436908722\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 133 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2101])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 237.56289672851562\n",
            "Eval_StdReturn : 12.763935089111328\n",
            "Eval_MaxReturn : 256.499267578125\n",
            "Eval_MinReturn : 224.43519592285156\n",
            "Eval_AverageEpLen : 113.75\n",
            "Train_AverageReturn : 226.61898803710938\n",
            "Train_StdReturn : 12.560606002807617\n",
            "Train_MaxReturn : 252.65542602539062\n",
            "Train_MinReturn : 199.10977172851562\n",
            "Train_AverageEpLen : 105.05\n",
            "Train_EnvstepsSoFar : 273851\n",
            "TimeSinceStart : 231.26112604141235\n",
            "Training Loss : -0.08407223969697952\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 134 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2046])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 231.90631103515625\n",
            "Eval_StdReturn : 14.012040138244629\n",
            "Eval_MaxReturn : 245.193603515625\n",
            "Eval_MinReturn : 210.3373260498047\n",
            "Eval_AverageEpLen : 110.75\n",
            "Train_AverageReturn : 229.1920928955078\n",
            "Train_StdReturn : 18.101747512817383\n",
            "Train_MaxReturn : 272.14447021484375\n",
            "Train_MinReturn : 186.43101501464844\n",
            "Train_AverageEpLen : 107.6842105263158\n",
            "Train_EnvstepsSoFar : 275897\n",
            "TimeSinceStart : 232.87665843963623\n",
            "Training Loss : 0.010536693036556244\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 135 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 209.33229064941406\n",
            "Eval_StdReturn : 87.43653869628906\n",
            "Eval_MaxReturn : 317.7330322265625\n",
            "Eval_MinReturn : 73.50359344482422\n",
            "Eval_AverageEpLen : 117.5\n",
            "Train_AverageReturn : 214.6951141357422\n",
            "Train_StdReturn : 52.178775787353516\n",
            "Train_MaxReturn : 248.97174072265625\n",
            "Train_MinReturn : 46.665863037109375\n",
            "Train_AverageEpLen : 102.5\n",
            "Train_EnvstepsSoFar : 277947\n",
            "TimeSinceStart : 234.53387427330017\n",
            "Training Loss : 0.01292768307030201\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 136 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2038])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 232.4613037109375\n",
            "Eval_StdReturn : 22.535083770751953\n",
            "Eval_MaxReturn : 260.50018310546875\n",
            "Eval_MinReturn : 200.56280517578125\n",
            "Eval_AverageEpLen : 111.75\n",
            "Train_AverageReturn : 218.4158477783203\n",
            "Train_StdReturn : 43.98868942260742\n",
            "Train_MaxReturn : 250.10232543945312\n",
            "Train_MinReturn : 32.12544250488281\n",
            "Train_AverageEpLen : 101.9\n",
            "Train_EnvstepsSoFar : 279985\n",
            "TimeSinceStart : 236.15308928489685\n",
            "Training Loss : -0.016683407127857208\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 137 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2071])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 211.24227905273438\n",
            "Eval_StdReturn : 24.306379318237305\n",
            "Eval_MaxReturn : 233.73680114746094\n",
            "Eval_MinReturn : 174.26556396484375\n",
            "Eval_AverageEpLen : 100.0\n",
            "Train_AverageReturn : 230.39024353027344\n",
            "Train_StdReturn : 12.404515266418457\n",
            "Train_MaxReturn : 254.59182739257812\n",
            "Train_MinReturn : 212.41592407226562\n",
            "Train_AverageEpLen : 109.0\n",
            "Train_EnvstepsSoFar : 282056\n",
            "TimeSinceStart : 237.84428811073303\n",
            "Training Loss : -0.019109666347503662\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 138 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2025])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 234.3366241455078\n",
            "Eval_StdReturn : 11.352643966674805\n",
            "Eval_MaxReturn : 253.37844848632812\n",
            "Eval_MinReturn : 223.4276580810547\n",
            "Eval_AverageEpLen : 110.5\n",
            "Train_AverageReturn : 234.68382263183594\n",
            "Train_StdReturn : 14.205283164978027\n",
            "Train_MaxReturn : 265.78155517578125\n",
            "Train_MinReturn : 212.71542358398438\n",
            "Train_AverageEpLen : 112.36842105263158\n",
            "Train_EnvstepsSoFar : 284191\n",
            "TimeSinceStart : 239.54137444496155\n",
            "Training Loss : -0.00029750351677648723\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 139 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 230.84478759765625\n",
            "Eval_StdReturn : 6.190742015838623\n",
            "Eval_MaxReturn : 240.96461486816406\n",
            "Eval_MinReturn : 225.64913940429688\n",
            "Eval_AverageEpLen : 104.25\n",
            "Train_AverageReturn : 234.64306640625\n",
            "Train_StdReturn : 16.353139877319336\n",
            "Train_MaxReturn : 267.3810729980469\n",
            "Train_MinReturn : 206.1754608154297\n",
            "Train_AverageEpLen : 113.88888888888889\n",
            "Train_EnvstepsSoFar : 286241\n",
            "TimeSinceStart : 241.17122507095337\n",
            "Training Loss : 0.04701285809278488\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 140 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2006])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 237.544921875\n",
            "Eval_StdReturn : 9.444390296936035\n",
            "Eval_MaxReturn : 247.19236755371094\n",
            "Eval_MinReturn : 225.64013671875\n",
            "Eval_AverageEpLen : 109.25\n",
            "Train_AverageReturn : 225.6026611328125\n",
            "Train_StdReturn : 42.208370208740234\n",
            "Train_MaxReturn : 277.4811096191406\n",
            "Train_MinReturn : 67.85614776611328\n",
            "Train_AverageEpLen : 111.44444444444444\n",
            "Train_EnvstepsSoFar : 288247\n",
            "TimeSinceStart : 242.78589487075806\n",
            "Training Loss : 0.0034750548657029867\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 141 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2002])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 246.08529663085938\n",
            "Eval_StdReturn : 27.256067276000977\n",
            "Eval_MaxReturn : 292.8941650390625\n",
            "Eval_MinReturn : 225.04116821289062\n",
            "Eval_AverageEpLen : 116.0\n",
            "Train_AverageReturn : 220.41819763183594\n",
            "Train_StdReturn : 24.072877883911133\n",
            "Train_MaxReturn : 257.5169677734375\n",
            "Train_MinReturn : 163.0746612548828\n",
            "Train_AverageEpLen : 105.36842105263158\n",
            "Train_EnvstepsSoFar : 290249\n",
            "TimeSinceStart : 245.4471139907837\n",
            "Training Loss : -0.058285191655159\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 142 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2015])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 244.33580017089844\n",
            "Eval_StdReturn : 10.841602325439453\n",
            "Eval_MaxReturn : 258.4449462890625\n",
            "Eval_MinReturn : 227.9788818359375\n",
            "Eval_AverageEpLen : 119.25\n",
            "Train_AverageReturn : 235.45404052734375\n",
            "Train_StdReturn : 11.571073532104492\n",
            "Train_MaxReturn : 263.26409912109375\n",
            "Train_MinReturn : 219.4907684326172\n",
            "Train_AverageEpLen : 111.94444444444444\n",
            "Train_EnvstepsSoFar : 292264\n",
            "TimeSinceStart : 248.01292371749878\n",
            "Training Loss : 0.0195155031979084\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 143 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2016])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 233.0414581298828\n",
            "Eval_StdReturn : 13.395166397094727\n",
            "Eval_MaxReturn : 255.4969024658203\n",
            "Eval_MinReturn : 220.24298095703125\n",
            "Eval_AverageEpLen : 105.5\n",
            "Train_AverageReturn : 227.3599090576172\n",
            "Train_StdReturn : 13.107396125793457\n",
            "Train_MaxReturn : 266.23175048828125\n",
            "Train_MinReturn : 198.883544921875\n",
            "Train_AverageEpLen : 106.10526315789474\n",
            "Train_EnvstepsSoFar : 294280\n",
            "TimeSinceStart : 251.3208713531494\n",
            "Training Loss : -0.07495567947626114\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 144 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2098])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 216.7476806640625\n",
            "Eval_StdReturn : 21.654584884643555\n",
            "Eval_MaxReturn : 237.4439697265625\n",
            "Eval_MinReturn : 180.71253967285156\n",
            "Eval_AverageEpLen : 106.25\n",
            "Train_AverageReturn : 230.9871826171875\n",
            "Train_StdReturn : 19.384506225585938\n",
            "Train_MaxReturn : 271.5419921875\n",
            "Train_MinReturn : 194.35568237304688\n",
            "Train_AverageEpLen : 110.42105263157895\n",
            "Train_EnvstepsSoFar : 296378\n",
            "TimeSinceStart : 252.99839115142822\n",
            "Training Loss : -0.0244313832372427\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 145 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2073])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 242.17247009277344\n",
            "Eval_StdReturn : 5.474605083465576\n",
            "Eval_MaxReturn : 248.83592224121094\n",
            "Eval_MinReturn : 233.89825439453125\n",
            "Eval_AverageEpLen : 117.0\n",
            "Train_AverageReturn : 226.0044708251953\n",
            "Train_StdReturn : 23.688941955566406\n",
            "Train_MaxReturn : 278.2259826660156\n",
            "Train_MinReturn : 161.43817138671875\n",
            "Train_AverageEpLen : 109.10526315789474\n",
            "Train_EnvstepsSoFar : 298451\n",
            "TimeSinceStart : 254.72263503074646\n",
            "Training Loss : -0.036939579993486404\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 146 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2027])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 240.42311096191406\n",
            "Eval_StdReturn : 13.373786926269531\n",
            "Eval_MaxReturn : 252.57969665527344\n",
            "Eval_MinReturn : 219.44964599609375\n",
            "Eval_AverageEpLen : 116.0\n",
            "Train_AverageReturn : 244.1736602783203\n",
            "Train_StdReturn : 22.12289047241211\n",
            "Train_MaxReturn : 292.56884765625\n",
            "Train_MinReturn : 205.22727966308594\n",
            "Train_AverageEpLen : 119.23529411764706\n",
            "Train_EnvstepsSoFar : 300478\n",
            "TimeSinceStart : 257.3527407646179\n",
            "Training Loss : 0.012011111713945866\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 147 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2038])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 233.8986358642578\n",
            "Eval_StdReturn : 6.337846755981445\n",
            "Eval_MaxReturn : 243.7176055908203\n",
            "Eval_MinReturn : 226.84107971191406\n",
            "Eval_AverageEpLen : 108.25\n",
            "Train_AverageReturn : 240.87075805664062\n",
            "Train_StdReturn : 24.01140594482422\n",
            "Train_MaxReturn : 302.4556884765625\n",
            "Train_MinReturn : 207.59112548828125\n",
            "Train_AverageEpLen : 119.88235294117646\n",
            "Train_EnvstepsSoFar : 302516\n",
            "TimeSinceStart : 260.04945135116577\n",
            "Training Loss : 0.024122970178723335\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 148 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2071])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 235.51763916015625\n",
            "Eval_StdReturn : 13.205025672912598\n",
            "Eval_MaxReturn : 255.72996520996094\n",
            "Eval_MinReturn : 220.34503173828125\n",
            "Eval_AverageEpLen : 109.5\n",
            "Train_AverageReturn : 231.50015258789062\n",
            "Train_StdReturn : 15.78339672088623\n",
            "Train_MaxReturn : 273.7896423339844\n",
            "Train_MinReturn : 195.14239501953125\n",
            "Train_AverageEpLen : 109.0\n",
            "Train_EnvstepsSoFar : 304587\n",
            "TimeSinceStart : 261.93468832969666\n",
            "Training Loss : -0.010292518883943558\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 149 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2014])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 234.80804443359375\n",
            "Eval_StdReturn : 18.592838287353516\n",
            "Eval_MaxReturn : 265.9140319824219\n",
            "Eval_MinReturn : 216.95944213867188\n",
            "Eval_AverageEpLen : 109.0\n",
            "Train_AverageReturn : 233.79356384277344\n",
            "Train_StdReturn : 21.539220809936523\n",
            "Train_MaxReturn : 297.82757568359375\n",
            "Train_MinReturn : 188.75588989257812\n",
            "Train_AverageEpLen : 111.88888888888889\n",
            "Train_EnvstepsSoFar : 306601\n",
            "TimeSinceStart : 264.84453868865967\n",
            "Training Loss : 0.025869037955999374\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 150 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2006])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 234.85049438476562\n",
            "Eval_StdReturn : 9.939579963684082\n",
            "Eval_MaxReturn : 251.61819458007812\n",
            "Eval_MinReturn : 226.03671264648438\n",
            "Eval_AverageEpLen : 109.0\n",
            "Train_AverageReturn : 234.253662109375\n",
            "Train_StdReturn : 19.3818302154541\n",
            "Train_MaxReturn : 303.66339111328125\n",
            "Train_MinReturn : 216.47512817382812\n",
            "Train_AverageEpLen : 111.44444444444444\n",
            "Train_EnvstepsSoFar : 308607\n",
            "TimeSinceStart : 267.26757860183716\n",
            "Training Loss : -0.02692083641886711\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 151 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2039])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 244.68817138671875\n",
            "Eval_StdReturn : 14.200798988342285\n",
            "Eval_MaxReturn : 267.5994873046875\n",
            "Eval_MinReturn : 228.90826416015625\n",
            "Eval_AverageEpLen : 117.25\n",
            "Train_AverageReturn : 229.98854064941406\n",
            "Train_StdReturn : 18.23556137084961\n",
            "Train_MaxReturn : 281.7470397949219\n",
            "Train_MinReturn : 186.758544921875\n",
            "Train_AverageEpLen : 107.3157894736842\n",
            "Train_EnvstepsSoFar : 310646\n",
            "TimeSinceStart : 268.8983242511749\n",
            "Training Loss : -0.04784189909696579\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 152 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2046])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 238.6868896484375\n",
            "Eval_StdReturn : 11.734431266784668\n",
            "Eval_MaxReturn : 252.9216766357422\n",
            "Eval_MinReturn : 220.30032348632812\n",
            "Eval_AverageEpLen : 110.5\n",
            "Train_AverageReturn : 234.1551055908203\n",
            "Train_StdReturn : 25.83500099182129\n",
            "Train_MaxReturn : 285.4247741699219\n",
            "Train_MinReturn : 149.327880859375\n",
            "Train_AverageEpLen : 113.66666666666667\n",
            "Train_EnvstepsSoFar : 312692\n",
            "TimeSinceStart : 270.6465184688568\n",
            "Training Loss : -0.0071487571112811565\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 153 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2082])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 235.16168212890625\n",
            "Eval_StdReturn : 19.985214233398438\n",
            "Eval_MaxReturn : 260.2586975097656\n",
            "Eval_MinReturn : 204.48468017578125\n",
            "Eval_AverageEpLen : 115.0\n",
            "Train_AverageReturn : 239.44918823242188\n",
            "Train_StdReturn : 19.00066566467285\n",
            "Train_MaxReturn : 280.6702880859375\n",
            "Train_MinReturn : 216.4313507080078\n",
            "Train_AverageEpLen : 115.66666666666667\n",
            "Train_EnvstepsSoFar : 314774\n",
            "TimeSinceStart : 272.32802081108093\n",
            "Training Loss : 0.01616174913942814\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 154 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2066])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 228.07894897460938\n",
            "Eval_StdReturn : 2.8040294647216797\n",
            "Eval_MaxReturn : 231.3804168701172\n",
            "Eval_MinReturn : 223.99234008789062\n",
            "Eval_AverageEpLen : 104.5\n",
            "Train_AverageReturn : 236.48008728027344\n",
            "Train_StdReturn : 21.271053314208984\n",
            "Train_MaxReturn : 291.81439208984375\n",
            "Train_MinReturn : 204.07064819335938\n",
            "Train_AverageEpLen : 114.77777777777777\n",
            "Train_EnvstepsSoFar : 316840\n",
            "TimeSinceStart : 273.97689414024353\n",
            "Training Loss : -0.005114552564918995\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 155 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2025])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 234.32443237304688\n",
            "Eval_StdReturn : 21.001569747924805\n",
            "Eval_MaxReturn : 261.53704833984375\n",
            "Eval_MinReturn : 207.86990356445312\n",
            "Eval_AverageEpLen : 108.75\n",
            "Train_AverageReturn : 237.9213104248047\n",
            "Train_StdReturn : 15.483477592468262\n",
            "Train_MaxReturn : 286.9257507324219\n",
            "Train_MinReturn : 218.49713134765625\n",
            "Train_AverageEpLen : 112.5\n",
            "Train_EnvstepsSoFar : 318865\n",
            "TimeSinceStart : 275.59663939476013\n",
            "Training Loss : 0.01576821319758892\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 156 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2048])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 269.1729736328125\n",
            "Eval_StdReturn : 38.93733215332031\n",
            "Eval_MaxReturn : 321.24169921875\n",
            "Eval_MinReturn : 227.62057495117188\n",
            "Eval_AverageEpLen : 141.33333333333334\n",
            "Train_AverageReturn : 234.66018676757812\n",
            "Train_StdReturn : 16.5886287689209\n",
            "Train_MaxReturn : 274.3477478027344\n",
            "Train_MinReturn : 209.9783935546875\n",
            "Train_AverageEpLen : 113.77777777777777\n",
            "Train_EnvstepsSoFar : 320913\n",
            "TimeSinceStart : 277.327942609787\n",
            "Training Loss : -0.04845724254846573\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 157 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2022])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 223.21548461914062\n",
            "Eval_StdReturn : 9.695647239685059\n",
            "Eval_MaxReturn : 238.52503967285156\n",
            "Eval_MinReturn : 213.56912231445312\n",
            "Eval_AverageEpLen : 107.25\n",
            "Train_AverageReturn : 238.05743408203125\n",
            "Train_StdReturn : 22.595842361450195\n",
            "Train_MaxReturn : 282.5887756347656\n",
            "Train_MinReturn : 205.67669677734375\n",
            "Train_AverageEpLen : 112.33333333333333\n",
            "Train_EnvstepsSoFar : 322935\n",
            "TimeSinceStart : 280.02459239959717\n",
            "Training Loss : 0.0049498677253723145\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 158 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2080])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 264.2936096191406\n",
            "Eval_StdReturn : 34.55119323730469\n",
            "Eval_MaxReturn : 301.1485595703125\n",
            "Eval_MinReturn : 218.08193969726562\n",
            "Eval_AverageEpLen : 139.66666666666666\n",
            "Train_AverageReturn : 238.62290954589844\n",
            "Train_StdReturn : 13.606682777404785\n",
            "Train_MaxReturn : 264.0430603027344\n",
            "Train_MinReturn : 220.24192810058594\n",
            "Train_AverageEpLen : 115.55555555555556\n",
            "Train_EnvstepsSoFar : 325015\n",
            "TimeSinceStart : 282.4077570438385\n",
            "Training Loss : -0.012486221268773079\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 159 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2088])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 227.24453735351562\n",
            "Eval_StdReturn : 10.998674392700195\n",
            "Eval_MaxReturn : 246.00399780273438\n",
            "Eval_MinReturn : 217.9422607421875\n",
            "Eval_AverageEpLen : 105.25\n",
            "Train_AverageReturn : 236.3218994140625\n",
            "Train_StdReturn : 15.404899597167969\n",
            "Train_MaxReturn : 271.9283447265625\n",
            "Train_MinReturn : 208.05838012695312\n",
            "Train_AverageEpLen : 109.89473684210526\n",
            "Train_EnvstepsSoFar : 327103\n",
            "TimeSinceStart : 284.0684506893158\n",
            "Training Loss : 0.004080853890627623\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 160 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2028])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 241.61927795410156\n",
            "Eval_StdReturn : 10.32292652130127\n",
            "Eval_MaxReturn : 254.5570526123047\n",
            "Eval_MinReturn : 227.49290466308594\n",
            "Eval_AverageEpLen : 117.5\n",
            "Train_AverageReturn : 227.92703247070312\n",
            "Train_StdReturn : 38.11703872680664\n",
            "Train_MaxReturn : 301.0931396484375\n",
            "Train_MinReturn : 121.21402740478516\n",
            "Train_AverageEpLen : 112.66666666666667\n",
            "Train_EnvstepsSoFar : 329131\n",
            "TimeSinceStart : 285.71460032463074\n",
            "Training Loss : 0.02240227721631527\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 161 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2022])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 235.14239501953125\n",
            "Eval_StdReturn : 10.154537200927734\n",
            "Eval_MaxReturn : 245.9928741455078\n",
            "Eval_MinReturn : 219.13372802734375\n",
            "Eval_AverageEpLen : 111.5\n",
            "Train_AverageReturn : 235.5979766845703\n",
            "Train_StdReturn : 26.176525115966797\n",
            "Train_MaxReturn : 307.1808166503906\n",
            "Train_MinReturn : 175.2954559326172\n",
            "Train_AverageEpLen : 112.33333333333333\n",
            "Train_EnvstepsSoFar : 331153\n",
            "TimeSinceStart : 287.33891344070435\n",
            "Training Loss : -0.04996659234166145\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 162 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2079])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 246.48187255859375\n",
            "Eval_StdReturn : 13.339177131652832\n",
            "Eval_MaxReturn : 267.54010009765625\n",
            "Eval_MinReturn : 230.64393615722656\n",
            "Eval_AverageEpLen : 116.5\n",
            "Train_AverageReturn : 228.88528442382812\n",
            "Train_StdReturn : 20.380590438842773\n",
            "Train_MaxReturn : 267.0737609863281\n",
            "Train_MinReturn : 167.5249481201172\n",
            "Train_AverageEpLen : 109.42105263157895\n",
            "Train_EnvstepsSoFar : 333232\n",
            "TimeSinceStart : 289.0173234939575\n",
            "Training Loss : -0.03792886063456535\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 163 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2027])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 213.0842742919922\n",
            "Eval_StdReturn : 57.07387924194336\n",
            "Eval_MaxReturn : 252.32781982421875\n",
            "Eval_MinReturn : 114.8009033203125\n",
            "Eval_AverageEpLen : 110.25\n",
            "Train_AverageReturn : 244.37539672851562\n",
            "Train_StdReturn : 23.9049129486084\n",
            "Train_MaxReturn : 307.4635009765625\n",
            "Train_MinReturn : 209.29934692382812\n",
            "Train_AverageEpLen : 119.23529411764706\n",
            "Train_EnvstepsSoFar : 335259\n",
            "TimeSinceStart : 291.51940751075745\n",
            "Training Loss : -0.02360169216990471\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 164 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2009])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 238.84657287597656\n",
            "Eval_StdReturn : 17.415903091430664\n",
            "Eval_MaxReturn : 266.3648986816406\n",
            "Eval_MinReturn : 220.37281799316406\n",
            "Eval_AverageEpLen : 112.25\n",
            "Train_AverageReturn : 240.9302978515625\n",
            "Train_StdReturn : 15.192380905151367\n",
            "Train_MaxReturn : 266.57623291015625\n",
            "Train_MinReturn : 214.910400390625\n",
            "Train_AverageEpLen : 118.17647058823529\n",
            "Train_EnvstepsSoFar : 337268\n",
            "TimeSinceStart : 293.14242696762085\n",
            "Training Loss : -0.00017711806867737323\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 165 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2079])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 229.06784057617188\n",
            "Eval_StdReturn : 7.333345890045166\n",
            "Eval_MaxReturn : 238.1671142578125\n",
            "Eval_MinReturn : 218.49356079101562\n",
            "Eval_AverageEpLen : 104.5\n",
            "Train_AverageReturn : 246.6630859375\n",
            "Train_StdReturn : 26.53638458251953\n",
            "Train_MaxReturn : 290.5000305175781\n",
            "Train_MinReturn : 163.915771484375\n",
            "Train_AverageEpLen : 122.29411764705883\n",
            "Train_EnvstepsSoFar : 339347\n",
            "TimeSinceStart : 294.85091733932495\n",
            "Training Loss : 0.03971489518880844\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 166 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2033])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 262.5680847167969\n",
            "Eval_StdReturn : 13.842040061950684\n",
            "Eval_MaxReturn : 282.10784912109375\n",
            "Eval_MinReturn : 251.7725372314453\n",
            "Eval_AverageEpLen : 134.0\n",
            "Train_AverageReturn : 226.4571533203125\n",
            "Train_StdReturn : 16.28618621826172\n",
            "Train_MaxReturn : 271.20684814453125\n",
            "Train_MinReturn : 189.8078155517578\n",
            "Train_AverageEpLen : 107.0\n",
            "Train_EnvstepsSoFar : 341380\n",
            "TimeSinceStart : 296.45254611968994\n",
            "Training Loss : -0.007390806917101145\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 167 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2047])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 236.50460815429688\n",
            "Eval_StdReturn : 10.159018516540527\n",
            "Eval_MaxReturn : 245.89031982421875\n",
            "Eval_MinReturn : 219.74252319335938\n",
            "Eval_AverageEpLen : 108.75\n",
            "Train_AverageReturn : 237.3306427001953\n",
            "Train_StdReturn : 22.142160415649414\n",
            "Train_MaxReturn : 307.65924072265625\n",
            "Train_MinReturn : 216.2781524658203\n",
            "Train_AverageEpLen : 113.72222222222223\n",
            "Train_EnvstepsSoFar : 343427\n",
            "TimeSinceStart : 298.0828061103821\n",
            "Training Loss : 0.02880915254354477\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 168 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2046])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 237.9344940185547\n",
            "Eval_StdReturn : 12.189289093017578\n",
            "Eval_MaxReturn : 247.61514282226562\n",
            "Eval_MinReturn : 217.17283630371094\n",
            "Eval_AverageEpLen : 114.0\n",
            "Train_AverageReturn : 245.87818908691406\n",
            "Train_StdReturn : 23.066242218017578\n",
            "Train_MaxReturn : 305.1185302734375\n",
            "Train_MinReturn : 220.04287719726562\n",
            "Train_AverageEpLen : 120.3529411764706\n",
            "Train_EnvstepsSoFar : 345473\n",
            "TimeSinceStart : 299.73984837532043\n",
            "Training Loss : -0.02138286642730236\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 169 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2038])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 249.69638061523438\n",
            "Eval_StdReturn : 25.31429100036621\n",
            "Eval_MaxReturn : 292.9014892578125\n",
            "Eval_MinReturn : 228.25656127929688\n",
            "Eval_AverageEpLen : 113.75\n",
            "Train_AverageReturn : 235.93150329589844\n",
            "Train_StdReturn : 27.45686149597168\n",
            "Train_MaxReturn : 299.94952392578125\n",
            "Train_MinReturn : 173.95501708984375\n",
            "Train_AverageEpLen : 113.22222222222223\n",
            "Train_EnvstepsSoFar : 347511\n",
            "TimeSinceStart : 302.03055334091187\n",
            "Training Loss : -0.012275319546461105\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 170 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2027])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 243.9414825439453\n",
            "Eval_StdReturn : 15.119413375854492\n",
            "Eval_MaxReturn : 267.540283203125\n",
            "Eval_MinReturn : 228.34165954589844\n",
            "Eval_AverageEpLen : 115.5\n",
            "Train_AverageReturn : 236.47445678710938\n",
            "Train_StdReturn : 50.02634048461914\n",
            "Train_MaxReturn : 298.7633056640625\n",
            "Train_MinReturn : 96.03184509277344\n",
            "Train_AverageEpLen : 119.23529411764706\n",
            "Train_EnvstepsSoFar : 349538\n",
            "TimeSinceStart : 304.09738636016846\n",
            "Training Loss : -0.0623604990541935\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 171 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2042])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 245.50057983398438\n",
            "Eval_StdReturn : 24.1546688079834\n",
            "Eval_MaxReturn : 284.033203125\n",
            "Eval_MinReturn : 219.37228393554688\n",
            "Eval_AverageEpLen : 120.25\n",
            "Train_AverageReturn : 237.0428924560547\n",
            "Train_StdReturn : 26.178434371948242\n",
            "Train_MaxReturn : 279.6264343261719\n",
            "Train_MinReturn : 178.02276611328125\n",
            "Train_AverageEpLen : 113.44444444444444\n",
            "Train_EnvstepsSoFar : 351580\n",
            "TimeSinceStart : 305.7594940662384\n",
            "Training Loss : -0.061461690813302994\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 172 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2045])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 222.0585174560547\n",
            "Eval_StdReturn : 39.330081939697266\n",
            "Eval_MaxReturn : 277.0963134765625\n",
            "Eval_MinReturn : 155.9884490966797\n",
            "Eval_AverageEpLen : 107.8\n",
            "Train_AverageReturn : 243.50416564941406\n",
            "Train_StdReturn : 32.454383850097656\n",
            "Train_MaxReturn : 296.2141418457031\n",
            "Train_MinReturn : 154.3727569580078\n",
            "Train_AverageEpLen : 120.29411764705883\n",
            "Train_EnvstepsSoFar : 353625\n",
            "TimeSinceStart : 307.44292998313904\n",
            "Training Loss : -0.003836740041151643\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 173 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2002])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 255.81192016601562\n",
            "Eval_StdReturn : 26.642486572265625\n",
            "Eval_MaxReturn : 293.370361328125\n",
            "Eval_MinReturn : 218.13644409179688\n",
            "Eval_AverageEpLen : 127.0\n",
            "Train_AverageReturn : 243.1072235107422\n",
            "Train_StdReturn : 25.082914352416992\n",
            "Train_MaxReturn : 308.5521240234375\n",
            "Train_MinReturn : 202.18919372558594\n",
            "Train_AverageEpLen : 117.76470588235294\n",
            "Train_EnvstepsSoFar : 355627\n",
            "TimeSinceStart : 309.09463334083557\n",
            "Training Loss : -0.019168639555573463\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 174 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2020])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 237.792724609375\n",
            "Eval_StdReturn : 21.36250114440918\n",
            "Eval_MaxReturn : 260.59368896484375\n",
            "Eval_MinReturn : 215.3656768798828\n",
            "Eval_AverageEpLen : 113.75\n",
            "Train_AverageReturn : 231.59654235839844\n",
            "Train_StdReturn : 36.77771759033203\n",
            "Train_MaxReturn : 287.2229309082031\n",
            "Train_MinReturn : 136.93063354492188\n",
            "Train_AverageEpLen : 112.22222222222223\n",
            "Train_EnvstepsSoFar : 357647\n",
            "TimeSinceStart : 310.7042348384857\n",
            "Training Loss : -0.0006462361779995263\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 175 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2029])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 257.5434265136719\n",
            "Eval_StdReturn : 33.458274841308594\n",
            "Eval_MaxReturn : 304.80255126953125\n",
            "Eval_MinReturn : 231.8848876953125\n",
            "Eval_AverageEpLen : 138.33333333333334\n",
            "Train_AverageReturn : 252.19679260253906\n",
            "Train_StdReturn : 31.270448684692383\n",
            "Train_MaxReturn : 319.49285888671875\n",
            "Train_MinReturn : 191.19398498535156\n",
            "Train_AverageEpLen : 126.8125\n",
            "Train_EnvstepsSoFar : 359676\n",
            "TimeSinceStart : 313.42025113105774\n",
            "Training Loss : 0.0004505018296185881\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 176 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2085])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 237.64376831054688\n",
            "Eval_StdReturn : 16.77766227722168\n",
            "Eval_MaxReturn : 265.71429443359375\n",
            "Eval_MinReturn : 222.3563690185547\n",
            "Eval_AverageEpLen : 108.25\n",
            "Train_AverageReturn : 236.68801879882812\n",
            "Train_StdReturn : 42.3595085144043\n",
            "Train_MaxReturn : 301.42303466796875\n",
            "Train_MinReturn : 96.47135162353516\n",
            "Train_AverageEpLen : 115.83333333333333\n",
            "Train_EnvstepsSoFar : 361761\n",
            "TimeSinceStart : 316.78155183792114\n",
            "Training Loss : -0.025479735806584358\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 177 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2022])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 247.0946502685547\n",
            "Eval_StdReturn : 8.609132766723633\n",
            "Eval_MaxReturn : 260.67694091796875\n",
            "Eval_MinReturn : 238.35984802246094\n",
            "Eval_AverageEpLen : 118.0\n",
            "Train_AverageReturn : 247.35919189453125\n",
            "Train_StdReturn : 34.109371185302734\n",
            "Train_MaxReturn : 309.62591552734375\n",
            "Train_MinReturn : 158.89093017578125\n",
            "Train_AverageEpLen : 126.375\n",
            "Train_EnvstepsSoFar : 363783\n",
            "TimeSinceStart : 318.4484598636627\n",
            "Training Loss : -0.1003522053360939\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 178 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2031])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 247.69296264648438\n",
            "Eval_StdReturn : 12.586708068847656\n",
            "Eval_MaxReturn : 269.28466796875\n",
            "Eval_MinReturn : 237.69886779785156\n",
            "Eval_AverageEpLen : 124.75\n",
            "Train_AverageReturn : 254.37391662597656\n",
            "Train_StdReturn : 26.98316192626953\n",
            "Train_MaxReturn : 314.88275146484375\n",
            "Train_MinReturn : 213.7559814453125\n",
            "Train_AverageEpLen : 126.9375\n",
            "Train_EnvstepsSoFar : 365814\n",
            "TimeSinceStart : 320.1243050098419\n",
            "Training Loss : -0.009489214047789574\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 179 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2067])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 239.14761352539062\n",
            "Eval_StdReturn : 19.161296844482422\n",
            "Eval_MaxReturn : 259.330322265625\n",
            "Eval_MinReturn : 212.18930053710938\n",
            "Eval_AverageEpLen : 112.0\n",
            "Train_AverageReturn : 240.1034393310547\n",
            "Train_StdReturn : 43.27012634277344\n",
            "Train_MaxReturn : 301.58917236328125\n",
            "Train_MinReturn : 131.59222412109375\n",
            "Train_AverageEpLen : 121.58823529411765\n",
            "Train_EnvstepsSoFar : 367881\n",
            "TimeSinceStart : 321.8068993091583\n",
            "Training Loss : -0.006405514199286699\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 180 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2089])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 261.4817810058594\n",
            "Eval_StdReturn : 21.554292678833008\n",
            "Eval_MaxReturn : 291.5400085449219\n",
            "Eval_MinReturn : 242.0642852783203\n",
            "Eval_AverageEpLen : 136.0\n",
            "Train_AverageReturn : 258.1729736328125\n",
            "Train_StdReturn : 25.686931610107422\n",
            "Train_MaxReturn : 304.50567626953125\n",
            "Train_MinReturn : 215.4249725341797\n",
            "Train_AverageEpLen : 130.5625\n",
            "Train_EnvstepsSoFar : 369970\n",
            "TimeSinceStart : 323.4425919055939\n",
            "Training Loss : -0.01169491931796074\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 181 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2026])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 213.71600341796875\n",
            "Eval_StdReturn : 28.375837326049805\n",
            "Eval_MaxReturn : 236.46432495117188\n",
            "Eval_MinReturn : 166.24575805664062\n",
            "Eval_AverageEpLen : 104.25\n",
            "Train_AverageReturn : 267.8940124511719\n",
            "Train_StdReturn : 28.8981876373291\n",
            "Train_MaxReturn : 347.81329345703125\n",
            "Train_MinReturn : 228.48715209960938\n",
            "Train_AverageEpLen : 135.06666666666666\n",
            "Train_EnvstepsSoFar : 371996\n",
            "TimeSinceStart : 325.0538520812988\n",
            "Training Loss : -0.017949026077985764\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 182 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2140])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 245.7598114013672\n",
            "Eval_StdReturn : 5.720577239990234\n",
            "Eval_MaxReturn : 255.460205078125\n",
            "Eval_MinReturn : 240.8695831298828\n",
            "Eval_AverageEpLen : 119.0\n",
            "Train_AverageReturn : 250.19732666015625\n",
            "Train_StdReturn : 45.90691375732422\n",
            "Train_MaxReturn : 339.4222412109375\n",
            "Train_MinReturn : 117.70973205566406\n",
            "Train_AverageEpLen : 125.88235294117646\n",
            "Train_EnvstepsSoFar : 374136\n",
            "TimeSinceStart : 326.7868494987488\n",
            "Training Loss : -0.0038870249409228563\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 183 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2055])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 253.53890991210938\n",
            "Eval_StdReturn : 12.940279006958008\n",
            "Eval_MaxReturn : 273.975341796875\n",
            "Eval_MinReturn : 240.8405303955078\n",
            "Eval_AverageEpLen : 118.5\n",
            "Train_AverageReturn : 252.36209106445312\n",
            "Train_StdReturn : 44.06071090698242\n",
            "Train_MaxReturn : 300.43414306640625\n",
            "Train_MinReturn : 106.43318939208984\n",
            "Train_AverageEpLen : 128.4375\n",
            "Train_EnvstepsSoFar : 376191\n",
            "TimeSinceStart : 329.298317193985\n",
            "Training Loss : -0.004952519200742245\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 184 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2013])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 265.0369873046875\n",
            "Eval_StdReturn : 21.382978439331055\n",
            "Eval_MaxReturn : 291.9128723144531\n",
            "Eval_MinReturn : 232.19546508789062\n",
            "Eval_AverageEpLen : 125.0\n",
            "Train_AverageReturn : 254.05856323242188\n",
            "Train_StdReturn : 27.904592514038086\n",
            "Train_MaxReturn : 316.9076843261719\n",
            "Train_MinReturn : 219.76861572265625\n",
            "Train_AverageEpLen : 125.8125\n",
            "Train_EnvstepsSoFar : 378204\n",
            "TimeSinceStart : 330.95916962623596\n",
            "Training Loss : 0.001032728818245232\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 185 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2004])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 248.9685516357422\n",
            "Eval_StdReturn : 18.16225814819336\n",
            "Eval_MaxReturn : 260.9042053222656\n",
            "Eval_MinReturn : 217.57208251953125\n",
            "Eval_AverageEpLen : 131.25\n",
            "Train_AverageReturn : 263.0545349121094\n",
            "Train_StdReturn : 20.030977249145508\n",
            "Train_MaxReturn : 303.65167236328125\n",
            "Train_MinReturn : 230.0751953125\n",
            "Train_AverageEpLen : 134.0625\n",
            "Train_EnvstepsSoFar : 380349\n",
            "TimeSinceStart : 333.16568779945374\n",
            "Training Loss : -0.06029026582837105\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 186 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2106])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 269.5796813964844\n",
            "Eval_StdReturn : 4.907998561859131\n",
            "Eval_MaxReturn : 276.4622802734375\n",
            "Eval_MinReturn : 265.36053466796875\n",
            "Eval_AverageEpLen : 152.66666666666666\n",
            "Train_AverageReturn : 242.20384216308594\n",
            "Train_StdReturn : 45.45530700683594\n",
            "Train_MaxReturn : 298.78826904296875\n",
            "Train_MinReturn : 127.42424774169922\n",
            "Train_AverageEpLen : 123.88235294117646\n",
            "Train_EnvstepsSoFar : 382455\n",
            "TimeSinceStart : 334.91538190841675\n",
            "Training Loss : -0.02110464684665203\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 187 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2054])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 283.447265625\n",
            "Eval_StdReturn : 26.802581787109375\n",
            "Eval_MaxReturn : 305.27935791015625\n",
            "Eval_MinReturn : 245.69677734375\n",
            "Eval_AverageEpLen : 151.0\n",
            "Train_AverageReturn : 280.5789794921875\n",
            "Train_StdReturn : 41.02477264404297\n",
            "Train_MaxReturn : 367.64776611328125\n",
            "Train_MinReturn : 208.1266632080078\n",
            "Train_AverageEpLen : 146.71428571428572\n",
            "Train_EnvstepsSoFar : 384509\n",
            "TimeSinceStart : 338.1177945137024\n",
            "Training Loss : -0.001519017037935555\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 188 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2027])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 283.5976867675781\n",
            "Eval_StdReturn : 17.942989349365234\n",
            "Eval_MaxReturn : 307.7637634277344\n",
            "Eval_MinReturn : 264.8118896484375\n",
            "Eval_AverageEpLen : 137.66666666666666\n",
            "Train_AverageReturn : 253.11865234375\n",
            "Train_StdReturn : 45.59886169433594\n",
            "Train_MaxReturn : 315.7322998046875\n",
            "Train_MinReturn : 96.78087615966797\n",
            "Train_AverageEpLen : 125.6470588235294\n",
            "Train_EnvstepsSoFar : 386645\n",
            "TimeSinceStart : 339.9884994029999\n",
            "Training Loss : -0.04755908250808716\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 189 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2040])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 258.9498596191406\n",
            "Eval_StdReturn : 18.30611228942871\n",
            "Eval_MaxReturn : 285.2438049316406\n",
            "Eval_MinReturn : 233.77748107910156\n",
            "Eval_AverageEpLen : 126.0\n",
            "Train_AverageReturn : 270.34326171875\n",
            "Train_StdReturn : 42.880584716796875\n",
            "Train_MaxReturn : 345.7145690917969\n",
            "Train_MinReturn : 161.310546875\n",
            "Train_AverageEpLen : 135.0625\n",
            "Train_EnvstepsSoFar : 388806\n",
            "TimeSinceStart : 343.3955616950989\n",
            "Training Loss : 0.0062422058545053005\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 190 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2112])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 309.2504577636719\n",
            "Eval_StdReturn : 22.66825294494629\n",
            "Eval_MaxReturn : 341.2552185058594\n",
            "Eval_MinReturn : 291.6524658203125\n",
            "Eval_AverageEpLen : 171.66666666666666\n",
            "Train_AverageReturn : 273.4102478027344\n",
            "Train_StdReturn : 31.03183364868164\n",
            "Train_MaxReturn : 344.11737060546875\n",
            "Train_MinReturn : 214.81448364257812\n",
            "Train_AverageEpLen : 140.8\n",
            "Train_EnvstepsSoFar : 390918\n",
            "TimeSinceStart : 345.48195600509644\n",
            "Training Loss : -0.04741966351866722\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 191 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2111])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 311.4732360839844\n",
            "Eval_StdReturn : 25.675193786621094\n",
            "Eval_MaxReturn : 333.85882568359375\n",
            "Eval_MinReturn : 275.5218505859375\n",
            "Eval_AverageEpLen : 180.0\n",
            "Train_AverageReturn : 281.8085021972656\n",
            "Train_StdReturn : 33.21913528442383\n",
            "Train_MaxReturn : 337.2471618652344\n",
            "Train_MinReturn : 213.48568725585938\n",
            "Train_AverageEpLen : 140.73333333333332\n",
            "Train_EnvstepsSoFar : 393029\n",
            "TimeSinceStart : 347.24832344055176\n",
            "Training Loss : 0.0009040480363182724\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 192 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2093])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 309.4290771484375\n",
            "Eval_StdReturn : 35.686195373535156\n",
            "Eval_MaxReturn : 347.2510070800781\n",
            "Eval_MinReturn : 261.5805358886719\n",
            "Eval_AverageEpLen : 163.66666666666666\n",
            "Train_AverageReturn : 274.27227783203125\n",
            "Train_StdReturn : 41.77484893798828\n",
            "Train_MaxReturn : 316.52569580078125\n",
            "Train_MinReturn : 164.33343505859375\n",
            "Train_AverageEpLen : 149.5\n",
            "Train_EnvstepsSoFar : 395122\n",
            "TimeSinceStart : 348.9516406059265\n",
            "Training Loss : -0.012912087142467499\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 193 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2002])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 300.9986267089844\n",
            "Eval_StdReturn : 39.797245025634766\n",
            "Eval_MaxReturn : 351.92596435546875\n",
            "Eval_MinReturn : 254.7855987548828\n",
            "Eval_AverageEpLen : 159.33333333333334\n",
            "Train_AverageReturn : 288.02020263671875\n",
            "Train_StdReturn : 48.348670959472656\n",
            "Train_MaxReturn : 371.6532287597656\n",
            "Train_MinReturn : 206.12667846679688\n",
            "Train_AverageEpLen : 150.78571428571428\n",
            "Train_EnvstepsSoFar : 397233\n",
            "TimeSinceStart : 350.6492567062378\n",
            "Training Loss : 0.029192844405770302\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 194 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2130])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 264.2734680175781\n",
            "Eval_StdReturn : 19.704805374145508\n",
            "Eval_MaxReturn : 293.7810363769531\n",
            "Eval_MinReturn : 238.92758178710938\n",
            "Eval_AverageEpLen : 124.0\n",
            "Train_AverageReturn : 300.8359069824219\n",
            "Train_StdReturn : 36.11445236206055\n",
            "Train_MaxReturn : 385.87969970703125\n",
            "Train_MinReturn : 245.89205932617188\n",
            "Train_AverageEpLen : 152.14285714285714\n",
            "Train_EnvstepsSoFar : 399363\n",
            "TimeSinceStart : 352.39790296554565\n",
            "Training Loss : -0.016894344240427017\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 195 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2027])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 315.2257385253906\n",
            "Eval_StdReturn : 6.439452171325684\n",
            "Eval_MaxReturn : 322.0167236328125\n",
            "Eval_MinReturn : 306.5755615234375\n",
            "Eval_AverageEpLen : 160.66666666666666\n",
            "Train_AverageReturn : 310.1197509765625\n",
            "Train_StdReturn : 41.259822845458984\n",
            "Train_MaxReturn : 388.7345275878906\n",
            "Train_MinReturn : 260.996337890625\n",
            "Train_AverageEpLen : 155.92307692307693\n",
            "Train_EnvstepsSoFar : 401390\n",
            "TimeSinceStart : 354.05340337753296\n",
            "Training Loss : 0.02264500968158245\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 196 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2056])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 283.6157531738281\n",
            "Eval_StdReturn : 30.342973709106445\n",
            "Eval_MaxReturn : 315.29742431640625\n",
            "Eval_MinReturn : 242.71005249023438\n",
            "Eval_AverageEpLen : 145.33333333333334\n",
            "Train_AverageReturn : 274.7892150878906\n",
            "Train_StdReturn : 55.413658142089844\n",
            "Train_MaxReturn : 374.857177734375\n",
            "Train_MinReturn : 191.31246948242188\n",
            "Train_AverageEpLen : 146.85714285714286\n",
            "Train_EnvstepsSoFar : 403446\n",
            "TimeSinceStart : 355.71203684806824\n",
            "Training Loss : 0.0017578031402081251\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 197 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2051])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 264.5005187988281\n",
            "Eval_StdReturn : 56.24932861328125\n",
            "Eval_MaxReturn : 325.1937561035156\n",
            "Eval_MinReturn : 189.6204376220703\n",
            "Eval_AverageEpLen : 144.66666666666666\n",
            "Train_AverageReturn : 275.0301208496094\n",
            "Train_StdReturn : 33.34516906738281\n",
            "Train_MaxReturn : 339.0863952636719\n",
            "Train_MinReturn : 216.24705505371094\n",
            "Train_AverageEpLen : 136.73333333333332\n",
            "Train_EnvstepsSoFar : 405497\n",
            "TimeSinceStart : 357.34690260887146\n",
            "Training Loss : 0.013948584906756878\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 198 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2075])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 289.2655029296875\n",
            "Eval_StdReturn : 89.0915756225586\n",
            "Eval_MaxReturn : 390.17333984375\n",
            "Eval_MinReturn : 173.4727020263672\n",
            "Eval_AverageEpLen : 155.33333333333334\n",
            "Train_AverageReturn : 290.31658935546875\n",
            "Train_StdReturn : 57.79018783569336\n",
            "Train_MaxReturn : 385.79107666015625\n",
            "Train_MinReturn : 157.84002685546875\n",
            "Train_AverageEpLen : 148.21428571428572\n",
            "Train_EnvstepsSoFar : 407572\n",
            "TimeSinceStart : 359.0311088562012\n",
            "Training Loss : -0.016485249623656273\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 199 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2033])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 276.397705078125\n",
            "Eval_StdReturn : 50.70132827758789\n",
            "Eval_MaxReturn : 321.58184814453125\n",
            "Eval_MinReturn : 205.5901641845703\n",
            "Eval_AverageEpLen : 148.0\n",
            "Train_AverageReturn : 302.0872802734375\n",
            "Train_StdReturn : 25.053081512451172\n",
            "Train_MaxReturn : 345.03802490234375\n",
            "Train_MinReturn : 270.80975341796875\n",
            "Train_AverageEpLen : 156.3846153846154\n",
            "Train_EnvstepsSoFar : 409605\n",
            "TimeSinceStart : 360.6694118976593\n",
            "Training Loss : 0.03224813565611839\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 200 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2095])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 307.9212341308594\n",
            "Eval_StdReturn : 24.32991600036621\n",
            "Eval_MaxReturn : 342.07122802734375\n",
            "Eval_MinReturn : 287.2060852050781\n",
            "Eval_AverageEpLen : 167.0\n",
            "Train_AverageReturn : 292.54827880859375\n",
            "Train_StdReturn : 55.969512939453125\n",
            "Train_MaxReturn : 394.48297119140625\n",
            "Train_MinReturn : 195.69879150390625\n",
            "Train_AverageEpLen : 149.64285714285714\n",
            "Train_EnvstepsSoFar : 411700\n",
            "TimeSinceStart : 362.42054653167725\n",
            "Training Loss : 0.02453155815601349\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 201 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2107])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 331.96588134765625\n",
            "Eval_StdReturn : 41.97090148925781\n",
            "Eval_MaxReturn : 389.6885070800781\n",
            "Eval_MinReturn : 291.1292419433594\n",
            "Eval_AverageEpLen : 171.0\n",
            "Train_AverageReturn : 316.39764404296875\n",
            "Train_StdReturn : 35.95567321777344\n",
            "Train_MaxReturn : 404.9736328125\n",
            "Train_MinReturn : 258.09417724609375\n",
            "Train_AverageEpLen : 162.07692307692307\n",
            "Train_EnvstepsSoFar : 413807\n",
            "TimeSinceStart : 364.14178466796875\n",
            "Training Loss : 0.010778895579278469\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 202 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2067])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 311.4468688964844\n",
            "Eval_StdReturn : 19.45326042175293\n",
            "Eval_MaxReturn : 332.01470947265625\n",
            "Eval_MinReturn : 285.3399658203125\n",
            "Eval_AverageEpLen : 158.33333333333334\n",
            "Train_AverageReturn : 308.3113098144531\n",
            "Train_StdReturn : 36.267921447753906\n",
            "Train_MaxReturn : 395.06610107421875\n",
            "Train_MinReturn : 243.60733032226562\n",
            "Train_AverageEpLen : 159.0\n",
            "Train_EnvstepsSoFar : 415874\n",
            "TimeSinceStart : 365.8083322048187\n",
            "Training Loss : -0.004923573695123196\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 203 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2024])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 334.1075134277344\n",
            "Eval_StdReturn : 43.53874206542969\n",
            "Eval_MaxReturn : 377.74847412109375\n",
            "Eval_MinReturn : 274.67010498046875\n",
            "Eval_AverageEpLen : 178.66666666666666\n",
            "Train_AverageReturn : 291.0499572753906\n",
            "Train_StdReturn : 56.075050354003906\n",
            "Train_MaxReturn : 387.82745361328125\n",
            "Train_MinReturn : 167.1650390625\n",
            "Train_AverageEpLen : 155.69230769230768\n",
            "Train_EnvstepsSoFar : 417898\n",
            "TimeSinceStart : 367.4818787574768\n",
            "Training Loss : -0.0074973623268306255\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 204 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2119])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 311.5393371582031\n",
            "Eval_StdReturn : 21.946226119995117\n",
            "Eval_MaxReturn : 341.5614013671875\n",
            "Eval_MinReturn : 289.71197509765625\n",
            "Eval_AverageEpLen : 172.66666666666666\n",
            "Train_AverageReturn : 293.04736328125\n",
            "Train_StdReturn : 65.24049377441406\n",
            "Train_MaxReturn : 421.2617492675781\n",
            "Train_MinReturn : 143.14425659179688\n",
            "Train_AverageEpLen : 151.35714285714286\n",
            "Train_EnvstepsSoFar : 420017\n",
            "TimeSinceStart : 369.2036769390106\n",
            "Training Loss : 0.008672741241753101\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 205 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2104])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 325.9990539550781\n",
            "Eval_StdReturn : 52.601234436035156\n",
            "Eval_MaxReturn : 383.234375\n",
            "Eval_MinReturn : 256.23016357421875\n",
            "Eval_AverageEpLen : 164.0\n",
            "Train_AverageReturn : 316.4985656738281\n",
            "Train_StdReturn : 28.11443519592285\n",
            "Train_MaxReturn : 376.043212890625\n",
            "Train_MinReturn : 265.8927307128906\n",
            "Train_AverageEpLen : 161.84615384615384\n",
            "Train_EnvstepsSoFar : 422121\n",
            "TimeSinceStart : 370.8938765525818\n",
            "Training Loss : -0.005357129964977503\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 206 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2009])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 285.6094970703125\n",
            "Eval_StdReturn : 40.225887298583984\n",
            "Eval_MaxReturn : 326.3493347167969\n",
            "Eval_MinReturn : 230.85379028320312\n",
            "Eval_AverageEpLen : 145.0\n",
            "Train_AverageReturn : 325.3081970214844\n",
            "Train_StdReturn : 38.59638214111328\n",
            "Train_MaxReturn : 426.9322814941406\n",
            "Train_MinReturn : 257.56182861328125\n",
            "Train_AverageEpLen : 167.41666666666666\n",
            "Train_EnvstepsSoFar : 424130\n",
            "TimeSinceStart : 372.4966802597046\n",
            "Training Loss : -0.013036848045885563\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 207 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2044])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 303.9782409667969\n",
            "Eval_StdReturn : 98.65525817871094\n",
            "Eval_MaxReturn : 429.3471374511719\n",
            "Eval_MinReturn : 188.2723846435547\n",
            "Eval_AverageEpLen : 173.0\n",
            "Train_AverageReturn : 296.4322204589844\n",
            "Train_StdReturn : 56.41084671020508\n",
            "Train_MaxReturn : 355.3005676269531\n",
            "Train_MinReturn : 125.33375549316406\n",
            "Train_AverageEpLen : 157.23076923076923\n",
            "Train_EnvstepsSoFar : 426174\n",
            "TimeSinceStart : 374.1899383068085\n",
            "Training Loss : -0.08122008293867111\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 208 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2121])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 341.3862609863281\n",
            "Eval_StdReturn : 29.888504028320312\n",
            "Eval_MaxReturn : 382.73968505859375\n",
            "Eval_MinReturn : 313.1329345703125\n",
            "Eval_AverageEpLen : 175.0\n",
            "Train_AverageReturn : 334.5473937988281\n",
            "Train_StdReturn : 50.409637451171875\n",
            "Train_MaxReturn : 414.1009521484375\n",
            "Train_MinReturn : 259.67938232421875\n",
            "Train_AverageEpLen : 176.75\n",
            "Train_EnvstepsSoFar : 428295\n",
            "TimeSinceStart : 375.95614099502563\n",
            "Training Loss : -0.02795013226568699\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 209 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2139])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 251.4955596923828\n",
            "Eval_StdReturn : 49.87519454956055\n",
            "Eval_MaxReturn : 309.1695556640625\n",
            "Eval_MinReturn : 187.4934539794922\n",
            "Eval_AverageEpLen : 138.66666666666666\n",
            "Train_AverageReturn : 332.6743469238281\n",
            "Train_StdReturn : 32.48119354248047\n",
            "Train_MaxReturn : 392.82965087890625\n",
            "Train_MinReturn : 263.0924072265625\n",
            "Train_AverageEpLen : 178.25\n",
            "Train_EnvstepsSoFar : 430434\n",
            "TimeSinceStart : 378.2188742160797\n",
            "Training Loss : -0.01022839080542326\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 210 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2182])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 310.06268310546875\n",
            "Eval_StdReturn : 13.706294059753418\n",
            "Eval_MaxReturn : 326.1850280761719\n",
            "Eval_MinReturn : 292.682373046875\n",
            "Eval_AverageEpLen : 172.0\n",
            "Train_AverageReturn : 340.5575866699219\n",
            "Train_StdReturn : 56.889549255371094\n",
            "Train_MaxReturn : 404.804443359375\n",
            "Train_MinReturn : 216.31680297851562\n",
            "Train_AverageEpLen : 181.83333333333334\n",
            "Train_EnvstepsSoFar : 432616\n",
            "TimeSinceStart : 380.6995131969452\n",
            "Training Loss : 0.022713784128427505\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 211 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2124])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 331.4195861816406\n",
            "Eval_StdReturn : 18.908363342285156\n",
            "Eval_MaxReturn : 355.96978759765625\n",
            "Eval_MinReturn : 309.9654235839844\n",
            "Eval_AverageEpLen : 168.0\n",
            "Train_AverageReturn : 325.23980712890625\n",
            "Train_StdReturn : 26.42884063720703\n",
            "Train_MaxReturn : 367.14691162109375\n",
            "Train_MinReturn : 281.16436767578125\n",
            "Train_AverageEpLen : 163.3846153846154\n",
            "Train_EnvstepsSoFar : 434740\n",
            "TimeSinceStart : 382.4156186580658\n",
            "Training Loss : 0.012548692524433136\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 212 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2037])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 296.0198059082031\n",
            "Eval_StdReturn : 28.58918571472168\n",
            "Eval_MaxReturn : 335.62200927734375\n",
            "Eval_MinReturn : 269.16455078125\n",
            "Eval_AverageEpLen : 142.0\n",
            "Train_AverageReturn : 309.6177062988281\n",
            "Train_StdReturn : 69.82907104492188\n",
            "Train_MaxReturn : 402.48553466796875\n",
            "Train_MinReturn : 103.10294342041016\n",
            "Train_AverageEpLen : 156.69230769230768\n",
            "Train_EnvstepsSoFar : 436777\n",
            "TimeSinceStart : 384.29334688186646\n",
            "Training Loss : -0.01672583445906639\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 213 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2003])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 282.8904113769531\n",
            "Eval_StdReturn : 50.03580093383789\n",
            "Eval_MaxReturn : 323.36590576171875\n",
            "Eval_MinReturn : 212.38662719726562\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 323.5771179199219\n",
            "Train_StdReturn : 40.9491081237793\n",
            "Train_MaxReturn : 387.1208801269531\n",
            "Train_MinReturn : 243.43319702148438\n",
            "Train_AverageEpLen : 166.53846153846155\n",
            "Train_EnvstepsSoFar : 438942\n",
            "TimeSinceStart : 386.02279806137085\n",
            "Training Loss : -0.06323807686567307\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 214 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2185])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 311.5625915527344\n",
            "Eval_StdReturn : 24.313678741455078\n",
            "Eval_MaxReturn : 340.948974609375\n",
            "Eval_MinReturn : 281.4077453613281\n",
            "Eval_AverageEpLen : 162.33333333333334\n",
            "Train_AverageReturn : 318.97540283203125\n",
            "Train_StdReturn : 45.4511604309082\n",
            "Train_MaxReturn : 413.1817932128906\n",
            "Train_MinReturn : 248.72125244140625\n",
            "Train_AverageEpLen : 168.07692307692307\n",
            "Train_EnvstepsSoFar : 441127\n",
            "TimeSinceStart : 387.7591369152069\n",
            "Training Loss : -0.03392820805311203\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 215 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2021])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 353.6626892089844\n",
            "Eval_StdReturn : 30.365753173828125\n",
            "Eval_MaxReturn : 384.0284423828125\n",
            "Eval_MinReturn : 323.29693603515625\n",
            "Eval_AverageEpLen : 208.0\n",
            "Train_AverageReturn : 302.3636474609375\n",
            "Train_StdReturn : 61.21746826171875\n",
            "Train_MaxReturn : 414.5048522949219\n",
            "Train_MinReturn : 178.77601623535156\n",
            "Train_AverageEpLen : 155.46153846153845\n",
            "Train_EnvstepsSoFar : 443148\n",
            "TimeSinceStart : 389.3345596790314\n",
            "Training Loss : 0.020606141537427902\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 216 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2064])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 316.3705139160156\n",
            "Eval_StdReturn : 26.613378524780273\n",
            "Eval_MaxReturn : 349.43865966796875\n",
            "Eval_MinReturn : 284.27105712890625\n",
            "Eval_AverageEpLen : 154.66666666666666\n",
            "Train_AverageReturn : 341.8706970214844\n",
            "Train_StdReturn : 34.6033935546875\n",
            "Train_MaxReturn : 413.3002014160156\n",
            "Train_MinReturn : 289.527099609375\n",
            "Train_AverageEpLen : 172.0\n",
            "Train_EnvstepsSoFar : 445212\n",
            "TimeSinceStart : 390.9910259246826\n",
            "Training Loss : 0.020570790395140648\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 217 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2093])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 290.4054260253906\n",
            "Eval_StdReturn : 79.34536743164062\n",
            "Eval_MaxReturn : 384.2327880859375\n",
            "Eval_MinReturn : 190.19210815429688\n",
            "Eval_AverageEpLen : 161.0\n",
            "Train_AverageReturn : 313.2256164550781\n",
            "Train_StdReturn : 39.03895950317383\n",
            "Train_MaxReturn : 368.879638671875\n",
            "Train_MinReturn : 225.1590576171875\n",
            "Train_AverageEpLen : 161.0\n",
            "Train_EnvstepsSoFar : 447305\n",
            "TimeSinceStart : 392.6909976005554\n",
            "Training Loss : 0.020765531808137894\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 218 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2062])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 317.6227111816406\n",
            "Eval_StdReturn : 4.932083606719971\n",
            "Eval_MaxReturn : 324.11322021484375\n",
            "Eval_MinReturn : 312.1654052734375\n",
            "Eval_AverageEpLen : 153.0\n",
            "Train_AverageReturn : 352.4114074707031\n",
            "Train_StdReturn : 55.136207580566406\n",
            "Train_MaxReturn : 429.89849853515625\n",
            "Train_MinReturn : 265.8553466796875\n",
            "Train_AverageEpLen : 187.45454545454547\n",
            "Train_EnvstepsSoFar : 449367\n",
            "TimeSinceStart : 394.38684034347534\n",
            "Training Loss : -0.001687409239821136\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 219 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2012])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 301.2831115722656\n",
            "Eval_StdReturn : 42.04143142700195\n",
            "Eval_MaxReturn : 353.60479736328125\n",
            "Eval_MinReturn : 250.66712951660156\n",
            "Eval_AverageEpLen : 161.0\n",
            "Train_AverageReturn : 301.5716247558594\n",
            "Train_StdReturn : 54.616127014160156\n",
            "Train_MaxReturn : 403.0278015136719\n",
            "Train_MinReturn : 199.65560913085938\n",
            "Train_AverageEpLen : 154.76923076923077\n",
            "Train_EnvstepsSoFar : 451379\n",
            "TimeSinceStart : 396.02442026138306\n",
            "Training Loss : -0.0095726503059268\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 220 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2117])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 332.95587158203125\n",
            "Eval_StdReturn : 30.318679809570312\n",
            "Eval_MaxReturn : 375.81298828125\n",
            "Eval_MinReturn : 310.39434814453125\n",
            "Eval_AverageEpLen : 159.66666666666666\n",
            "Train_AverageReturn : 317.6935729980469\n",
            "Train_StdReturn : 54.31692123413086\n",
            "Train_MaxReturn : 458.038818359375\n",
            "Train_MinReturn : 214.3379364013672\n",
            "Train_AverageEpLen : 162.84615384615384\n",
            "Train_EnvstepsSoFar : 453496\n",
            "TimeSinceStart : 397.7061152458191\n",
            "Training Loss : -0.00971390213817358\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 221 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2047])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 385.6831359863281\n",
            "Eval_StdReturn : 61.070281982421875\n",
            "Eval_MaxReturn : 446.75341796875\n",
            "Eval_MinReturn : 324.61285400390625\n",
            "Eval_AverageEpLen : 223.0\n",
            "Train_AverageReturn : 332.9296569824219\n",
            "Train_StdReturn : 41.98573684692383\n",
            "Train_MaxReturn : 441.8930969238281\n",
            "Train_MinReturn : 285.9668884277344\n",
            "Train_AverageEpLen : 170.58333333333334\n",
            "Train_EnvstepsSoFar : 455543\n",
            "TimeSinceStart : 399.325674533844\n",
            "Training Loss : -0.024491898715496063\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 222 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2127])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 310.3172302246094\n",
            "Eval_StdReturn : 43.599945068359375\n",
            "Eval_MaxReturn : 352.930908203125\n",
            "Eval_MinReturn : 250.41650390625\n",
            "Eval_AverageEpLen : 153.66666666666666\n",
            "Train_AverageReturn : 311.1820068359375\n",
            "Train_StdReturn : 67.46089172363281\n",
            "Train_MaxReturn : 408.9620361328125\n",
            "Train_MinReturn : 119.6881332397461\n",
            "Train_AverageEpLen : 163.6153846153846\n",
            "Train_EnvstepsSoFar : 457670\n",
            "TimeSinceStart : 401.0144510269165\n",
            "Training Loss : 0.004696309100836515\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 223 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2001])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 317.3785400390625\n",
            "Eval_StdReturn : 41.93642044067383\n",
            "Eval_MaxReturn : 355.40838623046875\n",
            "Eval_MinReturn : 258.9517822265625\n",
            "Eval_AverageEpLen : 161.33333333333334\n",
            "Train_AverageReturn : 323.1754455566406\n",
            "Train_StdReturn : 56.1098518371582\n",
            "Train_MaxReturn : 415.17938232421875\n",
            "Train_MinReturn : 235.90081787109375\n",
            "Train_AverageEpLen : 166.75\n",
            "Train_EnvstepsSoFar : 459671\n",
            "TimeSinceStart : 402.59583377838135\n",
            "Training Loss : 0.026898453012108803\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 224 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2010])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 337.5191955566406\n",
            "Eval_StdReturn : 52.77119827270508\n",
            "Eval_MaxReturn : 407.0133056640625\n",
            "Eval_MinReturn : 279.2110290527344\n",
            "Eval_AverageEpLen : 170.0\n",
            "Train_AverageReturn : 294.2945251464844\n",
            "Train_StdReturn : 40.724735260009766\n",
            "Train_MaxReturn : 384.7692565917969\n",
            "Train_MinReturn : 226.62142944335938\n",
            "Train_AverageEpLen : 143.57142857142858\n",
            "Train_EnvstepsSoFar : 461681\n",
            "TimeSinceStart : 404.27631187438965\n",
            "Training Loss : -0.013998088426887989\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 225 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2084])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 320.4639587402344\n",
            "Eval_StdReturn : 28.351028442382812\n",
            "Eval_MaxReturn : 357.62750244140625\n",
            "Eval_MinReturn : 288.85052490234375\n",
            "Eval_AverageEpLen : 161.33333333333334\n",
            "Train_AverageReturn : 318.07232666015625\n",
            "Train_StdReturn : 44.18004608154297\n",
            "Train_MaxReturn : 408.36041259765625\n",
            "Train_MinReturn : 249.01080322265625\n",
            "Train_AverageEpLen : 160.30769230769232\n",
            "Train_EnvstepsSoFar : 463765\n",
            "TimeSinceStart : 405.9376494884491\n",
            "Training Loss : -0.009477346204221249\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 226 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2009])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 345.0135803222656\n",
            "Eval_StdReturn : 14.570497512817383\n",
            "Eval_MaxReturn : 365.29730224609375\n",
            "Eval_MinReturn : 331.72894287109375\n",
            "Eval_AverageEpLen : 171.0\n",
            "Train_AverageReturn : 319.9988098144531\n",
            "Train_StdReturn : 62.93281555175781\n",
            "Train_MaxReturn : 440.894775390625\n",
            "Train_MinReturn : 154.1757354736328\n",
            "Train_AverageEpLen : 154.53846153846155\n",
            "Train_EnvstepsSoFar : 465774\n",
            "TimeSinceStart : 407.603080034256\n",
            "Training Loss : -0.01988324150443077\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 227 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2068])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 308.91424560546875\n",
            "Eval_StdReturn : 25.81699562072754\n",
            "Eval_MaxReturn : 333.1802978515625\n",
            "Eval_MinReturn : 273.1561279296875\n",
            "Eval_AverageEpLen : 153.0\n",
            "Train_AverageReturn : 320.7826843261719\n",
            "Train_StdReturn : 32.366390228271484\n",
            "Train_MaxReturn : 391.44573974609375\n",
            "Train_MinReturn : 254.03695678710938\n",
            "Train_AverageEpLen : 159.07692307692307\n",
            "Train_EnvstepsSoFar : 467842\n",
            "TimeSinceStart : 409.2945234775543\n",
            "Training Loss : -0.05024930089712143\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 228 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2115])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 329.6210021972656\n",
            "Eval_StdReturn : 51.88575744628906\n",
            "Eval_MaxReturn : 400.42108154296875\n",
            "Eval_MinReturn : 277.5263366699219\n",
            "Eval_AverageEpLen : 172.33333333333334\n",
            "Train_AverageReturn : 305.23101806640625\n",
            "Train_StdReturn : 44.311405181884766\n",
            "Train_MaxReturn : 399.56744384765625\n",
            "Train_MinReturn : 215.68765258789062\n",
            "Train_AverageEpLen : 151.07142857142858\n",
            "Train_EnvstepsSoFar : 469957\n",
            "TimeSinceStart : 411.03693413734436\n",
            "Training Loss : -0.002539584180340171\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 229 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2145])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 304.1988830566406\n",
            "Eval_StdReturn : 63.03984069824219\n",
            "Eval_MaxReturn : 372.5788879394531\n",
            "Eval_MinReturn : 220.4693603515625\n",
            "Eval_AverageEpLen : 154.0\n",
            "Train_AverageReturn : 308.7818908691406\n",
            "Train_StdReturn : 61.22215270996094\n",
            "Train_MaxReturn : 448.0581359863281\n",
            "Train_MinReturn : 171.68679809570312\n",
            "Train_AverageEpLen : 153.21428571428572\n",
            "Train_EnvstepsSoFar : 472102\n",
            "TimeSinceStart : 412.74263191223145\n",
            "Training Loss : -0.01573503389954567\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 230 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2121])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 316.2692565917969\n",
            "Eval_StdReturn : 47.210296630859375\n",
            "Eval_MaxReturn : 356.6877136230469\n",
            "Eval_MinReturn : 250.03851318359375\n",
            "Eval_AverageEpLen : 161.33333333333334\n",
            "Train_AverageReturn : 334.5115051269531\n",
            "Train_StdReturn : 32.487117767333984\n",
            "Train_MaxReturn : 382.6299743652344\n",
            "Train_MinReturn : 271.98876953125\n",
            "Train_AverageEpLen : 163.15384615384616\n",
            "Train_EnvstepsSoFar : 474223\n",
            "TimeSinceStart : 414.47265672683716\n",
            "Training Loss : 0.009599369950592518\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 231 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2022])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 355.1880187988281\n",
            "Eval_StdReturn : 20.476688385009766\n",
            "Eval_MaxReturn : 383.1354064941406\n",
            "Eval_MinReturn : 334.6454772949219\n",
            "Eval_AverageEpLen : 170.33333333333334\n",
            "Train_AverageReturn : 333.15484619140625\n",
            "Train_StdReturn : 27.318981170654297\n",
            "Train_MaxReturn : 393.09991455078125\n",
            "Train_MinReturn : 293.2066650390625\n",
            "Train_AverageEpLen : 168.5\n",
            "Train_EnvstepsSoFar : 476245\n",
            "TimeSinceStart : 416.12824153900146\n",
            "Training Loss : -0.006514545064419508\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 232 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2091])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 346.4820861816406\n",
            "Eval_StdReturn : 17.533357620239258\n",
            "Eval_MaxReturn : 369.18951416015625\n",
            "Eval_MinReturn : 326.50238037109375\n",
            "Eval_AverageEpLen : 176.0\n",
            "Train_AverageReturn : 326.4878845214844\n",
            "Train_StdReturn : 74.93585205078125\n",
            "Train_MaxReturn : 444.0655517578125\n",
            "Train_MinReturn : 120.0760269165039\n",
            "Train_AverageEpLen : 159.71428571428572\n",
            "Train_EnvstepsSoFar : 478481\n",
            "TimeSinceStart : 417.9549949169159\n",
            "Training Loss : -0.0003565665683709085\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 233 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2049])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 269.1439208984375\n",
            "Eval_StdReturn : 62.98734664916992\n",
            "Eval_MaxReturn : 326.6211853027344\n",
            "Eval_MinReturn : 181.4698944091797\n",
            "Eval_AverageEpLen : 133.66666666666666\n",
            "Train_AverageReturn : 321.7660827636719\n",
            "Train_StdReturn : 41.18527603149414\n",
            "Train_MaxReturn : 369.37860107421875\n",
            "Train_MinReturn : 222.9923858642578\n",
            "Train_AverageEpLen : 157.6153846153846\n",
            "Train_EnvstepsSoFar : 480530\n",
            "TimeSinceStart : 419.5760176181793\n",
            "Training Loss : 0.015953324735164642\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 234 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2145])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 275.4197082519531\n",
            "Eval_StdReturn : 62.22935485839844\n",
            "Eval_MaxReturn : 320.45953369140625\n",
            "Eval_MinReturn : 187.42233276367188\n",
            "Eval_AverageEpLen : 141.33333333333334\n",
            "Train_AverageReturn : 332.8087158203125\n",
            "Train_StdReturn : 53.25392150878906\n",
            "Train_MaxReturn : 485.772216796875\n",
            "Train_MinReturn : 243.39796447753906\n",
            "Train_AverageEpLen : 165.0\n",
            "Train_EnvstepsSoFar : 482675\n",
            "TimeSinceStart : 421.2493209838867\n",
            "Training Loss : -0.011130204424262047\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 235 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2026])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 377.5057678222656\n",
            "Eval_StdReturn : 32.58823776245117\n",
            "Eval_MaxReturn : 423.5118103027344\n",
            "Eval_MinReturn : 352.1421813964844\n",
            "Eval_AverageEpLen : 182.33333333333334\n",
            "Train_AverageReturn : 338.8142395019531\n",
            "Train_StdReturn : 36.007022857666016\n",
            "Train_MaxReturn : 421.46124267578125\n",
            "Train_MinReturn : 286.1767272949219\n",
            "Train_AverageEpLen : 155.84615384615384\n",
            "Train_EnvstepsSoFar : 484701\n",
            "TimeSinceStart : 422.94030022621155\n",
            "Training Loss : 0.010237443260848522\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 236 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2089])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 393.7158203125\n",
            "Eval_StdReturn : 26.687896728515625\n",
            "Eval_MaxReturn : 420.4037170410156\n",
            "Eval_MinReturn : 367.0279235839844\n",
            "Eval_AverageEpLen : 209.0\n",
            "Train_AverageReturn : 339.8202819824219\n",
            "Train_StdReturn : 48.811824798583984\n",
            "Train_MaxReturn : 381.7850341796875\n",
            "Train_MinReturn : 198.87347412109375\n",
            "Train_AverageEpLen : 160.69230769230768\n",
            "Train_EnvstepsSoFar : 486790\n",
            "TimeSinceStart : 424.62563037872314\n",
            "Training Loss : -0.004105960484594107\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 237 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2107])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 315.6942138671875\n",
            "Eval_StdReturn : 39.43517303466797\n",
            "Eval_MaxReturn : 361.8115234375\n",
            "Eval_MinReturn : 265.47686767578125\n",
            "Eval_AverageEpLen : 147.0\n",
            "Train_AverageReturn : 313.8526916503906\n",
            "Train_StdReturn : 58.25932693481445\n",
            "Train_MaxReturn : 376.008056640625\n",
            "Train_MinReturn : 190.7353973388672\n",
            "Train_AverageEpLen : 150.5\n",
            "Train_EnvstepsSoFar : 488897\n",
            "TimeSinceStart : 426.27551651000977\n",
            "Training Loss : 0.001065156888216734\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 238 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2048])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 333.9499206542969\n",
            "Eval_StdReturn : 42.64860534667969\n",
            "Eval_MaxReturn : 393.8773193359375\n",
            "Eval_MinReturn : 298.07977294921875\n",
            "Eval_AverageEpLen : 166.66666666666666\n",
            "Train_AverageReturn : 328.47412109375\n",
            "Train_StdReturn : 69.16380310058594\n",
            "Train_MaxReturn : 394.36492919921875\n",
            "Train_MinReturn : 182.90232849121094\n",
            "Train_AverageEpLen : 157.53846153846155\n",
            "Train_EnvstepsSoFar : 490945\n",
            "TimeSinceStart : 427.9174757003784\n",
            "Training Loss : 0.013283107429742813\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 239 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2117])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 356.3912658691406\n",
            "Eval_StdReturn : 43.5263557434082\n",
            "Eval_MaxReturn : 408.79254150390625\n",
            "Eval_MinReturn : 302.21929931640625\n",
            "Eval_AverageEpLen : 167.66666666666666\n",
            "Train_AverageReturn : 320.81170654296875\n",
            "Train_StdReturn : 57.611358642578125\n",
            "Train_MaxReturn : 392.31707763671875\n",
            "Train_MinReturn : 176.59213256835938\n",
            "Train_AverageEpLen : 151.21428571428572\n",
            "Train_EnvstepsSoFar : 493062\n",
            "TimeSinceStart : 429.65908122062683\n",
            "Training Loss : 0.012489652261137962\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 240 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2005])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 315.5531311035156\n",
            "Eval_StdReturn : 28.796794891357422\n",
            "Eval_MaxReturn : 356.2374572753906\n",
            "Eval_MinReturn : 293.63897705078125\n",
            "Eval_AverageEpLen : 152.66666666666666\n",
            "Train_AverageReturn : 335.2858581542969\n",
            "Train_StdReturn : 46.79953384399414\n",
            "Train_MaxReturn : 431.62664794921875\n",
            "Train_MinReturn : 236.71018981933594\n",
            "Train_AverageEpLen : 154.23076923076923\n",
            "Train_EnvstepsSoFar : 495067\n",
            "TimeSinceStart : 431.2763831615448\n",
            "Training Loss : 0.020821060985326767\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 241 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2002])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 333.0647277832031\n",
            "Eval_StdReturn : 14.714167594909668\n",
            "Eval_MaxReturn : 352.7557373046875\n",
            "Eval_MinReturn : 317.391845703125\n",
            "Eval_AverageEpLen : 161.0\n",
            "Train_AverageReturn : 311.3648681640625\n",
            "Train_StdReturn : 41.74480438232422\n",
            "Train_MaxReturn : 378.9479675292969\n",
            "Train_MinReturn : 238.46255493164062\n",
            "Train_AverageEpLen : 154.0\n",
            "Train_EnvstepsSoFar : 497069\n",
            "TimeSinceStart : 432.8901176452637\n",
            "Training Loss : 0.014840718358755112\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 242 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2005])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 325.5807800292969\n",
            "Eval_StdReturn : 44.12798309326172\n",
            "Eval_MaxReturn : 374.14654541015625\n",
            "Eval_MinReturn : 267.35760498046875\n",
            "Eval_AverageEpLen : 157.66666666666666\n",
            "Train_AverageReturn : 324.6771240234375\n",
            "Train_StdReturn : 29.820655822753906\n",
            "Train_MaxReturn : 379.3611145019531\n",
            "Train_MinReturn : 275.29937744140625\n",
            "Train_AverageEpLen : 154.23076923076923\n",
            "Train_EnvstepsSoFar : 499074\n",
            "TimeSinceStart : 434.5130956172943\n",
            "Training Loss : -0.004104121122509241\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 243 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2001])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 323.2040710449219\n",
            "Eval_StdReturn : 24.850801467895508\n",
            "Eval_MaxReturn : 341.1020812988281\n",
            "Eval_MinReturn : 288.061767578125\n",
            "Eval_AverageEpLen : 159.66666666666666\n",
            "Train_AverageReturn : 317.3712463378906\n",
            "Train_StdReturn : 91.66802978515625\n",
            "Train_MaxReturn : 492.86761474609375\n",
            "Train_MinReturn : 171.44363403320312\n",
            "Train_AverageEpLen : 153.92307692307693\n",
            "Train_EnvstepsSoFar : 501075\n",
            "TimeSinceStart : 436.11081171035767\n",
            "Training Loss : 0.0012978874146938324\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 244 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2103])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 343.2440185546875\n",
            "Eval_StdReturn : 45.38557815551758\n",
            "Eval_MaxReturn : 387.562744140625\n",
            "Eval_MinReturn : 280.87689208984375\n",
            "Eval_AverageEpLen : 167.0\n",
            "Train_AverageReturn : 339.1546325683594\n",
            "Train_StdReturn : 56.78849792480469\n",
            "Train_MaxReturn : 445.4939880371094\n",
            "Train_MinReturn : 242.79078674316406\n",
            "Train_AverageEpLen : 161.76923076923077\n",
            "Train_EnvstepsSoFar : 503178\n",
            "TimeSinceStart : 437.80391216278076\n",
            "Training Loss : -0.002573267323896289\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 245 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2075])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 346.7460021972656\n",
            "Eval_StdReturn : 58.561553955078125\n",
            "Eval_MaxReturn : 424.28350830078125\n",
            "Eval_MinReturn : 282.77532958984375\n",
            "Eval_AverageEpLen : 178.33333333333334\n",
            "Train_AverageReturn : 313.10736083984375\n",
            "Train_StdReturn : 38.62624740600586\n",
            "Train_MaxReturn : 383.00335693359375\n",
            "Train_MinReturn : 244.05758666992188\n",
            "Train_AverageEpLen : 159.6153846153846\n",
            "Train_EnvstepsSoFar : 505253\n",
            "TimeSinceStart : 439.48901081085205\n",
            "Training Loss : 0.006120339967310429\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 246 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2105])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 285.85601806640625\n",
            "Eval_StdReturn : 95.98265075683594\n",
            "Eval_MaxReturn : 354.51776123046875\n",
            "Eval_MinReturn : 150.119140625\n",
            "Eval_AverageEpLen : 138.33333333333334\n",
            "Train_AverageReturn : 315.69085693359375\n",
            "Train_StdReturn : 43.22826385498047\n",
            "Train_MaxReturn : 372.72113037109375\n",
            "Train_MinReturn : 233.57615661621094\n",
            "Train_AverageEpLen : 150.35714285714286\n",
            "Train_EnvstepsSoFar : 507358\n",
            "TimeSinceStart : 441.7597608566284\n",
            "Training Loss : -0.012158582918345928\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 247 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2028])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 300.4325866699219\n",
            "Eval_StdReturn : 15.620348930358887\n",
            "Eval_MaxReturn : 322.4933166503906\n",
            "Eval_MinReturn : 288.40948486328125\n",
            "Eval_AverageEpLen : 149.66666666666666\n",
            "Train_AverageReturn : 327.44671630859375\n",
            "Train_StdReturn : 62.4591064453125\n",
            "Train_MaxReturn : 480.21905517578125\n",
            "Train_MinReturn : 226.98892211914062\n",
            "Train_AverageEpLen : 156.0\n",
            "Train_EnvstepsSoFar : 509386\n",
            "TimeSinceStart : 443.46670484542847\n",
            "Training Loss : -0.04367842897772789\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 248 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2079])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 393.9449768066406\n",
            "Eval_StdReturn : 62.264156341552734\n",
            "Eval_MaxReturn : 467.52740478515625\n",
            "Eval_MinReturn : 315.26751708984375\n",
            "Eval_AverageEpLen : 190.66666666666666\n",
            "Train_AverageReturn : 353.205078125\n",
            "Train_StdReturn : 55.24559020996094\n",
            "Train_MaxReturn : 446.904296875\n",
            "Train_MinReturn : 215.16165161132812\n",
            "Train_AverageEpLen : 173.25\n",
            "Train_EnvstepsSoFar : 511465\n",
            "TimeSinceStart : 445.2009325027466\n",
            "Training Loss : -0.004328185226768255\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 249 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 350.8150634765625\n",
            "Eval_StdReturn : 22.15162467956543\n",
            "Eval_MaxReturn : 376.2186279296875\n",
            "Eval_MinReturn : 322.2376403808594\n",
            "Eval_AverageEpLen : 165.0\n",
            "Train_AverageReturn : 336.9454345703125\n",
            "Train_StdReturn : 38.707000732421875\n",
            "Train_MaxReturn : 381.7492980957031\n",
            "Train_MinReturn : 241.90658569335938\n",
            "Train_AverageEpLen : 165.92307692307693\n",
            "Train_EnvstepsSoFar : 513622\n",
            "TimeSinceStart : 446.91079235076904\n",
            "Training Loss : 0.02210729941725731\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 250 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2001])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 342.2249755859375\n",
            "Eval_StdReturn : 47.76298522949219\n",
            "Eval_MaxReturn : 406.3327331542969\n",
            "Eval_MinReturn : 291.74285888671875\n",
            "Eval_AverageEpLen : 165.0\n",
            "Train_AverageReturn : 313.10662841796875\n",
            "Train_StdReturn : 78.97635650634766\n",
            "Train_MaxReturn : 386.7989501953125\n",
            "Train_MinReturn : 113.2635726928711\n",
            "Train_AverageEpLen : 153.92307692307693\n",
            "Train_EnvstepsSoFar : 515623\n",
            "TimeSinceStart : 448.52790236473083\n",
            "Training Loss : -0.05547924339771271\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 251 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2012])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 461.31329345703125\n",
            "Eval_StdReturn : 1.5488739013671875\n",
            "Eval_MaxReturn : 462.8621520996094\n",
            "Eval_MinReturn : 459.764404296875\n",
            "Eval_AverageEpLen : 235.5\n",
            "Train_AverageReturn : 326.0190124511719\n",
            "Train_StdReturn : 75.6533432006836\n",
            "Train_MaxReturn : 430.6058654785156\n",
            "Train_MinReturn : 206.6664276123047\n",
            "Train_AverageEpLen : 167.66666666666666\n",
            "Train_EnvstepsSoFar : 517635\n",
            "TimeSinceStart : 450.1617579460144\n",
            "Training Loss : 0.019581707194447517\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 252 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2082])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 307.9679260253906\n",
            "Eval_StdReturn : 14.177197456359863\n",
            "Eval_MaxReturn : 319.4798278808594\n",
            "Eval_MinReturn : 287.99591064453125\n",
            "Eval_AverageEpLen : 134.33333333333334\n",
            "Train_AverageReturn : 323.02642822265625\n",
            "Train_StdReturn : 60.72554016113281\n",
            "Train_MaxReturn : 487.5835266113281\n",
            "Train_MinReturn : 230.77818298339844\n",
            "Train_AverageEpLen : 160.15384615384616\n",
            "Train_EnvstepsSoFar : 519717\n",
            "TimeSinceStart : 451.78244066238403\n",
            "Training Loss : -0.03367451950907707\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 253 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2056])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 345.0592041015625\n",
            "Eval_StdReturn : 13.930340766906738\n",
            "Eval_MaxReturn : 362.7283935546875\n",
            "Eval_MinReturn : 328.6793212890625\n",
            "Eval_AverageEpLen : 173.33333333333334\n",
            "Train_AverageReturn : 364.4615478515625\n",
            "Train_StdReturn : 52.96546173095703\n",
            "Train_MaxReturn : 486.2385559082031\n",
            "Train_MinReturn : 287.0010070800781\n",
            "Train_AverageEpLen : 171.33333333333334\n",
            "Train_EnvstepsSoFar : 521773\n",
            "TimeSinceStart : 454.0574872493744\n",
            "Training Loss : 0.04418782517313957\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 254 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2146])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 312.3045349121094\n",
            "Eval_StdReturn : 40.94231414794922\n",
            "Eval_MaxReturn : 348.29541015625\n",
            "Eval_MinReturn : 255.029296875\n",
            "Eval_AverageEpLen : 150.66666666666666\n",
            "Train_AverageReturn : 324.2426452636719\n",
            "Train_StdReturn : 50.407501220703125\n",
            "Train_MaxReturn : 407.34033203125\n",
            "Train_MinReturn : 188.81788635253906\n",
            "Train_AverageEpLen : 165.07692307692307\n",
            "Train_EnvstepsSoFar : 523919\n",
            "TimeSinceStart : 457.17971873283386\n",
            "Training Loss : 0.006447875406593084\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 255 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2139])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 327.42144775390625\n",
            "Eval_StdReturn : 40.2137565612793\n",
            "Eval_MaxReturn : 361.47576904296875\n",
            "Eval_MinReturn : 270.94879150390625\n",
            "Eval_AverageEpLen : 157.0\n",
            "Train_AverageReturn : 336.4621276855469\n",
            "Train_StdReturn : 35.441993713378906\n",
            "Train_MaxReturn : 392.6591796875\n",
            "Train_MinReturn : 280.164794921875\n",
            "Train_AverageEpLen : 164.53846153846155\n",
            "Train_EnvstepsSoFar : 526058\n",
            "TimeSinceStart : 459.31813502311707\n",
            "Training Loss : 0.003800867823883891\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 256 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2053])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 313.9598083496094\n",
            "Eval_StdReturn : 19.4318790435791\n",
            "Eval_MaxReturn : 341.44024658203125\n",
            "Eval_MinReturn : 300.09454345703125\n",
            "Eval_AverageEpLen : 148.0\n",
            "Train_AverageReturn : 363.38055419921875\n",
            "Train_StdReturn : 73.93531036376953\n",
            "Train_MaxReturn : 509.1219177246094\n",
            "Train_MinReturn : 273.1598205566406\n",
            "Train_AverageEpLen : 186.63636363636363\n",
            "Train_EnvstepsSoFar : 528111\n",
            "TimeSinceStart : 461.29739332199097\n",
            "Training Loss : -0.01020073052495718\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 257 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2021])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 413.1151123046875\n",
            "Eval_StdReturn : 50.819580078125\n",
            "Eval_MaxReturn : 463.9346923828125\n",
            "Eval_MinReturn : 362.2955322265625\n",
            "Eval_AverageEpLen : 216.5\n",
            "Train_AverageReturn : 337.6011962890625\n",
            "Train_StdReturn : 72.27776336669922\n",
            "Train_MaxReturn : 426.7804260253906\n",
            "Train_MinReturn : 150.6143798828125\n",
            "Train_AverageEpLen : 168.41666666666666\n",
            "Train_EnvstepsSoFar : 530132\n",
            "TimeSinceStart : 462.89346051216125\n",
            "Training Loss : -0.021719694137573242\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 258 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2078])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 339.7742614746094\n",
            "Eval_StdReturn : 44.77385711669922\n",
            "Eval_MaxReturn : 388.9810791015625\n",
            "Eval_MinReturn : 280.6590576171875\n",
            "Eval_AverageEpLen : 159.66666666666666\n",
            "Train_AverageReturn : 384.0525207519531\n",
            "Train_StdReturn : 49.32136535644531\n",
            "Train_MaxReturn : 468.5155029296875\n",
            "Train_MinReturn : 293.93963623046875\n",
            "Train_AverageEpLen : 188.9090909090909\n",
            "Train_EnvstepsSoFar : 532210\n",
            "TimeSinceStart : 464.5557725429535\n",
            "Training Loss : -0.04965607821941376\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 259 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2061])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 392.33056640625\n",
            "Eval_StdReturn : 53.61124801635742\n",
            "Eval_MaxReturn : 467.1037902832031\n",
            "Eval_MinReturn : 344.0823669433594\n",
            "Eval_AverageEpLen : 193.66666666666666\n",
            "Train_AverageReturn : 352.5605163574219\n",
            "Train_StdReturn : 36.67310333251953\n",
            "Train_MaxReturn : 423.4283142089844\n",
            "Train_MinReturn : 305.5103759765625\n",
            "Train_AverageEpLen : 171.75\n",
            "Train_EnvstepsSoFar : 534271\n",
            "TimeSinceStart : 466.2584912776947\n",
            "Training Loss : -0.006648094858974218\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 260 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2096])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 379.6871337890625\n",
            "Eval_StdReturn : 4.672877788543701\n",
            "Eval_MaxReturn : 385.05029296875\n",
            "Eval_MinReturn : 373.6617431640625\n",
            "Eval_AverageEpLen : 189.33333333333334\n",
            "Train_AverageReturn : 385.05010986328125\n",
            "Train_StdReturn : 22.419002532958984\n",
            "Train_MaxReturn : 427.75946044921875\n",
            "Train_MinReturn : 347.93408203125\n",
            "Train_AverageEpLen : 190.54545454545453\n",
            "Train_EnvstepsSoFar : 536367\n",
            "TimeSinceStart : 468.0129454135895\n",
            "Training Loss : 0.007937240414321423\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 261 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2052])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 363.848388671875\n",
            "Eval_StdReturn : 24.595321655273438\n",
            "Eval_MaxReturn : 383.50994873046875\n",
            "Eval_MinReturn : 329.1688232421875\n",
            "Eval_AverageEpLen : 169.0\n",
            "Train_AverageReturn : 326.59149169921875\n",
            "Train_StdReturn : 87.7860336303711\n",
            "Train_MaxReturn : 464.09197998046875\n",
            "Train_MinReturn : 115.98390197753906\n",
            "Train_AverageEpLen : 157.84615384615384\n",
            "Train_EnvstepsSoFar : 538419\n",
            "TimeSinceStart : 469.65276074409485\n",
            "Training Loss : 0.04044892638921738\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 262 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2004])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 364.0270690917969\n",
            "Eval_StdReturn : 15.535526275634766\n",
            "Eval_MaxReturn : 379.1971435546875\n",
            "Eval_MinReturn : 342.67864990234375\n",
            "Eval_AverageEpLen : 162.0\n",
            "Train_AverageReturn : 348.9456787109375\n",
            "Train_StdReturn : 57.00783920288086\n",
            "Train_MaxReturn : 410.9619140625\n",
            "Train_MinReturn : 180.06777954101562\n",
            "Train_AverageEpLen : 167.0\n",
            "Train_EnvstepsSoFar : 540423\n",
            "TimeSinceStart : 471.2679364681244\n",
            "Training Loss : -0.024353861808776855\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 263 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2170])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 284.57989501953125\n",
            "Eval_StdReturn : 53.64763641357422\n",
            "Eval_MaxReturn : 334.7862548828125\n",
            "Eval_MinReturn : 210.21624755859375\n",
            "Eval_AverageEpLen : 137.0\n",
            "Train_AverageReturn : 393.4344787597656\n",
            "Train_StdReturn : 60.45924377441406\n",
            "Train_MaxReturn : 523.5164794921875\n",
            "Train_MinReturn : 322.55499267578125\n",
            "Train_AverageEpLen : 180.83333333333334\n",
            "Train_EnvstepsSoFar : 542593\n",
            "TimeSinceStart : 472.9348051548004\n",
            "Training Loss : 0.03718011826276779\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 264 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2116])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 279.6956481933594\n",
            "Eval_StdReturn : 109.71123504638672\n",
            "Eval_MaxReturn : 416.84100341796875\n",
            "Eval_MinReturn : 148.28829956054688\n",
            "Eval_AverageEpLen : 138.66666666666666\n",
            "Train_AverageReturn : 333.68621826171875\n",
            "Train_StdReturn : 39.63246536254883\n",
            "Train_MaxReturn : 402.91851806640625\n",
            "Train_MinReturn : 264.89898681640625\n",
            "Train_AverageEpLen : 162.76923076923077\n",
            "Train_EnvstepsSoFar : 544709\n",
            "TimeSinceStart : 474.5878903865814\n",
            "Training Loss : 0.005372766871005297\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 265 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2121])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 463.2892150878906\n",
            "Eval_StdReturn : 40.151885986328125\n",
            "Eval_MaxReturn : 503.44110107421875\n",
            "Eval_MinReturn : 423.1373291015625\n",
            "Eval_AverageEpLen : 226.5\n",
            "Train_AverageReturn : 367.5632629394531\n",
            "Train_StdReturn : 25.99864959716797\n",
            "Train_MaxReturn : 431.13995361328125\n",
            "Train_MinReturn : 331.9388732910156\n",
            "Train_AverageEpLen : 176.75\n",
            "Train_EnvstepsSoFar : 546830\n",
            "TimeSinceStart : 477.65454721450806\n",
            "Training Loss : -0.03061661683022976\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 266 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2097])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 361.9833068847656\n",
            "Eval_StdReturn : 27.690153121948242\n",
            "Eval_MaxReturn : 383.6837158203125\n",
            "Eval_MinReturn : 322.903076171875\n",
            "Eval_AverageEpLen : 168.33333333333334\n",
            "Train_AverageReturn : 338.7110595703125\n",
            "Train_StdReturn : 62.08448028564453\n",
            "Train_MaxReturn : 435.355712890625\n",
            "Train_MinReturn : 157.74664306640625\n",
            "Train_AverageEpLen : 161.30769230769232\n",
            "Train_EnvstepsSoFar : 548927\n",
            "TimeSinceStart : 479.3634102344513\n",
            "Training Loss : -0.014620838686823845\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 267 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2049])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 408.2083435058594\n",
            "Eval_StdReturn : 30.77480125427246\n",
            "Eval_MaxReturn : 443.021728515625\n",
            "Eval_MinReturn : 368.181884765625\n",
            "Eval_AverageEpLen : 180.66666666666666\n",
            "Train_AverageReturn : 329.53814697265625\n",
            "Train_StdReturn : 88.90875244140625\n",
            "Train_MaxReturn : 466.5805358886719\n",
            "Train_MinReturn : 127.37371826171875\n",
            "Train_AverageEpLen : 157.6153846153846\n",
            "Train_EnvstepsSoFar : 550976\n",
            "TimeSinceStart : 481.02377820014954\n",
            "Training Loss : -0.0541958212852478\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 268 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2112])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 388.997314453125\n",
            "Eval_StdReturn : 12.80670166015625\n",
            "Eval_MaxReturn : 401.80401611328125\n",
            "Eval_MinReturn : 376.19061279296875\n",
            "Eval_AverageEpLen : 213.5\n",
            "Train_AverageReturn : 345.4936218261719\n",
            "Train_StdReturn : 41.98447799682617\n",
            "Train_MaxReturn : 404.61749267578125\n",
            "Train_MinReturn : 274.4618835449219\n",
            "Train_AverageEpLen : 162.46153846153845\n",
            "Train_EnvstepsSoFar : 553088\n",
            "TimeSinceStart : 482.6931617259979\n",
            "Training Loss : 0.01800377666950226\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 269 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2079])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 331.8882141113281\n",
            "Eval_StdReturn : 38.18085479736328\n",
            "Eval_MaxReturn : 382.7926330566406\n",
            "Eval_MinReturn : 290.8404235839844\n",
            "Eval_AverageEpLen : 159.0\n",
            "Train_AverageReturn : 363.5115661621094\n",
            "Train_StdReturn : 43.09449768066406\n",
            "Train_MaxReturn : 449.5596618652344\n",
            "Train_MinReturn : 283.26898193359375\n",
            "Train_AverageEpLen : 173.25\n",
            "Train_EnvstepsSoFar : 555167\n",
            "TimeSinceStart : 484.39605927467346\n",
            "Training Loss : 0.031074946746230125\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 270 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2082])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 313.07281494140625\n",
            "Eval_StdReturn : 74.41486358642578\n",
            "Eval_MaxReturn : 384.0141906738281\n",
            "Eval_MinReturn : 210.2831268310547\n",
            "Eval_AverageEpLen : 153.33333333333334\n",
            "Train_AverageReturn : 367.349853515625\n",
            "Train_StdReturn : 105.04252624511719\n",
            "Train_MaxReturn : 560.0335083007812\n",
            "Train_MinReturn : 150.2228546142578\n",
            "Train_AverageEpLen : 173.5\n",
            "Train_EnvstepsSoFar : 557249\n",
            "TimeSinceStart : 486.0497615337372\n",
            "Training Loss : -0.038514986634254456\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 271 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2102])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 301.2512512207031\n",
            "Eval_StdReturn : 47.448368072509766\n",
            "Eval_MaxReturn : 344.3031921386719\n",
            "Eval_MinReturn : 235.15040588378906\n",
            "Eval_AverageEpLen : 147.33333333333334\n",
            "Train_AverageReturn : 341.6933288574219\n",
            "Train_StdReturn : 63.736019134521484\n",
            "Train_MaxReturn : 417.27716064453125\n",
            "Train_MinReturn : 167.4134521484375\n",
            "Train_AverageEpLen : 161.69230769230768\n",
            "Train_EnvstepsSoFar : 559351\n",
            "TimeSinceStart : 487.6996476650238\n",
            "Training Loss : -0.02034624293446541\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 272 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2088])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 382.5286560058594\n",
            "Eval_StdReturn : 13.959535598754883\n",
            "Eval_MaxReturn : 401.04803466796875\n",
            "Eval_MinReturn : 367.34637451171875\n",
            "Eval_AverageEpLen : 173.0\n",
            "Train_AverageReturn : 371.4246520996094\n",
            "Train_StdReturn : 94.0394287109375\n",
            "Train_MaxReturn : 603.3148193359375\n",
            "Train_MinReturn : 171.0958251953125\n",
            "Train_AverageEpLen : 174.0\n",
            "Train_EnvstepsSoFar : 561439\n",
            "TimeSinceStart : 489.3853933811188\n",
            "Training Loss : -0.04907672479748726\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 273 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2107])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 354.3849182128906\n",
            "Eval_StdReturn : 40.778343200683594\n",
            "Eval_MaxReturn : 398.8455810546875\n",
            "Eval_MinReturn : 300.34661865234375\n",
            "Eval_AverageEpLen : 167.0\n",
            "Train_AverageReturn : 327.7544250488281\n",
            "Train_StdReturn : 117.38554382324219\n",
            "Train_MaxReturn : 496.70855712890625\n",
            "Train_MinReturn : 80.9046401977539\n",
            "Train_AverageEpLen : 162.07692307692307\n",
            "Train_EnvstepsSoFar : 563546\n",
            "TimeSinceStart : 491.1190092563629\n",
            "Training Loss : 0.024619633331894875\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 274 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2147])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 357.41748046875\n",
            "Eval_StdReturn : 46.088680267333984\n",
            "Eval_MaxReturn : 421.47308349609375\n",
            "Eval_MinReturn : 314.9537658691406\n",
            "Eval_AverageEpLen : 170.66666666666666\n",
            "Train_AverageReturn : 391.8306579589844\n",
            "Train_StdReturn : 72.8538818359375\n",
            "Train_MaxReturn : 527.3421630859375\n",
            "Train_MinReturn : 306.1893310546875\n",
            "Train_AverageEpLen : 195.1818181818182\n",
            "Train_EnvstepsSoFar : 565693\n",
            "TimeSinceStart : 492.8708403110504\n",
            "Training Loss : -0.007214331533759832\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 275 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2103])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 387.3973083496094\n",
            "Eval_StdReturn : 107.10910034179688\n",
            "Eval_MaxReturn : 494.50640869140625\n",
            "Eval_MinReturn : 280.2882080078125\n",
            "Eval_AverageEpLen : 206.0\n",
            "Train_AverageReturn : 344.7532043457031\n",
            "Train_StdReturn : 60.61066436767578\n",
            "Train_MaxReturn : 484.92584228515625\n",
            "Train_MinReturn : 213.9806671142578\n",
            "Train_AverageEpLen : 161.76923076923077\n",
            "Train_EnvstepsSoFar : 567796\n",
            "TimeSinceStart : 494.54464411735535\n",
            "Training Loss : -0.06758993119001389\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 276 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2097])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 378.3212890625\n",
            "Eval_StdReturn : 75.42024993896484\n",
            "Eval_MaxReturn : 480.9068298339844\n",
            "Eval_MinReturn : 301.74066162109375\n",
            "Eval_AverageEpLen : 175.66666666666666\n",
            "Train_AverageReturn : 324.8452453613281\n",
            "Train_StdReturn : 105.60320281982422\n",
            "Train_MaxReturn : 449.8202819824219\n",
            "Train_MinReturn : 99.1704330444336\n",
            "Train_AverageEpLen : 161.30769230769232\n",
            "Train_EnvstepsSoFar : 569893\n",
            "TimeSinceStart : 496.2441246509552\n",
            "Training Loss : -0.005770242772996426\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 277 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2059])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 402.6403503417969\n",
            "Eval_StdReturn : 18.54990005493164\n",
            "Eval_MaxReturn : 423.1754455566406\n",
            "Eval_MinReturn : 378.2348937988281\n",
            "Eval_AverageEpLen : 191.0\n",
            "Train_AverageReturn : 391.415283203125\n",
            "Train_StdReturn : 83.42019653320312\n",
            "Train_MaxReturn : 544.6395874023438\n",
            "Train_MinReturn : 289.5309143066406\n",
            "Train_AverageEpLen : 182.91666666666666\n",
            "Train_EnvstepsSoFar : 572088\n",
            "TimeSinceStart : 498.0208613872528\n",
            "Training Loss : 0.043245162814855576\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 278 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2130])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 485.0927429199219\n",
            "Eval_StdReturn : 73.40884399414062\n",
            "Eval_MaxReturn : 558.5015869140625\n",
            "Eval_MinReturn : 411.68389892578125\n",
            "Eval_AverageEpLen : 209.5\n",
            "Train_AverageReturn : 347.6072082519531\n",
            "Train_StdReturn : 75.95436096191406\n",
            "Train_MaxReturn : 524.918212890625\n",
            "Train_MinReturn : 210.80108642578125\n",
            "Train_AverageEpLen : 163.84615384615384\n",
            "Train_EnvstepsSoFar : 574218\n",
            "TimeSinceStart : 499.6641671657562\n",
            "Training Loss : 0.00593545800074935\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 279 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2083])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 310.7468566894531\n",
            "Eval_StdReturn : 195.65890502929688\n",
            "Eval_MaxReturn : 566.8807373046875\n",
            "Eval_MinReturn : 92.01466369628906\n",
            "Eval_AverageEpLen : 143.0\n",
            "Train_AverageReturn : 369.3305969238281\n",
            "Train_StdReturn : 92.76631164550781\n",
            "Train_MaxReturn : 622.6194458007812\n",
            "Train_MinReturn : 205.7535400390625\n",
            "Train_AverageEpLen : 173.58333333333334\n",
            "Train_EnvstepsSoFar : 576301\n",
            "TimeSinceStart : 501.2969801425934\n",
            "Training Loss : 0.011076664552092552\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 280 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2062])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 310.4437561035156\n",
            "Eval_StdReturn : 64.70442199707031\n",
            "Eval_MaxReturn : 401.2015380859375\n",
            "Eval_MinReturn : 254.95223999023438\n",
            "Eval_AverageEpLen : 155.33333333333334\n",
            "Train_AverageReturn : 368.4994201660156\n",
            "Train_StdReturn : 99.34774017333984\n",
            "Train_MaxReturn : 554.409423828125\n",
            "Train_MinReturn : 117.02191162109375\n",
            "Train_AverageEpLen : 171.83333333333334\n",
            "Train_EnvstepsSoFar : 578363\n",
            "TimeSinceStart : 502.918461561203\n",
            "Training Loss : 0.011556548066437244\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 281 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2009])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 318.4448547363281\n",
            "Eval_StdReturn : 34.19785690307617\n",
            "Eval_MaxReturn : 366.291015625\n",
            "Eval_MinReturn : 288.41448974609375\n",
            "Eval_AverageEpLen : 143.66666666666666\n",
            "Train_AverageReturn : 384.6763916015625\n",
            "Train_StdReturn : 71.43810272216797\n",
            "Train_MaxReturn : 544.0916748046875\n",
            "Train_MinReturn : 291.9569091796875\n",
            "Train_AverageEpLen : 182.63636363636363\n",
            "Train_EnvstepsSoFar : 580372\n",
            "TimeSinceStart : 504.4963393211365\n",
            "Training Loss : 0.009487083181738853\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 282 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2028])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 364.7532653808594\n",
            "Eval_StdReturn : 41.236061096191406\n",
            "Eval_MaxReturn : 423.0653381347656\n",
            "Eval_MinReturn : 334.96966552734375\n",
            "Eval_AverageEpLen : 182.33333333333334\n",
            "Train_AverageReturn : 371.59613037109375\n",
            "Train_StdReturn : 92.10486602783203\n",
            "Train_MaxReturn : 548.0662841796875\n",
            "Train_MinReturn : 236.5906219482422\n",
            "Train_AverageEpLen : 184.36363636363637\n",
            "Train_EnvstepsSoFar : 582400\n",
            "TimeSinceStart : 506.16225838661194\n",
            "Training Loss : 0.0035237297415733337\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 283 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2081])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 409.1679382324219\n",
            "Eval_StdReturn : 20.424753189086914\n",
            "Eval_MaxReturn : 437.9159851074219\n",
            "Eval_MinReturn : 392.361328125\n",
            "Eval_AverageEpLen : 204.0\n",
            "Train_AverageReturn : 315.4367980957031\n",
            "Train_StdReturn : 111.65644073486328\n",
            "Train_MaxReturn : 601.814453125\n",
            "Train_MinReturn : 113.2422103881836\n",
            "Train_AverageEpLen : 148.64285714285714\n",
            "Train_EnvstepsSoFar : 584481\n",
            "TimeSinceStart : 507.9023401737213\n",
            "Training Loss : -0.03611751273274422\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 284 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2069])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 370.5652160644531\n",
            "Eval_StdReturn : 89.05475616455078\n",
            "Eval_MaxReturn : 482.2247314453125\n",
            "Eval_MinReturn : 264.28509521484375\n",
            "Eval_AverageEpLen : 178.0\n",
            "Train_AverageReturn : 315.1653747558594\n",
            "Train_StdReturn : 75.57501220703125\n",
            "Train_MaxReturn : 416.508544921875\n",
            "Train_MinReturn : 146.06353759765625\n",
            "Train_AverageEpLen : 147.78571428571428\n",
            "Train_EnvstepsSoFar : 586550\n",
            "TimeSinceStart : 509.5595531463623\n",
            "Training Loss : 0.039470475167036057\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 285 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2036])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 376.1909484863281\n",
            "Eval_StdReturn : 70.19512939453125\n",
            "Eval_MaxReturn : 473.51519775390625\n",
            "Eval_MinReturn : 310.5869140625\n",
            "Eval_AverageEpLen : 171.66666666666666\n",
            "Train_AverageReturn : 358.2567443847656\n",
            "Train_StdReturn : 106.43777465820312\n",
            "Train_MaxReturn : 507.3011169433594\n",
            "Train_MinReturn : 127.69508361816406\n",
            "Train_AverageEpLen : 169.66666666666666\n",
            "Train_EnvstepsSoFar : 588586\n",
            "TimeSinceStart : 511.19377422332764\n",
            "Training Loss : 0.01795634813606739\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 286 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 324.0901184082031\n",
            "Eval_StdReturn : 58.967506408691406\n",
            "Eval_MaxReturn : 407.1536865234375\n",
            "Eval_MinReturn : 276.14874267578125\n",
            "Eval_AverageEpLen : 151.66666666666666\n",
            "Train_AverageReturn : 345.02008056640625\n",
            "Train_StdReturn : 77.11475372314453\n",
            "Train_MaxReturn : 526.8421630859375\n",
            "Train_MinReturn : 177.42752075195312\n",
            "Train_AverageEpLen : 161.53846153846155\n",
            "Train_EnvstepsSoFar : 590686\n",
            "TimeSinceStart : 512.8621108531952\n",
            "Training Loss : 0.025511663407087326\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 287 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 373.4425354003906\n",
            "Eval_StdReturn : 124.67259216308594\n",
            "Eval_MaxReturn : 538.5208740234375\n",
            "Eval_MinReturn : 237.2681121826172\n",
            "Eval_AverageEpLen : 171.0\n",
            "Train_AverageReturn : 378.5328063964844\n",
            "Train_StdReturn : 95.97317504882812\n",
            "Train_MaxReturn : 548.4345703125\n",
            "Train_MinReturn : 251.5680694580078\n",
            "Train_AverageEpLen : 186.36363636363637\n",
            "Train_EnvstepsSoFar : 592736\n",
            "TimeSinceStart : 514.5420062541962\n",
            "Training Loss : 0.039608366787433624\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 288 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2091])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 372.2645568847656\n",
            "Eval_StdReturn : 18.396005630493164\n",
            "Eval_MaxReturn : 386.43389892578125\n",
            "Eval_MinReturn : 346.28436279296875\n",
            "Eval_AverageEpLen : 187.0\n",
            "Train_AverageReturn : 402.390625\n",
            "Train_StdReturn : 93.40374755859375\n",
            "Train_MaxReturn : 557.2722778320312\n",
            "Train_MinReturn : 264.760009765625\n",
            "Train_AverageEpLen : 190.0909090909091\n",
            "Train_EnvstepsSoFar : 594827\n",
            "TimeSinceStart : 518.5669603347778\n",
            "Training Loss : -0.022023886442184448\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 289 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2083])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 317.2645568847656\n",
            "Eval_StdReturn : 97.55451202392578\n",
            "Eval_MaxReturn : 387.10308837890625\n",
            "Eval_MinReturn : 179.30520629882812\n",
            "Eval_AverageEpLen : 154.66666666666666\n",
            "Train_AverageReturn : 295.19085693359375\n",
            "Train_StdReturn : 117.34428405761719\n",
            "Train_MaxReturn : 488.3109130859375\n",
            "Train_MinReturn : 82.76248931884766\n",
            "Train_AverageEpLen : 148.78571428571428\n",
            "Train_EnvstepsSoFar : 596910\n",
            "TimeSinceStart : 522.8090078830719\n",
            "Training Loss : 0.006975165102630854\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 290 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2030])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 447.7651062011719\n",
            "Eval_StdReturn : 12.182769775390625\n",
            "Eval_MaxReturn : 459.9478759765625\n",
            "Eval_MinReturn : 435.58233642578125\n",
            "Eval_AverageEpLen : 200.0\n",
            "Train_AverageReturn : 350.0609130859375\n",
            "Train_StdReturn : 108.19264221191406\n",
            "Train_MaxReturn : 530.30224609375\n",
            "Train_MinReturn : 161.7516632080078\n",
            "Train_AverageEpLen : 169.16666666666666\n",
            "Train_EnvstepsSoFar : 598940\n",
            "TimeSinceStart : 526.3580107688904\n",
            "Training Loss : -0.04889748990535736\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 291 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2078])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 302.7890930175781\n",
            "Eval_StdReturn : 59.922271728515625\n",
            "Eval_MaxReturn : 383.7618408203125\n",
            "Eval_MinReturn : 240.65603637695312\n",
            "Eval_AverageEpLen : 161.33333333333334\n",
            "Train_AverageReturn : 351.57232666015625\n",
            "Train_StdReturn : 69.0943603515625\n",
            "Train_MaxReturn : 432.431884765625\n",
            "Train_MinReturn : 162.6591339111328\n",
            "Train_AverageEpLen : 167.69230769230768\n",
            "Train_EnvstepsSoFar : 601120\n",
            "TimeSinceStart : 529.8387434482574\n",
            "Training Loss : 0.02239292673766613\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 292 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2118])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 525.7451782226562\n",
            "Eval_StdReturn : 60.21868896484375\n",
            "Eval_MaxReturn : 585.9638671875\n",
            "Eval_MinReturn : 465.5264892578125\n",
            "Eval_AverageEpLen : 249.5\n",
            "Train_AverageReturn : 339.11474609375\n",
            "Train_StdReturn : 92.50103759765625\n",
            "Train_MaxReturn : 446.22332763671875\n",
            "Train_MinReturn : 89.22991180419922\n",
            "Train_AverageEpLen : 162.92307692307693\n",
            "Train_EnvstepsSoFar : 603238\n",
            "TimeSinceStart : 531.6264762878418\n",
            "Training Loss : 0.0401943065226078\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 293 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2014])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 281.6674499511719\n",
            "Eval_StdReturn : 94.40156555175781\n",
            "Eval_MaxReturn : 363.3123779296875\n",
            "Eval_MinReturn : 149.36785888671875\n",
            "Eval_AverageEpLen : 153.66666666666666\n",
            "Train_AverageReturn : 438.55902099609375\n",
            "Train_StdReturn : 98.45429992675781\n",
            "Train_MaxReturn : 576.869140625\n",
            "Train_MinReturn : 290.61834716796875\n",
            "Train_AverageEpLen : 201.4\n",
            "Train_EnvstepsSoFar : 605252\n",
            "TimeSinceStart : 533.2553746700287\n",
            "Training Loss : 0.015003526583313942\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 294 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2117])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 327.7270812988281\n",
            "Eval_StdReturn : 99.35098266601562\n",
            "Eval_MaxReturn : 428.92657470703125\n",
            "Eval_MinReturn : 192.71807861328125\n",
            "Eval_AverageEpLen : 160.33333333333334\n",
            "Train_AverageReturn : 356.62994384765625\n",
            "Train_StdReturn : 80.26761627197266\n",
            "Train_MaxReturn : 587.7681884765625\n",
            "Train_MinReturn : 243.70318603515625\n",
            "Train_AverageEpLen : 162.84615384615384\n",
            "Train_EnvstepsSoFar : 607369\n",
            "TimeSinceStart : 534.9678285121918\n",
            "Training Loss : 0.009774341247975826\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 295 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2075])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 334.5595397949219\n",
            "Eval_StdReturn : 78.87174224853516\n",
            "Eval_MaxReturn : 446.033203125\n",
            "Eval_MinReturn : 275.4548034667969\n",
            "Eval_AverageEpLen : 173.33333333333334\n",
            "Train_AverageReturn : 323.1268005371094\n",
            "Train_StdReturn : 95.34214782714844\n",
            "Train_MaxReturn : 470.8128356933594\n",
            "Train_MinReturn : 153.01844787597656\n",
            "Train_AverageEpLen : 159.6153846153846\n",
            "Train_EnvstepsSoFar : 609444\n",
            "TimeSinceStart : 536.6549687385559\n",
            "Training Loss : -0.00913701020181179\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 296 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2202])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 364.8971862792969\n",
            "Eval_StdReturn : 27.186399459838867\n",
            "Eval_MaxReturn : 402.00958251953125\n",
            "Eval_MinReturn : 337.64312744140625\n",
            "Eval_AverageEpLen : 166.33333333333334\n",
            "Train_AverageReturn : 411.7191162109375\n",
            "Train_StdReturn : 79.52101135253906\n",
            "Train_MaxReturn : 493.798095703125\n",
            "Train_MinReturn : 249.78207397460938\n",
            "Train_AverageEpLen : 200.1818181818182\n",
            "Train_EnvstepsSoFar : 611646\n",
            "TimeSinceStart : 539.2828130722046\n",
            "Training Loss : -0.011705040000379086\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 297 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2064])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 346.1090393066406\n",
            "Eval_StdReturn : 57.68999481201172\n",
            "Eval_MaxReturn : 390.0179748535156\n",
            "Eval_MinReturn : 264.60455322265625\n",
            "Eval_AverageEpLen : 170.33333333333334\n",
            "Train_AverageReturn : 334.64483642578125\n",
            "Train_StdReturn : 56.988338470458984\n",
            "Train_MaxReturn : 452.1778869628906\n",
            "Train_MinReturn : 220.60092163085938\n",
            "Train_AverageEpLen : 158.76923076923077\n",
            "Train_EnvstepsSoFar : 613710\n",
            "TimeSinceStart : 541.3542811870575\n",
            "Training Loss : 0.030836349353194237\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 298 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2023])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 398.6217956542969\n",
            "Eval_StdReturn : 50.461334228515625\n",
            "Eval_MaxReturn : 463.99053955078125\n",
            "Eval_MinReturn : 341.14398193359375\n",
            "Eval_AverageEpLen : 183.66666666666666\n",
            "Train_AverageReturn : 405.0551452636719\n",
            "Train_StdReturn : 77.35437774658203\n",
            "Train_MaxReturn : 573.823974609375\n",
            "Train_MinReturn : 292.100341796875\n",
            "Train_AverageEpLen : 181.5\n",
            "Train_EnvstepsSoFar : 615888\n",
            "TimeSinceStart : 543.3406448364258\n",
            "Training Loss : -0.05698823183774948\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 299 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2080])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 327.94769287109375\n",
            "Eval_StdReturn : 59.5081787109375\n",
            "Eval_MaxReturn : 377.13720703125\n",
            "Eval_MinReturn : 244.21640014648438\n",
            "Eval_AverageEpLen : 153.33333333333334\n",
            "Train_AverageReturn : 320.65460205078125\n",
            "Train_StdReturn : 96.70500946044922\n",
            "Train_MaxReturn : 478.29974365234375\n",
            "Train_MinReturn : 118.34994506835938\n",
            "Train_AverageEpLen : 148.57142857142858\n",
            "Train_EnvstepsSoFar : 617968\n",
            "TimeSinceStart : 545.0883884429932\n",
            "Training Loss : -0.03069501370191574\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python cs285/scripts/run_hw2.py \\\n",
        "--env_name Hopper-v2 --ep_len 1000 \\\n",
        "--discount 0.99 -n 300 -l 2 -s 32 -b 2000 -lr 0.001 \\\n",
        "--reward_to_go --nn_baseline --action_noise_std 0.5 --gae_lambda 0.99 \\\n",
        "--exp_name q5_b2000_r0.001_lambda99"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "8zvaO2u19-2i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b667c05-9c56-454a-bf7e-8d15bfd79351"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mLe flux de sortie a été tronqué et ne contient que les 5000 dernières lignes.\u001b[0m\n",
            "Train_AverageReturn : 229.24069213867188\n",
            "Train_StdReturn : 19.057218551635742\n",
            "Train_MaxReturn : 268.6636657714844\n",
            "Train_MinReturn : 196.82296752929688\n",
            "Train_AverageEpLen : 107.94736842105263\n",
            "Train_EnvstepsSoFar : 261186\n",
            "TimeSinceStart : 232.35146856307983\n",
            "Training Loss : -0.034301597625017166\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 128 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2051])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 225.52142333984375\n",
            "Eval_StdReturn : 11.326940536499023\n",
            "Eval_MaxReturn : 240.921875\n",
            "Eval_MinReturn : 208.9288787841797\n",
            "Eval_AverageEpLen : 106.25\n",
            "Train_AverageReturn : 231.32632446289062\n",
            "Train_StdReturn : 15.827957153320312\n",
            "Train_MaxReturn : 280.1209716796875\n",
            "Train_MinReturn : 208.06626892089844\n",
            "Train_AverageEpLen : 107.94736842105263\n",
            "Train_EnvstepsSoFar : 263237\n",
            "TimeSinceStart : 233.96667528152466\n",
            "Training Loss : 0.042837608605623245\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 129 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2042])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 226.8751983642578\n",
            "Eval_StdReturn : 23.94756507873535\n",
            "Eval_MaxReturn : 257.0042724609375\n",
            "Eval_MinReturn : 192.89024353027344\n",
            "Eval_AverageEpLen : 109.0\n",
            "Train_AverageReturn : 231.30670166015625\n",
            "Train_StdReturn : 16.711315155029297\n",
            "Train_MaxReturn : 265.4530334472656\n",
            "Train_MinReturn : 196.33055114746094\n",
            "Train_AverageEpLen : 113.44444444444444\n",
            "Train_EnvstepsSoFar : 265279\n",
            "TimeSinceStart : 235.56966137886047\n",
            "Training Loss : -0.024587633088231087\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 130 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2082])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 234.55044555664062\n",
            "Eval_StdReturn : 10.041496276855469\n",
            "Eval_MaxReturn : 249.00689697265625\n",
            "Eval_MinReturn : 220.69876098632812\n",
            "Eval_AverageEpLen : 112.0\n",
            "Train_AverageReturn : 216.65438842773438\n",
            "Train_StdReturn : 40.415122985839844\n",
            "Train_MaxReturn : 289.3973083496094\n",
            "Train_MinReturn : 69.3830795288086\n",
            "Train_AverageEpLen : 104.1\n",
            "Train_EnvstepsSoFar : 267361\n",
            "TimeSinceStart : 237.22502851486206\n",
            "Training Loss : -0.008567114360630512\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 131 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2014])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 213.05227661132812\n",
            "Eval_StdReturn : 42.70168685913086\n",
            "Eval_MaxReturn : 261.46429443359375\n",
            "Eval_MinReturn : 146.0673828125\n",
            "Eval_AverageEpLen : 102.5\n",
            "Train_AverageReturn : 221.4785919189453\n",
            "Train_StdReturn : 28.614849090576172\n",
            "Train_MaxReturn : 248.17039489746094\n",
            "Train_MinReturn : 123.1741943359375\n",
            "Train_AverageEpLen : 106.0\n",
            "Train_EnvstepsSoFar : 269375\n",
            "TimeSinceStart : 238.80227828025818\n",
            "Training Loss : 0.053261127322912216\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 132 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2010])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 225.28677368164062\n",
            "Eval_StdReturn : 12.837212562561035\n",
            "Eval_MaxReturn : 242.19692993164062\n",
            "Eval_MinReturn : 208.58131408691406\n",
            "Eval_AverageEpLen : 102.0\n",
            "Train_AverageReturn : 218.23211669921875\n",
            "Train_StdReturn : 37.793113708496094\n",
            "Train_MaxReturn : 275.4861145019531\n",
            "Train_MinReturn : 108.26640319824219\n",
            "Train_AverageEpLen : 105.78947368421052\n",
            "Train_EnvstepsSoFar : 271385\n",
            "TimeSinceStart : 240.3837718963623\n",
            "Training Loss : -0.034268468618392944\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 133 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2017])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 226.84893798828125\n",
            "Eval_StdReturn : 6.364688396453857\n",
            "Eval_MaxReturn : 234.0787811279297\n",
            "Eval_MinReturn : 216.8458709716797\n",
            "Eval_AverageEpLen : 106.5\n",
            "Train_AverageReturn : 223.74996948242188\n",
            "Train_StdReturn : 19.713773727416992\n",
            "Train_MaxReturn : 266.5228576660156\n",
            "Train_MinReturn : 181.3354949951172\n",
            "Train_AverageEpLen : 106.15789473684211\n",
            "Train_EnvstepsSoFar : 273402\n",
            "TimeSinceStart : 241.96719026565552\n",
            "Training Loss : -0.0017286734655499458\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 134 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2052])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 220.41705322265625\n",
            "Eval_StdReturn : 13.210087776184082\n",
            "Eval_MaxReturn : 237.7237091064453\n",
            "Eval_MinReturn : 200.5992431640625\n",
            "Eval_AverageEpLen : 104.25\n",
            "Train_AverageReturn : 235.669677734375\n",
            "Train_StdReturn : 29.146392822265625\n",
            "Train_MaxReturn : 294.02972412109375\n",
            "Train_MinReturn : 144.94940185546875\n",
            "Train_AverageEpLen : 114.0\n",
            "Train_EnvstepsSoFar : 275454\n",
            "TimeSinceStart : 243.61171627044678\n",
            "Training Loss : 0.011751014739274979\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 135 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2011])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 243.83753967285156\n",
            "Eval_StdReturn : 22.402626037597656\n",
            "Eval_MaxReturn : 277.20977783203125\n",
            "Eval_MinReturn : 221.67788696289062\n",
            "Eval_AverageEpLen : 120.25\n",
            "Train_AverageReturn : 222.3983612060547\n",
            "Train_StdReturn : 20.91791534423828\n",
            "Train_MaxReturn : 275.9989013671875\n",
            "Train_MinReturn : 178.79196166992188\n",
            "Train_AverageEpLen : 105.84210526315789\n",
            "Train_EnvstepsSoFar : 277465\n",
            "TimeSinceStart : 245.23532819747925\n",
            "Training Loss : 0.006665164139121771\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 136 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2095])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 211.95542907714844\n",
            "Eval_StdReturn : 35.6772575378418\n",
            "Eval_MaxReturn : 241.52011108398438\n",
            "Eval_MinReturn : 151.02728271484375\n",
            "Eval_AverageEpLen : 102.25\n",
            "Train_AverageReturn : 224.4351348876953\n",
            "Train_StdReturn : 41.73587417602539\n",
            "Train_MaxReturn : 327.9996643066406\n",
            "Train_MinReturn : 130.97805786132812\n",
            "Train_AverageEpLen : 110.26315789473684\n",
            "Train_EnvstepsSoFar : 279560\n",
            "TimeSinceStart : 246.8638026714325\n",
            "Training Loss : 0.02080935426056385\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 137 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2058])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 227.59303283691406\n",
            "Eval_StdReturn : 15.592942237854004\n",
            "Eval_MaxReturn : 253.19944763183594\n",
            "Eval_MinReturn : 211.0728759765625\n",
            "Eval_AverageEpLen : 110.25\n",
            "Train_AverageReturn : 235.6581268310547\n",
            "Train_StdReturn : 19.03211212158203\n",
            "Train_MaxReturn : 271.66766357421875\n",
            "Train_MinReturn : 206.6417694091797\n",
            "Train_AverageEpLen : 114.33333333333333\n",
            "Train_EnvstepsSoFar : 281618\n",
            "TimeSinceStart : 248.48184514045715\n",
            "Training Loss : -0.07414212822914124\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 138 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2028])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 236.13339233398438\n",
            "Eval_StdReturn : 5.745268821716309\n",
            "Eval_MaxReturn : 243.4513397216797\n",
            "Eval_MinReturn : 228.1784210205078\n",
            "Eval_AverageEpLen : 110.0\n",
            "Train_AverageReturn : 224.1024169921875\n",
            "Train_StdReturn : 26.79996109008789\n",
            "Train_MaxReturn : 297.23345947265625\n",
            "Train_MinReturn : 170.53257751464844\n",
            "Train_AverageEpLen : 106.3\n",
            "Train_EnvstepsSoFar : 283744\n",
            "TimeSinceStart : 250.13227462768555\n",
            "Training Loss : -0.012013540603220463\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 139 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2087])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 208.76119995117188\n",
            "Eval_StdReturn : 42.25891876220703\n",
            "Eval_MaxReturn : 235.71046447753906\n",
            "Eval_MinReturn : 124.81588745117188\n",
            "Eval_AverageEpLen : 102.0\n",
            "Train_AverageReturn : 231.0148468017578\n",
            "Train_StdReturn : 27.87871742248535\n",
            "Train_MaxReturn : 267.0618591308594\n",
            "Train_MinReturn : 133.26644897460938\n",
            "Train_AverageEpLen : 109.84210526315789\n",
            "Train_EnvstepsSoFar : 285831\n",
            "TimeSinceStart : 251.81040143966675\n",
            "Training Loss : 0.007960276678204536\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 140 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2048])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 226.41746520996094\n",
            "Eval_StdReturn : 13.1178617477417\n",
            "Eval_MaxReturn : 249.0826873779297\n",
            "Eval_MinReturn : 217.7578887939453\n",
            "Eval_AverageEpLen : 105.25\n",
            "Train_AverageReturn : 214.77334594726562\n",
            "Train_StdReturn : 45.35789108276367\n",
            "Train_MaxReturn : 264.9765930175781\n",
            "Train_MinReturn : 35.69662094116211\n",
            "Train_AverageEpLen : 102.4\n",
            "Train_EnvstepsSoFar : 287879\n",
            "TimeSinceStart : 253.39056539535522\n",
            "Training Loss : 0.025134488940238953\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 141 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2071])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 223.1793212890625\n",
            "Eval_StdReturn : 7.644927024841309\n",
            "Eval_MaxReturn : 234.4386444091797\n",
            "Eval_MinReturn : 212.89889526367188\n",
            "Eval_AverageEpLen : 101.75\n",
            "Train_AverageReturn : 213.41317749023438\n",
            "Train_StdReturn : 45.429290771484375\n",
            "Train_MaxReturn : 266.83251953125\n",
            "Train_MinReturn : 99.55087280273438\n",
            "Train_AverageEpLen : 103.55\n",
            "Train_EnvstepsSoFar : 289950\n",
            "TimeSinceStart : 255.65817856788635\n",
            "Training Loss : -0.023216666653752327\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 142 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2019])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 210.4105682373047\n",
            "Eval_StdReturn : 26.234281539916992\n",
            "Eval_MaxReturn : 231.97325134277344\n",
            "Eval_MinReturn : 160.48037719726562\n",
            "Eval_AverageEpLen : 96.2\n",
            "Train_AverageReturn : 233.59957885742188\n",
            "Train_StdReturn : 26.31450080871582\n",
            "Train_MaxReturn : 310.13299560546875\n",
            "Train_MinReturn : 170.69085693359375\n",
            "Train_AverageEpLen : 111.15789473684211\n",
            "Train_EnvstepsSoFar : 292062\n",
            "TimeSinceStart : 257.3524103164673\n",
            "Training Loss : -0.0003291688044555485\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 143 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2047])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 225.79519653320312\n",
            "Eval_StdReturn : 9.407209396362305\n",
            "Eval_MaxReturn : 241.77316284179688\n",
            "Eval_MinReturn : 218.01754760742188\n",
            "Eval_AverageEpLen : 107.5\n",
            "Train_AverageReturn : 228.84664916992188\n",
            "Train_StdReturn : 23.934276580810547\n",
            "Train_MaxReturn : 290.05419921875\n",
            "Train_MinReturn : 178.9775390625\n",
            "Train_AverageEpLen : 107.73684210526316\n",
            "Train_EnvstepsSoFar : 294109\n",
            "TimeSinceStart : 258.954895734787\n",
            "Training Loss : -0.024242185056209564\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 144 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2018])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 225.00112915039062\n",
            "Eval_StdReturn : 15.126733779907227\n",
            "Eval_MaxReturn : 248.72113037109375\n",
            "Eval_MinReturn : 204.42811584472656\n",
            "Eval_AverageEpLen : 103.8\n",
            "Train_AverageReturn : 219.85952758789062\n",
            "Train_StdReturn : 37.693870544433594\n",
            "Train_MaxReturn : 281.73138427734375\n",
            "Train_MinReturn : 119.52519989013672\n",
            "Train_AverageEpLen : 106.21052631578948\n",
            "Train_EnvstepsSoFar : 296127\n",
            "TimeSinceStart : 260.5763683319092\n",
            "Training Loss : -0.03261449933052063\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 145 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 232.8879852294922\n",
            "Eval_StdReturn : 10.460472106933594\n",
            "Eval_MaxReturn : 251.0029754638672\n",
            "Eval_MinReturn : 226.54605102539062\n",
            "Eval_AverageEpLen : 106.5\n",
            "Train_AverageReturn : 222.2510528564453\n",
            "Train_StdReturn : 30.621368408203125\n",
            "Train_MaxReturn : 278.502197265625\n",
            "Train_MinReturn : 140.88600158691406\n",
            "Train_AverageEpLen : 107.89473684210526\n",
            "Train_EnvstepsSoFar : 298177\n",
            "TimeSinceStart : 262.16972041130066\n",
            "Training Loss : -0.004348267801105976\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 146 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2106])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 224.53160095214844\n",
            "Eval_StdReturn : 15.995375633239746\n",
            "Eval_MaxReturn : 244.10470581054688\n",
            "Eval_MinReturn : 206.9599151611328\n",
            "Eval_AverageEpLen : 104.0\n",
            "Train_AverageReturn : 224.7660675048828\n",
            "Train_StdReturn : 29.790138244628906\n",
            "Train_MaxReturn : 254.7664337158203\n",
            "Train_MinReturn : 121.30377960205078\n",
            "Train_AverageEpLen : 110.84210526315789\n",
            "Train_EnvstepsSoFar : 300283\n",
            "TimeSinceStart : 263.80307960510254\n",
            "Training Loss : 0.03661419823765755\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 147 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2015])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 228.9955596923828\n",
            "Eval_StdReturn : 9.726409912109375\n",
            "Eval_MaxReturn : 242.38047790527344\n",
            "Eval_MinReturn : 215.5658416748047\n",
            "Eval_AverageEpLen : 107.75\n",
            "Train_AverageReturn : 241.03736877441406\n",
            "Train_StdReturn : 20.263525009155273\n",
            "Train_MaxReturn : 269.742431640625\n",
            "Train_MinReturn : 195.24703979492188\n",
            "Train_AverageEpLen : 118.52941176470588\n",
            "Train_EnvstepsSoFar : 302298\n",
            "TimeSinceStart : 265.40292525291443\n",
            "Training Loss : 0.021285051479935646\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 148 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2077])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 236.0960693359375\n",
            "Eval_StdReturn : 21.273704528808594\n",
            "Eval_MaxReturn : 272.7281494140625\n",
            "Eval_MinReturn : 221.98854064941406\n",
            "Eval_AverageEpLen : 110.25\n",
            "Train_AverageReturn : 232.2930145263672\n",
            "Train_StdReturn : 12.56486988067627\n",
            "Train_MaxReturn : 264.244140625\n",
            "Train_MinReturn : 212.1372528076172\n",
            "Train_AverageEpLen : 109.3157894736842\n",
            "Train_EnvstepsSoFar : 304375\n",
            "TimeSinceStart : 267.0933063030243\n",
            "Training Loss : 0.03010023944079876\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 149 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2121])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 237.37741088867188\n",
            "Eval_StdReturn : 15.790481567382812\n",
            "Eval_MaxReturn : 261.15948486328125\n",
            "Eval_MinReturn : 219.50942993164062\n",
            "Eval_AverageEpLen : 112.0\n",
            "Train_AverageReturn : 234.10182189941406\n",
            "Train_StdReturn : 15.215712547302246\n",
            "Train_MaxReturn : 262.9604187011719\n",
            "Train_MinReturn : 195.69906616210938\n",
            "Train_AverageEpLen : 111.63157894736842\n",
            "Train_EnvstepsSoFar : 306496\n",
            "TimeSinceStart : 268.7444097995758\n",
            "Training Loss : -0.011545257642865181\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 150 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2013])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 240.80519104003906\n",
            "Eval_StdReturn : 25.816133499145508\n",
            "Eval_MaxReturn : 284.529296875\n",
            "Eval_MinReturn : 218.6442413330078\n",
            "Eval_AverageEpLen : 119.0\n",
            "Train_AverageReturn : 226.45225524902344\n",
            "Train_StdReturn : 30.48587989807129\n",
            "Train_MaxReturn : 265.69256591796875\n",
            "Train_MinReturn : 109.69371795654297\n",
            "Train_AverageEpLen : 105.94736842105263\n",
            "Train_EnvstepsSoFar : 308509\n",
            "TimeSinceStart : 270.3368139266968\n",
            "Training Loss : 0.02618323266506195\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 151 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2037])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 228.25521850585938\n",
            "Eval_StdReturn : 12.646313667297363\n",
            "Eval_MaxReturn : 249.7440185546875\n",
            "Eval_MinReturn : 218.09934997558594\n",
            "Eval_AverageEpLen : 103.0\n",
            "Train_AverageReturn : 225.20755004882812\n",
            "Train_StdReturn : 21.144031524658203\n",
            "Train_MaxReturn : 259.24322509765625\n",
            "Train_MinReturn : 160.39901733398438\n",
            "Train_AverageEpLen : 107.21052631578948\n",
            "Train_EnvstepsSoFar : 310546\n",
            "TimeSinceStart : 271.9417870044708\n",
            "Training Loss : -0.04282999783754349\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 152 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 239.556396484375\n",
            "Eval_StdReturn : 15.709732055664062\n",
            "Eval_MaxReturn : 264.60455322265625\n",
            "Eval_MinReturn : 225.0334014892578\n",
            "Eval_AverageEpLen : 119.75\n",
            "Train_AverageReturn : 225.27685546875\n",
            "Train_StdReturn : 30.842037200927734\n",
            "Train_MaxReturn : 267.0731201171875\n",
            "Train_MinReturn : 127.40180206298828\n",
            "Train_AverageEpLen : 107.89473684210526\n",
            "Train_EnvstepsSoFar : 312596\n",
            "TimeSinceStart : 273.5635120868683\n",
            "Training Loss : 0.022246409207582474\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 153 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2019])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 199.3695068359375\n",
            "Eval_StdReturn : 58.15359878540039\n",
            "Eval_MaxReturn : 244.2506561279297\n",
            "Eval_MinReturn : 84.6177978515625\n",
            "Eval_AverageEpLen : 93.4\n",
            "Train_AverageReturn : 231.97906494140625\n",
            "Train_StdReturn : 31.001253128051758\n",
            "Train_MaxReturn : 281.1394958496094\n",
            "Train_MinReturn : 128.8101348876953\n",
            "Train_AverageEpLen : 112.16666666666667\n",
            "Train_EnvstepsSoFar : 314615\n",
            "TimeSinceStart : 275.1898169517517\n",
            "Training Loss : 0.0024719710927456617\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 154 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2037])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 234.58018493652344\n",
            "Eval_StdReturn : 22.244049072265625\n",
            "Eval_MaxReturn : 270.8644714355469\n",
            "Eval_MinReturn : 212.54205322265625\n",
            "Eval_AverageEpLen : 111.0\n",
            "Train_AverageReturn : 238.12109375\n",
            "Train_StdReturn : 22.69001579284668\n",
            "Train_MaxReturn : 303.80120849609375\n",
            "Train_MinReturn : 204.30271911621094\n",
            "Train_AverageEpLen : 113.16666666666667\n",
            "Train_EnvstepsSoFar : 316652\n",
            "TimeSinceStart : 276.84680223464966\n",
            "Training Loss : -0.010052979923784733\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 155 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2073])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 235.23883056640625\n",
            "Eval_StdReturn : 7.823436737060547\n",
            "Eval_MaxReturn : 247.54774475097656\n",
            "Eval_MinReturn : 227.33912658691406\n",
            "Eval_AverageEpLen : 109.75\n",
            "Train_AverageReturn : 231.59022521972656\n",
            "Train_StdReturn : 17.4752254486084\n",
            "Train_MaxReturn : 282.1119384765625\n",
            "Train_MinReturn : 210.22476196289062\n",
            "Train_AverageEpLen : 109.10526315789474\n",
            "Train_EnvstepsSoFar : 318725\n",
            "TimeSinceStart : 278.46940445899963\n",
            "Training Loss : -0.015067649073898792\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 156 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2023])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 209.74993896484375\n",
            "Eval_StdReturn : 21.223949432373047\n",
            "Eval_MaxReturn : 226.01803588867188\n",
            "Eval_MinReturn : 173.35159301757812\n",
            "Eval_AverageEpLen : 106.0\n",
            "Train_AverageReturn : 234.2478790283203\n",
            "Train_StdReturn : 14.021282196044922\n",
            "Train_MaxReturn : 262.17352294921875\n",
            "Train_MinReturn : 206.07139587402344\n",
            "Train_AverageEpLen : 112.38888888888889\n",
            "Train_EnvstepsSoFar : 320748\n",
            "TimeSinceStart : 280.0570778846741\n",
            "Training Loss : -0.004423239268362522\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 157 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2007])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 233.27938842773438\n",
            "Eval_StdReturn : 14.108471870422363\n",
            "Eval_MaxReturn : 252.0112762451172\n",
            "Eval_MinReturn : 214.09262084960938\n",
            "Eval_AverageEpLen : 109.0\n",
            "Train_AverageReturn : 232.80007934570312\n",
            "Train_StdReturn : 24.295188903808594\n",
            "Train_MaxReturn : 305.13470458984375\n",
            "Train_MinReturn : 210.4376220703125\n",
            "Train_AverageEpLen : 111.5\n",
            "Train_EnvstepsSoFar : 322755\n",
            "TimeSinceStart : 281.63352274894714\n",
            "Training Loss : -0.013444801792502403\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 158 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2020])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 226.55255126953125\n",
            "Eval_StdReturn : 8.307476043701172\n",
            "Eval_MaxReturn : 238.31744384765625\n",
            "Eval_MinReturn : 214.96913146972656\n",
            "Eval_AverageEpLen : 104.75\n",
            "Train_AverageReturn : 227.8145294189453\n",
            "Train_StdReturn : 16.689517974853516\n",
            "Train_MaxReturn : 253.13523864746094\n",
            "Train_MinReturn : 183.9197235107422\n",
            "Train_AverageEpLen : 106.3157894736842\n",
            "Train_EnvstepsSoFar : 324775\n",
            "TimeSinceStart : 283.21731877326965\n",
            "Training Loss : -0.06520773470401764\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 159 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2061])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 234.7202911376953\n",
            "Eval_StdReturn : 21.62235450744629\n",
            "Eval_MaxReturn : 272.05804443359375\n",
            "Eval_MinReturn : 220.7005157470703\n",
            "Eval_AverageEpLen : 111.75\n",
            "Train_AverageReturn : 237.45228576660156\n",
            "Train_StdReturn : 28.330530166625977\n",
            "Train_MaxReturn : 290.0552673339844\n",
            "Train_MinReturn : 155.4849853515625\n",
            "Train_AverageEpLen : 114.5\n",
            "Train_EnvstepsSoFar : 326836\n",
            "TimeSinceStart : 284.8311605453491\n",
            "Training Loss : -0.06542062759399414\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 160 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2019])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 216.0509033203125\n",
            "Eval_StdReturn : 26.737451553344727\n",
            "Eval_MaxReturn : 238.16497802734375\n",
            "Eval_MinReturn : 170.1252899169922\n",
            "Eval_AverageEpLen : 99.0\n",
            "Train_AverageReturn : 226.2543182373047\n",
            "Train_StdReturn : 25.301359176635742\n",
            "Train_MaxReturn : 275.57806396484375\n",
            "Train_MinReturn : 150.92286682128906\n",
            "Train_AverageEpLen : 106.26315789473684\n",
            "Train_EnvstepsSoFar : 328855\n",
            "TimeSinceStart : 286.47031593322754\n",
            "Training Loss : -0.013221632689237595\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 161 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2046])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 243.963623046875\n",
            "Eval_StdReturn : 32.34107208251953\n",
            "Eval_MaxReturn : 278.001708984375\n",
            "Eval_MinReturn : 199.82827758789062\n",
            "Eval_AverageEpLen : 119.75\n",
            "Train_AverageReturn : 236.6770782470703\n",
            "Train_StdReturn : 20.296680450439453\n",
            "Train_MaxReturn : 293.1302490234375\n",
            "Train_MinReturn : 212.0364532470703\n",
            "Train_AverageEpLen : 113.66666666666667\n",
            "Train_EnvstepsSoFar : 330901\n",
            "TimeSinceStart : 288.12829661369324\n",
            "Training Loss : 0.008604058995842934\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 162 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2052])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 236.0857391357422\n",
            "Eval_StdReturn : 13.560651779174805\n",
            "Eval_MaxReturn : 257.671875\n",
            "Eval_MinReturn : 220.17408752441406\n",
            "Eval_AverageEpLen : 110.75\n",
            "Train_AverageReturn : 225.42015075683594\n",
            "Train_StdReturn : 37.019004821777344\n",
            "Train_MaxReturn : 262.3497314453125\n",
            "Train_MinReturn : 82.95331573486328\n",
            "Train_AverageEpLen : 108.0\n",
            "Train_EnvstepsSoFar : 332953\n",
            "TimeSinceStart : 289.7260899543762\n",
            "Training Loss : 0.000992128741927445\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 163 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2071])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 219.6512908935547\n",
            "Eval_StdReturn : 7.660660266876221\n",
            "Eval_MaxReturn : 227.23202514648438\n",
            "Eval_MinReturn : 206.27691650390625\n",
            "Eval_AverageEpLen : 98.4\n",
            "Train_AverageReturn : 237.42222595214844\n",
            "Train_StdReturn : 19.80070686340332\n",
            "Train_MaxReturn : 285.0362548828125\n",
            "Train_MinReturn : 203.6471710205078\n",
            "Train_AverageEpLen : 115.05555555555556\n",
            "Train_EnvstepsSoFar : 335024\n",
            "TimeSinceStart : 291.37570571899414\n",
            "Training Loss : 0.012168250977993011\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 164 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2001])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 244.75384521484375\n",
            "Eval_StdReturn : 10.932372093200684\n",
            "Eval_MaxReturn : 260.1692199707031\n",
            "Eval_MinReturn : 231.40379333496094\n",
            "Eval_AverageEpLen : 122.0\n",
            "Train_AverageReturn : 223.53477478027344\n",
            "Train_StdReturn : 46.2163200378418\n",
            "Train_MaxReturn : 316.3288269042969\n",
            "Train_MinReturn : 85.88824462890625\n",
            "Train_AverageEpLen : 108.89473684210526\n",
            "Train_EnvstepsSoFar : 337093\n",
            "TimeSinceStart : 293.0275094509125\n",
            "Training Loss : -0.004112315364181995\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 165 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2027])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 233.60076904296875\n",
            "Eval_StdReturn : 3.7992968559265137\n",
            "Eval_MaxReturn : 237.26596069335938\n",
            "Eval_MinReturn : 227.26307678222656\n",
            "Eval_AverageEpLen : 108.75\n",
            "Train_AverageReturn : 240.1437225341797\n",
            "Train_StdReturn : 22.53190803527832\n",
            "Train_MaxReturn : 276.06884765625\n",
            "Train_MinReturn : 185.30136108398438\n",
            "Train_AverageEpLen : 117.94444444444444\n",
            "Train_EnvstepsSoFar : 339216\n",
            "TimeSinceStart : 294.70500326156616\n",
            "Training Loss : 0.04463760927319527\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 166 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2039])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 249.13031005859375\n",
            "Eval_StdReturn : 18.77437400817871\n",
            "Eval_MaxReturn : 270.9423522949219\n",
            "Eval_MinReturn : 219.4466552734375\n",
            "Eval_AverageEpLen : 127.0\n",
            "Train_AverageReturn : 217.37435913085938\n",
            "Train_StdReturn : 47.8853874206543\n",
            "Train_MaxReturn : 250.91073608398438\n",
            "Train_MinReturn : 15.288714408874512\n",
            "Train_AverageEpLen : 101.95\n",
            "Train_EnvstepsSoFar : 341255\n",
            "TimeSinceStart : 296.3929524421692\n",
            "Training Loss : -0.018695039674639702\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 167 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2078])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 232.78887939453125\n",
            "Eval_StdReturn : 2.9166688919067383\n",
            "Eval_MaxReturn : 236.97686767578125\n",
            "Eval_MinReturn : 228.83688354492188\n",
            "Eval_AverageEpLen : 105.5\n",
            "Train_AverageReturn : 238.5909881591797\n",
            "Train_StdReturn : 20.950632095336914\n",
            "Train_MaxReturn : 297.2044677734375\n",
            "Train_MinReturn : 207.86834716796875\n",
            "Train_AverageEpLen : 115.44444444444444\n",
            "Train_EnvstepsSoFar : 343333\n",
            "TimeSinceStart : 298.0368609428406\n",
            "Training Loss : 0.005676828324794769\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 168 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 233.9165496826172\n",
            "Eval_StdReturn : 8.381509780883789\n",
            "Eval_MaxReturn : 248.4323272705078\n",
            "Eval_MinReturn : 228.8866729736328\n",
            "Eval_AverageEpLen : 109.0\n",
            "Train_AverageReturn : 242.318359375\n",
            "Train_StdReturn : 19.354063034057617\n",
            "Train_MaxReturn : 298.3201904296875\n",
            "Train_MinReturn : 217.78627014160156\n",
            "Train_AverageEpLen : 117.6470588235294\n",
            "Train_EnvstepsSoFar : 345333\n",
            "TimeSinceStart : 299.6123821735382\n",
            "Training Loss : -3.715324419317767e-05\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 169 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2079])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 242.071044921875\n",
            "Eval_StdReturn : 23.586660385131836\n",
            "Eval_MaxReturn : 281.6220397949219\n",
            "Eval_MinReturn : 221.71583557128906\n",
            "Eval_AverageEpLen : 118.25\n",
            "Train_AverageReturn : 235.38504028320312\n",
            "Train_StdReturn : 39.73704147338867\n",
            "Train_MaxReturn : 300.1820983886719\n",
            "Train_MinReturn : 94.07157897949219\n",
            "Train_AverageEpLen : 115.5\n",
            "Train_EnvstepsSoFar : 347412\n",
            "TimeSinceStart : 301.2529058456421\n",
            "Training Loss : -0.07263743877410889\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 170 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2091])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 261.9061584472656\n",
            "Eval_StdReturn : 23.365764617919922\n",
            "Eval_MaxReturn : 278.86346435546875\n",
            "Eval_MinReturn : 228.86582946777344\n",
            "Eval_AverageEpLen : 134.66666666666666\n",
            "Train_AverageReturn : 245.9987335205078\n",
            "Train_StdReturn : 23.49578857421875\n",
            "Train_MaxReturn : 298.00787353515625\n",
            "Train_MinReturn : 189.8527374267578\n",
            "Train_AverageEpLen : 123.0\n",
            "Train_EnvstepsSoFar : 349503\n",
            "TimeSinceStart : 302.8625593185425\n",
            "Training Loss : -0.03823067247867584\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 171 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2032])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 237.58448791503906\n",
            "Eval_StdReturn : 7.641657829284668\n",
            "Eval_MaxReturn : 243.0607452392578\n",
            "Eval_MinReturn : 224.52325439453125\n",
            "Eval_AverageEpLen : 111.25\n",
            "Train_AverageReturn : 235.94284057617188\n",
            "Train_StdReturn : 24.465457916259766\n",
            "Train_MaxReturn : 282.45391845703125\n",
            "Train_MinReturn : 178.69786071777344\n",
            "Train_AverageEpLen : 112.88888888888889\n",
            "Train_EnvstepsSoFar : 351535\n",
            "TimeSinceStart : 304.47707772254944\n",
            "Training Loss : 0.009376422502100468\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 172 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2104])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 248.79827880859375\n",
            "Eval_StdReturn : 18.020418167114258\n",
            "Eval_MaxReturn : 269.48046875\n",
            "Eval_MinReturn : 222.03323364257812\n",
            "Eval_AverageEpLen : 126.75\n",
            "Train_AverageReturn : 239.117919921875\n",
            "Train_StdReturn : 20.2584228515625\n",
            "Train_MaxReturn : 286.28875732421875\n",
            "Train_MinReturn : 195.59693908691406\n",
            "Train_AverageEpLen : 116.88888888888889\n",
            "Train_EnvstepsSoFar : 353639\n",
            "TimeSinceStart : 306.1744031906128\n",
            "Training Loss : 0.0010310896905139089\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 173 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2036])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 250.98822021484375\n",
            "Eval_StdReturn : 22.34714698791504\n",
            "Eval_MaxReturn : 279.0415954589844\n",
            "Eval_MinReturn : 218.77047729492188\n",
            "Eval_AverageEpLen : 127.0\n",
            "Train_AverageReturn : 239.13519287109375\n",
            "Train_StdReturn : 33.549495697021484\n",
            "Train_MaxReturn : 282.7294921875\n",
            "Train_MinReturn : 127.44182586669922\n",
            "Train_AverageEpLen : 119.76470588235294\n",
            "Train_EnvstepsSoFar : 355675\n",
            "TimeSinceStart : 307.8444011211395\n",
            "Training Loss : 0.06396022439002991\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 174 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2074])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 227.89370727539062\n",
            "Eval_StdReturn : 12.875636100769043\n",
            "Eval_MaxReturn : 250.16175842285156\n",
            "Eval_MinReturn : 219.4708251953125\n",
            "Eval_AverageEpLen : 107.25\n",
            "Train_AverageReturn : 227.35983276367188\n",
            "Train_StdReturn : 29.490915298461914\n",
            "Train_MaxReturn : 277.0544128417969\n",
            "Train_MinReturn : 141.04148864746094\n",
            "Train_AverageEpLen : 109.15789473684211\n",
            "Train_EnvstepsSoFar : 357749\n",
            "TimeSinceStart : 309.4440155029297\n",
            "Training Loss : -0.0008638665894977748\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 175 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2114])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 262.4800109863281\n",
            "Eval_StdReturn : 34.2726936340332\n",
            "Eval_MaxReturn : 310.94891357421875\n",
            "Eval_MinReturn : 238.21453857421875\n",
            "Eval_AverageEpLen : 137.66666666666666\n",
            "Train_AverageReturn : 240.3631591796875\n",
            "Train_StdReturn : 41.67947006225586\n",
            "Train_MaxReturn : 299.9740295410156\n",
            "Train_MinReturn : 127.6773681640625\n",
            "Train_AverageEpLen : 124.3529411764706\n",
            "Train_EnvstepsSoFar : 359863\n",
            "TimeSinceStart : 311.0808837413788\n",
            "Training Loss : -0.005599714815616608\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 176 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2079])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 247.94442749023438\n",
            "Eval_StdReturn : 38.26719284057617\n",
            "Eval_MaxReturn : 311.10931396484375\n",
            "Eval_MinReturn : 210.5670166015625\n",
            "Eval_AverageEpLen : 130.5\n",
            "Train_AverageReturn : 233.73245239257812\n",
            "Train_StdReturn : 39.6856689453125\n",
            "Train_MaxReturn : 288.45587158203125\n",
            "Train_MinReturn : 87.01034545898438\n",
            "Train_AverageEpLen : 115.5\n",
            "Train_EnvstepsSoFar : 361942\n",
            "TimeSinceStart : 312.77207112312317\n",
            "Training Loss : 0.0012882901355624199\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 177 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2042])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 231.6488800048828\n",
            "Eval_StdReturn : 5.077244758605957\n",
            "Eval_MaxReturn : 240.04811096191406\n",
            "Eval_MinReturn : 226.6599884033203\n",
            "Eval_AverageEpLen : 106.0\n",
            "Train_AverageReturn : 243.16090393066406\n",
            "Train_StdReturn : 21.36376953125\n",
            "Train_MaxReturn : 294.5352478027344\n",
            "Train_MinReturn : 209.8675994873047\n",
            "Train_AverageEpLen : 120.11764705882354\n",
            "Train_EnvstepsSoFar : 363984\n",
            "TimeSinceStart : 314.37246346473694\n",
            "Training Loss : -0.08358907699584961\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 178 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2095])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 266.2767028808594\n",
            "Eval_StdReturn : 6.076674938201904\n",
            "Eval_MaxReturn : 274.680419921875\n",
            "Eval_MinReturn : 260.5185546875\n",
            "Eval_AverageEpLen : 138.66666666666666\n",
            "Train_AverageReturn : 248.1485595703125\n",
            "Train_StdReturn : 21.864912033081055\n",
            "Train_MaxReturn : 319.9908752441406\n",
            "Train_MinReturn : 215.96849060058594\n",
            "Train_AverageEpLen : 123.23529411764706\n",
            "Train_EnvstepsSoFar : 366079\n",
            "TimeSinceStart : 316.02574634552\n",
            "Training Loss : 0.023893315345048904\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 179 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2025])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 234.04110717773438\n",
            "Eval_StdReturn : 12.524566650390625\n",
            "Eval_MaxReturn : 252.31845092773438\n",
            "Eval_MinReturn : 221.6029815673828\n",
            "Eval_AverageEpLen : 110.75\n",
            "Train_AverageReturn : 242.0880126953125\n",
            "Train_StdReturn : 25.249996185302734\n",
            "Train_MaxReturn : 309.00390625\n",
            "Train_MinReturn : 192.96463012695312\n",
            "Train_AverageEpLen : 119.11764705882354\n",
            "Train_EnvstepsSoFar : 368104\n",
            "TimeSinceStart : 317.6266975402832\n",
            "Training Loss : 0.0018242424121126533\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 180 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2055])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 262.8445739746094\n",
            "Eval_StdReturn : 26.27608871459961\n",
            "Eval_MaxReturn : 299.9912414550781\n",
            "Eval_MinReturn : 243.4093780517578\n",
            "Eval_AverageEpLen : 138.66666666666666\n",
            "Train_AverageReturn : 257.1229248046875\n",
            "Train_StdReturn : 22.5847225189209\n",
            "Train_MaxReturn : 298.7865295410156\n",
            "Train_MinReturn : 223.74143981933594\n",
            "Train_AverageEpLen : 128.4375\n",
            "Train_EnvstepsSoFar : 370159\n",
            "TimeSinceStart : 319.21775364875793\n",
            "Training Loss : -0.009966990910470486\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 181 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2009])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 247.34170532226562\n",
            "Eval_StdReturn : 22.60137176513672\n",
            "Eval_MaxReturn : 282.5276184082031\n",
            "Eval_MinReturn : 219.53028869628906\n",
            "Eval_AverageEpLen : 113.0\n",
            "Train_AverageReturn : 235.6385498046875\n",
            "Train_StdReturn : 60.13618087768555\n",
            "Train_MaxReturn : 318.4741516113281\n",
            "Train_MinReturn : 104.4345703125\n",
            "Train_AverageEpLen : 125.5625\n",
            "Train_EnvstepsSoFar : 372168\n",
            "TimeSinceStart : 320.7836892604828\n",
            "Training Loss : -0.006424961145967245\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 182 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2124])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 229.2100067138672\n",
            "Eval_StdReturn : 16.411115646362305\n",
            "Eval_MaxReturn : 249.9593505859375\n",
            "Eval_MinReturn : 206.99282836914062\n",
            "Eval_AverageEpLen : 108.0\n",
            "Train_AverageReturn : 251.42193603515625\n",
            "Train_StdReturn : 21.859840393066406\n",
            "Train_MaxReturn : 298.1802673339844\n",
            "Train_MinReturn : 218.75331115722656\n",
            "Train_AverageEpLen : 124.94117647058823\n",
            "Train_EnvstepsSoFar : 374292\n",
            "TimeSinceStart : 322.45495986938477\n",
            "Training Loss : -0.00864610355347395\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 183 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2016])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 242.37158203125\n",
            "Eval_StdReturn : 10.348955154418945\n",
            "Eval_MaxReturn : 259.7193603515625\n",
            "Eval_MinReturn : 232.72891235351562\n",
            "Eval_AverageEpLen : 111.0\n",
            "Train_AverageReturn : 245.2239227294922\n",
            "Train_StdReturn : 50.34817886352539\n",
            "Train_MaxReturn : 291.07080078125\n",
            "Train_MinReturn : 61.067440032958984\n",
            "Train_AverageEpLen : 126.0\n",
            "Train_EnvstepsSoFar : 376308\n",
            "TimeSinceStart : 324.10302114486694\n",
            "Training Loss : 0.00636756606400013\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 184 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2118])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 275.2701110839844\n",
            "Eval_StdReturn : 10.081354141235352\n",
            "Eval_MaxReturn : 285.73114013671875\n",
            "Eval_MinReturn : 261.65057373046875\n",
            "Eval_AverageEpLen : 137.33333333333334\n",
            "Train_AverageReturn : 242.50588989257812\n",
            "Train_StdReturn : 49.615440368652344\n",
            "Train_MaxReturn : 304.13079833984375\n",
            "Train_MinReturn : 62.49721145629883\n",
            "Train_AverageEpLen : 124.58823529411765\n",
            "Train_EnvstepsSoFar : 378426\n",
            "TimeSinceStart : 325.7681636810303\n",
            "Training Loss : -0.0463080070912838\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 185 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2033])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 291.42889404296875\n",
            "Eval_StdReturn : 11.311760902404785\n",
            "Eval_MaxReturn : 307.2794189453125\n",
            "Eval_MinReturn : 281.631591796875\n",
            "Eval_AverageEpLen : 151.66666666666666\n",
            "Train_AverageReturn : 252.35568237304688\n",
            "Train_StdReturn : 21.98233413696289\n",
            "Train_MaxReturn : 296.6338195800781\n",
            "Train_MinReturn : 216.0904541015625\n",
            "Train_AverageEpLen : 127.0625\n",
            "Train_EnvstepsSoFar : 380459\n",
            "TimeSinceStart : 327.4149408340454\n",
            "Training Loss : 0.008859720081090927\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 186 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2094])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 244.0485382080078\n",
            "Eval_StdReturn : 32.683929443359375\n",
            "Eval_MaxReturn : 268.53143310546875\n",
            "Eval_MinReturn : 188.4386749267578\n",
            "Eval_AverageEpLen : 131.25\n",
            "Train_AverageReturn : 238.72161865234375\n",
            "Train_StdReturn : 41.46208572387695\n",
            "Train_MaxReturn : 305.606201171875\n",
            "Train_MinReturn : 109.5079574584961\n",
            "Train_AverageEpLen : 123.17647058823529\n",
            "Train_EnvstepsSoFar : 382553\n",
            "TimeSinceStart : 329.13606905937195\n",
            "Training Loss : -0.041686318814754486\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 187 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2051])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 221.20602416992188\n",
            "Eval_StdReturn : 91.05110168457031\n",
            "Eval_MaxReturn : 308.75067138671875\n",
            "Eval_MinReturn : 68.35713195800781\n",
            "Eval_AverageEpLen : 125.5\n",
            "Train_AverageReturn : 274.42498779296875\n",
            "Train_StdReturn : 26.024803161621094\n",
            "Train_MaxReturn : 339.0286865234375\n",
            "Train_MinReturn : 226.6914825439453\n",
            "Train_AverageEpLen : 146.5\n",
            "Train_EnvstepsSoFar : 384604\n",
            "TimeSinceStart : 330.8123199939728\n",
            "Training Loss : 0.04231174662709236\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 188 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2080])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 270.3056335449219\n",
            "Eval_StdReturn : 21.481412887573242\n",
            "Eval_MaxReturn : 303.2829895019531\n",
            "Eval_MinReturn : 243.5626678466797\n",
            "Eval_AverageEpLen : 137.5\n",
            "Train_AverageReturn : 252.87274169921875\n",
            "Train_StdReturn : 37.76710891723633\n",
            "Train_MaxReturn : 327.45245361328125\n",
            "Train_MinReturn : 142.95590209960938\n",
            "Train_AverageEpLen : 130.0\n",
            "Train_EnvstepsSoFar : 386684\n",
            "TimeSinceStart : 332.55158162117004\n",
            "Training Loss : -0.0008179701399058104\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 189 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2122])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 273.609619140625\n",
            "Eval_StdReturn : 24.080854415893555\n",
            "Eval_MaxReturn : 304.796630859375\n",
            "Eval_MinReturn : 246.16879272460938\n",
            "Eval_AverageEpLen : 141.66666666666666\n",
            "Train_AverageReturn : 258.46466064453125\n",
            "Train_StdReturn : 39.79187774658203\n",
            "Train_MaxReturn : 306.90045166015625\n",
            "Train_MinReturn : 137.80142211914062\n",
            "Train_AverageEpLen : 132.625\n",
            "Train_EnvstepsSoFar : 388806\n",
            "TimeSinceStart : 334.2267835140228\n",
            "Training Loss : -0.01987140253186226\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 190 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2022])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 282.7188415527344\n",
            "Eval_StdReturn : 10.638899803161621\n",
            "Eval_MaxReturn : 292.069091796875\n",
            "Eval_MinReturn : 267.83544921875\n",
            "Eval_AverageEpLen : 147.33333333333334\n",
            "Train_AverageReturn : 260.3133544921875\n",
            "Train_StdReturn : 39.66180419921875\n",
            "Train_MaxReturn : 310.09051513671875\n",
            "Train_MinReturn : 126.95282745361328\n",
            "Train_AverageEpLen : 133.0\n",
            "Train_EnvstepsSoFar : 390934\n",
            "TimeSinceStart : 335.8905062675476\n",
            "Training Loss : -0.048693690448999405\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 191 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2101])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 268.4756774902344\n",
            "Eval_StdReturn : 20.267606735229492\n",
            "Eval_MaxReturn : 294.03765869140625\n",
            "Eval_MinReturn : 244.46514892578125\n",
            "Eval_AverageEpLen : 134.66666666666666\n",
            "Train_AverageReturn : 259.24957275390625\n",
            "Train_StdReturn : 28.224685668945312\n",
            "Train_MaxReturn : 297.7809143066406\n",
            "Train_MinReturn : 175.03482055664062\n",
            "Train_AverageEpLen : 131.3125\n",
            "Train_EnvstepsSoFar : 393035\n",
            "TimeSinceStart : 337.5508575439453\n",
            "Training Loss : -0.028526507318019867\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 192 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2129])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 252.1584930419922\n",
            "Eval_StdReturn : 50.44135284423828\n",
            "Eval_MaxReturn : 320.1986389160156\n",
            "Eval_MinReturn : 199.58042907714844\n",
            "Eval_AverageEpLen : 138.66666666666666\n",
            "Train_AverageReturn : 272.4732971191406\n",
            "Train_StdReturn : 23.11271095275879\n",
            "Train_MaxReturn : 320.96722412109375\n",
            "Train_MinReturn : 236.14927673339844\n",
            "Train_AverageEpLen : 141.93333333333334\n",
            "Train_EnvstepsSoFar : 395164\n",
            "TimeSinceStart : 339.23708605766296\n",
            "Training Loss : -0.013518367893993855\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 193 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2122])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 245.92822265625\n",
            "Eval_StdReturn : 19.767213821411133\n",
            "Eval_MaxReturn : 265.232177734375\n",
            "Eval_MinReturn : 217.79617309570312\n",
            "Eval_AverageEpLen : 126.0\n",
            "Train_AverageReturn : 284.670654296875\n",
            "Train_StdReturn : 26.582548141479492\n",
            "Train_MaxReturn : 334.10772705078125\n",
            "Train_MinReturn : 240.84449768066406\n",
            "Train_AverageEpLen : 151.57142857142858\n",
            "Train_EnvstepsSoFar : 397286\n",
            "TimeSinceStart : 340.9443325996399\n",
            "Training Loss : -0.02642691507935524\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 194 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2000])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 176.64739990234375\n",
            "Eval_StdReturn : 67.53488159179688\n",
            "Eval_MaxReturn : 245.92893981933594\n",
            "Eval_MinReturn : 70.0621566772461\n",
            "Eval_AverageEpLen : 103.0\n",
            "Train_AverageReturn : 291.39434814453125\n",
            "Train_StdReturn : 29.026416778564453\n",
            "Train_MaxReturn : 372.7245788574219\n",
            "Train_MinReturn : 256.32904052734375\n",
            "Train_AverageEpLen : 153.21428571428572\n",
            "Train_EnvstepsSoFar : 399431\n",
            "TimeSinceStart : 342.6062569618225\n",
            "Training Loss : 0.04137182980775833\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 195 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2065])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 317.6637878417969\n",
            "Eval_StdReturn : 10.663538932800293\n",
            "Eval_MaxReturn : 327.4390869140625\n",
            "Eval_MinReturn : 302.8313293457031\n",
            "Eval_AverageEpLen : 176.66666666666666\n",
            "Train_AverageReturn : 264.1263427734375\n",
            "Train_StdReturn : 42.54714584350586\n",
            "Train_MaxReturn : 337.916015625\n",
            "Train_MinReturn : 141.25942993164062\n",
            "Train_AverageEpLen : 137.66666666666666\n",
            "Train_EnvstepsSoFar : 401496\n",
            "TimeSinceStart : 344.79092288017273\n",
            "Training Loss : 0.00044797523878514767\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 196 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2011])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 292.2445983886719\n",
            "Eval_StdReturn : 16.20322608947754\n",
            "Eval_MaxReturn : 305.24676513671875\n",
            "Eval_MinReturn : 269.4026184082031\n",
            "Eval_AverageEpLen : 160.33333333333334\n",
            "Train_AverageReturn : 263.8284606933594\n",
            "Train_StdReturn : 35.53754806518555\n",
            "Train_MaxReturn : 333.0107421875\n",
            "Train_MinReturn : 183.91273498535156\n",
            "Train_AverageEpLen : 143.64285714285714\n",
            "Train_EnvstepsSoFar : 403507\n",
            "TimeSinceStart : 346.6134696006775\n",
            "Training Loss : 0.05713599920272827\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 197 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2021])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 279.3415832519531\n",
            "Eval_StdReturn : 16.160030364990234\n",
            "Eval_MaxReturn : 299.5166015625\n",
            "Eval_MinReturn : 259.9564208984375\n",
            "Eval_AverageEpLen : 141.33333333333334\n",
            "Train_AverageReturn : 266.34393310546875\n",
            "Train_StdReturn : 36.01645278930664\n",
            "Train_MaxReturn : 329.540771484375\n",
            "Train_MinReturn : 172.4607696533203\n",
            "Train_AverageEpLen : 134.73333333333332\n",
            "Train_EnvstepsSoFar : 405528\n",
            "TimeSinceStart : 348.21298599243164\n",
            "Training Loss : -0.044015754014253616\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 198 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2091])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 273.3965148925781\n",
            "Eval_StdReturn : 50.482845306396484\n",
            "Eval_MaxReturn : 344.78167724609375\n",
            "Eval_MinReturn : 236.75668334960938\n",
            "Eval_AverageEpLen : 149.0\n",
            "Train_AverageReturn : 280.95233154296875\n",
            "Train_StdReturn : 32.47600555419922\n",
            "Train_MaxReturn : 340.6851806640625\n",
            "Train_MinReturn : 236.30636596679688\n",
            "Train_AverageEpLen : 139.4\n",
            "Train_EnvstepsSoFar : 407619\n",
            "TimeSinceStart : 349.8569040298462\n",
            "Training Loss : -0.007004791405051947\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 199 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2083])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 271.6435241699219\n",
            "Eval_StdReturn : 2.3082351684570312\n",
            "Eval_MaxReturn : 274.73468017578125\n",
            "Eval_MinReturn : 269.18939208984375\n",
            "Eval_AverageEpLen : 136.0\n",
            "Train_AverageReturn : 278.28021240234375\n",
            "Train_StdReturn : 31.712989807128906\n",
            "Train_MaxReturn : 332.6958923339844\n",
            "Train_MinReturn : 206.78121948242188\n",
            "Train_AverageEpLen : 148.78571428571428\n",
            "Train_EnvstepsSoFar : 409702\n",
            "TimeSinceStart : 351.4845745563507\n",
            "Training Loss : 0.00982681754976511\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 200 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2074])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 346.1195068359375\n",
            "Eval_StdReturn : 8.060775756835938\n",
            "Eval_MaxReturn : 354.1802673339844\n",
            "Eval_MinReturn : 338.0587158203125\n",
            "Eval_AverageEpLen : 210.0\n",
            "Train_AverageReturn : 274.8945007324219\n",
            "Train_StdReturn : 21.995567321777344\n",
            "Train_MaxReturn : 318.99212646484375\n",
            "Train_MinReturn : 240.7125244140625\n",
            "Train_AverageEpLen : 138.26666666666668\n",
            "Train_EnvstepsSoFar : 411776\n",
            "TimeSinceStart : 353.08667612075806\n",
            "Training Loss : 0.01235438697040081\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 201 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2068])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 304.0786437988281\n",
            "Eval_StdReturn : 19.10000991821289\n",
            "Eval_MaxReturn : 330.94390869140625\n",
            "Eval_MinReturn : 288.215087890625\n",
            "Eval_AverageEpLen : 170.33333333333334\n",
            "Train_AverageReturn : 297.5475158691406\n",
            "Train_StdReturn : 41.29480743408203\n",
            "Train_MaxReturn : 374.9317626953125\n",
            "Train_MinReturn : 241.55169677734375\n",
            "Train_AverageEpLen : 159.07692307692307\n",
            "Train_EnvstepsSoFar : 413844\n",
            "TimeSinceStart : 354.77006101608276\n",
            "Training Loss : 0.026387972757220268\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 202 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2067])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 292.5767822265625\n",
            "Eval_StdReturn : 34.79316329956055\n",
            "Eval_MaxReturn : 324.4925231933594\n",
            "Eval_MinReturn : 244.18612670898438\n",
            "Eval_AverageEpLen : 143.66666666666666\n",
            "Train_AverageReturn : 297.1238708496094\n",
            "Train_StdReturn : 20.288169860839844\n",
            "Train_MaxReturn : 339.07818603515625\n",
            "Train_MinReturn : 266.13690185546875\n",
            "Train_AverageEpLen : 159.0\n",
            "Train_EnvstepsSoFar : 415911\n",
            "TimeSinceStart : 356.4097547531128\n",
            "Training Loss : -0.02268587425351143\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 203 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2034])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 279.7951965332031\n",
            "Eval_StdReturn : 25.51824188232422\n",
            "Eval_MaxReturn : 310.0321044921875\n",
            "Eval_MinReturn : 247.61602783203125\n",
            "Eval_AverageEpLen : 152.0\n",
            "Train_AverageReturn : 281.14404296875\n",
            "Train_StdReturn : 40.872432708740234\n",
            "Train_MaxReturn : 356.54376220703125\n",
            "Train_MinReturn : 197.26638793945312\n",
            "Train_AverageEpLen : 145.28571428571428\n",
            "Train_EnvstepsSoFar : 417945\n",
            "TimeSinceStart : 358.02580857276917\n",
            "Training Loss : -0.0008030753815546632\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 204 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2082])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 264.14501953125\n",
            "Eval_StdReturn : 44.43513870239258\n",
            "Eval_MaxReturn : 297.8222351074219\n",
            "Eval_MinReturn : 201.35963439941406\n",
            "Eval_AverageEpLen : 150.0\n",
            "Train_AverageReturn : 287.7689514160156\n",
            "Train_StdReturn : 26.734085083007812\n",
            "Train_MaxReturn : 336.92724609375\n",
            "Train_MinReturn : 254.5079803466797\n",
            "Train_AverageEpLen : 148.71428571428572\n",
            "Train_EnvstepsSoFar : 420027\n",
            "TimeSinceStart : 359.6545388698578\n",
            "Training Loss : -0.025291776284575462\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 205 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2014])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 300.0516052246094\n",
            "Eval_StdReturn : 31.4718074798584\n",
            "Eval_MaxReturn : 336.25006103515625\n",
            "Eval_MinReturn : 259.5254821777344\n",
            "Eval_AverageEpLen : 151.66666666666666\n",
            "Train_AverageReturn : 286.1675109863281\n",
            "Train_StdReturn : 33.72476577758789\n",
            "Train_MaxReturn : 331.76123046875\n",
            "Train_MinReturn : 224.48056030273438\n",
            "Train_AverageEpLen : 154.92307692307693\n",
            "Train_EnvstepsSoFar : 422041\n",
            "TimeSinceStart : 361.24188351631165\n",
            "Training Loss : 0.00837420392781496\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 206 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2020])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 297.57794189453125\n",
            "Eval_StdReturn : 11.02490234375\n",
            "Eval_MaxReturn : 312.87469482421875\n",
            "Eval_MinReturn : 287.316162109375\n",
            "Eval_AverageEpLen : 156.33333333333334\n",
            "Train_AverageReturn : 298.09844970703125\n",
            "Train_StdReturn : 31.94301414489746\n",
            "Train_MaxReturn : 375.4156494140625\n",
            "Train_MinReturn : 251.3889923095703\n",
            "Train_AverageEpLen : 155.3846153846154\n",
            "Train_EnvstepsSoFar : 424061\n",
            "TimeSinceStart : 362.8421709537506\n",
            "Training Loss : -0.04668299853801727\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 207 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2127])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 243.16098022460938\n",
            "Eval_StdReturn : 56.78741455078125\n",
            "Eval_MaxReturn : 302.8086242675781\n",
            "Eval_MinReturn : 151.32957458496094\n",
            "Eval_AverageEpLen : 127.25\n",
            "Train_AverageReturn : 301.79443359375\n",
            "Train_StdReturn : 27.856924057006836\n",
            "Train_MaxReturn : 344.15240478515625\n",
            "Train_MinReturn : 256.53228759765625\n",
            "Train_AverageEpLen : 163.6153846153846\n",
            "Train_EnvstepsSoFar : 426188\n",
            "TimeSinceStart : 364.54242515563965\n",
            "Training Loss : 0.007151835132390261\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 208 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2091])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 288.56939697265625\n",
            "Eval_StdReturn : 34.845767974853516\n",
            "Eval_MaxReturn : 330.2715148925781\n",
            "Eval_MinReturn : 244.97979736328125\n",
            "Eval_AverageEpLen : 163.66666666666666\n",
            "Train_AverageReturn : 302.4567565917969\n",
            "Train_StdReturn : 60.73530197143555\n",
            "Train_MaxReturn : 381.59124755859375\n",
            "Train_MinReturn : 179.2018585205078\n",
            "Train_AverageEpLen : 174.25\n",
            "Train_EnvstepsSoFar : 428279\n",
            "TimeSinceStart : 366.2337656021118\n",
            "Training Loss : -0.0020407598931342363\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 209 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2122])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 293.1199035644531\n",
            "Eval_StdReturn : 21.169755935668945\n",
            "Eval_MaxReturn : 322.5957946777344\n",
            "Eval_MinReturn : 273.8414306640625\n",
            "Eval_AverageEpLen : 166.0\n",
            "Train_AverageReturn : 312.4222412109375\n",
            "Train_StdReturn : 21.966629028320312\n",
            "Train_MaxReturn : 352.8846435546875\n",
            "Train_MinReturn : 284.39324951171875\n",
            "Train_AverageEpLen : 163.23076923076923\n",
            "Train_EnvstepsSoFar : 430401\n",
            "TimeSinceStart : 367.93735933303833\n",
            "Training Loss : -0.019065935164690018\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 210 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2143])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 299.2309265136719\n",
            "Eval_StdReturn : 17.099794387817383\n",
            "Eval_MaxReturn : 323.2341613769531\n",
            "Eval_MinReturn : 284.6821594238281\n",
            "Eval_AverageEpLen : 152.33333333333334\n",
            "Train_AverageReturn : 304.782958984375\n",
            "Train_StdReturn : 27.09137725830078\n",
            "Train_MaxReturn : 351.3236389160156\n",
            "Train_MinReturn : 257.0680236816406\n",
            "Train_AverageEpLen : 164.84615384615384\n",
            "Train_EnvstepsSoFar : 432544\n",
            "TimeSinceStart : 369.5858130455017\n",
            "Training Loss : 0.003981465939432383\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 211 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2059])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 300.8351745605469\n",
            "Eval_StdReturn : 15.033533096313477\n",
            "Eval_MaxReturn : 319.2921142578125\n",
            "Eval_MinReturn : 282.46795654296875\n",
            "Eval_AverageEpLen : 161.33333333333334\n",
            "Train_AverageReturn : 307.1993103027344\n",
            "Train_StdReturn : 32.56110763549805\n",
            "Train_MaxReturn : 362.9602966308594\n",
            "Train_MinReturn : 251.6593475341797\n",
            "Train_AverageEpLen : 158.3846153846154\n",
            "Train_EnvstepsSoFar : 434603\n",
            "TimeSinceStart : 371.2312660217285\n",
            "Training Loss : 0.03164062649011612\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 212 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2042])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 309.0766906738281\n",
            "Eval_StdReturn : 32.449867248535156\n",
            "Eval_MaxReturn : 352.3807678222656\n",
            "Eval_MinReturn : 274.26947021484375\n",
            "Eval_AverageEpLen : 158.66666666666666\n",
            "Train_AverageReturn : 302.8690185546875\n",
            "Train_StdReturn : 29.888219833374023\n",
            "Train_MaxReturn : 341.7117004394531\n",
            "Train_MinReturn : 243.858642578125\n",
            "Train_AverageEpLen : 157.07692307692307\n",
            "Train_EnvstepsSoFar : 436645\n",
            "TimeSinceStart : 372.8450665473938\n",
            "Training Loss : 0.02476668171584606\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 213 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2126])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 309.1153259277344\n",
            "Eval_StdReturn : 20.0125789642334\n",
            "Eval_MaxReturn : 324.22442626953125\n",
            "Eval_MinReturn : 280.83538818359375\n",
            "Eval_AverageEpLen : 165.33333333333334\n",
            "Train_AverageReturn : 279.2206115722656\n",
            "Train_StdReturn : 31.101675033569336\n",
            "Train_MaxReturn : 344.97955322265625\n",
            "Train_MinReturn : 210.40524291992188\n",
            "Train_AverageEpLen : 141.73333333333332\n",
            "Train_EnvstepsSoFar : 438771\n",
            "TimeSinceStart : 374.5292475223541\n",
            "Training Loss : -0.01800389774143696\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 214 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2063])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 308.5439147949219\n",
            "Eval_StdReturn : 27.491487503051758\n",
            "Eval_MaxReturn : 346.64581298828125\n",
            "Eval_MinReturn : 282.7953796386719\n",
            "Eval_AverageEpLen : 156.33333333333334\n",
            "Train_AverageReturn : 292.9128112792969\n",
            "Train_StdReturn : 33.467529296875\n",
            "Train_MaxReturn : 339.0986328125\n",
            "Train_MinReturn : 191.34010314941406\n",
            "Train_AverageEpLen : 158.69230769230768\n",
            "Train_EnvstepsSoFar : 440834\n",
            "TimeSinceStart : 376.1740097999573\n",
            "Training Loss : 0.012119632214307785\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 215 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2010])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 275.018310546875\n",
            "Eval_StdReturn : 41.8775520324707\n",
            "Eval_MaxReturn : 311.5476989746094\n",
            "Eval_MinReturn : 216.3828582763672\n",
            "Eval_AverageEpLen : 152.0\n",
            "Train_AverageReturn : 314.0610656738281\n",
            "Train_StdReturn : 42.28582000732422\n",
            "Train_MaxReturn : 391.96063232421875\n",
            "Train_MinReturn : 235.58216857910156\n",
            "Train_AverageEpLen : 167.5\n",
            "Train_EnvstepsSoFar : 442844\n",
            "TimeSinceStart : 377.7595593929291\n",
            "Training Loss : 0.02812846750020981\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 216 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2040])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 330.1424255371094\n",
            "Eval_StdReturn : 21.75994300842285\n",
            "Eval_MaxReturn : 354.610107421875\n",
            "Eval_MinReturn : 301.74560546875\n",
            "Eval_AverageEpLen : 164.66666666666666\n",
            "Train_AverageReturn : 296.3718566894531\n",
            "Train_StdReturn : 32.04640197753906\n",
            "Train_MaxReturn : 351.28863525390625\n",
            "Train_MinReturn : 238.1483917236328\n",
            "Train_AverageEpLen : 156.92307692307693\n",
            "Train_EnvstepsSoFar : 444884\n",
            "TimeSinceStart : 379.3912663459778\n",
            "Training Loss : 0.0035836962051689625\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 217 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2014])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 274.241943359375\n",
            "Eval_StdReturn : 25.999061584472656\n",
            "Eval_MaxReturn : 309.2982177734375\n",
            "Eval_MinReturn : 247.11070251464844\n",
            "Eval_AverageEpLen : 139.0\n",
            "Train_AverageReturn : 294.9862365722656\n",
            "Train_StdReturn : 19.16301727294922\n",
            "Train_MaxReturn : 325.1453857421875\n",
            "Train_MinReturn : 262.0071716308594\n",
            "Train_AverageEpLen : 152.64285714285714\n",
            "Train_EnvstepsSoFar : 447021\n",
            "TimeSinceStart : 381.01183700561523\n",
            "Training Loss : -0.05255713313817978\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 218 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2050])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 315.8050537109375\n",
            "Eval_StdReturn : 10.374917984008789\n",
            "Eval_MaxReturn : 330.3022766113281\n",
            "Eval_MinReturn : 306.5989990234375\n",
            "Eval_AverageEpLen : 170.66666666666666\n",
            "Train_AverageReturn : 301.7889404296875\n",
            "Train_StdReturn : 34.341087341308594\n",
            "Train_MaxReturn : 383.1746826171875\n",
            "Train_MinReturn : 257.5657653808594\n",
            "Train_AverageEpLen : 157.69230769230768\n",
            "Train_EnvstepsSoFar : 449071\n",
            "TimeSinceStart : 382.6519458293915\n",
            "Training Loss : 0.0012749821180477738\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 219 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2038])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 360.92315673828125\n",
            "Eval_StdReturn : 20.5081787109375\n",
            "Eval_MaxReturn : 381.43133544921875\n",
            "Eval_MinReturn : 340.41497802734375\n",
            "Eval_AverageEpLen : 204.5\n",
            "Train_AverageReturn : 298.0003662109375\n",
            "Train_StdReturn : 39.143218994140625\n",
            "Train_MaxReturn : 393.55010986328125\n",
            "Train_MinReturn : 239.2015838623047\n",
            "Train_AverageEpLen : 156.76923076923077\n",
            "Train_EnvstepsSoFar : 451109\n",
            "TimeSinceStart : 384.2387046813965\n",
            "Training Loss : -0.00012384617002680898\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 220 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2117])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 302.8274841308594\n",
            "Eval_StdReturn : 9.28972053527832\n",
            "Eval_MaxReturn : 315.253662109375\n",
            "Eval_MinReturn : 292.9210205078125\n",
            "Eval_AverageEpLen : 168.0\n",
            "Train_AverageReturn : 302.77392578125\n",
            "Train_StdReturn : 31.435392379760742\n",
            "Train_MaxReturn : 355.2036437988281\n",
            "Train_MinReturn : 241.4677734375\n",
            "Train_AverageEpLen : 151.21428571428572\n",
            "Train_EnvstepsSoFar : 453226\n",
            "TimeSinceStart : 385.95742654800415\n",
            "Training Loss : -0.050727713853120804\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 221 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2008])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 312.0090637207031\n",
            "Eval_StdReturn : 21.754098892211914\n",
            "Eval_MaxReturn : 328.877685546875\n",
            "Eval_MinReturn : 281.29364013671875\n",
            "Eval_AverageEpLen : 168.66666666666666\n",
            "Train_AverageReturn : 336.9625244140625\n",
            "Train_StdReturn : 49.643577575683594\n",
            "Train_MaxReturn : 428.87274169921875\n",
            "Train_MinReturn : 246.3693084716797\n",
            "Train_AverageEpLen : 182.54545454545453\n",
            "Train_EnvstepsSoFar : 455234\n",
            "TimeSinceStart : 387.5691213607788\n",
            "Training Loss : -0.0466393381357193\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 222 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2120])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 274.27850341796875\n",
            "Eval_StdReturn : 17.4249267578125\n",
            "Eval_MaxReturn : 287.619140625\n",
            "Eval_MinReturn : 249.6648712158203\n",
            "Eval_AverageEpLen : 134.66666666666666\n",
            "Train_AverageReturn : 329.876708984375\n",
            "Train_StdReturn : 45.25874328613281\n",
            "Train_MaxReturn : 414.7628173828125\n",
            "Train_MinReturn : 265.1396484375\n",
            "Train_AverageEpLen : 176.66666666666666\n",
            "Train_EnvstepsSoFar : 457354\n",
            "TimeSinceStart : 389.20642137527466\n",
            "Training Loss : 0.009885921142995358\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 223 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2110])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 281.1949157714844\n",
            "Eval_StdReturn : 18.922237396240234\n",
            "Eval_MaxReturn : 306.3495178222656\n",
            "Eval_MinReturn : 260.7112121582031\n",
            "Eval_AverageEpLen : 137.0\n",
            "Train_AverageReturn : 331.5788269042969\n",
            "Train_StdReturn : 27.931377410888672\n",
            "Train_MaxReturn : 380.9947509765625\n",
            "Train_MinReturn : 281.86981201171875\n",
            "Train_AverageEpLen : 175.83333333333334\n",
            "Train_EnvstepsSoFar : 459464\n",
            "TimeSinceStart : 390.8315405845642\n",
            "Training Loss : 0.0584944523870945\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 224 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2035])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 291.6103515625\n",
            "Eval_StdReturn : 17.02457046508789\n",
            "Eval_MaxReturn : 308.26165771484375\n",
            "Eval_MinReturn : 268.22467041015625\n",
            "Eval_AverageEpLen : 158.0\n",
            "Train_AverageReturn : 293.03076171875\n",
            "Train_StdReturn : 38.33857727050781\n",
            "Train_MaxReturn : 365.16107177734375\n",
            "Train_MinReturn : 201.81704711914062\n",
            "Train_AverageEpLen : 145.35714285714286\n",
            "Train_EnvstepsSoFar : 461499\n",
            "TimeSinceStart : 392.4306073188782\n",
            "Training Loss : 0.005006884690374136\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 225 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2061])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 273.7843017578125\n",
            "Eval_StdReturn : 17.8237247467041\n",
            "Eval_MaxReturn : 297.9024963378906\n",
            "Eval_MinReturn : 255.37997436523438\n",
            "Eval_AverageEpLen : 136.66666666666666\n",
            "Train_AverageReturn : 306.25\n",
            "Train_StdReturn : 36.688323974609375\n",
            "Train_MaxReturn : 371.38238525390625\n",
            "Train_MinReturn : 251.54873657226562\n",
            "Train_AverageEpLen : 158.53846153846155\n",
            "Train_EnvstepsSoFar : 463560\n",
            "TimeSinceStart : 394.0289943218231\n",
            "Training Loss : -0.01672796532511711\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 226 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2027])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 298.9365539550781\n",
            "Eval_StdReturn : 33.409454345703125\n",
            "Eval_MaxReturn : 335.8078918457031\n",
            "Eval_MinReturn : 254.91445922851562\n",
            "Eval_AverageEpLen : 170.0\n",
            "Train_AverageReturn : 297.7997131347656\n",
            "Train_StdReturn : 37.017574310302734\n",
            "Train_MaxReturn : 357.0993957519531\n",
            "Train_MinReturn : 198.30596923828125\n",
            "Train_AverageEpLen : 144.78571428571428\n",
            "Train_EnvstepsSoFar : 465587\n",
            "TimeSinceStart : 395.6798167228699\n",
            "Training Loss : 0.04239746928215027\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 227 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2015])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 258.4373474121094\n",
            "Eval_StdReturn : 35.39930725097656\n",
            "Eval_MaxReturn : 300.2052917480469\n",
            "Eval_MinReturn : 210.1362762451172\n",
            "Eval_AverageEpLen : 130.25\n",
            "Train_AverageReturn : 321.7111511230469\n",
            "Train_StdReturn : 46.14624786376953\n",
            "Train_MaxReturn : 413.4494934082031\n",
            "Train_MinReturn : 222.13153076171875\n",
            "Train_AverageEpLen : 167.0\n",
            "Train_EnvstepsSoFar : 467758\n",
            "TimeSinceStart : 397.42366766929626\n",
            "Training Loss : -0.014511155895888805\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 228 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2048])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 285.3258972167969\n",
            "Eval_StdReturn : 49.72199249267578\n",
            "Eval_MaxReturn : 355.5640869140625\n",
            "Eval_MinReturn : 247.3153533935547\n",
            "Eval_AverageEpLen : 140.66666666666666\n",
            "Train_AverageReturn : 296.9775390625\n",
            "Train_StdReturn : 40.887264251708984\n",
            "Train_MaxReturn : 374.21185302734375\n",
            "Train_MinReturn : 212.71360778808594\n",
            "Train_AverageEpLen : 157.53846153846155\n",
            "Train_EnvstepsSoFar : 469806\n",
            "TimeSinceStart : 399.02202582359314\n",
            "Training Loss : -0.050672899931669235\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 229 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2067])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 293.3299255371094\n",
            "Eval_StdReturn : 21.129676818847656\n",
            "Eval_MaxReturn : 322.6510009765625\n",
            "Eval_MinReturn : 273.6793212890625\n",
            "Eval_AverageEpLen : 145.66666666666666\n",
            "Train_AverageReturn : 312.063232421875\n",
            "Train_StdReturn : 28.390174865722656\n",
            "Train_MaxReturn : 363.09747314453125\n",
            "Train_MinReturn : 256.7606506347656\n",
            "Train_AverageEpLen : 159.0\n",
            "Train_EnvstepsSoFar : 471873\n",
            "TimeSinceStart : 400.642076253891\n",
            "Training Loss : -0.02230614796280861\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 230 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2135])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 322.22540283203125\n",
            "Eval_StdReturn : 56.55815887451172\n",
            "Eval_MaxReturn : 391.3952331542969\n",
            "Eval_MinReturn : 252.85702514648438\n",
            "Eval_AverageEpLen : 176.66666666666666\n",
            "Train_AverageReturn : 310.9021301269531\n",
            "Train_StdReturn : 28.303022384643555\n",
            "Train_MaxReturn : 342.6334228515625\n",
            "Train_MinReturn : 243.04489135742188\n",
            "Train_AverageEpLen : 152.5\n",
            "Train_EnvstepsSoFar : 474008\n",
            "TimeSinceStart : 402.35505199432373\n",
            "Training Loss : 0.023921892046928406\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 231 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2047])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 294.7498474121094\n",
            "Eval_StdReturn : 60.162353515625\n",
            "Eval_MaxReturn : 352.810302734375\n",
            "Eval_MinReturn : 211.85867309570312\n",
            "Eval_AverageEpLen : 147.0\n",
            "Train_AverageReturn : 322.1345520019531\n",
            "Train_StdReturn : 37.88082504272461\n",
            "Train_MaxReturn : 377.88916015625\n",
            "Train_MinReturn : 254.66818237304688\n",
            "Train_AverageEpLen : 167.3846153846154\n",
            "Train_EnvstepsSoFar : 476184\n",
            "TimeSinceStart : 404.05016899108887\n",
            "Training Loss : -0.022389614954590797\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 232 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2014])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 301.04083251953125\n",
            "Eval_StdReturn : 1.951951265335083\n",
            "Eval_MaxReturn : 303.5690002441406\n",
            "Eval_MinReturn : 298.81683349609375\n",
            "Eval_AverageEpLen : 154.0\n",
            "Train_AverageReturn : 302.09375\n",
            "Train_StdReturn : 56.42751693725586\n",
            "Train_MaxReturn : 366.174072265625\n",
            "Train_MinReturn : 173.11233520507812\n",
            "Train_AverageEpLen : 154.92307692307693\n",
            "Train_EnvstepsSoFar : 478198\n",
            "TimeSinceStart : 405.6521415710449\n",
            "Training Loss : -0.0348847471177578\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 233 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2019])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 322.0790100097656\n",
            "Eval_StdReturn : 7.036874771118164\n",
            "Eval_MaxReturn : 327.69366455078125\n",
            "Eval_MinReturn : 312.1559753417969\n",
            "Eval_AverageEpLen : 169.0\n",
            "Train_AverageReturn : 333.2864685058594\n",
            "Train_StdReturn : 29.44497299194336\n",
            "Train_MaxReturn : 370.437744140625\n",
            "Train_MinReturn : 260.0718994140625\n",
            "Train_AverageEpLen : 168.25\n",
            "Train_EnvstepsSoFar : 480217\n",
            "TimeSinceStart : 407.3048822879791\n",
            "Training Loss : 0.02894827350974083\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 234 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2035])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 303.9162292480469\n",
            "Eval_StdReturn : 15.631095886230469\n",
            "Eval_MaxReturn : 323.01171875\n",
            "Eval_MinReturn : 284.723876953125\n",
            "Eval_AverageEpLen : 150.66666666666666\n",
            "Train_AverageReturn : 320.239013671875\n",
            "Train_StdReturn : 30.48573875427246\n",
            "Train_MaxReturn : 373.7786865234375\n",
            "Train_MinReturn : 267.1209716796875\n",
            "Train_AverageEpLen : 169.58333333333334\n",
            "Train_EnvstepsSoFar : 482252\n",
            "TimeSinceStart : 408.9183883666992\n",
            "Training Loss : -0.0027825222350656986\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 235 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2044])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 291.4682312011719\n",
            "Eval_StdReturn : 31.021268844604492\n",
            "Eval_MaxReturn : 313.88397216796875\n",
            "Eval_MinReturn : 247.60105895996094\n",
            "Eval_AverageEpLen : 157.0\n",
            "Train_AverageReturn : 334.5208435058594\n",
            "Train_StdReturn : 39.311397552490234\n",
            "Train_MaxReturn : 409.7672119140625\n",
            "Train_MinReturn : 283.3222961425781\n",
            "Train_AverageEpLen : 170.33333333333334\n",
            "Train_EnvstepsSoFar : 484296\n",
            "TimeSinceStart : 410.5387077331543\n",
            "Training Loss : 0.013314127922058105\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 236 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2124])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 363.765625\n",
            "Eval_StdReturn : 49.021461486816406\n",
            "Eval_MaxReturn : 429.68902587890625\n",
            "Eval_MinReturn : 312.22344970703125\n",
            "Eval_AverageEpLen : 188.33333333333334\n",
            "Train_AverageReturn : 340.04559326171875\n",
            "Train_StdReturn : 21.1091365814209\n",
            "Train_MaxReturn : 379.2396240234375\n",
            "Train_MinReturn : 308.5966796875\n",
            "Train_AverageEpLen : 177.0\n",
            "Train_EnvstepsSoFar : 486420\n",
            "TimeSinceStart : 412.26646518707275\n",
            "Training Loss : -0.028042549267411232\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 237 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2003])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 265.47796630859375\n",
            "Eval_StdReturn : 70.58917999267578\n",
            "Eval_MaxReturn : 358.1732177734375\n",
            "Eval_MinReturn : 187.0376434326172\n",
            "Eval_AverageEpLen : 141.66666666666666\n",
            "Train_AverageReturn : 321.16644287109375\n",
            "Train_StdReturn : 48.76264190673828\n",
            "Train_MaxReturn : 413.01385498046875\n",
            "Train_MinReturn : 232.80894470214844\n",
            "Train_AverageEpLen : 164.30769230769232\n",
            "Train_EnvstepsSoFar : 488556\n",
            "TimeSinceStart : 413.91740226745605\n",
            "Training Loss : -0.019958017393946648\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 238 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2060])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 286.3133850097656\n",
            "Eval_StdReturn : 69.30818176269531\n",
            "Eval_MaxReturn : 370.68780517578125\n",
            "Eval_MinReturn : 200.92718505859375\n",
            "Eval_AverageEpLen : 146.33333333333334\n",
            "Train_AverageReturn : 338.3276672363281\n",
            "Train_StdReturn : 43.14003372192383\n",
            "Train_MaxReturn : 435.40087890625\n",
            "Train_MinReturn : 286.3898010253906\n",
            "Train_AverageEpLen : 171.66666666666666\n",
            "Train_EnvstepsSoFar : 490616\n",
            "TimeSinceStart : 415.54381680488586\n",
            "Training Loss : 0.007437842898070812\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 239 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2067])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 309.4375305175781\n",
            "Eval_StdReturn : 48.589847564697266\n",
            "Eval_MaxReturn : 360.31036376953125\n",
            "Eval_MinReturn : 243.99578857421875\n",
            "Eval_AverageEpLen : 155.33333333333334\n",
            "Train_AverageReturn : 320.78656005859375\n",
            "Train_StdReturn : 55.93186569213867\n",
            "Train_MaxReturn : 385.3548889160156\n",
            "Train_MinReturn : 182.09913635253906\n",
            "Train_AverageEpLen : 172.25\n",
            "Train_EnvstepsSoFar : 492683\n",
            "TimeSinceStart : 417.23284220695496\n",
            "Training Loss : -0.003898057620972395\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 240 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2003])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 337.0716857910156\n",
            "Eval_StdReturn : 30.554128646850586\n",
            "Eval_MaxReturn : 379.40692138671875\n",
            "Eval_MinReturn : 308.4122314453125\n",
            "Eval_AverageEpLen : 175.33333333333334\n",
            "Train_AverageReturn : 349.9789733886719\n",
            "Train_StdReturn : 30.960140228271484\n",
            "Train_MaxReturn : 390.7489318847656\n",
            "Train_MinReturn : 302.8443603515625\n",
            "Train_AverageEpLen : 182.0909090909091\n",
            "Train_EnvstepsSoFar : 494686\n",
            "TimeSinceStart : 418.8662326335907\n",
            "Training Loss : -0.04665046185255051\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 241 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2022])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 307.7051086425781\n",
            "Eval_StdReturn : 46.36159133911133\n",
            "Eval_MaxReturn : 355.3172302246094\n",
            "Eval_MinReturn : 244.8617401123047\n",
            "Eval_AverageEpLen : 166.0\n",
            "Train_AverageReturn : 334.43890380859375\n",
            "Train_StdReturn : 42.4355354309082\n",
            "Train_MaxReturn : 415.25390625\n",
            "Train_MinReturn : 255.4447784423828\n",
            "Train_AverageEpLen : 168.5\n",
            "Train_EnvstepsSoFar : 496708\n",
            "TimeSinceStart : 420.5919852256775\n",
            "Training Loss : 0.004850832745432854\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 242 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2039])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 313.504150390625\n",
            "Eval_StdReturn : 37.95694351196289\n",
            "Eval_MaxReturn : 356.8979187011719\n",
            "Eval_MinReturn : 264.4425048828125\n",
            "Eval_AverageEpLen : 156.0\n",
            "Train_AverageReturn : 316.00189208984375\n",
            "Train_StdReturn : 68.31401062011719\n",
            "Train_MaxReturn : 393.76806640625\n",
            "Train_MinReturn : 140.9766387939453\n",
            "Train_AverageEpLen : 156.84615384615384\n",
            "Train_EnvstepsSoFar : 498747\n",
            "TimeSinceStart : 422.24402809143066\n",
            "Training Loss : -0.017652956768870354\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 243 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2063])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 311.1406555175781\n",
            "Eval_StdReturn : 9.912383079528809\n",
            "Eval_MaxReturn : 325.06365966796875\n",
            "Eval_MinReturn : 302.7664794921875\n",
            "Eval_AverageEpLen : 148.33333333333334\n",
            "Train_AverageReturn : 302.2551574707031\n",
            "Train_StdReturn : 61.30302047729492\n",
            "Train_MaxReturn : 374.7041931152344\n",
            "Train_MinReturn : 168.9465789794922\n",
            "Train_AverageEpLen : 147.35714285714286\n",
            "Train_EnvstepsSoFar : 500810\n",
            "TimeSinceStart : 423.8552770614624\n",
            "Training Loss : -0.03265860676765442\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 244 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2021])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 336.8403015136719\n",
            "Eval_StdReturn : 34.48366165161133\n",
            "Eval_MaxReturn : 385.587158203125\n",
            "Eval_MinReturn : 311.2454833984375\n",
            "Eval_AverageEpLen : 181.66666666666666\n",
            "Train_AverageReturn : 350.28778076171875\n",
            "Train_StdReturn : 55.61930465698242\n",
            "Train_MaxReturn : 449.69879150390625\n",
            "Train_MinReturn : 269.2135009765625\n",
            "Train_AverageEpLen : 183.72727272727272\n",
            "Train_EnvstepsSoFar : 502831\n",
            "TimeSinceStart : 425.5029966831207\n",
            "Training Loss : 0.037483129650354385\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 245 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2010])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 359.1913146972656\n",
            "Eval_StdReturn : 8.935014724731445\n",
            "Eval_MaxReturn : 371.7813720703125\n",
            "Eval_MinReturn : 351.96368408203125\n",
            "Eval_AverageEpLen : 180.66666666666666\n",
            "Train_AverageReturn : 334.80743408203125\n",
            "Train_StdReturn : 69.21080780029297\n",
            "Train_MaxReturn : 442.80242919921875\n",
            "Train_MinReturn : 215.9904327392578\n",
            "Train_AverageEpLen : 177.25\n",
            "Train_EnvstepsSoFar : 504958\n",
            "TimeSinceStart : 427.20638132095337\n",
            "Training Loss : -0.003576976712793112\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 246 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2122])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 348.7350158691406\n",
            "Eval_StdReturn : 12.159711837768555\n",
            "Eval_MaxReturn : 365.58367919921875\n",
            "Eval_MinReturn : 337.330810546875\n",
            "Eval_AverageEpLen : 172.33333333333334\n",
            "Train_AverageReturn : 340.25848388671875\n",
            "Train_StdReturn : 43.46712875366211\n",
            "Train_MaxReturn : 425.19622802734375\n",
            "Train_MinReturn : 266.2468566894531\n",
            "Train_AverageEpLen : 176.83333333333334\n",
            "Train_EnvstepsSoFar : 507080\n",
            "TimeSinceStart : 428.8972611427307\n",
            "Training Loss : 0.01744733937084675\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 247 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2090])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 387.62677001953125\n",
            "Eval_StdReturn : 16.915176391601562\n",
            "Eval_MaxReturn : 404.54193115234375\n",
            "Eval_MinReturn : 370.7115783691406\n",
            "Eval_AverageEpLen : 212.0\n",
            "Train_AverageReturn : 325.6786804199219\n",
            "Train_StdReturn : 64.87631225585938\n",
            "Train_MaxReturn : 398.82061767578125\n",
            "Train_MinReturn : 184.09059143066406\n",
            "Train_AverageEpLen : 174.16666666666666\n",
            "Train_EnvstepsSoFar : 509170\n",
            "TimeSinceStart : 430.5373396873474\n",
            "Training Loss : 0.02654236927628517\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 248 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2104])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 384.83367919921875\n",
            "Eval_StdReturn : 8.08428955078125\n",
            "Eval_MaxReturn : 392.91796875\n",
            "Eval_MinReturn : 376.7493896484375\n",
            "Eval_AverageEpLen : 210.5\n",
            "Train_AverageReturn : 312.0256652832031\n",
            "Train_StdReturn : 64.01890563964844\n",
            "Train_MaxReturn : 380.57177734375\n",
            "Train_MinReturn : 157.3594970703125\n",
            "Train_AverageEpLen : 150.28571428571428\n",
            "Train_EnvstepsSoFar : 511274\n",
            "TimeSinceStart : 432.14729857444763\n",
            "Training Loss : -0.0018599710892885923\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 249 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2150])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 330.14495849609375\n",
            "Eval_StdReturn : 20.38606071472168\n",
            "Eval_MaxReturn : 358.8939514160156\n",
            "Eval_MinReturn : 313.89727783203125\n",
            "Eval_AverageEpLen : 161.66666666666666\n",
            "Train_AverageReturn : 346.257568359375\n",
            "Train_StdReturn : 69.87060546875\n",
            "Train_MaxReturn : 450.8056640625\n",
            "Train_MinReturn : 179.874267578125\n",
            "Train_AverageEpLen : 179.16666666666666\n",
            "Train_EnvstepsSoFar : 513424\n",
            "TimeSinceStart : 433.82178807258606\n",
            "Training Loss : 0.011999261565506458\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 250 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2006])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 361.5016784667969\n",
            "Eval_StdReturn : 17.867128372192383\n",
            "Eval_MaxReturn : 385.7000732421875\n",
            "Eval_MinReturn : 343.1033020019531\n",
            "Eval_AverageEpLen : 197.0\n",
            "Train_AverageReturn : 351.1167297363281\n",
            "Train_StdReturn : 46.663917541503906\n",
            "Train_MaxReturn : 424.7351379394531\n",
            "Train_MinReturn : 266.98419189453125\n",
            "Train_AverageEpLen : 182.36363636363637\n",
            "Train_EnvstepsSoFar : 515430\n",
            "TimeSinceStart : 435.4845461845398\n",
            "Training Loss : -0.01332841906696558\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 251 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2061])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 351.943115234375\n",
            "Eval_StdReturn : 64.58656311035156\n",
            "Eval_MaxReturn : 424.05853271484375\n",
            "Eval_MinReturn : 267.3399658203125\n",
            "Eval_AverageEpLen : 181.66666666666666\n",
            "Train_AverageReturn : 366.5214538574219\n",
            "Train_StdReturn : 54.513832092285156\n",
            "Train_MaxReturn : 456.0946044921875\n",
            "Train_MinReturn : 236.97979736328125\n",
            "Train_AverageEpLen : 187.36363636363637\n",
            "Train_EnvstepsSoFar : 517491\n",
            "TimeSinceStart : 437.1704523563385\n",
            "Training Loss : -0.02135048247873783\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 252 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2095])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 337.7802429199219\n",
            "Eval_StdReturn : 4.743189811706543\n",
            "Eval_MaxReturn : 344.36181640625\n",
            "Eval_MinReturn : 333.367431640625\n",
            "Eval_AverageEpLen : 163.66666666666666\n",
            "Train_AverageReturn : 394.8003234863281\n",
            "Train_StdReturn : 42.63089370727539\n",
            "Train_MaxReturn : 464.164306640625\n",
            "Train_MinReturn : 315.0177001953125\n",
            "Train_AverageEpLen : 209.5\n",
            "Train_EnvstepsSoFar : 519586\n",
            "TimeSinceStart : 438.8405644893646\n",
            "Training Loss : -0.006118532735854387\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 253 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2022])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 321.7580261230469\n",
            "Eval_StdReturn : 19.603349685668945\n",
            "Eval_MaxReturn : 346.35394287109375\n",
            "Eval_MinReturn : 298.38226318359375\n",
            "Eval_AverageEpLen : 162.66666666666666\n",
            "Train_AverageReturn : 349.83056640625\n",
            "Train_StdReturn : 31.8089542388916\n",
            "Train_MaxReturn : 413.81591796875\n",
            "Train_MinReturn : 303.57989501953125\n",
            "Train_AverageEpLen : 168.5\n",
            "Train_EnvstepsSoFar : 521608\n",
            "TimeSinceStart : 440.4855947494507\n",
            "Training Loss : 0.01769087091088295\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 254 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2061])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 357.9751892089844\n",
            "Eval_StdReturn : 30.186500549316406\n",
            "Eval_MaxReturn : 390.46270751953125\n",
            "Eval_MinReturn : 317.74688720703125\n",
            "Eval_AverageEpLen : 187.0\n",
            "Train_AverageReturn : 330.6240539550781\n",
            "Train_StdReturn : 56.18675994873047\n",
            "Train_MaxReturn : 415.198974609375\n",
            "Train_MinReturn : 220.98907470703125\n",
            "Train_AverageEpLen : 171.75\n",
            "Train_EnvstepsSoFar : 523669\n",
            "TimeSinceStart : 442.17159485816956\n",
            "Training Loss : -0.0215659961104393\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 255 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2020])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 400.28436279296875\n",
            "Eval_StdReturn : 8.6536865234375\n",
            "Eval_MaxReturn : 408.93804931640625\n",
            "Eval_MinReturn : 391.63067626953125\n",
            "Eval_AverageEpLen : 203.5\n",
            "Train_AverageReturn : 344.5897216796875\n",
            "Train_StdReturn : 27.099409103393555\n",
            "Train_MaxReturn : 382.70501708984375\n",
            "Train_MinReturn : 281.9061279296875\n",
            "Train_AverageEpLen : 168.33333333333334\n",
            "Train_EnvstepsSoFar : 525689\n",
            "TimeSinceStart : 443.7439548969269\n",
            "Training Loss : 0.02100369706749916\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 256 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2011])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 339.3357849121094\n",
            "Eval_StdReturn : 31.63780403137207\n",
            "Eval_MaxReturn : 383.9953308105469\n",
            "Eval_MinReturn : 314.6461181640625\n",
            "Eval_AverageEpLen : 179.66666666666666\n",
            "Train_AverageReturn : 373.3586730957031\n",
            "Train_StdReturn : 54.51058578491211\n",
            "Train_MaxReturn : 463.35870361328125\n",
            "Train_MinReturn : 290.4299621582031\n",
            "Train_AverageEpLen : 196.8181818181818\n",
            "Train_EnvstepsSoFar : 527854\n",
            "TimeSinceStart : 445.49273204803467\n",
            "Training Loss : -0.003026058431714773\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 257 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2043])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 356.3527526855469\n",
            "Eval_StdReturn : 23.954927444458008\n",
            "Eval_MaxReturn : 380.4620056152344\n",
            "Eval_MinReturn : 323.68707275390625\n",
            "Eval_AverageEpLen : 179.66666666666666\n",
            "Train_AverageReturn : 341.962890625\n",
            "Train_StdReturn : 25.163158416748047\n",
            "Train_MaxReturn : 376.63421630859375\n",
            "Train_MinReturn : 304.4700012207031\n",
            "Train_AverageEpLen : 170.25\n",
            "Train_EnvstepsSoFar : 529897\n",
            "TimeSinceStart : 447.17112278938293\n",
            "Training Loss : -0.02918349951505661\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 258 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2036])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 366.8068542480469\n",
            "Eval_StdReturn : 18.632352828979492\n",
            "Eval_MaxReturn : 392.6435546875\n",
            "Eval_MinReturn : 349.40576171875\n",
            "Eval_AverageEpLen : 184.33333333333334\n",
            "Train_AverageReturn : 374.4758605957031\n",
            "Train_StdReturn : 29.37029266357422\n",
            "Train_MaxReturn : 413.2979431152344\n",
            "Train_MinReturn : 332.26300048828125\n",
            "Train_AverageEpLen : 203.6\n",
            "Train_EnvstepsSoFar : 531933\n",
            "TimeSinceStart : 448.8295724391937\n",
            "Training Loss : 0.049109429121017456\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 259 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2135])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 374.3089294433594\n",
            "Eval_StdReturn : 44.082759857177734\n",
            "Eval_MaxReturn : 436.50640869140625\n",
            "Eval_MinReturn : 339.5307922363281\n",
            "Eval_AverageEpLen : 195.0\n",
            "Train_AverageReturn : 338.36956787109375\n",
            "Train_StdReturn : 39.46623992919922\n",
            "Train_MaxReturn : 383.11236572265625\n",
            "Train_MinReturn : 215.43246459960938\n",
            "Train_AverageEpLen : 164.23076923076923\n",
            "Train_EnvstepsSoFar : 534068\n",
            "TimeSinceStart : 450.58441829681396\n",
            "Training Loss : -0.004018071573227644\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 260 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2059])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 379.44329833984375\n",
            "Eval_StdReturn : 12.097274780273438\n",
            "Eval_MaxReturn : 391.54058837890625\n",
            "Eval_MinReturn : 367.3460388183594\n",
            "Eval_AverageEpLen : 202.0\n",
            "Train_AverageReturn : 378.3734436035156\n",
            "Train_StdReturn : 41.41349792480469\n",
            "Train_MaxReturn : 434.9798583984375\n",
            "Train_MinReturn : 294.2210693359375\n",
            "Train_AverageEpLen : 205.9\n",
            "Train_EnvstepsSoFar : 536127\n",
            "TimeSinceStart : 452.1850326061249\n",
            "Training Loss : 0.045161936432123184\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 261 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2115])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 367.9041442871094\n",
            "Eval_StdReturn : 31.59616470336914\n",
            "Eval_MaxReturn : 408.04827880859375\n",
            "Eval_MinReturn : 330.83758544921875\n",
            "Eval_AverageEpLen : 186.66666666666666\n",
            "Train_AverageReturn : 365.8296203613281\n",
            "Train_StdReturn : 35.09225845336914\n",
            "Train_MaxReturn : 441.3487854003906\n",
            "Train_MinReturn : 316.3305969238281\n",
            "Train_AverageEpLen : 192.27272727272728\n",
            "Train_EnvstepsSoFar : 538242\n",
            "TimeSinceStart : 453.90451407432556\n",
            "Training Loss : 0.01002472173422575\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 262 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2149])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 349.7055969238281\n",
            "Eval_StdReturn : 20.953819274902344\n",
            "Eval_MaxReturn : 379.333740234375\n",
            "Eval_MinReturn : 334.41815185546875\n",
            "Eval_AverageEpLen : 168.0\n",
            "Train_AverageReturn : 344.57421875\n",
            "Train_StdReturn : 60.95061492919922\n",
            "Train_MaxReturn : 414.57208251953125\n",
            "Train_MinReturn : 176.69769287109375\n",
            "Train_AverageEpLen : 179.08333333333334\n",
            "Train_EnvstepsSoFar : 540391\n",
            "TimeSinceStart : 455.61222290992737\n",
            "Training Loss : 0.0009584795334376395\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 263 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2086])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 396.2065124511719\n",
            "Eval_StdReturn : 22.10723876953125\n",
            "Eval_MaxReturn : 418.3137512207031\n",
            "Eval_MinReturn : 374.0992736816406\n",
            "Eval_AverageEpLen : 225.0\n",
            "Train_AverageReturn : 352.301025390625\n",
            "Train_StdReturn : 36.723052978515625\n",
            "Train_MaxReturn : 438.83013916015625\n",
            "Train_MinReturn : 294.72076416015625\n",
            "Train_AverageEpLen : 173.83333333333334\n",
            "Train_EnvstepsSoFar : 542477\n",
            "TimeSinceStart : 457.2908477783203\n",
            "Training Loss : -0.02264910563826561\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 264 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2100])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 338.5250549316406\n",
            "Eval_StdReturn : 31.170976638793945\n",
            "Eval_MaxReturn : 378.2657470703125\n",
            "Eval_MinReturn : 302.1334228515625\n",
            "Eval_AverageEpLen : 177.0\n",
            "Train_AverageReturn : 365.87982177734375\n",
            "Train_StdReturn : 31.501663208007812\n",
            "Train_MaxReturn : 413.19281005859375\n",
            "Train_MinReturn : 311.9359130859375\n",
            "Train_AverageEpLen : 190.9090909090909\n",
            "Train_EnvstepsSoFar : 544577\n",
            "TimeSinceStart : 458.99287128448486\n",
            "Training Loss : 0.0065492684952914715\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 265 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2152])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 407.30078125\n",
            "Eval_StdReturn : 18.556472778320312\n",
            "Eval_MaxReturn : 425.8572692871094\n",
            "Eval_MinReturn : 388.74432373046875\n",
            "Eval_AverageEpLen : 216.5\n",
            "Train_AverageReturn : 356.2137145996094\n",
            "Train_StdReturn : 27.058086395263672\n",
            "Train_MaxReturn : 391.4476623535156\n",
            "Train_MinReturn : 310.02728271484375\n",
            "Train_AverageEpLen : 179.33333333333334\n",
            "Train_EnvstepsSoFar : 546729\n",
            "TimeSinceStart : 460.66438817977905\n",
            "Training Loss : 0.018070872873067856\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 266 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2006])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 335.246337890625\n",
            "Eval_StdReturn : 4.657480239868164\n",
            "Eval_MaxReturn : 339.5489807128906\n",
            "Eval_MinReturn : 328.7760314941406\n",
            "Eval_AverageEpLen : 171.66666666666666\n",
            "Train_AverageReturn : 380.42987060546875\n",
            "Train_StdReturn : 30.764760971069336\n",
            "Train_MaxReturn : 432.3011474609375\n",
            "Train_MinReturn : 341.962646484375\n",
            "Train_AverageEpLen : 201.1818181818182\n",
            "Train_EnvstepsSoFar : 548942\n",
            "TimeSinceStart : 462.42958545684814\n",
            "Training Loss : -0.005908322054892778\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 267 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2012])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 373.6997375488281\n",
            "Eval_StdReturn : 21.69997215270996\n",
            "Eval_MaxReturn : 391.5085754394531\n",
            "Eval_MinReturn : 343.1512451171875\n",
            "Eval_AverageEpLen : 196.0\n",
            "Train_AverageReturn : 364.27978515625\n",
            "Train_StdReturn : 34.011940002441406\n",
            "Train_MaxReturn : 437.1112060546875\n",
            "Train_MinReturn : 327.0780944824219\n",
            "Train_AverageEpLen : 180.91666666666666\n",
            "Train_EnvstepsSoFar : 551113\n",
            "TimeSinceStart : 464.20995116233826\n",
            "Training Loss : 0.0025634129997342825\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 268 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2016])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 352.0\n",
            "Eval_StdReturn : 9.905438423156738\n",
            "Eval_MaxReturn : 362.892822265625\n",
            "Eval_MinReturn : 338.92559814453125\n",
            "Eval_AverageEpLen : 176.66666666666666\n",
            "Train_AverageReturn : 359.6244812011719\n",
            "Train_StdReturn : 32.97063064575195\n",
            "Train_MaxReturn : 421.94879150390625\n",
            "Train_MinReturn : 308.4609375\n",
            "Train_AverageEpLen : 180.41666666666666\n",
            "Train_EnvstepsSoFar : 553278\n",
            "TimeSinceStart : 465.9481291770935\n",
            "Training Loss : -0.02869306690990925\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 269 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2002])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 319.3046875\n",
            "Eval_StdReturn : 11.247881889343262\n",
            "Eval_MaxReturn : 332.09912109375\n",
            "Eval_MinReturn : 304.72216796875\n",
            "Eval_AverageEpLen : 157.0\n",
            "Train_AverageReturn : 346.03375244140625\n",
            "Train_StdReturn : 50.75766372680664\n",
            "Train_MaxReturn : 432.36309814453125\n",
            "Train_MinReturn : 236.20448303222656\n",
            "Train_AverageEpLen : 182.0\n",
            "Train_EnvstepsSoFar : 555280\n",
            "TimeSinceStart : 467.544593334198\n",
            "Training Loss : -0.028245512396097183\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 270 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2096])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 314.1989440917969\n",
            "Eval_StdReturn : 97.06100463867188\n",
            "Eval_MaxReturn : 409.6676025390625\n",
            "Eval_MinReturn : 181.05056762695312\n",
            "Eval_AverageEpLen : 176.66666666666666\n",
            "Train_AverageReturn : 379.3533935546875\n",
            "Train_StdReturn : 33.492828369140625\n",
            "Train_MaxReturn : 442.8494873046875\n",
            "Train_MinReturn : 329.85693359375\n",
            "Train_AverageEpLen : 190.54545454545453\n",
            "Train_EnvstepsSoFar : 557376\n",
            "TimeSinceStart : 469.22591185569763\n",
            "Training Loss : -0.026445426046848297\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 271 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2003])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 330.4612121582031\n",
            "Eval_StdReturn : 37.664024353027344\n",
            "Eval_MaxReturn : 375.00457763671875\n",
            "Eval_MinReturn : 282.89556884765625\n",
            "Eval_AverageEpLen : 168.66666666666666\n",
            "Train_AverageReturn : 361.5031433105469\n",
            "Train_StdReturn : 22.121912002563477\n",
            "Train_MaxReturn : 393.65960693359375\n",
            "Train_MinReturn : 323.2929382324219\n",
            "Train_AverageEpLen : 182.0909090909091\n",
            "Train_EnvstepsSoFar : 559379\n",
            "TimeSinceStart : 470.8479788303375\n",
            "Training Loss : 0.002526023192331195\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 272 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2092])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 364.0658264160156\n",
            "Eval_StdReturn : 3.673506259918213\n",
            "Eval_MaxReturn : 368.7997741699219\n",
            "Eval_MinReturn : 359.8456726074219\n",
            "Eval_AverageEpLen : 177.0\n",
            "Train_AverageReturn : 372.0776672363281\n",
            "Train_StdReturn : 32.7440071105957\n",
            "Train_MaxReturn : 423.84710693359375\n",
            "Train_MinReturn : 310.17108154296875\n",
            "Train_AverageEpLen : 190.1818181818182\n",
            "Train_EnvstepsSoFar : 561471\n",
            "TimeSinceStart : 472.51867270469666\n",
            "Training Loss : -0.014597643166780472\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 273 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2133])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 349.0268859863281\n",
            "Eval_StdReturn : 17.319786071777344\n",
            "Eval_MaxReturn : 365.8014831542969\n",
            "Eval_MinReturn : 325.1824951171875\n",
            "Eval_AverageEpLen : 174.33333333333334\n",
            "Train_AverageReturn : 353.52508544921875\n",
            "Train_StdReturn : 31.869949340820312\n",
            "Train_MaxReturn : 412.24700927734375\n",
            "Train_MinReturn : 320.98406982421875\n",
            "Train_AverageEpLen : 164.07692307692307\n",
            "Train_EnvstepsSoFar : 563604\n",
            "TimeSinceStart : 474.23303389549255\n",
            "Training Loss : -0.055595915764570236\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 274 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2126])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 402.85247802734375\n",
            "Eval_StdReturn : 54.5303955078125\n",
            "Eval_MaxReturn : 457.38287353515625\n",
            "Eval_MinReturn : 348.32208251953125\n",
            "Eval_AverageEpLen : 213.0\n",
            "Train_AverageReturn : 376.7577209472656\n",
            "Train_StdReturn : 36.17386245727539\n",
            "Train_MaxReturn : 423.44598388671875\n",
            "Train_MinReturn : 307.9637756347656\n",
            "Train_AverageEpLen : 193.27272727272728\n",
            "Train_EnvstepsSoFar : 565730\n",
            "TimeSinceStart : 475.9198844432831\n",
            "Training Loss : 0.02811047062277794\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 275 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2007])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 384.7408447265625\n",
            "Eval_StdReturn : 13.278701782226562\n",
            "Eval_MaxReturn : 398.0195617675781\n",
            "Eval_MinReturn : 371.462158203125\n",
            "Eval_AverageEpLen : 204.5\n",
            "Train_AverageReturn : 351.12957763671875\n",
            "Train_StdReturn : 28.27129554748535\n",
            "Train_MaxReturn : 415.18878173828125\n",
            "Train_MinReturn : 298.49859619140625\n",
            "Train_AverageEpLen : 165.92307692307693\n",
            "Train_EnvstepsSoFar : 567887\n",
            "TimeSinceStart : 477.58472895622253\n",
            "Training Loss : 0.01428015436977148\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 276 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2144])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 318.0852355957031\n",
            "Eval_StdReturn : 11.251976013183594\n",
            "Eval_MaxReturn : 333.253662109375\n",
            "Eval_MinReturn : 306.33575439453125\n",
            "Eval_AverageEpLen : 148.33333333333334\n",
            "Train_AverageReturn : 349.7121276855469\n",
            "Train_StdReturn : 61.75444793701172\n",
            "Train_MaxReturn : 419.064697265625\n",
            "Train_MinReturn : 191.2872314453125\n",
            "Train_AverageEpLen : 178.66666666666666\n",
            "Train_EnvstepsSoFar : 570031\n",
            "TimeSinceStart : 479.2377173900604\n",
            "Training Loss : 0.023801913484930992\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 277 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2097])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 372.0611267089844\n",
            "Eval_StdReturn : 12.030989646911621\n",
            "Eval_MaxReturn : 387.32354736328125\n",
            "Eval_MinReturn : 357.91754150390625\n",
            "Eval_AverageEpLen : 186.0\n",
            "Train_AverageReturn : 360.8192443847656\n",
            "Train_StdReturn : 23.005781173706055\n",
            "Train_MaxReturn : 402.508544921875\n",
            "Train_MinReturn : 324.92083740234375\n",
            "Train_AverageEpLen : 174.75\n",
            "Train_EnvstepsSoFar : 572128\n",
            "TimeSinceStart : 480.9353222846985\n",
            "Training Loss : -0.0014600708382204175\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 278 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2006])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 349.2149963378906\n",
            "Eval_StdReturn : 6.650760650634766\n",
            "Eval_MaxReturn : 357.9676513671875\n",
            "Eval_MinReturn : 341.856689453125\n",
            "Eval_AverageEpLen : 162.66666666666666\n",
            "Train_AverageReturn : 344.3946533203125\n",
            "Train_StdReturn : 36.2881965637207\n",
            "Train_MaxReturn : 392.32525634765625\n",
            "Train_MinReturn : 256.60028076171875\n",
            "Train_AverageEpLen : 167.16666666666666\n",
            "Train_EnvstepsSoFar : 574134\n",
            "TimeSinceStart : 482.5448064804077\n",
            "Training Loss : -0.05880138278007507\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 279 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2006])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 338.8385925292969\n",
            "Eval_StdReturn : 30.289127349853516\n",
            "Eval_MaxReturn : 379.54534912109375\n",
            "Eval_MinReturn : 306.9367370605469\n",
            "Eval_AverageEpLen : 159.33333333333334\n",
            "Train_AverageReturn : 349.3753967285156\n",
            "Train_StdReturn : 32.603912353515625\n",
            "Train_MaxReturn : 392.71820068359375\n",
            "Train_MinReturn : 283.0209045410156\n",
            "Train_AverageEpLen : 167.16666666666666\n",
            "Train_EnvstepsSoFar : 576140\n",
            "TimeSinceStart : 484.1161186695099\n",
            "Training Loss : 0.04971285164356232\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 280 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2021])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 371.7861328125\n",
            "Eval_StdReturn : 23.386930465698242\n",
            "Eval_MaxReturn : 394.4954528808594\n",
            "Eval_MinReturn : 339.6075134277344\n",
            "Eval_AverageEpLen : 184.66666666666666\n",
            "Train_AverageReturn : 370.9138488769531\n",
            "Train_StdReturn : 34.98210144042969\n",
            "Train_MaxReturn : 434.72894287109375\n",
            "Train_MinReturn : 310.8599548339844\n",
            "Train_AverageEpLen : 180.66666666666666\n",
            "Train_EnvstepsSoFar : 578308\n",
            "TimeSinceStart : 485.86295557022095\n",
            "Training Loss : 0.017656151205301285\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 281 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2129])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 342.6307067871094\n",
            "Eval_StdReturn : 5.995490550994873\n",
            "Eval_MaxReturn : 351.089599609375\n",
            "Eval_MinReturn : 337.89739990234375\n",
            "Eval_AverageEpLen : 156.0\n",
            "Train_AverageReturn : 354.7171325683594\n",
            "Train_StdReturn : 44.62831497192383\n",
            "Train_MaxReturn : 404.17291259765625\n",
            "Train_MinReturn : 242.22482299804688\n",
            "Train_AverageEpLen : 177.41666666666666\n",
            "Train_EnvstepsSoFar : 580437\n",
            "TimeSinceStart : 487.553692817688\n",
            "Training Loss : -0.03580348566174507\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 282 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2060])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 342.7955322265625\n",
            "Eval_StdReturn : 24.682422637939453\n",
            "Eval_MaxReturn : 377.1780700683594\n",
            "Eval_MinReturn : 320.38751220703125\n",
            "Eval_AverageEpLen : 160.66666666666666\n",
            "Train_AverageReturn : 354.3775634765625\n",
            "Train_StdReturn : 35.06398010253906\n",
            "Train_MaxReturn : 430.66888427734375\n",
            "Train_MinReturn : 311.7828063964844\n",
            "Train_AverageEpLen : 171.66666666666666\n",
            "Train_EnvstepsSoFar : 582497\n",
            "TimeSinceStart : 489.17854499816895\n",
            "Training Loss : -0.034290436655282974\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 283 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2170])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 354.929443359375\n",
            "Eval_StdReturn : 37.17869567871094\n",
            "Eval_MaxReturn : 407.1675720214844\n",
            "Eval_MinReturn : 323.6367492675781\n",
            "Eval_AverageEpLen : 176.66666666666666\n",
            "Train_AverageReturn : 343.5583190917969\n",
            "Train_StdReturn : 59.364227294921875\n",
            "Train_MaxReturn : 397.70819091796875\n",
            "Train_MinReturn : 171.75148010253906\n",
            "Train_AverageEpLen : 166.92307692307693\n",
            "Train_EnvstepsSoFar : 584667\n",
            "TimeSinceStart : 490.9026174545288\n",
            "Training Loss : 0.015983548015356064\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 284 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2008])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 368.3241271972656\n",
            "Eval_StdReturn : 15.935098648071289\n",
            "Eval_MaxReturn : 383.77838134765625\n",
            "Eval_MinReturn : 346.392578125\n",
            "Eval_AverageEpLen : 177.0\n",
            "Train_AverageReturn : 343.7696838378906\n",
            "Train_StdReturn : 22.534963607788086\n",
            "Train_MaxReturn : 376.011962890625\n",
            "Train_MinReturn : 300.80267333984375\n",
            "Train_AverageEpLen : 166.23076923076923\n",
            "Train_EnvstepsSoFar : 586828\n",
            "TimeSinceStart : 492.61829471588135\n",
            "Training Loss : 0.021847952157258987\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 285 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2002])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 339.17864990234375\n",
            "Eval_StdReturn : 9.8328857421875\n",
            "Eval_MaxReturn : 350.509033203125\n",
            "Eval_MinReturn : 326.53167724609375\n",
            "Eval_AverageEpLen : 161.66666666666666\n",
            "Train_AverageReturn : 329.2774658203125\n",
            "Train_StdReturn : 41.713226318359375\n",
            "Train_MaxReturn : 371.9336242675781\n",
            "Train_MinReturn : 228.27450561523438\n",
            "Train_AverageEpLen : 154.0\n",
            "Train_EnvstepsSoFar : 588830\n",
            "TimeSinceStart : 494.2349042892456\n",
            "Training Loss : -0.04535815492272377\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 286 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2056])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 338.8642272949219\n",
            "Eval_StdReturn : 47.21372985839844\n",
            "Eval_MaxReturn : 401.714599609375\n",
            "Eval_MinReturn : 287.9178466796875\n",
            "Eval_AverageEpLen : 164.33333333333334\n",
            "Train_AverageReturn : 349.173583984375\n",
            "Train_StdReturn : 28.62590789794922\n",
            "Train_MaxReturn : 394.461181640625\n",
            "Train_MinReturn : 291.0549011230469\n",
            "Train_AverageEpLen : 171.33333333333334\n",
            "Train_EnvstepsSoFar : 590886\n",
            "TimeSinceStart : 495.88003182411194\n",
            "Training Loss : -0.02146868035197258\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 287 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2104])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 317.5679626464844\n",
            "Eval_StdReturn : 12.452296257019043\n",
            "Eval_MaxReturn : 334.4440612792969\n",
            "Eval_MinReturn : 304.7724609375\n",
            "Eval_AverageEpLen : 143.66666666666666\n",
            "Train_AverageReturn : 348.80078125\n",
            "Train_StdReturn : 30.365161895751953\n",
            "Train_MaxReturn : 399.7096252441406\n",
            "Train_MinReturn : 287.13494873046875\n",
            "Train_AverageEpLen : 161.84615384615384\n",
            "Train_EnvstepsSoFar : 592990\n",
            "TimeSinceStart : 497.5142366886139\n",
            "Training Loss : -0.012857467867434025\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 288 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2140])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 363.483154296875\n",
            "Eval_StdReturn : 17.39786720275879\n",
            "Eval_MaxReturn : 386.129638671875\n",
            "Eval_MinReturn : 343.83038330078125\n",
            "Eval_AverageEpLen : 168.66666666666666\n",
            "Train_AverageReturn : 349.6052551269531\n",
            "Train_StdReturn : 31.44757843017578\n",
            "Train_MaxReturn : 397.65740966796875\n",
            "Train_MinReturn : 306.36920166015625\n",
            "Train_AverageEpLen : 164.6153846153846\n",
            "Train_EnvstepsSoFar : 595130\n",
            "TimeSinceStart : 499.22191524505615\n",
            "Training Loss : 0.02430851384997368\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 289 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2002])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 321.9595642089844\n",
            "Eval_StdReturn : 69.78514862060547\n",
            "Eval_MaxReturn : 411.30987548828125\n",
            "Eval_MinReturn : 240.98919677734375\n",
            "Eval_AverageEpLen : 165.66666666666666\n",
            "Train_AverageReturn : 344.0322265625\n",
            "Train_StdReturn : 37.11595153808594\n",
            "Train_MaxReturn : 391.1513366699219\n",
            "Train_MinReturn : 273.3815002441406\n",
            "Train_AverageEpLen : 164.46153846153845\n",
            "Train_EnvstepsSoFar : 597268\n",
            "TimeSinceStart : 500.9057776927948\n",
            "Training Loss : 0.006784418132156134\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 290 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2004])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 361.278076171875\n",
            "Eval_StdReturn : 37.47675704956055\n",
            "Eval_MaxReturn : 412.0455322265625\n",
            "Eval_MinReturn : 322.7125549316406\n",
            "Eval_AverageEpLen : 175.66666666666666\n",
            "Train_AverageReturn : 362.1625671386719\n",
            "Train_StdReturn : 36.19336700439453\n",
            "Train_MaxReturn : 421.7900695800781\n",
            "Train_MinReturn : 305.8227233886719\n",
            "Train_AverageEpLen : 182.1818181818182\n",
            "Train_EnvstepsSoFar : 599272\n",
            "TimeSinceStart : 502.5205843448639\n",
            "Training Loss : 0.019561611115932465\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 291 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2030])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 338.6083068847656\n",
            "Eval_StdReturn : 47.01357650756836\n",
            "Eval_MaxReturn : 387.6539306640625\n",
            "Eval_MinReturn : 275.2099304199219\n",
            "Eval_AverageEpLen : 165.66666666666666\n",
            "Train_AverageReturn : 359.1654052734375\n",
            "Train_StdReturn : 28.79874038696289\n",
            "Train_MaxReturn : 414.73272705078125\n",
            "Train_MinReturn : 308.272216796875\n",
            "Train_AverageEpLen : 169.16666666666666\n",
            "Train_EnvstepsSoFar : 601302\n",
            "TimeSinceStart : 504.14968490600586\n",
            "Training Loss : 0.05173354968428612\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 292 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2095])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 353.9598083496094\n",
            "Eval_StdReturn : 12.394157409667969\n",
            "Eval_MaxReturn : 365.1462707519531\n",
            "Eval_MinReturn : 336.68023681640625\n",
            "Eval_AverageEpLen : 168.66666666666666\n",
            "Train_AverageReturn : 365.0647277832031\n",
            "Train_StdReturn : 22.7733154296875\n",
            "Train_MaxReturn : 428.118896484375\n",
            "Train_MinReturn : 340.8610534667969\n",
            "Train_AverageEpLen : 174.58333333333334\n",
            "Train_EnvstepsSoFar : 603397\n",
            "TimeSinceStart : 505.83471512794495\n",
            "Training Loss : -0.031174205243587494\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 293 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2146])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 367.8915100097656\n",
            "Eval_StdReturn : 8.065290451049805\n",
            "Eval_MaxReturn : 379.2940673828125\n",
            "Eval_MinReturn : 361.9453430175781\n",
            "Eval_AverageEpLen : 180.0\n",
            "Train_AverageReturn : 337.0205383300781\n",
            "Train_StdReturn : 59.31674575805664\n",
            "Train_MaxReturn : 388.9968566894531\n",
            "Train_MinReturn : 151.59103393554688\n",
            "Train_AverageEpLen : 165.07692307692307\n",
            "Train_EnvstepsSoFar : 605543\n",
            "TimeSinceStart : 507.5850760936737\n",
            "Training Loss : -0.007854712195694447\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 294 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2043])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 378.3569641113281\n",
            "Eval_StdReturn : 38.30265808105469\n",
            "Eval_MaxReturn : 411.4249267578125\n",
            "Eval_MinReturn : 324.6676025390625\n",
            "Eval_AverageEpLen : 183.33333333333334\n",
            "Train_AverageReturn : 343.0645446777344\n",
            "Train_StdReturn : 24.435100555419922\n",
            "Train_MaxReturn : 391.9665832519531\n",
            "Train_MinReturn : 297.3560791015625\n",
            "Train_AverageEpLen : 170.25\n",
            "Train_EnvstepsSoFar : 607586\n",
            "TimeSinceStart : 509.2580120563507\n",
            "Training Loss : 0.04321887344121933\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 295 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2040])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 359.2735290527344\n",
            "Eval_StdReturn : 23.783302307128906\n",
            "Eval_MaxReturn : 384.955322265625\n",
            "Eval_MinReturn : 327.62298583984375\n",
            "Eval_AverageEpLen : 165.33333333333334\n",
            "Train_AverageReturn : 353.4278564453125\n",
            "Train_StdReturn : 24.256685256958008\n",
            "Train_MaxReturn : 382.78680419921875\n",
            "Train_MinReturn : 312.64739990234375\n",
            "Train_AverageEpLen : 170.0\n",
            "Train_EnvstepsSoFar : 609626\n",
            "TimeSinceStart : 510.877436876297\n",
            "Training Loss : 0.0024974066764116287\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 296 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2133])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 329.637939453125\n",
            "Eval_StdReturn : 50.70806884765625\n",
            "Eval_MaxReturn : 369.9212646484375\n",
            "Eval_MinReturn : 258.1163024902344\n",
            "Eval_AverageEpLen : 162.0\n",
            "Train_AverageReturn : 366.1293640136719\n",
            "Train_StdReturn : 40.135032653808594\n",
            "Train_MaxReturn : 428.0719909667969\n",
            "Train_MinReturn : 285.60223388671875\n",
            "Train_AverageEpLen : 177.75\n",
            "Train_EnvstepsSoFar : 611759\n",
            "TimeSinceStart : 512.5477440357208\n",
            "Training Loss : 0.0525113083422184\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 297 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2045])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 415.2748107910156\n",
            "Eval_StdReturn : 24.363677978515625\n",
            "Eval_MaxReturn : 439.63848876953125\n",
            "Eval_MinReturn : 390.9111328125\n",
            "Eval_AverageEpLen : 207.0\n",
            "Train_AverageReturn : 358.5397033691406\n",
            "Train_StdReturn : 26.623435974121094\n",
            "Train_MaxReturn : 396.276123046875\n",
            "Train_MinReturn : 308.126220703125\n",
            "Train_AverageEpLen : 170.41666666666666\n",
            "Train_EnvstepsSoFar : 613804\n",
            "TimeSinceStart : 514.1384196281433\n",
            "Training Loss : 0.0435006245970726\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 298 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2105])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 343.2364807128906\n",
            "Eval_StdReturn : 56.208221435546875\n",
            "Eval_MaxReturn : 404.5912780761719\n",
            "Eval_MinReturn : 268.7899475097656\n",
            "Eval_AverageEpLen : 167.0\n",
            "Train_AverageReturn : 372.5976867675781\n",
            "Train_StdReturn : 35.24159622192383\n",
            "Train_MaxReturn : 442.9771728515625\n",
            "Train_MinReturn : 318.4493408203125\n",
            "Train_AverageEpLen : 175.41666666666666\n",
            "Train_EnvstepsSoFar : 615909\n",
            "TimeSinceStart : 515.8012166023254\n",
            "Training Loss : -0.012337175197899342\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********** Iteration 299 ************\n",
            "\n",
            "Collecting data to be used for training...\n",
            "\n",
            "Training agent using sampled data from replay buffer...\n",
            "torch.Size([2035])\n",
            "\n",
            "Beginning logging procedure...\n",
            "\n",
            "Collecting data for eval...\n",
            "Eval_AverageReturn : 344.7168273925781\n",
            "Eval_StdReturn : 60.36629867553711\n",
            "Eval_MaxReturn : 401.79412841796875\n",
            "Eval_MinReturn : 261.1984558105469\n",
            "Eval_AverageEpLen : 180.0\n",
            "Train_AverageReturn : 356.180419921875\n",
            "Train_StdReturn : 30.258512496948242\n",
            "Train_MaxReturn : 390.360595703125\n",
            "Train_MinReturn : 297.5968933105469\n",
            "Train_AverageEpLen : 169.58333333333334\n",
            "Train_EnvstepsSoFar : 617944\n",
            "TimeSinceStart : 517.4449374675751\n",
            "Training Loss : 0.056124474853277206\n",
            "Initial_DataCollection_AverageReturn : 9.491950988769531\n",
            "Done logging...\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python cs285/scripts/run_hw2.py \\\n",
        "--env_name Hopper-v2 --ep_len 1000 \\\n",
        "--discount 0.99 -n 300 -l 2 -s 32 -b 2000 -lr 0.001 \\\n",
        "--reward_to_go --nn_baseline --action_noise_std 0.5 --gae_lambda 1 \\\n",
        "--exp_name q5_b2000_r0.001_lambda1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjJlZMc59o7N"
      },
      "source": [
        "##Plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "grCIAL0U9qzz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "outputId": "269fc641-3343-473e-c9ec-5ef569d30853"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-cac133ce-bf38-46f8-bd03-a860e16058d2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Iteration</th>\n",
              "      <th>Config</th>\n",
              "      <th>Train_EnvstepsSoFar</th>\n",
              "      <th>Eval_AverageReturn</th>\n",
              "      <th>Eval_AverageReturn_Smooth</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>b2000_r0.001_lambda0</td>\n",
              "      <td>2003.0</td>\n",
              "      <td>9.813517</td>\n",
              "      <td>9.813517</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>b2000_r0.001_lambda0</td>\n",
              "      <td>4020.0</td>\n",
              "      <td>9.081988</td>\n",
              "      <td>9.290996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>b2000_r0.001_lambda0</td>\n",
              "      <td>6024.0</td>\n",
              "      <td>8.909616</td>\n",
              "      <td>9.046521</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>b2000_r0.001_lambda0</td>\n",
              "      <td>8026.0</td>\n",
              "      <td>14.367980</td>\n",
              "      <td>12.323282</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>b2000_r0.001_lambda0</td>\n",
              "      <td>10034.0</td>\n",
              "      <td>12.645652</td>\n",
              "      <td>12.518705</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1195</th>\n",
              "      <td>295</td>\n",
              "      <td>b2000_r0.001_lambda1</td>\n",
              "      <td>609626.0</td>\n",
              "      <td>359.273529</td>\n",
              "      <td>364.063385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1196</th>\n",
              "      <td>296</td>\n",
              "      <td>b2000_r0.001_lambda1</td>\n",
              "      <td>611759.0</td>\n",
              "      <td>329.637939</td>\n",
              "      <td>343.408118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1197</th>\n",
              "      <td>297</td>\n",
              "      <td>b2000_r0.001_lambda1</td>\n",
              "      <td>613804.0</td>\n",
              "      <td>415.274811</td>\n",
              "      <td>386.528134</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1198</th>\n",
              "      <td>298</td>\n",
              "      <td>b2000_r0.001_lambda1</td>\n",
              "      <td>615909.0</td>\n",
              "      <td>343.236481</td>\n",
              "      <td>360.553142</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1199</th>\n",
              "      <td>299</td>\n",
              "      <td>b2000_r0.001_lambda1</td>\n",
              "      <td>617944.0</td>\n",
              "      <td>344.716827</td>\n",
              "      <td>351.051353</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1200 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cac133ce-bf38-46f8-bd03-a860e16058d2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cac133ce-bf38-46f8-bd03-a860e16058d2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cac133ce-bf38-46f8-bd03-a860e16058d2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      Iteration  ... Eval_AverageReturn_Smooth\n",
              "0             0  ...                  9.813517\n",
              "1             1  ...                  9.290996\n",
              "2             2  ...                  9.046521\n",
              "3             3  ...                 12.323282\n",
              "4             4  ...                 12.518705\n",
              "...         ...  ...                       ...\n",
              "1195        295  ...                364.063385\n",
              "1196        296  ...                343.408118\n",
              "1197        297  ...                386.528134\n",
              "1198        298  ...                360.553142\n",
              "1199        299  ...                351.051353\n",
              "\n",
              "[1200 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ],
      "source": [
        "data_q5 = read_data('','Hopper-v2',5)\n",
        "data_q5"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=figsize)\n",
        "sns.lineplot(data=data_q5, x='Iteration', y='Eval_AverageReturn_Smooth', hue='Config')\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "VarUD2wM9wQD",
        "outputId": "a10e2af3-a3fa-4937-cc0e-e044f318962f"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fa49e19fcd0>"
            ]
          },
          "metadata": {},
          "execution_count": 95
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x216 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "km7LlYvhqKTl"
      },
      "outputs": [],
      "source": [
        "#@markdown You can visualize your runs with tensorboard from within the notebook\n",
        "\n",
        "## requires tensorflow==2.3.0\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir /content/cs285_f2021/homework_fall2021/hw2/data"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "hw2_colab_MCO.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}